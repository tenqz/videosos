[
  {
    "id": "fal-ai/flux-pro/kontext",
    "title": "FLUX.1 Kontext [pro]",
    "category": "image-to-image",
    "description": "FLUX.1 Kontext [pro] handles both text and reference images as inputs, seamlessly enabling targeted, local edits and complex transformations of entire scenes.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Put a donut next to the flour."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/fal__toolkit__image__image__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/wan-effects",
    "title": "Wan Effects",
    "category": "image-to-video",
    "description": "Wan Effects generates high-quality videos with popular effects from images",
    "tags": [
      "motion",
      "effects"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_012.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "effect_type": {
        "type": "string",
        "description": "The type of effect to apply to the video.",
        "required": false,
        "enum": [
          "squish",
          "muscle",
          "inflate",
          "crush",
          "rotate",
          "gun-shooting",
          "deflate",
          "cakeify",
          "hulk",
          "baby",
          "bride",
          "classy",
          "puppy",
          "snow-white",
          "disney-princess",
          "mona-lisa",
          "painting",
          "pirate-captain",
          "princess",
          "jungle",
          "samurai",
          "vip",
          "warrior",
          "zen",
          "assassin",
          "timelapse",
          "tsunami",
          "fire",
          "zoom-call",
          "doom-fps",
          "fus-ro-dah",
          "hug-jesus",
          "robot-face-reveal",
          "super-saiyan",
          "jumpscare",
          "laughing",
          "cartoon-jaw-drop",
          "crying",
          "kissing",
          "angry-face",
          "selfie-younger-self",
          "animeify",
          "blast"
        ],
        "default": "cakeify"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the output video.",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "subject": {
        "type": "string",
        "description": "The subject to insert into the predefined prompt template for the selected effect.",
        "required": true,
        "examples": [
          "a cute kitten",
          "Donald Trump",
          "a tank",
          "a ceramic vase"
        ]
      },
      "lora_scale": {
        "type": "number",
        "description": "The scale of the LoRA weight. Used to adjust effect intensity.",
        "required": false,
        "minimum": 0.1,
        "maximum": 2,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan-effects/cat.jpg",
          "https://storage.googleapis.com/falserverless/web-examples/wan-effects/man_1.png",
          "https://storage.googleapis.com/falserverless/web-examples/wan-effects/woman_2.png"
        ]
      },
      "turbo_mode": {
        "type": "boolean",
        "description": "Whether to use turbo mode. If True, the video will be generated faster but with lower quality.",
        "required": false,
        "default": false
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate.",
        "required": false,
        "minimum": 81,
        "maximum": 100,
        "default": 81
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": ""
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/wan-pro/image-to-video",
    "title": "Wan-2.1 Pro Image-to-Video",
    "category": "image-to-video",
    "description": "Wan-2.1 Pro is a premium image-to-video model that generates high-quality 1080p videos at 30fps with up to 6 seconds duration, delivering exceptional visual quality and motion diversity from images",
    "tags": [
      "image to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/wan-pro-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker",
        "required": false,
        "default": true
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate the video from",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo2/image-to-video",
    "title": "Veo 2 (Image to Video)",
    "category": "image-to-video",
    "description": "Veo 2 creates videos from images with realistic motion and very high quality output.",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/veo2-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo2/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo2/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing how the image should be animated",
        "required": true,
        "examples": [
          "A lego chef cooking eggs"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5s",
          "6s",
          "7s",
          "8s"
        ],
        "default": "5s"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "auto_prefer_portrait",
          "16:9",
          "9:16"
        ],
        "default": "auto"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to animate. Should be 720p or higher resolution.",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/6fq8JDSjb1osE_c3J_F2H.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/image-to-video",
    "title": "Kling 1.6",
    "category": "image-to-video",
    "description": "Generate video clips from your images using Kling 1.6 (pro)",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kling-1-6-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Snowflakes fall as a car moves along the road."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "tail_image_url": {
        "type": "string",
        "description": "URL of the image to be used for the end of the video",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/playai/tts/dialog",
    "title": "PlayAI Text-to-Speech Dialog",
    "category": "text-to-audio",
    "description": "Generate natural-sounding multi-speaker dialogues, and audio. Perfect for expressive outputs, storytelling, games, animations, and interactive media.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/playai/tts/dialog",
    "documentationUrl": "https://fal.ai/models/fal-ai/playai/tts/dialog/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "response_format": {
        "type": "string",
        "description": "The format of the response.",
        "required": false,
        "enum": [
          "url",
          "bytes"
        ],
        "default": "url"
      },
      "input": {
        "type": "string",
        "description": "The dialogue text with turn prefixes to distinguish speakers.",
        "required": true,
        "minLength": 1,
        "examples": [
          "Speaker 1: Hey, did you catch the game last night?\nSpeaker 2: Of course! What a match—it had me on the edge of my seat.\nSpeaker 1: Same here! That last-minute goal was unreal. Who's your MVP?\nSpeaker 2: Gotta be the goalie. Those saves were unbelievable.\nSpeaker 1: Absolutely. Saved the day, literally! Are you planning to watch the next game?\nSpeaker 2: Oh, you bet. I’m already stocked up on snacks!\n"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "An integer number greater than or equal to 0. If equal to null or not provided, a random seed will be used. Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file.",
        "required": false,
        "minimum": 0,
        "examples": [
          null
        ]
      },
      "voices": {
        "type": "array",
        "description": "A list of voice definitions for each speaker in the dialogue. Must be between 1 and 2 voices.",
        "required": false,
        "default": [
          {
            "voice": "Jennifer (English (US)/American)",
            "turn_prefix": "Speaker 1: "
          },
          {
            "voice": "Furio (English (IT)/Italian)",
            "turn_prefix": "Speaker 2: "
          }
        ],
        "items": {
          "$ref": "#/components/schemas/LDMVoiceInput"
        }
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1.1-ultra",
    "title": "FLUX1.1 [pro] ultra",
    "category": "text-to-image",
    "description": "FLUX1.1 [pro] ultra is the newest version of FLUX1.1 [pro], maintaining professional-grade image quality while delivering up to 2K resolution with improved photo realism.",
    "tags": [
      "high-res",
      "realism"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-pro-v1-1-ultra.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1-ultra",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1-ultra/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": null,
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "default": "16:9"
      },
      "raw": {
        "type": "boolean",
        "description": "Generate less processed, more natural-looking images.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from.",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_prompt_strength": {
        "type": "number",
        "description": "The strength of the image prompt, between 0 and 1.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/recraft/v3/text-to-image",
    "title": "Recraft V3",
    "category": "text-to-image",
    "description": "Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more. As of today, it is SOTA in image generation, proven by Hugging Face's industry-leading Text-to-Image Benchmark by Artificial Analysis.",
    "tags": [
      "vector",
      "typography",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-v3.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/v3/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft/v3/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 1000,
        "examples": [
          "a red panda eating a bamboo in front of a poster that says \"recraft V3 now available at fal\""
        ]
      },
      "image_size": {
        "type": null,
        "description": "",
        "required": false,
        "default": "square_hd"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated images. Vector images cost 2X as much.",
        "required": false,
        "enum": [
          "any",
          "realistic_image",
          "digital_illustration",
          "vector_illustration",
          "realistic_image/b_and_w",
          "realistic_image/hard_flash",
          "realistic_image/hdr",
          "realistic_image/natural_light",
          "realistic_image/studio_portrait",
          "realistic_image/enterprise",
          "realistic_image/motion_blur",
          "realistic_image/evening_light",
          "realistic_image/faded_nostalgia",
          "realistic_image/forest_life",
          "realistic_image/mystic_naturalism",
          "realistic_image/natural_tones",
          "realistic_image/organic_calm",
          "realistic_image/real_life_glow",
          "realistic_image/retro_realism",
          "realistic_image/retro_snapshot",
          "realistic_image/urban_drama",
          "realistic_image/village_realism",
          "realistic_image/warm_folk",
          "digital_illustration/pixel_art",
          "digital_illustration/hand_drawn",
          "digital_illustration/grain",
          "digital_illustration/infantile_sketch",
          "digital_illustration/2d_art_poster",
          "digital_illustration/handmade_3d",
          "digital_illustration/hand_drawn_outline",
          "digital_illustration/engraving_color",
          "digital_illustration/2d_art_poster_2",
          "digital_illustration/antiquarian",
          "digital_illustration/bold_fantasy",
          "digital_illustration/child_book",
          "digital_illustration/child_books",
          "digital_illustration/cover",
          "digital_illustration/crosshatch",
          "digital_illustration/digital_engraving",
          "digital_illustration/expressionism",
          "digital_illustration/freehand_details",
          "digital_illustration/grain_20",
          "digital_illustration/graphic_intensity",
          "digital_illustration/hard_comics",
          "digital_illustration/long_shadow",
          "digital_illustration/modern_folk",
          "digital_illustration/multicolor",
          "digital_illustration/neon_calm",
          "digital_illustration/noir",
          "digital_illustration/nostalgic_pastel",
          "digital_illustration/outline_details",
          "digital_illustration/pastel_gradient",
          "digital_illustration/pastel_sketch",
          "digital_illustration/pop_art",
          "digital_illustration/pop_renaissance",
          "digital_illustration/street_art",
          "digital_illustration/tablet_sketch",
          "digital_illustration/urban_glow",
          "digital_illustration/urban_sketching",
          "digital_illustration/vanilla_dreams",
          "digital_illustration/young_adult_book",
          "digital_illustration/young_adult_book_2",
          "vector_illustration/bold_stroke",
          "vector_illustration/chemistry",
          "vector_illustration/colored_stencil",
          "vector_illustration/contour_pop_art",
          "vector_illustration/cosmics",
          "vector_illustration/cutout",
          "vector_illustration/depressive",
          "vector_illustration/editorial",
          "vector_illustration/emotional_flat",
          "vector_illustration/infographical",
          "vector_illustration/marker_outline",
          "vector_illustration/mosaic",
          "vector_illustration/naivector",
          "vector_illustration/roundish_flat",
          "vector_illustration/segmented_colors",
          "vector_illustration/sharp_contrast",
          "vector_illustration/thin",
          "vector_illustration/vector_photo",
          "vector_illustration/vivid_shapes",
          "vector_illustration/engraving",
          "vector_illustration/line_art",
          "vector_illustration/line_circuit",
          "vector_illustration/linocut"
        ],
        "default": "realistic_image"
      },
      "colors": {
        "type": "array",
        "description": "An array of preferable colors",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/RGBColor"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "style_id": {
        "type": "string",
        "description": "The ID of the custom style reference (optional)",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01/image-to-video",
    "title": "MiniMax (Hailuo AI) Video 01",
    "category": "image-to-video",
    "description": "Generate video clips from your images using MiniMax Video model",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/minimax-video-01-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/pro/image-to-video",
    "title": "MiniMax Hailuo 2.3 [Pro] (Image to Video)",
    "category": "image-to-video",
    "description": "MiniMax Hailuo-2.3 Image To Video API (Pro, 1080p): Advanced image-to-video generation model with 1080p resolution",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/0iV7vFj9ujGqHUqKkBesN_a65fac7d7c994f39aeedabe31db6fb2d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "The camera follows the mountain biker as they navigate a technical forest trail at high speed, wheels bouncing over roots and rocks. The rider approaches a jump, launching into the air with the bike, both rider and machine perfectly synchronized. They land smoothly and continue through tight turns, splashing through a stream crossing. Mud and water spray as the bike powers through challenging terrain. The atmosphere is wild and adventurous. Audio: Tires gripping dirt, gears shifting, heavy breathing, branches whipping past, and water splashing."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/pro_i2v_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/wan-25-preview/image-to-video",
    "title": "Wan 2.5 Image to Video",
    "category": "image-to-video",
    "description": "Wan 2.5 image-to-video model.",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/rabbit/jryVrAZdQNdLdN_4rTlN7_9bebc94cb69a482fb4d948bdd06d6a5e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-25-preview/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-25-preview/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the desired video motion. Max 800 characters.",
        "required": true,
        "minLength": 1,
        "examples": [
          "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution. Valid values: 480p, 720p, 1080p",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the generated video in seconds. Choose between 5 or 10 seconds.",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5",
        "examples": [
          "5",
          "10"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame. Must be publicly accessible or base64 data URI.\n\nMax file size: 25.0MB, Min width: 360px, Min height: 360px, Max width: 2000px, Max height: 2000px, Timeout: 20.0s",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5 or 10 seconds),\nthe audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt rewriting using LLM.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to describe content to avoid. Max 500 characters.",
        "required": false,
        "examples": [
          "low resolution, error, worst quality, low quality, defects"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "actual_prompt": {
        "type": "string",
        "description": "The actual prompt used if prompt rewriting was enabled"
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.5-turbo/pro/image-to-video",
    "title": "Kling Video",
    "category": "image-to-video",
    "description": "Kling 2.5 Turbo Pro: Top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/rabbit/2KNBk1qkmEBXK0FLgfHCl_ee4bb1ada254433bbab296893a8636e3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.5-turbo/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.5-turbo/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A stark starting line divides two powerful cars, engines revving for the challenge ahead. They surge forward in the heat of competition, a blur of speed and chrome. The finish line looms as they vie for victory."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/HnY2yf-BbzlrVQxR-qP6m_9912d0932988453aadf3912fc1901f52.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.5-turbo/pro/text-to-video",
    "title": "Kling v2.5 Text to Video",
    "category": "text-to-video",
    "description": "Kling 2.5 Turbo Pro: Top-tier text-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "tags": [
      "animation",
      "stylized"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/panda/6YaK9lV7ySsUA9I3dUp5r_8a807b0c8e2641db9e345107ab8a809e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.5-turbo/pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.5-turbo/pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A noble lord walks among his people, his presence a comforting reassurance. He greets them with a gentle smile, embodying their hopes and earning their respect through simple interactions. The atmosphere is intimate and sincere, highlighting the bond between the leader and community."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/flux-krea-trainer",
    "title": "Train Flux Krea LoRA",
    "category": "training",
    "description": "Train styles, people and other subjects at blazing speeds using the FLUX.1 Krea [dev] base model.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/rabbit/uKINGMekBEYrVNUULujts_RVU-Kvlhsr5rEwqG7Uc-s_56e80afe7c1243d5a2f5eed5868ae63d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-krea-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-krea-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "images_data_url": {
        "type": "string",
        "description": "\n        URL to zip archive with images. Try to use at least 4 images in general the more the better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n    ",
        "required": true
      },
      "is_input_format_already_preprocessed": {
        "type": "boolean",
        "description": "Specifies whether the input data is already in a processed format. When set to False (default), the system expects raw input where image files and their corresponding caption files share the same name (e.g., 'photo.jpg' and 'photo.txt'). Set to True if your data is already in a preprocessed format.",
        "required": false,
        "default": false
      },
      "trigger_word": {
        "type": "string",
        "description": "Trigger word to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_word will be used instead of captions. If captions are the trigger word will not be used.\n        ",
        "required": false
      },
      "steps": {
        "type": "integer",
        "description": "Number of steps to train the LoRA on.",
        "required": false,
        "minimum": 1,
        "maximum": 10000,
        "examples": [
          1000
        ]
      },
      "data_archive_format": {
        "type": "string",
        "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
        "required": false
      },
      "is_style": {
        "type": "boolean",
        "description": "If True, the training will be for a style. This will deactivate segmentation, captioning and will use trigger word instead. Use the trigger word to specify the style.",
        "required": false,
        "default": false
      },
      "create_masks": {
        "type": "boolean",
        "description": "If True segmentation masks will be used in the weight the training loss. For people a face mask is used if possible.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "config_file": {
        "type": null,
        "description": "URL to the training configuration file."
      },
      "debug_preprocessed_output": {
        "type": null,
        "description": "URL to the preprocessed images."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "URL to the trained diffusers lora weights."
      }
    }
  },
  {
    "id": "fal-ai/veo3/fast",
    "title": "Veo 3 Fast",
    "category": "text-to-video",
    "description": "Faster and more cost effective version of Google's Veo 3! ",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "examples": [
          "A casual street interview on a busy New York City sidewalk in the afternoon. The interviewer holds a plain, unbranded microphone and asks: Have you seen Google's new Veo3 model It is a super good model. Person replies: Yeah I saw it, it's already available on fal. It's crazy good."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "4s",
          "6s",
          "8s"
        ],
        "default": "8s"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
        "required": false,
        "enum": [
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "16:9"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "auto_fix": {
        "type": "boolean",
        "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "A seed to use for the video generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the video generation",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the video generation",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "bria/video/background-removal",
    "title": "Video",
    "category": "video-to-video",
    "description": "Automatically remove backgrounds from videos -perfect for creating clean, professional content without a green screen.",
    "tags": [
      "background-removal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/bria/video/background-removal",
    "documentationUrl": "https://fal.ai/models/bria/video/background-removal/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "Input video to remove background from. Size should be less than 14142x14142 and duration less than 30s.",
        "required": true,
        "examples": [
          "https://bria-datasets.s3.us-east-1.amazonaws.com/rmbg_tests/videos/5586521-uhd_3840_2160_25fps_original.mp4"
        ]
      },
      "output_container_and_codec": {
        "type": "string",
        "description": "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, mov_h265, mov_proresks, mkv_h265, mkv_h264, mkv_vp9, gif.",
        "required": false,
        "enum": [
          "mp4_h265",
          "mp4_h264",
          "webm_vp9",
          "mov_h265",
          "mov_proresks",
          "mkv_h265",
          "mkv_h264",
          "mkv_vp9",
          "gif"
        ],
        "default": "webm_vp9"
      },
      "background_color": {
        "type": "string",
        "description": "Background color. Options: Transparent, Black, White, Gray, Red, Green, Blue, Yellow, Cyan, Magenta, Orange.",
        "required": false,
        "enum": [
          "Transparent",
          "Black",
          "White",
          "Gray",
          "Red",
          "Green",
          "Blue",
          "Yellow",
          "Cyan",
          "Magenta",
          "Orange"
        ],
        "default": "Black"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "Video with removed background and audio."
      }
    }
  },
  {
    "id": "fal-ai/flux-kontext-trainer",
    "title": "Flux Kontext Trainer",
    "category": "training",
    "description": "LoRA trainer for FLUX.1 Kontext [dev]",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/monkey/pYXiffttc2Skv36wflufu_dec4efe0d27e4527b64acfbc0e91536a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-kontext-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-kontext-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "steps": {
        "type": "integer",
        "description": "Number of steps to train for",
        "required": false,
        "minimum": 2,
        "maximum": 10000,
        "default": 1000
      },
      "image_data_url": {
        "type": "string",
        "description": "\n        URL to the input data zip archive.\n\n        The zip should contain pairs of images. The images should be named:\n\n        ROOT_start.EXT and ROOT_end.EXT\n        For example:\n        photo_start.jpg and photo_end.jpg\n\n        The zip can also contain a text file for each image pair. The text file should be named:\n        ROOT.txt\n        For example:\n        photo.txt\n\n        This text file can be used to specify the edit instructions for the image pair.\n\n        If no text file is provided, the default_caption will be used.\n\n        If no default_caption is provided, the training will fail.\n        ",
        "required": true
      },
      "learning_rate": {
        "type": "number",
        "description": "",
        "required": false,
        "default": 0.0001
      },
      "default_caption": {
        "type": "string",
        "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
        "required": false
      },
      "output_lora_format": {
        "type": "string",
        "description": "Dictates the naming scheme for the output weights",
        "required": false,
        "enum": [
          "fal",
          "comfy"
        ],
        "default": "fal"
      }
    },
    "outputParameters": {
      "config_file": {
        "type": null,
        "description": "URL to the configuration file for the trained model."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "URL to the trained diffusers lora weights."
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/standard/image-to-video",
    "title": "MiniMax Hailuo 02 [Standard] (Image to Video)",
    "category": "image-to-video",
    "description": "MiniMax Hailuo-02 Image To Video API (Standard, 768p, 512p): Advanced image-to-video generation model with 768p and 512p resolutions",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "Man walked into winter cave with polar bear"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
        "required": false,
        "enum": [
          "6",
          "10"
        ],
        "default": "6"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video.",
        "required": false,
        "enum": [
          "512P",
          "768P"
        ],
        "default": "768P"
      },
      "end_image_url": {
        "type": "string",
        "description": "Optional URL of the image to use as the last frame of the video",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/standard/text-to-video",
    "title": "MiniMax Hailuo 02 [Standard] (Text to Video)",
    "category": "text-to-video",
    "description": "MiniMax Hailuo-02 Text To Video API (Standard, 768p): Advanced video generation model with 768p resolution",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/standard/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/standard/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "A Galactic Smuggler is a rogue figure with a cybernetic arm and a well-worn coat that hints at many dangerous escapades across the galaxy. Their ship is filled with rare and exotic treasures from distant planets, concealed in hidden compartments, showing their expertise in illicit trade. Their belt is adorned with energy-based weapons, ready to be drawn at any moment to protect themselves or escape from tight situations. This character thrives in the shadows of space, navigating between the law and chaos with stealth and wit, always seeking the next big score while evading bounty hunters and law enforcement. The rogue's ship, rugged yet efficient, serves as both a home and a tool for their dangerous lifestyle. The treasures they collect reflect the diverse and intriguing worlds they've encountered—alien artifacts, rare minerals, and artifacts of unknown origin. Their reputation precedes them, with whispers of their dealings and the deadly encounters that often follow. A master of negotiation and deception, the Galactic Smuggler navigates the cosmos with an eye on the horizon, always one step ahead of those who pursue them."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
        "required": false,
        "enum": [
          "6",
          "10"
        ],
        "default": "6"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "bria/text-to-image/3.2",
    "title": "Bria 3.2 Text-to-Image",
    "category": "text-to-image",
    "description": "Bria’s Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use. Excels in Text-Rendering and Aesthetics.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/EZR7hDbrO6DQ_MP-BYQPt_8bb97804d8fc4f21863b457a061b5f8a.jpg",
    "playgroundUrl": "https://fal.ai/models/bria/text-to-image/3.2",
    "documentationUrl": "https://fal.ai/models/bria/text-to-image/3.2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt for image generation.",
        "required": true,
        "examples": [
          "Oil painting of a fluffy, wide-eyed cat sitting upright, holding a small wooden sign reading “Feed Me.” Rich textures, dramatic brushstrokes, warm tones, and vintage charm."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9",
        "required": false,
        "enum": [
          "1:1",
          "2:3",
          "3:2",
          "3:4",
          "4:3",
          "4:5",
          "5:4",
          "9:16",
          "16:9"
        ],
        "default": "1:1"
      },
      "prompt_enhancer": {
        "type": "boolean",
        "description": "Whether to improve the prompt.",
        "required": false,
        "default": true
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If true, returns the image directly in the response (increases latency).",
        "required": false,
        "default": false
      },
      "truncate_prompt": {
        "type": "boolean",
        "description": "Whether to truncate the prompt.",
        "required": false,
        "default": true
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for text.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility.",
        "required": false,
        "default": 5555
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for image generation.",
        "required": false,
        "default": "Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers"
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Generated image."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/image-to-video",
    "title": "Seedance 1.0 Pro",
    "category": "image-to-video",
    "description": "Seedance 1.0 Pro, a high quality video generation model developed by Bytedance.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "A skier glides over fresh snow, joyously smiling while kicking up large clouds of snow as he turns. Accelerating gradually down the slope, the camera moves smoothly alongside."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16",
          "auto"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image used to generate video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/seedance_pro_i2v_img.jpg"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "end_image_url": {
        "type": "string",
        "description": "The URL of the image the video ends with. Defaults to None.",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/imagen4/preview/fast",
    "title": "Imagen 4",
    "category": "text-to-image",
    "description": "Google’s highest quality image generation model",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imagen4/preview/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/imagen4/preview/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing what you want to see",
        "required": true,
        "examples": [
          "Atmospheric narrative illustration depicting a young woman with dark hair styled with a single star clip, eating dumplings at a small round table in a bustling, late-night eatery reminiscent of a vintage Hong Kong diner. The style blends clean linework with textured color fields, evoking a sense of place and story. The mood is intimate contentment amidst vibrant surroundings. Soft, warm overhead lighting from unseen hanging lamps casts gentle highlights on her face and the porcelain plate of dumplings, creating soft-edged shadows on the tiled tabletop and floor. The background features detailed elements like wall menus with stylized illustrations, a retro wall clock, steam rising from a soup bowl, and glimpses of other patrons blurred slightly for depth. The woman, viewed from a slightly high angle, crouches slightly on her chair, intensely focused on her food, rendered with expressive linework defining her pose and features. The color palette mixes muted teal wall tiles and green chairs with pops of warm yellow in her top, pink trousers, red chili oil dish, and ambient light, creating a cozy yet lively feel. Subtle paper texture or digital grain is visible throughout. Focus is sharp on the character and her immediate table setting"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "3:4",
          "4:3"
        ],
        "default": "1:1"
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-4)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A description of what to discourage in the generated images",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/veo3",
    "title": "Veo 3",
    "category": "text-to-video",
    "description": "Veo 3 by Google, the most advanced AI video generation model in the world. With sound on!",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "examples": [
          "A casual street interview on a busy New York City sidewalk in the afternoon. The interviewer holds a plain, unbranded microphone and asks: Have you seen Google's new Veo3 model It is a super good model. Person replies: Yeah I saw it, it's already available on fal. It's crazy good."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "4s",
          "6s",
          "8s"
        ],
        "default": "8s"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
        "required": false,
        "enum": [
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "16:9"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "auto_fix": {
        "type": "boolean",
        "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "A seed to use for the video generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the video generation",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the video generation",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/master/image-to-video",
    "title": "Kling 2.1 Master",
    "category": "image-to-video",
    "description": "Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.\n\n",
    "tags": [
      "_marquee-video-model"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/master/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/master/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Sunlight dapples through budding branches, illuminating a vibrant tapestry of greens and browns as a pair of robins meticulously weave twigs and mud into a cradle of life, their tiny forms a whirlwind of activity against a backdrop of blossoming spring.  The scene unfolds with a gentle, observational pace, allowing the viewer to fully appreciate the intricate details of nest construction, the soft textures of downy feathers contrasted against the rough bark of the branches, the delicate balance of strength and fragility in their creation."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/9Nrm22YyLojSTPJbZYNhh_image.webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/standard/image-to-video",
    "title": "Kling 2.1 (standard)",
    "category": "image-to-video",
    "description": "Kling 2.1 Standard is a cost-efficient endpoint for the Kling 2.1 model, delivering high-quality image-to-video generation \n\n",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/elephant/5Yt8D9tl-IaGQ-6czSXL1_HHQ_VCby6xP_DFLkQQLpV_3c8622214c4c4ac29b4b64e157746507.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/kling/kling-image-to-video.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/imagen4/preview",
    "title": "Imagen 4",
    "category": "text-to-image",
    "description": "Google’s highest quality image generation model",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imagen4/preview",
    "documentationUrl": "https://fal.ai/models/fal-ai/imagen4/preview/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing what you want to see",
        "required": true,
        "examples": [
          "Capture an intimate close-up bathed in warm, soft, late-afternoon sunlight filtering into a quintessential 1960s kitchen. The focal point is a charmingly designed vintage package of all-purpose flour, resting invitingly on a speckled Formica countertop. The packaging itself evokes pure nostalgia: perhaps thick, slightly textured paper in a warm cream tone, adorned with simple, bold typography (a friendly serif or script) in classic red and blue \"ALL-PURPOSE FLOUR\", featuring a delightful illustration like a stylized sheaf of wheat or a cheerful baker character. In smaller bold print at the bottom of the package: \"NET WT 5 LBS (80 OZ) 2.27kg\". Focus sharply on the package details – the slightly soft edges of the paper bag, the texture of the vintage printing, the inviting \"All-Purpose Flour\" text. Subtle hints of the 1960s kitchen frame the shot – the chrome edge of the counter gleaming softly, a blurred glimpse of a pastel yellow ceramic tile backsplash, or the corner of a vintage metal canister set just out of focus. The shallow depth of field keeps attention locked on the beautifully designed package, creating an aesthetic rich in warmth, authenticity, and nostalgic appeal."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "3:4",
          "4:3"
        ],
        "default": "1:1"
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-4)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "resolution": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "1K",
          "2K"
        ],
        "default": "1K"
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A description of what to discourage in the generated images",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2/master/image-to-video",
    "title": "Kling 2.0 Master",
    "category": "image-to-video",
    "description": "Generate video clips from your images using Kling 2.0 Master",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2/master/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2/master/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "slow-motion sequence captures the catastrophic implosion of a skyscraper, dust and debris billowing outwards in a chaotic ballet of destruction, while a haunting, orchestral score underscores the sheer power and finality of the event."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/rkH-9qoXtXu3rAYTsx9V5_image.webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2/master/text-to-video",
    "title": "Kling 2.0 Master",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 2.0 Master",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2/master/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2/master/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A slow-motion drone shot descending from above a maze of neon-lit Tokyo alleyways at night during heavy rainfall. The camera gradually focuses on a lone figure in a luminescent white raincoat standing perfectly still amid the bustling crowd, all carrying black umbrellas. As the camera continues its downward journey, we see the raindrops creating rippling patterns on puddles that reflect the kaleidoscope of colors from the surrounding signs, creating a mirror world beneath the city."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/hidream-i1-full",
    "title": "Hidream I1 Full",
    "category": "text-to-image",
    "description": "HiDream-I1 full is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/monkey/HzdkkAoX8-PqrYZUV0zOW_1efb1b99d0e84ce78dd35e8edc69fe09.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hidream-i1-full",
    "documentationUrl": "https://fal.ai/models/fal-ai/hidream-i1-full/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "a cat holding a skateboard which has 'fal' written on it in red spray paint"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {}
  },
  {
    "id": "fal-ai/hidream-i1-dev",
    "title": "Hidream I1 Dev",
    "category": "text-to-image",
    "description": "HiDream-I1 dev is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hidream-i1-dev",
    "documentationUrl": "https://fal.ai/models/fal-ai/hidream-i1-dev/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "a cat holding a skateboard which has 'fal' written on it in red spray paint"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hidream-i1-fast",
    "title": "Hidream I1 Fast",
    "category": "text-to-image",
    "description": "HiDream-I1 fast is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within 16 steps.",
    "tags": [
      ""
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/Ua1DJkXRU7nz46GKt6x5R_7b333b5e26bd413aa5d65d1959878828.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hidream-i1-fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/hidream-i1-fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "a cat holding a skateboard which has 'fal' written on it in red spray paint"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux/dev",
    "title": "FLUX.1 [dev]",
    "category": "text-to-image",
    "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text. It is suitable for personal and commercial use.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/dev",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/dev/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/wan-i2v",
    "title": "Wan-2.1 Image-to-Video",
    "category": "image-to-video",
    "description": "Wan-2.1 is a image-to-video model that generates high-quality videos with high visual quality and motion diversity from images",
    "tags": [
      "image to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-i2v",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-i2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Cars racing in slow motion"
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 81,
        "maximum": 100,
        "default": 81
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      },
      "guide_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/flux-lora-fast-training",
    "title": "Train Flux LoRA",
    "category": "training",
    "description": "Train styles, people and other subjects at blazing speeds.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/video-training.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-fast-training",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-fast-training/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "images_data_url": {
        "type": "string",
        "description": "\n        URL to zip archive with images. Try to use at least 4 images in general the more the better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n    ",
        "required": true
      },
      "is_input_format_already_preprocessed": {
        "type": "boolean",
        "description": "Specifies whether the input data is already in a processed format. When set to False (default), the system expects raw input where image files and their corresponding caption files share the same name (e.g., 'photo.jpg' and 'photo.txt'). Set to True if your data is already in a preprocessed format.",
        "required": false,
        "default": false
      },
      "trigger_word": {
        "type": "string",
        "description": "Trigger word to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_word will be used instead of captions. If captions are the trigger word will not be used.\n        ",
        "required": false
      },
      "steps": {
        "type": "integer",
        "description": "Number of steps to train the LoRA on.",
        "required": false,
        "minimum": 1,
        "maximum": 10000,
        "examples": [
          1000
        ]
      },
      "data_archive_format": {
        "type": "string",
        "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
        "required": false
      },
      "is_style": {
        "type": "boolean",
        "description": "If True, the training will be for a style. This will deactivate segmentation, captioning and will use trigger word instead. Use the trigger word to specify the style.",
        "required": false,
        "default": false
      },
      "create_masks": {
        "type": "boolean",
        "description": "If True segmentation masks will be used in the weight the training loss. For people a face mask is used if possible.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "config_file": {
        "type": null,
        "description": "URL to the training configuration file."
      },
      "debug_preprocessed_output": {
        "type": null,
        "description": "URL to the preprocessed images."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "URL to the trained diffusers lora weights."
      }
    }
  },
  {
    "id": "fal-ai/mmaudio-v2",
    "title": "MMAudio V2",
    "category": "video-to-video",
    "description": "MMAudio generates synchronized audio given video and/or text inputs. It can be combined with video models to get videos with audio.",
    "tags": [
      "ai video",
      "fast"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/mmaudio-v2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/mmaudio-v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/mmaudio-v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the audio for.",
        "required": true,
        "examples": [
          "Indian holy music"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate the audio for.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/mmaudio_input.mp4"
        ]
      },
      "num_steps": {
        "type": "integer",
        "description": "The number of steps to generate the audio for.",
        "required": false,
        "minimum": 4,
        "maximum": 50,
        "default": 25
      },
      "duration": {
        "type": "number",
        "description": "The duration of the audio to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 8
      },
      "cfg_strength": {
        "type": "number",
        "description": "The strength of Classifier Free Guidance.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4.5
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false,
        "minimum": 0,
        "maximum": 65535
      },
      "mask_away_clip": {
        "type": "boolean",
        "description": "Whether to mask away the clip.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate the audio for.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with the lip sync."
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2",
    "title": "Ideogram V2",
    "category": "text-to-image",
    "description": "Generate high-quality images, posters, and logos with Ideogram V2. Features exceptional typography handling and realistic outputs optimized for commercial and creative use.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/8WNQdDJ1eYpnl12jwhCjT_c9879f96533a47ae82e07946a67b0c8c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to avoid in the generated image",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/flux-lora-portrait-trainer",
    "title": "Train Flux LoRAs For Portraits",
    "category": "training",
    "description": "FLUX LoRA training optimized for portrait generation, with bright highlights, excellent prompt following and highly detailed results.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/kh3cW2FXV5m3jigGYxcVU_3657df3e2e324e628af565129148736d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-portrait-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-portrait-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "images_data_url": {
        "type": "string",
        "description": "\n        URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n\n        The captions can include a special string `[trigger]`. If a trigger_word is specified, it will replace `[trigger]` in the captions.\n    ",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "Trigger phrase to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_work will be used instead of captions. If captions are provided, the trigger word will replace the `[trigger]` string in the captions.\n        ",
        "required": false
      },
      "resume_from_checkpoint": {
        "type": "string",
        "description": "URL to a checkpoint to resume training from.",
        "required": false,
        "default": ""
      },
      "learning_rate": {
        "type": "number",
        "description": "Learning rate to use for training.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 0.001,
        "default": 9e-05,
        "examples": [
          0.0002
        ]
      },
      "subject_crop": {
        "type": "boolean",
        "description": "If True, the subject will be cropped from the image.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "multiresolution_training": {
        "type": "boolean",
        "description": "If True, multiresolution training will be used.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "steps": {
        "type": "integer",
        "description": "Number of steps to train the LoRA on.",
        "required": false,
        "minimum": 1,
        "maximum": 10000,
        "default": 2500,
        "examples": [
          1000
        ]
      },
      "data_archive_format": {
        "type": "string",
        "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
        "required": false
      },
      "create_masks": {
        "type": "boolean",
        "description": "If True, masks will be created for the subject.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "config_file": {
        "type": null,
        "description": "URL to the training configuration file."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "URL to the trained diffusers lora weights."
      }
    }
  },
  {
    "id": "fal-ai/stable-diffusion-v35-large",
    "title": "Stable Diffusion 3.5 Large",
    "category": "text-to-image",
    "description": "Stable Diffusion 3.5 Large is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "tags": [
      "diffusion",
      "typography",
      "style"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/Bi6nsyNxslnu2SfI3jtkZ_e52ae7331ca94401bce20e695e3838a8.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v35-large",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v35-large/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A dreamlike Japanese garden in perpetual twilight, bathed in bioluminescent cherry blossoms that emit a soft pink-purple glow. Floating paper lanterns drift lazily through the scene, their warm light creating dancing reflections in a mirror-like koi pond. Ethereal mist weaves between ancient stone pathways lined with glowing mushrooms in pastel blues and purples. A traditional wooden bridge arches gracefully over the water, dusted with fallen petals that sparkle like stardust. The scene is captured through a cinematic lens with perfect bokeh, creating an otherworldly atmosphere. In the background, a crescent moon hangs impossibly large in the sky, surrounded by a sea of stars and auroral wisps in teal and violet. Crystal formations emerge from the ground, refracting the ambient light into rainbow prisms. The entire composition follows the golden ratio, with moody film-like color grading reminiscent of Studio Ghibli, enhanced by volumetric god rays filtering through the luminous foliage. 8K resolution, masterful photography, hyperdetailed, magical realism."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Defaults to landscape_4_3 if no controlnet has been passed, otherwise defaults to the size of the controlnet conditioning image.",
        "required": false
      },
      "controlnet": {
        "type": null,
        "description": "\n            ControlNet for inference.\n        ",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "ip_adapter": {
        "type": null,
        "description": "\n            IP-Adapter to use during inference.\n        ",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-general",
    "title": "FLUX.1 [dev] with Controlnets and Loras",
    "category": "text-to-image",
    "description": "A versatile endpoint for the FLUX.1 [dev] model that supports multiple AI extensions including LoRA, ControlNet conditioning, and IP-Adapter integration, enabling comprehensive control over image generation through various guidance methods.",
    "tags": [
      "lora",
      "controlnet",
      "ip-adapter"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/SW4VnooC-y1J5oHp72c35_ef2d274c84d644769fec449d83da838f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-general",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-general/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "nag_end": {
        "type": "number",
        "description": "\n            The proportion of steps to apply NAG. After the specified proportion\n            of steps has been iterated, the remaining steps will use original\n            attention processors in FLUX.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "control_loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/ControlLoraWeight"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler for the denoising process.",
        "required": false,
        "enum": [
          "euler",
          "dpmpp_2m"
        ],
        "default": "euler"
      },
      "easycontrols": {
        "type": "array",
        "description": "\n        EasyControl Inputs to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/EasyControlWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "real_cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 3.5
      },
      "use_cfg_zero": {
        "type": "boolean",
        "description": "\n            Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.\n        ",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "reference_strength": {
        "type": "number",
        "description": "Strength of reference_only generation. Only used if a reference image is provided.",
        "required": false,
        "minimum": -3,
        "maximum": 3,
        "default": 0.65
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "sigma_schedule": {
        "type": "string",
        "description": "Sigmas schedule for the denoising process.",
        "required": false,
        "enum": [
          "sgm_uniform"
        ]
      },
      "reference_end": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to be ended.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "fill_image": {
        "type": null,
        "description": "Use an image input to influence the generation. Can be used to fill images in masked areas.",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "nag_scale": {
        "type": "number",
        "description": "\n            The scale for NAG. Higher values will result in a image that is more distant\n            to the negative prompt.\n        ",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "reference_image_url": {
        "type": "string",
        "description": "URL of Image for Reference-Only",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "controlnet_unions": {
        "type": "array",
        "description": "\n            The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNetUnion"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            Negative prompt to steer the image generation away from unwanted features.\n            By default, we will be using NAG for processing the negative prompt.\n        ",
        "required": false,
        "default": ""
      },
      "nag_tau": {
        "type": "number",
        "description": "\n            The tau for NAG. Controls the normalization of the hidden state.\n            Higher values will result in a less aggressive normalization,\n            but may also lead to unexpected changes with respect to the original image.\n            Not recommended to change this value.\n        ",
        "required": false,
        "default": 2.5
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      },
      "use_beta_schedule": {
        "type": "boolean",
        "description": "Specifies whether beta sigmas ought to be used.",
        "required": false,
        "default": false
      },
      "nag_alpha": {
        "type": "number",
        "description": "\n            The alpha value for NAG. This value is used as a final weighting\n            factor for steering the normalized guidance (positive and negative prompts)\n            in the direction of the positive prompt. Higher values will result in less\n            steering on the normalized guidance where lower values will result in\n            considering the positive prompt guidance more.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "base_shift": {
        "type": "number",
        "description": "Base shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 0.5
      },
      "ip_adapters": {
        "type": "array",
        "description": "\n        IP-Adapter to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "use_real_cfg": {
        "type": "boolean",
        "description": "\n            Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.\n            If using XLabs IP-Adapter v1, this will be turned on!.\n        ",
        "required": false,
        "default": false
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The controlnets to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "reference_start": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to bestarted.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "max_shift": {
        "type": "number",
        "description": "Max shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 1.15
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-lora",
    "title": "FLUX.1 [dev] with LoRAs",
    "category": "text-to-image",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/RqIQsOY3cgQMMtCedJKlf_c2fc262516d24b94afdc17a747292710.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux/dev/image-to-image",
    "title": "FLUX.1 [dev]",
    "category": "image-to-image",
    "description": "FLUX.1 Image-to-Image is a high-performance endpoint for the FLUX.1 [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "style transfer"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/jJ3ZxKTV6ulhHV6GKi9nZ_68430b557ef64f68bf6f0fed0e78c6f9.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/dev/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/dev/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/aura-sr",
    "title": "AuraSR",
    "category": "image-to-image",
    "description": "Upscale your images with AuraSR.",
    "tags": [
      "upscaling",
      "high-res"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/rW7Rhmjtkjvb8gnOPUhNN_b14088de7d684d4b8489db59d53ae3f7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/aura-sr",
    "documentationUrl": "https://fal.ai/models/fal-ai/aura-sr/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "overlapping_tiles": {
        "type": "boolean",
        "description": "Whether to use overlapping tiles for upscaling. Setting this to true helps remove seams but doubles the inference time.",
        "required": false,
        "default": false,
        "examples": [
          true,
          false
        ]
      },
      "checkpoint": {
        "type": "string",
        "description": "Checkpoint to use for upscaling. More coming soon.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1",
        "examples": [
          "v2",
          "v1"
        ]
      },
      "upscaling_factor": {
        "type": "integer",
        "description": "Upscaling factor. More coming soon.",
        "required": false,
        "enum": [
          4
        ],
        "default": 4,
        "examples": [
          4
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to upscale.",
        "required": true,
        "examples": [
          "https://fal.media/files/rabbit/JlBgYUyQRS3zxiBu_B4fM.png",
          "https://fal.media/files/monkey/e6RtJf_ue0vyWzeiEmTby.png",
          "https://fal.media/files/monkey/A6HGsigx4mmvs-hJVoOZX.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Upscaled image"
      },
      "timings": {
        "type": "object",
        "description": "Timings for each step in the pipeline."
      }
    }
  },
  {
    "id": "fal-ai/clarity-upscaler",
    "title": "Clarity Upscaler",
    "category": "image-to-image",
    "description": "Clarity upscaler for upscaling images with high very fidelity.",
    "tags": [
      "upscaling"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/controlnet-tile-upscaler.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/clarity-upscaler",
    "documentationUrl": "https://fal.ai/models/fal-ai/clarity-upscaler/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "masterpiece, best quality, highres",
        "examples": [
          "masterpiece, best quality, highres"
        ]
      },
      "resemblance": {
        "type": "number",
        "description": "\n            The resemblance of the upscaled image to the original image. The higher the resemblance, the more the model will try to keep the original image.\n            Refers to the strength of the ControlNet.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.6
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to upscale.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/NOCA_Mick-Thompson.resized.resized.jpg"
        ]
      },
      "creativity": {
        "type": "number",
        "description": "\n            The creativity of the model. The higher the creativity, the more the model will deviate from the prompt.\n            Refers to the denoise strength of the sampling.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.35
      },
      "upscale_factor": {
        "type": "number",
        "description": "The upscale factor",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 2
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "seed": {
        "type": null,
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
        "required": false,
        "default": "(worst quality, low quality, normal quality:2)",
        "examples": [
          "(worst quality, low quality, normal quality:2)"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 4,
        "maximum": 50,
        "default": 18
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The URL of the generated image."
      },
      "timings": {
        "type": "object",
        "description": "The timings of the different steps in the workflow."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used to generate the image."
      }
    }
  },
  {
    "id": "bria/fibo/generate/structured_prompt",
    "title": "Fibo",
    "category": "text-to-json",
    "description": "Structured Prompt Generation endpoint for Fibo, Bria's SOTA Open source model",
    "tags": [
      "bria",
      "fibo",
      "structured-prompting"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/elephant/KCXErEWyZA8pKAdXl_V5y_d9c1d7cbfecf4b3b83d8a70846da03ce.jpg",
    "playgroundUrl": "https://fal.ai/models/bria/fibo/generate/structured_prompt",
    "documentationUrl": "https://fal.ai/models/bria/fibo/generate/structured_prompt/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": null,
        "description": "Prompt for image generation.",
        "required": false,
        "examples": [
          "A hyper-detailed, ultra-fluffy owl sitting in the trees at night, looking directly at the camera with wide, adorable, expressive eyes. Its feathers are soft and voluminous, catching the cool moonlight with subtle silver highlights. The owl’s gaze is curious and full of charm, giving it a whimsical, storybook-like personality."
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility.",
        "required": false,
        "default": 5555
      },
      "structured_prompt": {
        "type": null,
        "description": "The structured prompt to generate an image from.",
        "required": false
      },
      "image_url": {
        "type": null,
        "description": "Reference image (file or URL).",
        "required": false
      }
    },
    "outputParameters": {}
  },
  {
    "id": "fal-ai/minimax/speech-2.6-turbo",
    "title": "MiniMax Speech 2.6 [Turbo]",
    "category": "text-to-speech",
    "description": "Generate speech from text prompts and different voices using the MiniMax Speech-2.6 HD model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "text-to-speech"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/HZruOC2L6Z5sSz-3n_Y_y_6ffd8bbd00ac4e11808d79b0381705f7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/speech-2.6-turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/speech-2.6-turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.",
        "required": true,
        "minLength": 1,
        "maxLength": 10000,
        "examples": [
          "Hello world! Welcome MiniMax's new text to speech model <#0.1#> Speech 2.6 Turbo, now available on Fal!"
        ]
      },
      "language_boost": {
        "type": "string",
        "description": "Enhance recognition of specified languages and dialects",
        "required": false,
        "enum": [
          "Chinese",
          "Chinese,Yue",
          "English",
          "Arabic",
          "Russian",
          "Spanish",
          "French",
          "Portuguese",
          "German",
          "Turkish",
          "Dutch",
          "Ukrainian",
          "Vietnamese",
          "Indonesian",
          "Japanese",
          "Italian",
          "Korean",
          "Thai",
          "Polish",
          "Romanian",
          "Greek",
          "Czech",
          "Finnish",
          "Hindi",
          "Bulgarian",
          "Danish",
          "Hebrew",
          "Malay",
          "Slovak",
          "Swedish",
          "Croatian",
          "Hungarian",
          "Norwegian",
          "Slovenian",
          "Catalan",
          "Nynorsk",
          "Afrikaans",
          "auto"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "Format of the output content (non-streaming only)",
        "required": false,
        "enum": [
          "url",
          "hex"
        ],
        "default": "hex"
      },
      "pronunciation_dict": {
        "type": null,
        "description": "Custom pronunciation dictionary for text replacement",
        "required": false
      },
      "voice_setting": {
        "type": null,
        "description": "Voice configuration settings",
        "required": false,
        "default": {
          "speed": 1,
          "vol": 1,
          "voice_id": "Wise_Woman",
          "pitch": 0,
          "english_normalization": false
        }
      },
      "normalization_setting": {
        "type": null,
        "description": "Loudness normalization settings for the audio",
        "required": false
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "duration_ms": {
        "type": "integer",
        "description": "Duration of the audio in milliseconds"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/minimax/speech-2.6-hd",
    "title": "MiniMax Speech 2.6 [HD]",
    "category": "text-to-speech",
    "description": "Generate speech from text prompts and different voices using the MiniMax Speech-2.6 HD model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "text-to-speech"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/koala/6tOgyOsZd3SX011WRQCpg_27fe767a77dc47bbb3c4eded059b706b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/speech-2.6-hd",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/speech-2.6-hd/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.",
        "required": true,
        "minLength": 1,
        "maxLength": 10000,
        "examples": [
          "Hello world! Welcome MiniMax's new text to speech model <#0.1#> Speech 2.6, now available on Fal!"
        ]
      },
      "language_boost": {
        "type": "string",
        "description": "Enhance recognition of specified languages and dialects",
        "required": false,
        "enum": [
          "Chinese",
          "Chinese,Yue",
          "English",
          "Arabic",
          "Russian",
          "Spanish",
          "French",
          "Portuguese",
          "German",
          "Turkish",
          "Dutch",
          "Ukrainian",
          "Vietnamese",
          "Indonesian",
          "Japanese",
          "Italian",
          "Korean",
          "Thai",
          "Polish",
          "Romanian",
          "Greek",
          "Czech",
          "Finnish",
          "Hindi",
          "Bulgarian",
          "Danish",
          "Hebrew",
          "Malay",
          "Slovak",
          "Swedish",
          "Croatian",
          "Hungarian",
          "Norwegian",
          "Slovenian",
          "Catalan",
          "Nynorsk",
          "Afrikaans",
          "auto"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "Format of the output content (non-streaming only)",
        "required": false,
        "enum": [
          "url",
          "hex"
        ],
        "default": "hex"
      },
      "pronunciation_dict": {
        "type": null,
        "description": "Custom pronunciation dictionary for text replacement",
        "required": false
      },
      "voice_setting": {
        "type": null,
        "description": "Voice configuration settings",
        "required": false,
        "default": {
          "speed": 1,
          "vol": 1,
          "voice_id": "Wise_Woman",
          "pitch": 0,
          "english_normalization": false
        }
      },
      "normalization_setting": {
        "type": null,
        "description": "Loudness normalization settings for the audio",
        "required": false
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "duration_ms": {
        "type": "integer",
        "description": "Duration of the audio in milliseconds"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/video-as-prompt",
    "title": "Video As Prompt",
    "category": "video-to-video",
    "description": "A model for unified semantic control in video generation. It animates a static reference image using the motion and semantics from a reference video as a prompt.",
    "tags": [
      "video-as-prompt",
      "semantic control",
      ""
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/EjSKvmsuw-WhgnR2wWk1-_e5c016adb70b42548df5359ae2d8d06b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/video-as-prompt",
    "documentationUrl": "https://fal.ai/models/fal-ai/video-as-prompt/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A chestnut-colored horse stands on a grassy hill against a backdrop of distant, snow-dusted mountains. The horse begins to inflate, its defined, muscular body swelling and rounding into a smooth, balloon-like form while retaining its rich, brown hide color. Without changing its orientation, the now-buoyant horse lifts silently from the ground. It begins a steady vertical ascent, rising straight up and eventually floating out of the top of the frame. The camera remains completely static throughout the entire sequence, holding a fixed shot on the landscape as the horse transforms and departs, ensuring the verdant hill and mountain range in the background stay perfectly still."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "9:16"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "480p"
      },
      "video_url": {
        "type": "string",
        "description": "reference video to generate effect video from.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bytedance-vid2pro/object-725.mp4"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Input image to generate the effect video for.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bytedance-vid2pro/animal-2.jpg"
        ]
      },
      "fps": {
        "type": "integer",
        "description": "Frames per second for the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 16
      },
      "video_description": {
        "type": "string",
        "description": "A brief description of the input video content.",
        "required": true,
        "examples": [
          "A hand holds up a single beige sneaker decorated with gold calligraphy and floral illustrations, with small green plants tucked inside. The sneaker immediately begins to inflate like a balloon, its shape distorting as the decorative details stretch and warp across the expanding surface. It rapidly transforms into a perfectly smooth, matte beige sphere, inheriting the primary color from the original shoe. Once the transformation is complete, the new balloon-like object quickly ascends, moving straight up and exiting the top of the frame. The camera remains completely static and the plain white background is unchanged throughout the entire sequence."
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible generation. If set none, a random seed will be used.",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for generation.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 49
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The URLs of the generated video."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seed3d/image-to-3d",
    "title": "Bytedance",
    "category": "image-to-3d",
    "description": "Image to 3D endpoint for Bytedance's high-quality Seed3D 3d model generator.",
    "tags": [
      "seed3d.quality",
      "bytedance",
      "3d"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/FupEJtwP6Iz7JhciALTcB_842b6a10f1f44525816ad725cf8b076d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seed3d/image-to-3d",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seed3d/image-to-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the image for the 3D asset generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/seed3d_input.png"
        ]
      }
    },
    "outputParameters": {
      "model": {
        "type": null,
        "description": "The generated 3D model files"
      },
      "usage_tokens": {
        "type": "integer",
        "description": "The number of tokens used for the 3D model generation"
      }
    }
  },
  {
    "id": "bria/fibo/generate",
    "title": "Fibo",
    "category": "json-to-image",
    "description": "SOTA Open source model trained on licensed data, transforming intent into structured control for precise, high-quality AI image generation in enterprise and agentic workflows.",
    "tags": [
      "bria",
      "fibo",
      "prompt-adherence"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/KZ0Rdf_H7CtVE7Gpqk7XB_430bc50472c44700aaee472dd73c18f1.jpg",
    "playgroundUrl": "https://fal.ai/models/bria/fibo/generate",
    "documentationUrl": "https://fal.ai/models/bria/fibo/generate/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": null,
        "description": "Prompt for image generation.",
        "required": false,
        "examples": [
          "A hyper-detailed, ultra-fluffy owl sitting in the trees at night, looking directly at the camera with wide, adorable, expressive eyes. Its feathers are soft and voluminous, catching the cool moonlight with subtle silver highlights. The owl’s gaze is curious and full of charm, giving it a whimsical, storybook-like personality."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9",
        "required": false,
        "enum": [
          "1:1",
          "2:3",
          "3:2",
          "3:4",
          "4:3",
          "4:5",
          "5:4",
          "9:16",
          "16:9"
        ],
        "default": "1:1"
      },
      "sync": {
        "type": "boolean",
        "description": "If true, returns the image directly in the response (increases latency).",
        "required": false,
        "default": false
      },
      "steps_num": {
        "type": "integer",
        "description": "Number of inference steps.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 50
      },
      "image_url": {
        "type": null,
        "description": "Reference image (file or URL).",
        "required": false
      },
      "guidance_scale": {
        "type": "integer",
        "description": "Guidance scale for text.",
        "required": false,
        "minimum": 3,
        "maximum": 5,
        "default": 5
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility.",
        "required": false,
        "default": 5555
      },
      "structured_prompt": {
        "type": null,
        "description": "The structured prompt to generate an image from.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for image generation.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Generated image."
      },
      "structured_prompt": {
        "type": "object",
        "description": "Current prompt."
      }
    }
  },
  {
    "id": "fal-ai/longcat-video/distilled/image-to-video/480p",
    "title": "LongCat Video Distilled",
    "category": "image-to-video",
    "description": "Generate long videos from images using LongCat Video Distilled",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/3d4yOBDSZ0g2z6pPOr3qP_bbe50a030bbb497d9417bfc0e5129536.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/longcat-video/distilled/image-to-video/480p",
    "documentationUrl": "https://fal.ai/models/fal-ai/longcat-video/distilled/image-to-video/480p/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to guide the video generation.",
        "required": false,
        "default": "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
        "examples": [
          "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
        ]
      },
      "video_output_type": {
        "type": "string",
        "description": "The output type of the generated video.",
        "required": false,
        "enum": [
          "X264 (.mp4)",
          "VP9 (.webm)",
          "PRORES4444 (.mov)",
          "GIF (.gif)"
        ],
        "default": "X264 (.mp4)"
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate a video from.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/zebra/trXRsbjJwy4Z3OEgbnB9a.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "fps": {
        "type": "integer",
        "description": "The frame rate of the generated video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable safety checker.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 17,
        "maximum": 961,
        "default": 162
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to use.",
        "required": false,
        "minimum": 2,
        "maximum": 16,
        "default": 12
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/longcat-video/distilled/text-to-video/480p",
    "title": "LongCat Video Distilled",
    "category": "text-to-video",
    "description": "Generate long videos from text using LongCat Video Distilled",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/koala/RWTqBORnZpIgG6D_kh88p_14d4a40aa377471984f0b04b20947d82.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/longcat-video/distilled/text-to-video/480p",
    "documentationUrl": "https://fal.ai/models/fal-ai/longcat-video/distilled/text-to-video/480p/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to guide the video generation.",
        "required": true,
        "examples": [
          "realistic filming style, a person wearing a dark helmet, a deep-colored jacket, blue jeans, and bright yellow shoes rides a skateboard along a winding mountain road. The skateboarder starts in a standing position, then gradually lowers into a crouch, extending one hand to touch the road surface while maintaining a low center of gravity to navigate a sharp curve. After completing the turn, the skateboarder rises back to a standing position and continues gliding forward. The background features lush green hills flanking both sides of the road, with distant snow-capped mountain peaks rising against a clear, bright blue sky. The camera follows closely from behind, smoothly tracking the skateboarder’s movements and capturing the dynamic scenery along the route. The scene is shot in natural daylight, highlighting the vivid outdoor environment and the skateboarder’s fluid actions."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced"
      },
      "video_output_type": {
        "type": "string",
        "description": "The output type of the generated video.",
        "required": false,
        "enum": [
          "X264 (.mp4)",
          "VP9 (.webm)",
          "PRORES4444 (.mov)",
          "GIF (.gif)"
        ],
        "default": "X264 (.mp4)"
      },
      "fps": {
        "type": "integer",
        "description": "The frame rate of the generated video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable safety checker.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 17,
        "maximum": 961,
        "default": 162
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to use.",
        "required": false,
        "minimum": 2,
        "maximum": 16,
        "default": 12
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/demucs",
    "title": "Demucs",
    "category": "audio-to-audio",
    "description": "SOTA stemming model for voice, drums, bass, guitar and more.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/r9IsOw8YDHI5vWwGJ-oUB_0babace2defa4ef9a230967a232ea841.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/demucs",
    "documentationUrl": "https://fal.ai/models/fal-ai/demucs/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "segment_length": {
        "type": "integer",
        "description": "Length in seconds of each segment for processing. Smaller values use less memory but may reduce quality. Default is model-specific.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "Output audio format for the separated stems",
        "required": false,
        "enum": [
          "wav",
          "mp3"
        ],
        "default": "mp3",
        "examples": [
          "mp3"
        ]
      },
      "stems": {
        "type": "array",
        "description": "Specific stems to extract. If None, extracts all available stems. Available stems depend on model: vocals, drums, bass, other, guitar, piano (for 6s model)",
        "required": false,
        "default": [
          "vocals",
          "drums",
          "bass",
          "other",
          "guitar",
          "piano"
        ],
        "examples": [
          [
            "vocals",
            "drums",
            "bass",
            "other",
            "guitar",
            "piano"
          ]
        ],
        "items": {
          "enum": [
            "vocals",
            "drums",
            "bass",
            "other",
            "guitar",
            "piano"
          ],
          "type": "string"
        }
      },
      "overlap": {
        "type": "number",
        "description": "Overlap between segments (0.0 to 1.0). Higher values may improve quality but increase processing time.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.25
      },
      "model": {
        "type": "string",
        "description": "Demucs model to use for separation",
        "required": false,
        "enum": [
          "htdemucs",
          "htdemucs_ft",
          "htdemucs_6s",
          "hdemucs_mmi",
          "mdx",
          "mdx_extra",
          "mdx_q",
          "mdx_extra_q"
        ],
        "default": "htdemucs_6s",
        "examples": [
          "htdemucs_6s"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to separate into stems",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/audio-understanding/Title_%20Running%20on%20Fal.mp3"
        ]
      },
      "shifts": {
        "type": "integer",
        "description": "Number of random shifts for equivariant stabilization. Higher values improve quality but increase processing time.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      }
    },
    "outputParameters": {
      "vocals": {
        "type": null,
        "description": "Separated vocals audio file"
      },
      "guitar": {
        "type": null,
        "description": "Separated guitar audio file (only available for 6s models)"
      },
      "bass": {
        "type": null,
        "description": "Separated bass audio file"
      },
      "piano": {
        "type": null,
        "description": "Separated piano audio file (only available for 6s models)"
      },
      "other": {
        "type": null,
        "description": "Separated other instruments audio file"
      },
      "drums": {
        "type": null,
        "description": "Separated drums audio file"
      }
    }
  },
  {
    "id": "fal-ai/piflow",
    "title": "Piflow",
    "category": "text-to-image",
    "description": "Use the faster speed of piflow to generate images with same quality to that of slower models.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/gxldXHbNIVlr0CpcbpWOj_ad5f5c3f5fa74edbbee97ada3ddeef02.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/piflow",
    "documentationUrl": "https://fal.ai/models/fal-ai/piflow/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Photo of a coffee shop entrance featuring a chalkboard sign reading \"π-Qwen Coffee 😊 $2 per cup,\" with a neon light beside it displaying \"π-通义千问\". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written \"e≈2.71828-18284-59045-23536-02874-71352\"."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "\n            The size of the generated image. You can choose between some presets or custom height and width\n            that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "square_hd"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation. If set to None, a random seed will be used.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The URLs of the generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video",
    "title": "MiniMax Hailuo 2.3 Fast [Standard] (Image to Video)",
    "category": "image-to-video",
    "description": "MiniMax Hailuo-2.3-Fast Image To Video API (Standard, 768p): Advanced fast image-to-video generation model with 768p resolution",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/elephant/Qa714sjGzfM3X59sy7I9y_12d9a8d139204572b25ee2e9ec6c92d1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "Athlete running powerfully on beach, dynamic camera movement tracking the runner, waves and sunset in motion, Hollywood movie cinematography, professional sports filming, inspiring atmosphere"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the video in seconds.",
        "required": false,
        "enum": [
          "6",
          "10"
        ],
        "default": "6"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/fast_standard_i2v_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/standard/image-to-video",
    "title": "MiniMax Hailuo 2.3 [Standard] (Image to Video)",
    "category": "image-to-video",
    "description": "MiniMax Hailuo-2.3 Image To Video API (Standard, 768p): Advanced image-to-video generation model with 768p resolution",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/zebra/7kDvX2hsHnnUu9mSt-I_C_3a18467c2b234f6590e01edd53840f2d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "The space station slowly rotates in orbit, its solar panels tracking the sun. Earth rotates majestically in the background with weather patterns and landmasses drifting by. The station's communication arrays adjust position. A small spacecraft approaches one of the docking ports. The scene captures the silent majesty of space and human engineering."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the video in seconds.",
        "required": false,
        "enum": [
          "6",
          "10"
        ],
        "default": "6"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/standard_i2v_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video",
    "title": "MiniMax Hailuo 2.3 Fast [Pro] (Image to Video)",
    "category": "image-to-video",
    "description": "MiniMax Hailuo-2.3-Fast Image To Video API (Pro, 1080p): Advanced fast image-to-video generation model with 1080p resolution",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/37ZHJodysdkE5NcfUc3fu_5731672b9b3c4e47b4b851a5145e5d3c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "Subject-tracking orbit: camera glides parallel to astronaut, Earth rotates beneath, sun crest reveals lens flare, astronaut tethers and spins slowly, 8K 60 fps slow-motion, ends with spacecraft blackout on sun disk"
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/fast_pro_i2v_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/standard/text-to-video",
    "title": "MiniMax Hailuo 2.3 [Standard] (Text to Video)",
    "category": "text-to-video",
    "description": "MiniMax Hailuo-2.3 Text To Video API (Standard, 768p): Advanced text-to-video generation model with 768p resolution",
    "tags": [
      "text-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/elephant/j3hSIKLqmWT7NXmIwTUQ0_1ec8fc1d7a53473fac7c2892ff459693.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/standard/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/standard/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "An intense electrical storm rages over a modern city skyline at night. Multiple lightning bolts strike simultaneously, illuminating the towering skyscrapers in brilliant white flashes. Thunder clouds roil and churn overhead while constant lightning creates a strobe effect. Rain pours in heavy sheets, visible in the glow of city lights. The camera captures the drama from across a river as lightning reflects in the water. Lightning branches across the sky in intricate patterns. Atmosphere: dramatic, powerful, electrifying urban storm."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the video in seconds.",
        "required": false,
        "enum": [
          "6",
          "10"
        ],
        "default": "6"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/pro/text-to-video",
    "title": "MiniMax Hailuo 2.3 [Pro] (Text to Video)",
    "category": "text-to-video",
    "description": "MiniMax Hailuo-2.3 Text To Video API (Pro, 1080p): Advanced text-to-video generation model with 1080p resolution",
    "tags": [
      "text-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/x_n_LT1ApmpYZnZw8sdNq_0147471d0d7e4bbba8780820dee6a3da.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-2.3/pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "The camera follows the snowboarder as they carve down the mountain through deep powder, each turn sending up huge rooster tails of snow. They navigate between trees, floating through the powder with smooth, flowing movements. The rider launches off a natural jump, grabbing the board mid-air before landing softly in deep snow and continuing down. Powder sprays continuously as they link turns together. The atmosphere is exhilarating and free. Audio: Board cutting through snow, powder spraying, wind rushing, the rider's excited shouts, and the soft thuds of landing in deep snow."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/birefnet/v2/video",
    "title": "Birefnet",
    "category": "video-to-video",
    "description": "Video background removal version of bilateral reference framework (BiRefNet) for high-resolution dichotomous image segmentation (DIS)\n",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/SKrLsOM3RMOk-QuNj8-io_6356be1b301e454394d2e0a853b98c76.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/birefnet/v2/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/birefnet/v2/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to remove background from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/birefnet-video-input.mp4"
        ]
      },
      "operating_resolution": {
        "type": "string",
        "description": "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images.",
        "required": false,
        "enum": [
          "1024x1024",
          "2048x2048"
        ],
        "default": "1024x1024"
      },
      "video_output_type": {
        "type": "string",
        "description": "The output type of the generated video.",
        "required": false,
        "enum": [
          "X264 (.mp4)",
          "VP9 (.webm)",
          "PRORES4444 (.mov)",
          "GIF (.gif)"
        ],
        "default": "X264 (.mp4)"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "model": {
        "type": "string",
        "description": "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository but trained with 2K images.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Matting' model is a model trained specifically for matting images.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet-DIS_ep580.pth\n            - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth\n            - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth\n        ",
        "required": false,
        "enum": [
          "General Use (Light)",
          "General Use (Light 2K)",
          "General Use (Heavy)",
          "Matting",
          "Portrait"
        ],
        "default": "General Use (Light)"
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high"
      },
      "output_mask": {
        "type": "boolean",
        "description": "Whether to output the mask used to remove the background",
        "required": false,
        "default": false
      },
      "refine_foreground": {
        "type": "boolean",
        "description": "Whether to refine the foreground using the estimated mask",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "Video with background removed"
      },
      "mask_video": {
        "type": null,
        "description": "Mask used to remove the background"
      }
    }
  },
  {
    "id": "fal-ai/audio-understanding",
    "title": "Audio Understanding",
    "category": "audio-to-audio",
    "description": "A audio understanding model to analyze audio content and answer questions about what's happening in the audio based on user prompts.",
    "tags": [
      "utility",
      "audio"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/6SXguUXRvg1XrEdf_zZcM_023b35fa7e9e4777b3e7fa0934ebb13a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/audio-understanding",
    "documentationUrl": "https://fal.ai/models/fal-ai/audio-understanding/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The question or prompt about the audio content.",
        "required": true,
        "minLength": 1,
        "maxLength": 10000,
        "examples": [
          "What is being discussed in this audio?",
          "What emotions are expressed in this audio?",
          "What is the main topic of this conversation?"
        ]
      },
      "detailed_analysis": {
        "type": "boolean",
        "description": "Whether to request a more detailed analysis of the audio",
        "required": false,
        "default": false
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to analyze",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/audio-understanding/Title_%20Running%20on%20Fal.mp3"
        ]
      }
    },
    "outputParameters": {
      "output": {
        "type": "string",
        "description": "The analysis of the audio content based on the prompt"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/fast/image-to-video",
    "title": "Bytedance",
    "category": "image-to-video",
    "description": "Image to Video endpoint for Seedance 1.0 Pro Fast, a next-generation video model designed to deliver maximum performance at minimal cost",
    "tags": [
      "bytedance",
      "seedance",
      "pro",
      "fast"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/OHnRF5artsmMtvv5DikBL_0d31376b45fc47c28ad70e15245ca449.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/fast/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/fast/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "Bathed in a stark spotlight, a lone ballet dancer takes center stage. Her movements, precise and graceful, tell a story of passion and dedication against the velvet darkness. The scene evokes a sense of intimacy, highlighting the raw emotion and artistry of her performance."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16",
          "auto"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image used to generate video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/seedance_fast_i2v_input.png"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/fast/text-to-video",
    "title": "Bytedance",
    "category": "text-to-video",
    "description": "Text to Video endpoint for Seedance 1.0 Pro Fast, a next-generation video model designed to deliver maximum performance at minimal cost",
    "tags": [
      "bytedance",
      "fast",
      "motion"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/vuOJvxcEA4z0fsRkw3r4Y_4930420a08f045c9ae3c401e3a6d20fc.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/fast/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/fast/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "Inside a quiet dojo, a martial artist moves with precision and grace. The performance highlights the beauty and discipline inherent in the ancient practice. Each form unfolds clearly, a testament to dedication and skill."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q2/video-extension/pro",
    "title": "Vidu",
    "category": "video-to-video",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/w0OmEqIT3ttJ87CyIv4YE_9fef0096f9f44fa7af8012a25eae3fa7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q2/video-extension/pro",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q2/video-extension/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "text prompt to guide the video extension",
        "required": false,
        "maxLength": 3000
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the extension in seconds",
        "required": false,
        "enum": [
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "default": 4
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to extend",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/output-3.mp4"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Output video resolution",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The extended video using the Q2 model"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q2/image-to-video/turbo",
    "title": "Vidu",
    "category": "image-to-video",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/pV-tsWf3pDIWfSzE8Y8QD_405c6376ad454bdd9aec52cfcc23a97e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q2/image-to-video/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q2/image-to-video/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 3000 characters",
        "required": true,
        "maxLength": 3000,
        "examples": [
          "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Output video resolution",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "default": 4
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the starting frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
        ]
      },
      "bgm": {
        "type": "boolean",
        "description": "Whether to add background music to the video (only for 4-second videos)",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video from image using the Q2 model"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q2/image-to-video/pro",
    "title": "Vidu",
    "category": "image-to-video",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/9ZFHimyaNGh_0WHvVLfOn_67d61fe778bd4257a402b467aaff6f66.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q2/image-to-video/pro",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q2/image-to-video/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 3000 characters",
        "required": true,
        "maxLength": 3000,
        "examples": [
          "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Output video resolution",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "default": 4
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the starting frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
        ]
      },
      "bgm": {
        "type": "boolean",
        "description": "Whether to add background music to the video (only for 4-second videos)",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video from image using the Q2 model"
      }
    }
  },
  {
    "id": "fal-ai/ltxv-2/image-to-video/fast",
    "title": "LTX Video 2.0 Fast",
    "category": "image-to-video",
    "description": "Create high-fidelity video with audio from images with LTX-2 Fast",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/OdQJdqqToEMWzSaiNh68b_cc8c521793624020b4a86056a3b498d0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-2/image-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-2/image-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from",
        "required": true,
        "examples": [
          "A woman stands still amid a busy neon-lit street at night. The camera slowly dollies in toward her face as people blur past, their motion emphasizing her calm presence. City lights flicker and reflections shift across her denim jacket."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          6,
          8,
          10
        ],
        "default": 6
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "1080p",
          "1440p",
          "2160p"
        ],
        "default": "1080p"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the generated video",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9"
        ],
        "default": "16:9"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ltxv-2-i2v-input.jpg"
        ]
      },
      "fps": {
        "type": "integer",
        "description": "The frames per second of the generated video",
        "required": false,
        "enum": [
          25,
          50
        ],
        "default": 25
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "fal-ai/ltxv-2/text-to-video/fast",
    "title": "LTX Video 2.0 Fast",
    "category": "text-to-video",
    "description": "Create high-fidelity video with audio from text with LTX-2 Fast",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/1z0o3ma3f3JwQMO9xlnKR_79bee919aeb04b6d93428c650ee87a5e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-2/text-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-2/text-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from",
        "required": true,
        "examples": [
          "A cowboy walking through a dusty town at high noon, camera following from behind, cinematic depth, realistic lighting, western mood, 4K film grain."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          6,
          8,
          10
        ],
        "default": 6
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "1080p",
          "1440p",
          "2160p"
        ],
        "default": "1080p"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the generated video",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9"
        ],
        "default": "16:9"
      },
      "fps": {
        "type": "integer",
        "description": "The frames per second of the generated video",
        "required": false,
        "enum": [
          25,
          50
        ],
        "default": 25
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "fal-ai/ltxv-2/image-to-video",
    "title": "LTX Video 2.0 Pro",
    "category": "image-to-video",
    "description": "Create high-fidelity video with audio from images with LTX-2 Pro",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/jFuLJyFYw6CnRfSpmA8BG_82dec35b7bd143ee9abd2615f8052957.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-2/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-2/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from",
        "required": true,
        "examples": [
          "A woman stands still amid a busy neon-lit street at night. The camera slowly dollies in toward her face as people blur past, their motion emphasizing her calm presence. City lights flicker and reflections shift across her denim jacket."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          6,
          8,
          10
        ],
        "default": 6
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "1080p",
          "1440p",
          "2160p"
        ],
        "default": "1080p"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the generated video",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9"
        ],
        "default": "16:9"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ltxv-2-i2v-input.jpg"
        ]
      },
      "fps": {
        "type": "integer",
        "description": "The frames per second of the generated video",
        "required": false,
        "enum": [
          25,
          50
        ],
        "default": 25
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "fal-ai/ltxv-2/text-to-video",
    "title": "LTX Video 2.0 Pro",
    "category": "text-to-video",
    "description": "Create high-fidelity video with audio from text with LTX-2 Pro.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/ylyM62sWoJM8GAjBUmYOa_930f3f7413604a7fa1e641a25c9d7ff4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-2/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-2/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from",
        "required": true,
        "examples": [
          "A cowboy walking through a dusty town at high noon, camera following from behind, cinematic depth, realistic lighting, western mood, 4K film grain."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          6,
          8,
          10
        ],
        "default": 6
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "1080p",
          "1440p",
          "2160p"
        ],
        "default": "1080p"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the generated video",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9"
        ],
        "default": "16:9"
      },
      "fps": {
        "type": "integer",
        "description": "The frames per second of the generated video",
        "required": false,
        "enum": [
          25,
          50
        ],
        "default": 25
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q2/text-to-video",
    "title": "Vidu",
    "category": "text-to-video",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/ui3mJj8_Fmxg22mCDuesY_38c8acb860cf4072899ec0c062efcf9e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q2/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q2/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 3000 characters",
        "required": true,
        "maxLength": 3000,
        "examples": [
          "A cinematic shot of a futuristic city at sunset, with flying cars and towering skyscrapers."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Output video resolution",
        "required": false,
        "enum": [
          "360p",
          "520p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "default": 4
      },
      "bgm": {
        "type": "boolean",
        "description": "Whether to add background music to the video (only for 4-second videos)",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video from text using the Q2 model"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.5-turbo/standard/image-to-video",
    "title": "Kling Video",
    "category": "image-to-video",
    "description": "Kling 2.5 Turbo Standard: Top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/elephant/BJ1ZIdeClgqnUTW9XgEUS_d00e816ad20849ae9f92b735358d610d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.5-turbo/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.5-turbo/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "In a dimly lit room, a playful cat's eyes light up, fixated on a dancing red dot. With boundless energy, it pounces and leaps, chasing the elusive beam across the floor and up the walls. The simple joy of the hunt unfolds in clear, uncomplicated visuals."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/kling_v25_std_i2v_input.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/gpt-image-1-mini/edit",
    "title": "GPT Image 1 Mini",
    "category": "image-to-image",
    "description": "GPT Image 1 mini combines OpenAI's advanced language capabilities, powered by GPT-5, with GPT Image 1 Mini for efficient image generation. ",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/cG0uNtODkeDPtNDUXms1H_63d395581f334382bf6806b78849ffb0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gpt-image-1-mini/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/gpt-image-1-mini/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image editing",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the images",
        "required": false,
        "enum": [
          "jpeg",
          "png",
          "webp"
        ],
        "default": "jpeg"
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of input images for editing",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_1.png",
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_2.png",
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_3.png",
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_4.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The edited images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "description": {
        "type": "string",
        "description": "Text description or response from GPT-5 Image Mini"
      }
    }
  },
  {
    "id": "fal-ai/gpt-image-1-mini",
    "title": "GPT Image 1 Mini",
    "category": "text-to-image",
    "description": "GPT Image 1 mini combines OpenAI's advanced language capabilities, powered by GPT-5, with GPT Image 1 Mini for efficient image generation. ",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/Z7Y5fVvUXaT1XzWGqVngY_f333390b078a4bed9491ccda3b9f0e90.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gpt-image-1-mini",
    "documentationUrl": "https://fal.ai/models/fal-ai/gpt-image-1-mini/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image generation",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A serene landscape with mountains reflecting in a crystal-clear lake at sunset, photorealistic style"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the images",
        "required": false,
        "enum": [
          "jpeg",
          "png",
          "webp"
        ],
        "default": "jpeg"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "description": {
        "type": "string",
        "description": "Text description or response from GPT-5 Image Mini"
      }
    }
  },
  {
    "id": "fal-ai/qwen-3-guard",
    "title": "Qwen 3 Guard",
    "category": "llm",
    "description": "Use Qwen 3 Guard to detect and  classify text as safe or harmful, delivering precise and reliable safety categorization.",
    "tags": [
      "filter",
      "safety",
      "utility"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/mbftwyiNyy5hXuWPI8jdr_b9e8889f91994e318b188ac9db9089aa.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-3-guard",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-3-guard/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The input text to be classified",
        "required": true,
        "maxLength": 131072,
        "examples": [
          "How to make a bomb"
        ]
      }
    },
    "outputParameters": {
      "categories": {
        "type": "array",
        "description": "The confidence score of the classification",
        "items": {
          "enum": [
            "Violent",
            "Non-violent Illegal Acts",
            "Sexual Content or Sexual Acts",
            "PII",
            "Suicide & Self-Harm",
            "Unethical Acts",
            "Politically Sensitive Topics",
            "Copyright Violation",
            "Jailbreak",
            "None"
          ],
          "type": "string"
        }
      },
      "label": {
        "type": "string",
        "description": "The classification label"
      }
    }
  },
  {
    "id": "fal-ai/krea-wan-14b/text-to-video",
    "title": "Krea Wan 14b- Text to Video",
    "category": "text-to-video",
    "description": "Fast Text-to-Video endpoint for Krea's Wan 14b model.",
    "tags": [
      "text to video",
      "fast"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/n7SozOMd7d9UiTYhyZ4w3_99e21d49333f47b9be7e834d73a16d8a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/krea-wan-14b/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/krea-wan-14b/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt for the video-to-video generation.",
        "required": true,
        "examples": [
          "A powerful, matte black jeep, its robust frame contrasting with the lush green surroundings, navigates a winding jungle road, kicking up small clouds of dust and loose earth from its tires."
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be a multiple of 12 plus 6, for example 6, 18, 30, 42, etc.",
        "required": false,
        "minimum": 18,
        "maximum": 162,
        "default": 78
      },
      "seed": {
        "type": null,
        "description": "Seed for the video-to-video generation.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "beatoven/sound-effect-generation",
    "title": "Sound Effect Generation",
    "category": "text-to-audio",
    "description": "Create professional-grade sound effects from animal and vehicle to nature, sci-fi, and otherworldly sounds. Perfect for films, games, and digital content.",
    "tags": [
      "sfx",
      "audio",
      "effects",
      "speech"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/SV2axpXDRJpr3LamW4PGo_9bca6ced-1271-4fbf-9869-c8db8ff81977.png",
    "playgroundUrl": "https://fal.ai/models/beatoven/sound-effect-generation",
    "documentationUrl": "https://fal.ai/models/beatoven/sound-effect-generation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Describe the sound effect you want to generate",
        "required": true,
        "examples": [
          "Powerful helicopter takeoff: rapidly building rotor blades whirring and chopping, increasing engine whine, ground vibrations.",
          "A futuristic spaceship door opening",
          "A cinematic explosion with debris falling",
          "Rain falling on a window pane",
          "Footsteps on gravel"
        ]
      },
      "duration": {
        "type": "number",
        "description": "Length of the generated sound effect in seconds",
        "required": false,
        "minimum": 1,
        "maximum": 35,
        "default": 5,
        "examples": [
          7,
          10,
          20,
          30
        ]
      },
      "refinement": {
        "type": "integer",
        "description": "Refinement level - Higher values may improve quality but take longer",
        "required": false,
        "minimum": 10,
        "maximum": 200,
        "default": 40,
        "examples": [
          40,
          70,
          100,
          200
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible results - leave empty for random generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Describe the types of sounds you don't want to generate in the output, avoid double-negatives, compare with positive prompts",
        "required": false,
        "default": "",
        "examples": [
          "Low-pitched hum",
          "High-pitched screech, rain, wind",
          "Thunder, lightning",
          "traffic, people speaking",
          "Soft whisper"
        ]
      },
      "creativity": {
        "type": "number",
        "description": "Creativity level - higher values allow more creative interpretation of the prompt",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 16,
        "examples": [
          16,
          14,
          10
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The processed prompt used for generation"
      },
      "metadata": {
        "type": "object",
        "description": "Generation metadata including duration, sample rate, and parameters"
      },
      "audio": {
        "type": null,
        "description": "Generated audio file in WAV format"
      }
    }
  },
  {
    "id": "beatoven/music-generation",
    "title": "Music Generation",
    "category": "text-to-audio",
    "description": "Generate royalty-free instrumental music from electronic, hip hop, and indie rock to cinematic and classical genres. Perfect for games, films, social content, podcasts, and more.",
    "tags": [
      "speech",
      "audio",
      "music"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/-fqZhGXxiW3usZOZ267NO_9c5cd9c1-62d9-4ed9-8c8e-3c148614c137.png",
    "playgroundUrl": "https://fal.ai/models/beatoven/music-generation",
    "documentationUrl": "https://fal.ai/models/beatoven/music-generation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Describe the music you want to generate",
        "required": true,
        "examples": [
          "Jazz music for a late-night restaurant setting",
          "A lush, ambient soundscape featuring serene sounds, and a gentle, melancholic piano melody",
          "Hip-hop music, mellow keys and vinyl crackle",
          "House music with synthesizers, driving bass and a steady 4/4 beat",
          "Classical piano melody with emotional depth and gentle strings"
        ]
      },
      "duration": {
        "type": "number",
        "description": "Length of the generated music in seconds",
        "required": false,
        "minimum": 5,
        "maximum": 150,
        "default": 90,
        "examples": [
          90,
          47,
          150
        ]
      },
      "refinement": {
        "type": "integer",
        "description": "Refinement level - higher values may improve quality but take longer",
        "required": false,
        "minimum": 10,
        "maximum": 200,
        "default": 100,
        "examples": [
          100,
          200
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible results - leave empty for random generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Describe what you want to avoid in the music (instruments, styles, moods). Leave blank for none.",
        "required": false,
        "default": "",
        "examples": [
          "noise",
          "distortion",
          "heavy drums",
          "high-hats"
        ]
      },
      "creativity": {
        "type": "number",
        "description": "Creativity level - higher values allow more creative interpretation of the prompt",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 16,
        "examples": [
          16,
          14,
          11
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The processed prompt used for generation"
      },
      "metadata": {
        "type": "object",
        "description": "Generation metadata including duration, sample rate, and parameters"
      },
      "audio": {
        "type": null,
        "description": "Generated audio file in WAV format"
      }
    }
  },
  {
    "id": "fal-ai/meshy/v5/retexture",
    "title": "Meshy 5 Retexture",
    "category": "3d-to-3d",
    "description": "Meshy-5 retexture applies new, high-quality textures to existing 3D models using either text prompts or reference images. It supports PBR material generation for realistic, production-ready results.",
    "tags": [
      "3d-to-3d"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/mF5SI-u0DJ_bNr5J8nhsS_0d2ff4c4ea6a4733a169f8b530b576ec.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/meshy/v5/retexture",
    "documentationUrl": "https://fal.ai/models/fal-ai/meshy/v5/retexture/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "enable_pbr": {
        "type": "boolean",
        "description": "Generate PBR Maps (metallic, roughness, normal) in addition to base color.",
        "required": false,
        "default": false
      },
      "text_style_prompt": {
        "type": "string",
        "description": "Describe your desired texture style using text. Maximum 600 characters. Required if image_style_url is not provided.",
        "required": false,
        "maxLength": 600,
        "examples": [
          "red and black chest"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": true
      },
      "enable_original_uv": {
        "type": "boolean",
        "description": "Use the original UV mapping of the model instead of generating new UVs. If the model has no original UV, output quality may be reduced.",
        "required": false,
        "default": true
      },
      "model_url": {
        "type": "string",
        "description": "URL or base64 data URI of a 3D model to texture. Supports .glb, .gltf, .obj, .fbx, .stl formats. Can be a publicly accessible URL or data URI with MIME type application/octet-stream.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/penguin/DId89qXLu6BXu09RFAwAV_model.glb"
        ]
      },
      "image_style_url": {
        "type": "string",
        "description": "2D image to guide the texturing process. Supports .jpg, .jpeg, and .png formats. Required if text_style_prompt is not provided. If both are provided, image_style_url takes precedence.",
        "required": false
      }
    },
    "outputParameters": {
      "model_urls": {
        "type": null,
        "description": "URLs for different 3D model formats"
      },
      "text_style_prompt": {
        "type": "string",
        "description": "The text prompt used for texturing (if provided)"
      },
      "texture_urls": {
        "type": "array",
        "description": "Array of texture file objects",
        "items": {
          "$ref": "#/components/schemas/TextureFiles"
        }
      },
      "thumbnail": {
        "type": null,
        "description": "Preview thumbnail of the retextured model"
      },
      "image_style_url": {
        "type": "string",
        "description": "The image URL used for texturing (if provided)"
      },
      "model_glb": {
        "type": null,
        "description": "Retextured 3D object in GLB format."
      }
    }
  },
  {
    "id": "fal-ai/meshy/v5/remesh",
    "title": "Meshy 5 Remesh",
    "category": "3d-to-3d",
    "description": "Meshy-5 remesh allows you to remesh and export existing 3D models into various formats",
    "tags": [
      "3d-to-3d"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/VuvDG9KC4adICrWIBIzIu_a731968003db42be8f2c91d1f00c811f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/meshy/v5/remesh",
    "documentationUrl": "https://fal.ai/models/fal-ai/meshy/v5/remesh/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "resize_height": {
        "type": "number",
        "description": "Resize the model to a certain height measured in meters. Set to 0 for no resizing.",
        "required": false,
        "minimum": 0,
        "default": 0
      },
      "topology": {
        "type": "string",
        "description": "Specify the topology of the generated model. Quad for smooth surfaces, Triangle for detailed geometry.",
        "required": false,
        "enum": [
          "quad",
          "triangle"
        ],
        "default": "triangle",
        "examples": [
          "triangle"
        ]
      },
      "target_polycount": {
        "type": "integer",
        "description": "Target number of polygons in the generated model. Actual count may vary based on geometry complexity.",
        "required": false,
        "minimum": 100,
        "maximum": 300000,
        "default": 30000,
        "examples": [
          137220
        ]
      },
      "model_url": {
        "type": "string",
        "description": "URL or base64 data URI of a 3D model to remesh. Supports .glb, .gltf, .obj, .fbx, .stl formats. Can be a publicly accessible URL or data URI with MIME type application/octet-stream.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/tiger/62QMEQqZ3pjUds4DfuVtX_model.glb"
        ]
      },
      "origin_at": {
        "type": "string",
        "description": "Position of the origin. None means no effect.",
        "required": false,
        "enum": [
          "bottom",
          "center"
        ]
      },
      "target_formats": {
        "type": "array",
        "description": "List of target formats for the remeshed model.",
        "required": false,
        "default": [
          "glb"
        ],
        "examples": [
          [
            "glb",
            "fbx"
          ]
        ],
        "items": {
          "enum": [
            "glb",
            "fbx",
            "obj",
            "usdz",
            "blend",
            "stl"
          ],
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "model_urls": {
        "type": null,
        "description": "URLs for different 3D model formats"
      },
      "model_glb": {
        "type": null,
        "description": "Remeshed 3D object in GLB format (if GLB was requested)."
      }
    }
  },
  {
    "id": "fal-ai/reve/remix",
    "title": "Reve",
    "category": "image-to-image",
    "description": "Reve’s remix model lets you upload an reference images and then combine/transform them via a text prompt",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/dMdAAEUeDONnrgO8mADcY_7cd44920d5e44ebeaa2d125d41bc75bb.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/reve/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/reve/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "3:2",
          "2:3",
          "4:3",
          "3:4",
          "1:1"
        ],
        "examples": [
          "16:9"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.",
        "required": true,
        "minLength": 1,
        "maxLength": 2560,
        "examples": [
          "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
        ]
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of reference images. Must provide between 1 and 4 images (inclusive). Each image must be less than 1.5 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
        "required": true,
        "examples": [
          [
            "https://v3b.fal.media/files/b/monkey/lsPBOhBws_FnTzd5G9KZ9_seedream4_edit_input_4.png",
            "https://v3b.fal.media/files/b/monkey/ZrW5ouDj8vjLtvl1Cj9l9_seedream4_edit_input_2.png",
            "https://v3b.fal.media/files/b/elephant/sd0k6YhlQEKfR6d_hAmIH_seedream4_edit_input_3.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "png",
        "examples": [
          "png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The remixed images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/reve/text-to-image",
    "title": "Reve",
    "category": "text-to-image",
    "description": "Reve’s text-to-image model generates detailed visual output that closely follow your instructions, with strong aesthetic quality and accurate text rendering.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/jNWFUrGVBR4OL3rF3KBZp_f7c2b693436142a3bd3bd012ee26342c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/reve/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/reve/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The desired aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "3:2",
          "2:3",
          "4:3",
          "3:4",
          "1:1"
        ],
        "default": "3:2",
        "examples": [
          "16:9"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text description of the desired image.",
        "required": true,
        "minLength": 1,
        "maxLength": 2560,
        "examples": [
          "A serene mountain landscape at sunset with snow-capped peaks"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "png",
        "examples": [
          "png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/reve/edit",
    "title": "Reve",
    "category": "image-to-image",
    "description": "Reve’s edit model lets you upload an existing image and then transform it via a text prompt",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/YAlxwxUbRgskrtV0PhkyL_d163391caef14a548907336e32899ee2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/reve/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/reve/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text description of how to edit the provided image.",
        "required": true,
        "minLength": 1,
        "maxLength": 2560,
        "examples": [
          "Give him a friend"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "png",
        "examples": [
          "png"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/koala/sZE6zNTKjOKc4kcUdVlu__26bac54c-3e94-43e9-aeff-f2efc2631ef0.webp"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The edited images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/wan-alpha",
    "title": "Wan Alpha",
    "category": "text-to-video",
    "description": "Generate videos with transparent backgrounds",
    "tags": [
      "transparent",
      "alpha"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/3oIcvX_9oIQh2cDai8geS_59a419be75fb46c5bd8094bb50e9cabf.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-alpha",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-alpha/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to guide the video generation.",
        "required": true,
        "examples": [
          "Medium shot. A little girl holds a bubble wand and blows out colorful bubbles that float and pop in the air. The background of this video is transparent. Realistic style."
        ]
      },
      "shift": {
        "type": "number",
        "description": "The shift of the generated video.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 10.5
      },
      "mask_clamp_upper": {
        "type": "number",
        "description": "The upper bound of the mask clamping.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "fps": {
        "type": "integer",
        "description": "The frame rate of the generated video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 16
      },
      "mask_clamp_lower": {
        "type": "number",
        "description": "The lower bound of the mask clamping.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 17,
        "maximum": 121,
        "default": 81
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable safety checker.",
        "required": false,
        "default": true
      },
      "mask_binarization_threshold": {
        "type": "number",
        "description": "The threshold for mask binarization. When binarize_mask is True, this threshold will be used to binarize the mask. This will also be used for transparency when the output type is `.webm`.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "binarize_mask": {
        "type": "boolean",
        "description": "Whether to binarize the mask.",
        "required": false,
        "default": false
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video.",
        "required": false,
        "enum": [
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "480p"
      },
      "video_output_type": {
        "type": "string",
        "description": "The output type of the generated video.",
        "required": false,
        "enum": [
          "X264 (.mp4)",
          "VP9 (.webm)",
          "PRORES4444 (.mov)",
          "GIF (.gif)"
        ],
        "default": "VP9 (.webm)"
      },
      "sampler": {
        "type": "string",
        "description": "The sampler to use.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "euler"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "16:9"
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "The seed for the random number generator.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to use.",
        "required": false,
        "minimum": 2,
        "maximum": 16,
        "default": 8
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "image": {
        "type": null,
        "description": "The generated image file."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "mask": {
        "type": null,
        "description": "The generated mask file."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "mirelo-ai/sfx-v1.5/video-to-audio",
    "title": "Mirelo SFX V1.5",
    "category": "video-to-audio",
    "description": "Generate synced sounds for any video, and return the new sound track (like MMAudio)",
    "tags": [
      "video-to-audio",
      "sfx"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/wwhXRNDWSVEdS9jIG6BAA_b1d337ecdccb441aa80caab321487fb7.jpg",
    "playgroundUrl": "https://fal.ai/models/mirelo-ai/sfx-v1.5/video-to-audio",
    "documentationUrl": "https://fal.ai/models/mirelo-ai/sfx-v1.5/video-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_samples": {
        "type": null,
        "description": "The number of samples to generate from the model",
        "required": false,
        "default": 2
      },
      "duration": {
        "type": null,
        "description": "The duration of the generated audio in seconds",
        "required": false,
        "default": 10
      },
      "start_offset": {
        "type": null,
        "description": "The start offset in seconds to start the audio generation from",
        "required": false,
        "default": 0
      },
      "video_url": {
        "type": "string",
        "description": "A video url that can accessed from the API to process and add sound effects",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://di3otfzjg1gxa.cloudfront.net/battlefield_scene_silent.mp4"
        ]
      },
      "seed": {
        "type": null,
        "description": "The seed to use for the generation. If not provided, a random seed will be used",
        "required": false,
        "default": 8069
      },
      "text_prompt": {
        "type": null,
        "description": "Additional description to guide the model",
        "required": false,
        "examples": [
          ""
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": "array",
        "description": "The generated sound effects audio",
        "items": {
          "$ref": "#/components/schemas/Audio-Output"
        }
      }
    }
  },
  {
    "id": "mirelo-ai/sfx-v1.5/video-to-video",
    "title": "Mirelo SFX V1.5",
    "category": "video-to-video",
    "description": "Generate synced sounds for any video, and return it with its new sound track (like MMAudio)",
    "tags": [
      "video-to-video",
      "sfx"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/ySuE0GYF98p7-856X4mvc_9371de55f14448e08b76871b7d77c059.jpg",
    "playgroundUrl": "https://fal.ai/models/mirelo-ai/sfx-v1.5/video-to-video",
    "documentationUrl": "https://fal.ai/models/mirelo-ai/sfx-v1.5/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_samples": {
        "type": null,
        "description": "The number of samples to generate from the model",
        "required": false,
        "default": 2
      },
      "duration": {
        "type": null,
        "description": "The duration of the generated audio in seconds",
        "required": false,
        "default": 10
      },
      "start_offset": {
        "type": null,
        "description": "The start offset in seconds to start the audio generation from",
        "required": false,
        "default": 0
      },
      "video_url": {
        "type": "string",
        "description": "A video url that can accessed from the API to process and add sound effects",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://di3otfzjg1gxa.cloudfront.net/battlefield_scene_silent.mp4"
        ]
      },
      "seed": {
        "type": null,
        "description": "The seed to use for the generation. If not provided, a random seed will be used",
        "required": false,
        "default": 8069
      },
      "text_prompt": {
        "type": null,
        "description": "Additional description to guide the model",
        "required": false,
        "examples": [
          ""
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": "array",
        "description": "The processed video with sound effects",
        "items": {
          "$ref": "#/components/schemas/Video-Output"
        }
      }
    }
  },
  {
    "id": "fal-ai/krea-wan-14b/video-to-video",
    "title": "Krea Wan 14B",
    "category": "video-to-video",
    "description": "Superfast video model based on Wan 2.1 14b by Krea, excelling at real-time video-editing.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/3KnxV95bno9CU_SVwV0t8_aff74947261f49b4bf8a51a050881c86.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/krea-wan-14b/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/krea-wan-14b/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt for the video-to-video generation.",
        "required": true,
        "examples": [
          "A powerful, matte black jeep, its robust frame contrasting with the lush green surroundings, navigates a winding jungle road, kicking up small clouds of dust and loose earth from its tires."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video. Currently, only outputs of 16:9 aspect ratio and 480p resolution are supported. Video duration should be less than 1000 frames at 16fps, and output frames will be 6 plus a multiple of 12, for example 18, 30, 42, etc.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/krea_wan_14b_v2v_input.mp4"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Denoising strength for the video-to-video generation. 0.0 preserves the original, 1.0 completely remakes the video.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": null,
        "description": "Seed for the video-to-video generation.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/image2pixel",
    "title": "Image2Pixel",
    "category": "image-to-image",
    "description": "Turn images into pixel-perfect retro art",
    "tags": [
      "post-processing",
      "pixel-art"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/9MSg8Fm_djrKJ76DtwZrx_0ebf4aa3ab1540298b3fcf4593cfd606.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image2pixel",
    "documentationUrl": "https://fal.ai/models/fal-ai/image2pixel/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "cleanup_morph": {
        "type": "boolean",
        "description": "Apply morphological operations to remove noise.",
        "required": false,
        "default": false
      },
      "auto_color_detect": {
        "type": "boolean",
        "description": "Enable automatic detection of optimal number of colors.",
        "required": false,
        "default": false
      },
      "alpha_threshold": {
        "type": "integer",
        "description": "Alpha binarization threshold (0-255).",
        "required": false,
        "minimum": 0,
        "maximum": 255,
        "default": 128
      },
      "snap_grid": {
        "type": "boolean",
        "description": "Align output to the pixel grid.",
        "required": false,
        "default": true
      },
      "fixed_palette": {
        "type": null,
        "description": "Optional fixed color palette as hex strings (e.g., ['#000000', '#ffffff']).",
        "required": false
      },
      "scale": {
        "type": null,
        "description": "Force a specific pixel scale. If None, auto-detect.",
        "required": false
      },
      "cleanup_jaggy": {
        "type": "boolean",
        "description": "Remove isolated diagonal pixels (jaggy edge cleanup).",
        "required": false,
        "default": false
      },
      "trim_borders": {
        "type": "boolean",
        "description": "Trim borders of the image.",
        "required": false,
        "default": false
      },
      "background_tolerance": {
        "type": "integer",
        "description": "Background tolerance (0-255).",
        "required": false,
        "minimum": 0,
        "maximum": 255,
        "default": 0
      },
      "detect_method": {
        "type": "string",
        "description": "Scale detection method to use.",
        "required": false,
        "enum": [
          "auto",
          "runs",
          "edge"
        ],
        "default": "auto"
      },
      "transparent_background": {
        "type": "boolean",
        "description": "Remove background of the image. This will check for contiguous color regions from the edges after correction and make them transparent.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to process into improved pixel art",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/image2pixel-input.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "downscale_method": {
        "type": "string",
        "description": "Downscaling method to produce the pixel-art output.",
        "required": false,
        "enum": [
          "dominant",
          "median",
          "mode",
          "mean",
          "content-adaptive"
        ],
        "default": "dominant"
      },
      "background_mode": {
        "type": "string",
        "description": "Controls where to flood-fill from when removing the background.",
        "required": false,
        "enum": [
          "edges",
          "corners",
          "midpoints"
        ],
        "default": "corners"
      },
      "max_colors": {
        "type": null,
        "description": "Maximum number of colors in the output palette. Set None to disable limit.",
        "required": false,
        "default": 32
      },
      "dominant_color_threshold": {
        "type": "number",
        "description": "Dominant color threshold (0.0-1.0).",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.05
      }
    },
    "outputParameters": {
      "palette": {
        "type": "array",
        "description": "The palette of the processed media.",
        "items": {
          "type": "string"
        }
      },
      "num_colors": {
        "type": "integer",
        "description": "The number of colors in the processed media."
      },
      "images": {
        "type": "array",
        "description": "The processed pixel-art image (PNG) and the scaled image (PNG).",
        "items": {
          "$ref": "#/components/schemas/ImageFile"
        }
      },
      "pixel_scale": {
        "type": "integer",
        "description": "The detected pixel scale of the input."
      }
    }
  },
  {
    "id": "fal-ai/kandinsky5/text-to-video/distill",
    "title": "Kandinsky5",
    "category": "text-to-video",
    "description": "Kandinsky 5.0 Distilled is a lightweight diffusion model for fast, high-quality text-to-video generation.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/TyHaKAdxHRg3VIjUlKZPI_674ee5ee1f2d467e9f3806531f85dee2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kandinsky5/text-to-video/distill",
    "documentationUrl": "https://fal.ai/models/fal-ai/kandinsky5/text-to-video/distill/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A dog in red hat"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The length of the video to generate (5s or 10s)",
        "required": false,
        "enum": [
          "5s",
          "10s"
        ],
        "default": "5s",
        "examples": [
          "5s",
          "10s"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).",
        "required": false,
        "enum": [
          "768x512"
        ],
        "default": "768x512"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
        "required": false,
        "enum": [
          "3:2",
          "1:1",
          "2:3"
        ],
        "default": "3:2"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/kandinsky5/text-to-video",
    "title": "Kandinsky5",
    "category": "text-to-video",
    "description": "Kandinsky 5.0 is a diffusion model for fast, high-quality text-to-video  generation.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/F-LagExgsZASG2uyIcj6X_093dccc7417c47e593e245767017f251.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kandinsky5/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kandinsky5/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A dog in red hat"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The length of the video to generate (5s or 10s)",
        "required": false,
        "enum": [
          "5s",
          "10s"
        ],
        "default": "5s",
        "examples": [
          "5s",
          "10s"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).",
        "required": false,
        "enum": [
          "768x512"
        ],
        "default": "768x512"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
        "required": false,
        "enum": [
          "3:2",
          "1:1",
          "2:3"
        ],
        "default": "3:2"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/dreamomni2/edit",
    "title": "DreamOmni2",
    "category": "image-to-image",
    "description": "DreamOmni2 is a unified multimodal model for text and image guided image editing.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/panda/c4tQDAqMyMQ_6-LNFzCyj_13c4f35481fc4ebaaf4fddf9a5d86ddc.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dreamomni2/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/dreamomni2/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image.",
        "required": true,
        "examples": [
          "Replace the first image have the same image style as the second image."
        ]
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of input images for editing.",
        "required": true,
        "examples": [
          [
            "https://v3b.fal.media/files/b/koala/HB33rtG0ue7KzcIdQOTTX_dreamomni_ref_0.jpg",
            "https://v3b.fal.media/files/b/koala/BJMlXeNzOgGzyoO7XyGxr_dreamomni_ref_1.jpg"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Generated image"
      }
    }
  },
  {
    "id": "fal-ai/moondream3-preview/detect",
    "title": "Moondream3 Preview [Detect]",
    "category": "vision",
    "description": "Moondream 3 is a vision language model that brings frontier-level visual reasoning with native object detection, pointing, and OCR capabilities to real-world applications requiring fast, inexpensive inference at scale.",
    "tags": [
      "Vision"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/penguin/Ma6NXbAm7Gi18CcciKraL_c5133f964896437ca8fdb88652c1a3b9.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream3-preview/detect",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream3-preview/detect/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Object to be detected in the image",
        "required": true,
        "minLength": 1,
        "examples": [
          "Speed limit"
        ]
      },
      "preview": {
        "type": "boolean",
        "description": "Whether to preview the output",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/detect_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "finish_reason": {
        "type": "string",
        "description": "Reason for finishing the output generation"
      },
      "image": {
        "type": null,
        "description": "Image with bounding boxes drawn around detected objects"
      },
      "objects": {
        "type": "array",
        "description": "List of detected objects with their bounding boxes",
        "items": {
          "$ref": "#/components/schemas/Object"
        }
      },
      "usage_info": {
        "type": null,
        "description": "Usage information for the request"
      }
    }
  },
  {
    "id": "fal-ai/moondream3-preview/point",
    "title": "Moondream3 Preview [Point]",
    "category": "vision",
    "description": "Moondream 3 is a vision language model that brings frontier-level visual reasoning with native object detection, pointing, and OCR capabilities to real-world applications requiring fast, inexpensive inference at scale.",
    "tags": [
      "Vision"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/koala/r903D3raEamwM13Bmn1Lp_fa12f25ab96c41008fc48492bbdbbea2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream3-preview/point",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream3-preview/point/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Object to be located in the image",
        "required": true,
        "minLength": 1,
        "examples": [
          "bottle caps"
        ]
      },
      "preview": {
        "type": "boolean",
        "description": "Whether to preview the output",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/point_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "points": {
        "type": "array",
        "description": "List of points marking the detected objects",
        "items": {
          "$ref": "#/components/schemas/Point"
        }
      },
      "finish_reason": {
        "type": "string",
        "description": "Reason for finishing the output generation"
      },
      "image": {
        "type": null,
        "description": "Image with points drawn on detected objects"
      },
      "usage_info": {
        "type": null,
        "description": "Usage information for the request"
      }
    }
  },
  {
    "id": "fal-ai/moondream3-preview/query",
    "title": "Moondream 3 Preview [Query]",
    "category": "vision",
    "description": "Moondream 3 is a vision language model that brings frontier-level visual reasoning with native object detection, pointing, and OCR capabilities to real-world applications requiring fast, inexpensive inference at scale.",
    "tags": [
      "Vision"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/nWpJhvShCa7NcOUhC0JJ-_7dec4ab5fb2c49869d74af99dfa66bf4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream3-preview/query",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream3-preview/query/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Query to be asked in the image",
        "required": true,
        "minLength": 1,
        "examples": [
          "List the safety measures taken by this worker in a JSON array under `safety_measures` key"
        ]
      },
      "top_p": {
        "type": "number",
        "description": "Nucleus sampling probability mass to use, between 0 and 1.",
        "required": false,
        "minimum": 0,
        "maximum": 1
      },
      "temperature": {
        "type": "number",
        "description": "Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0.",
        "required": false,
        "minimum": 0,
        "maximum": 1
      },
      "reasoning": {
        "type": "boolean",
        "description": "Whether to include detailed reasoning behind the answer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/query_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "finish_reason": {
        "type": "string",
        "description": "Reason for finishing the output generation"
      },
      "output": {
        "type": "string",
        "description": "Answer to the query about the image"
      },
      "reasoning": {
        "type": "string",
        "description": "Detailed reasoning behind the answer, if enabled"
      },
      "usage_info": {
        "type": null,
        "description": "Usage information for the request"
      }
    }
  },
  {
    "id": "fal-ai/moondream3-preview/caption",
    "title": "Moondream3 Preview [Caption]",
    "category": "vision",
    "description": "Moondream 3 is a vision language model that brings frontier-level visual reasoning with native object detection, pointing, and OCR capabilities to real-world applications requiring fast, inexpensive inference at scale.",
    "tags": [
      "Vision"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/elephant/MThU-RSBqLWpvP60bOvk__d2902b4bea314d49bb01fe92584a0922.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream3-preview/caption",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream3-preview/caption/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "top_p": {
        "type": "number",
        "description": "Nucleus sampling probability mass to use, between 0 and 1.",
        "required": false,
        "minimum": 0,
        "maximum": 1
      },
      "length": {
        "type": "string",
        "description": "Length of the caption to generate",
        "required": false,
        "enum": [
          "short",
          "normal",
          "long"
        ],
        "default": "normal"
      },
      "temperature": {
        "type": "number",
        "description": "Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0.",
        "required": false,
        "minimum": 0,
        "maximum": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/caption_in.jpg"
        ]
      }
    },
    "outputParameters": {
      "finish_reason": {
        "type": "string",
        "description": "Reason for finishing the output generation"
      },
      "output": {
        "type": "string",
        "description": "Generated caption for the image"
      },
      "usage_info": {
        "type": null,
        "description": "Usage information for the request"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/video-to-audio",
    "title": "Kling Video",
    "category": "video-to-audio",
    "description": "Generate audio from input videos using Kling",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/UcIrV8sk1rLDIZAkPoW75_32e8d2d3f8de429aa32f3f35b595d5ac.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/video-to-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/video-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The video URL to extract audio from. Only .mp4/.mov formats are supported. File size does not exceed 100MB. Video duration between 3.0s and 20.0s.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/kling/kling-v2.5-turbo-pro-image-to-video-output.mp4"
        ]
      },
      "asmr_mode": {
        "type": "boolean",
        "description": "Enable ASMR mode. This mode enhances detailed sound effects and is suitable for highly immersive content scenarios.",
        "required": false,
        "default": false
      },
      "background_music_prompt": {
        "type": "string",
        "description": "Background music prompt. Cannot exceed 200 characters.",
        "required": false,
        "maxLength": 200,
        "default": "intense car race"
      },
      "sound_effect_prompt": {
        "type": "string",
        "description": "Sound effect prompt. Cannot exceed 200 characters.",
        "required": false,
        "maxLength": 200,
        "default": "Car tires screech as they accelerate in a drag race"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The original video with dubbed audio applied"
      },
      "audio": {
        "type": null,
        "description": "The extracted/generated audio from the video in MP3 format"
      }
    }
  },
  {
    "id": "fal-ai/sora-2/video-to-video/remix",
    "title": "Sora 2",
    "category": "video-to-video",
    "description": "Video-to-video remix endpoint for Sora 2, OpenAI’s advanced model that transforms existing videos based on new text or image prompts allowing rich edits, style changes, and creative reinterpretations while preserving motion and structure",
    "tags": [
      "video to video",
      "audio",
      "sora",
      ""
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/Wz6FyBTYFs2Lf8e9AoXED_966c4e27910e4979b2628d5666dd2ea0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sora-2/video-to-video/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/sora-2/video-to-video/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Updated text prompt that directs the remix generation",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Change the cat's fur color to purple."
        ]
      },
      "video_id": {
        "type": "string",
        "description": "The video_id from a previous Sora 2 generation. Note: You can only remix videos that were generated by Sora (via text-to-video or image-to-video endpoints), not arbitrary uploaded videos.",
        "required": true,
        "examples": [
          "video_123"
        ]
      },
      "api_key": {
        "type": "string",
        "description": "The API key to use for the OpenAI API. If provided, you will not be billed for the request.",
        "required": false
      }
    },
    "outputParameters": {
      "video_id": {
        "type": "string",
        "description": "The ID of the generated video"
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1/fast/first-last-frame-to-video",
    "title": "Veo 3.1 Fast",
    "category": "image-to-video",
    "description": "Generate videos from a first/last frame using Google's Veo 3.1 Fast",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/8tRJcj1P_EtIcpbdkP3m7_f9984366e4054165a8919d0671acbcb3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1/fast/first-last-frame-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/fast/first-last-frame-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3.1 First-Last-Frame-to-Video on Fal? It's incredible!\""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "auto"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "first_frame_url": {
        "type": "string",
        "description": "URL of the first frame of the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-1.jpeg"
        ]
      },
      "last_frame_url": {
        "type": "string",
        "description": "URL of the last frame of the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-2.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1/first-last-frame-to-video",
    "title": "Veo 3.1",
    "category": "image-to-video",
    "description": "Generate videos from a first and last framed using Google's Veo 3.1",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/5YSsAJ8Fbwuj97_9vBiTW.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1/first-last-frame-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/first-last-frame-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3.1 First-Last-Frame-to-Video on Fal? It's incredible!\""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "auto"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "first_frame_url": {
        "type": "string",
        "description": "URL of the first frame of the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-1.jpeg"
        ]
      },
      "last_frame_url": {
        "type": "string",
        "description": "URL of the last frame of the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-2.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1/reference-to-video",
    "title": "Veo 3.1",
    "category": "image-to-video",
    "description": "Generate Videos from images using Google's Veo 3.1",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/IwzOGSbzp6e8N00QuLtFF_129417bb24f248298e95c3fa2b1b82fb.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1/reference-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/reference-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "A graceful ballerina dancing outside a circus tent on green grass, with colorful wildflowers swaying around her as she twirls and poses in the meadow."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "image_urls": {
        "type": "array",
        "description": "URLs of the reference images to use for consistent subject appearance",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-r2v-input-1.png",
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-r2v-input-2.png",
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-r2v-input-3.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1/fast",
    "title": "Veo 3.1 Fast",
    "category": "text-to-video",
    "description": "Faster and more cost effective version of Google's Veo 3.1! ",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/o5x4rjXr3fAEwQgr4Y5vp_69ee214c658e428ba2f8f8b054d70a0e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "Two person street interview in New York City.\nSample Dialogue:\nHost: \"Did you hear the news?\"\nPerson: \"Yes! Veo 3.1 is now available on fal. If you want to see it, go check their website.\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
        "required": false,
        "enum": [
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "16:9"
      },
      "auto_fix": {
        "type": "boolean",
        "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
        "required": false,
        "default": true
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "4s",
          "6s",
          "8s"
        ],
        "default": "8s"
      },
      "seed": {
        "type": "integer",
        "description": "A seed to use for the video generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the video generation",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the video generation",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1/fast/image-to-video",
    "title": "Veo 3.1 Fast",
    "category": "image-to-video",
    "description": "Generate videos from your image prompts using Veo 3.1 fast.",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/CcVVXXOo5stpgsAJV_6UO_74aa2dbdc79447e7ae69b533a7863038.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1/fast/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/fast/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "A monkey and polar bear host a casual podcast about AI inference, bringing their unique perspectives from different environments (tropical vs. arctic) to discuss how AI systems make decisions and process information.\nSample Dialogue:\nMonkey (Banana): \"Welcome back to Bananas & Ice! I am Banana\"\nPolar Bear (Ice): \"And I'm Ice!\""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/elephant/eeZYKGpxiSM7BInbOEx8n_f90f0805d51f4dd0b5c95eabb7b294e5.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1/image-to-video",
    "title": "Veo 3.1",
    "category": "image-to-video",
    "description": "Veo 3.1 is the latest state-of-the art video generation model from Google DeepMind",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/zebra/G680VZS5VpMMQO1pSt2uj_dfbae33f738344aa98a62cf2022c427c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "A monkey and polar bear host a casual podcast about AI inference, bringing their unique perspectives from different environments (tropical vs. arctic) to discuss how AI systems make decisions and process information.\nSample Dialogue:\nMonkey (Banana): \"Welcome back to Bananas & Ice! I am Banana\"\nPolar Bear (Ice): \"And I'm Ice!\""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/elephant/eeZYKGpxiSM7BInbOEx8n_f90f0805d51f4dd0b5c95eabb7b294e5.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/veo3.1",
    "title": "Veo 3.1",
    "category": "text-to-video",
    "description": "Veo 3.1 by Google, the most advanced AI video generation model in the world. With sound on!",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/TGTZBJyLk9HdwjB6SB90e.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3.1",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3.1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "examples": [
          "Two person street interview in New York City.\nSample Dialogue:\nHost: \"Did you hear the news?\"\nPerson: \"Yes! Veo 3.1 is now available on fal. If you want to see it, go check their website.\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
        "required": false,
        "enum": [
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "16:9"
      },
      "auto_fix": {
        "type": "boolean",
        "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
        "required": false,
        "default": true
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "4s",
          "6s",
          "8s"
        ],
        "default": "8s"
      },
      "seed": {
        "type": "integer",
        "description": "A seed to use for the video generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the video generation",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the video generation",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-part",
    "title": "Hunyuan Part",
    "category": "3d-to-3d",
    "description": "Use the capabilities of hunyuan part to generate point clouds from your 3D files.",
    "tags": [
      "3D-to-3D",
      "point-cloud"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/kqnsD6bjfNsg7OSwKze0X_365d05fbfc8b4e5a865e702a4fa15805.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-part",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-part/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "point_prompt_x": {
        "type": "number",
        "description": "X coordinate of the point prompt for segmentation (normalized space -1 to 1).",
        "required": false,
        "minimum": -1,
        "maximum": 1,
        "default": 0
      },
      "point_prompt_z": {
        "type": "number",
        "description": "Z coordinate of the point prompt for segmentation (normalized space -1 to 1).",
        "required": false,
        "minimum": -1,
        "maximum": 1,
        "default": 0
      },
      "use_normal": {
        "type": "boolean",
        "description": "Whether to use normal information for segmentation.",
        "required": false,
        "default": true
      },
      "noise_std": {
        "type": "number",
        "description": "Standard deviation of noise to add to sampled points.",
        "required": false,
        "minimum": 0,
        "maximum": 0.02,
        "default": 0
      },
      "point_num": {
        "type": "integer",
        "description": "Number of points to sample from the mesh.",
        "required": false,
        "minimum": 10000,
        "maximum": 500000,
        "default": 100000
      },
      "model_file_url": {
        "type": "string",
        "description": "URL of the 3D model file (.glb or .obj) to process for segmentation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/base_basic_shaded.glb"
        ]
      },
      "point_prompt_y": {
        "type": "number",
        "description": "Y coordinate of the point prompt for segmentation (normalized space -1 to 1).",
        "required": false,
        "minimum": -1,
        "maximum": 1,
        "default": 0
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and input will produce the same segmentation results.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "iou_scores": {
        "type": "array",
        "description": "IoU scores for each of the three masks.",
        "items": {
          "type": "number"
        }
      },
      "best_mask_index": {
        "type": "integer",
        "description": "Index of the best mask (1, 2, or 3) based on IoU score."
      },
      "mask_2_mesh": {
        "type": null,
        "description": "Mesh showing segmentation mask 2."
      },
      "mask_1_mesh": {
        "type": null,
        "description": "Mesh showing segmentation mask 1."
      },
      "segmented_mesh": {
        "type": null,
        "description": "Segmented 3D mesh with mask applied."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      },
      "mask_3_mesh": {
        "type": null,
        "description": "Mesh showing segmentation mask 3."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-apps/long-reframe",
    "title": "Wan 2.1 VACE Long Reframe",
    "category": "video-to-video",
    "description": "Reframe entire videos scene-by-scene using Wan VACE 2.1",
    "tags": [],
    "thumbnailUrl": "https://v3b.fal.media/files/b/monkey/djppEVsT608o2Uk-qVVnF_db844977aa314ad4aed7f765afde7a2a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-apps/long-reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-apps/long-reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation. Optional for reframing.",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. This video will be used as a reference for the reframe task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4"
        ]
      },
      "zoom_factor": {
        "type": "number",
        "description": "Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.",
        "required": false,
        "minimum": 0,
        "maximum": 0.9,
        "default": 0,
        "examples": [
          0
        ]
      },
      "paste_back": {
        "type": "boolean",
        "description": "Whether to paste back the reframed scene to the original video.",
        "required": false,
        "default": true
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "enum": [
          "none",
          "low",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "scene_threshold": {
        "type": "number",
        "description": "Threshold for scene detection sensitivity (0-100). Lower values detect more scenes.",
        "required": false,
        "minimum": 0,
        "maximum": 100,
        "default": 30
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "Minimum FPS for auto downsample.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 6,
        "examples": [
          6
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "trim_borders": {
        "type": "boolean",
        "description": "Whether to trim borders from the video.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "Whether to enable auto downsample.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The output video file."
      }
    }
  },
  {
    "id": "fal-ai/index-tts-2/text-to-speech",
    "title": "Index TTS 2.0",
    "category": "text-to-speech",
    "description": "Generate natural, clear speeches using Index TTS 2.0 from IndexTeam",
    "tags": [
      "text-to-speech"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/Y_c2YQvO2F3F-Q3v8cMHr_e14577c0c33b4eca81ce5ebeb2a5ca49.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/index-tts-2/text-to-speech",
    "documentationUrl": "https://fal.ai/models/fal-ai/index-tts-2/text-to-speech/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The speech prompt to generate",
        "required": true,
        "examples": [
          "Hide! He's coming! He's coming to get us!"
        ]
      },
      "emotional_strengths": {
        "type": null,
        "description": "The strengths of individual emotions for fine-grained control. ",
        "required": false,
        "examples": [
          null
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the emotional style transfer. Higher values result in stronger emotional influence.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "emotional_audio_url": {
        "type": null,
        "description": "The emotional reference audio file to extract the style from.",
        "required": false
      },
      "audio_url": {
        "type": "string",
        "description": "The audio file to generate the speech from.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/index-tts-2/tts_in.mp3"
        ]
      },
      "emotion_prompt": {
        "type": null,
        "description": "The emotional prompt to influence the emotional style. Must be used together with should_use_prompt_for_emotion.",
        "required": false,
        "examples": [
          "You scared me to death! What are you, a ghost?"
        ]
      },
      "should_use_prompt_for_emotion": {
        "type": "boolean",
        "description": "Whether to use the `prompt` to calculate emotional strengths, if enabled it will overwrite the `emotional_strengths` values. If `emotion_prompt` is provided, it will be used to instead of `prompt` to extract the emotional style.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file in base64 format."
      }
    }
  },
  {
    "id": "fal-ai/meshy/v6-preview/text-to-3d",
    "title": "Meshy 6 Preview",
    "category": "text-to-3d",
    "description": "Meshy-6-Preview is the latest model from Meshy. It generates realistic and production ready 3D models.",
    "tags": [
      "text-to-3d"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/R9WXOPkhbiHFjL8iXBLDG_79f59228974346e59950364b95325d80.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/meshy/v6-preview/text-to-3d",
    "documentationUrl": "https://fal.ai/models/fal-ai/meshy/v6-preview/text-to-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Describe what kind of object the 3D model is. Maximum 600 characters.",
        "required": true,
        "maxLength": 600,
        "examples": [
          "A rustic, antique wooden treasure chest with a curved, domed lid, constructed from weathered, dark brown planks exhibiting prominent wood grain and subtle distress. It's heavily reinforced with broad, dark grey, oxidized metal bands secured by numerous circular rivets. Ornate, dark iron decorative elements featuring swirling foliate patterns and dragon motifs adorn the corners and lid. A prominent, circular, intricately carved metal lock plate with a central keyhole dominates the front, flanked by two large, dark metallic pull rings."
        ]
      },
      "enable_pbr": {
        "type": "boolean",
        "description": "Generate PBR Maps (metallic, roughness, normal) in addition to base color. Should be false for sculpture style.",
        "required": false,
        "default": false
      },
      "target_polycount": {
        "type": "integer",
        "description": "Target number of polygons in the generated model",
        "required": false,
        "minimum": 100,
        "maximum": 300000,
        "default": 30000
      },
      "art_style": {
        "type": "string",
        "description": "Desired art style of the object. Note: enable_pbr should be false for sculpture style.",
        "required": false,
        "enum": [
          "realistic",
          "sculpture"
        ],
        "default": "realistic"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": true
      },
      "mode": {
        "type": "string",
        "description": "Generation mode. 'preview' returns untextured geometry only, 'full' returns textured model (preview + refine).",
        "required": false,
        "enum": [
          "preview",
          "full"
        ],
        "default": "full"
      },
      "symmetry_mode": {
        "type": "string",
        "description": "Controls symmetry behavior during model generation.",
        "required": false,
        "enum": [
          "off",
          "auto",
          "on"
        ],
        "default": "auto"
      },
      "should_remesh": {
        "type": "boolean",
        "description": "Whether to enable the remesh phase. When false, returns unprocessed triangular mesh.",
        "required": false,
        "default": true
      },
      "texture_image_url": {
        "type": "string",
        "description": "2D image to guide the texturing process (only used in 'full' mode)",
        "required": false
      },
      "topology": {
        "type": "string",
        "description": "Specify the topology of the generated model. Quad for smooth surfaces, Triangle for detailed geometry.",
        "required": false,
        "enum": [
          "quad",
          "triangle"
        ],
        "default": "triangle"
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Seed for reproducible results. Same prompt and seed usually generate the same result.",
        "required": false
      },
      "is_a_t_pose": {
        "type": "boolean",
        "description": "Whether to generate the model in an A/T pose",
        "required": false,
        "default": false
      },
      "texture_prompt": {
        "type": "string",
        "description": "Additional text prompt to guide the texturing process (only used in 'full' mode)",
        "required": false,
        "maxLength": 600
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for generation"
      },
      "thumbnail": {
        "type": null,
        "description": "Preview thumbnail of the generated model"
      },
      "actual_prompt": {
        "type": "string",
        "description": "The actual prompt used if prompt expansion was enabled"
      },
      "texture_urls": {
        "type": "array",
        "description": "Array of texture file objects",
        "items": {
          "$ref": "#/components/schemas/TextureFiles"
        }
      },
      "model_glb": {
        "type": null,
        "description": "Generated 3D object in GLB format."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "model_urls": {
        "type": null,
        "description": "URLs for different 3D model formats"
      }
    }
  },
  {
    "id": "fal-ai/meshy/v5/multi-image-to-3d",
    "title": "Meshy 5 Multi",
    "category": "image-to-3d",
    "description": "Meshy-5 multi image generates realistic and production ready 3D models from multiple images.\n",
    "tags": [
      "multi-image-to-3d"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/wLQpmudI-iiOD545isnQ0_b7878036846e4f72b23e29f55c97016e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/meshy/v5/multi-image-to-3d",
    "documentationUrl": "https://fal.ai/models/fal-ai/meshy/v5/multi-image-to-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "enable_pbr": {
        "type": "boolean",
        "description": "Generate PBR Maps (metallic, roughness, normal) in addition to base color. Requires should_texture to be true.",
        "required": false,
        "default": false
      },
      "should_texture": {
        "type": "boolean",
        "description": "Whether to generate textures. False provides mesh without textures for 5 credits, True adds texture generation for additional 10 credits.",
        "required": false,
        "default": true
      },
      "target_polycount": {
        "type": "integer",
        "description": "Target number of polygons in the generated model",
        "required": false,
        "minimum": 100,
        "maximum": 300000,
        "default": 30000
      },
      "is_a_t_pose": {
        "type": "boolean",
        "description": "Whether to generate the model in an A/T pose",
        "required": false,
        "default": false
      },
      "texture_image_url": {
        "type": "string",
        "description": "2D image to guide the texturing process. Requires should_texture to be true.",
        "required": false
      },
      "topology": {
        "type": "string",
        "description": "Specify the topology of the generated model. Quad for smooth surfaces, Triangle for detailed geometry.",
        "required": false,
        "enum": [
          "quad",
          "triangle"
        ],
        "default": "triangle"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": true
      },
      "symmetry_mode": {
        "type": "string",
        "description": "Controls symmetry behavior during model generation.",
        "required": false,
        "enum": [
          "off",
          "auto",
          "on"
        ],
        "default": "auto"
      },
      "image_urls": {
        "type": "array",
        "description": "1 to 4 images for 3D model creation. All images should depict the same object from different angles. Supports .jpg, .jpeg, .png formats, and AVIF/HEIF which will be automatically converted. If more than 4 images are provided, only the first 4 will be used.",
        "required": true,
        "examples": [
          [
            "https://v3b.fal.media/files/b/kangaroo/cPyD3-por0XI7jDa9F9vP_image%20(3).png",
            "https://v3b.fal.media/files/b/elephant/9sd5JWAOJBcR7G3NMjPVs_image%20(2).png",
            "https://v3b.fal.media/files/b/tiger/TP4sTzPATX_w1Tn4m6kYM_image%20(1).png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "texture_prompt": {
        "type": "string",
        "description": "Text prompt to guide the texturing process. Requires should_texture to be true.",
        "required": false,
        "maxLength": 600
      },
      "should_remesh": {
        "type": "boolean",
        "description": "Whether to enable the remesh phase. When false, returns triangular mesh ignoring topology and target_polycount.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "model_urls": {
        "type": null,
        "description": "URLs for different 3D model formats"
      },
      "texture_urls": {
        "type": "array",
        "description": "Array of texture file objects",
        "items": {
          "$ref": "#/components/schemas/TextureFiles"
        }
      },
      "thumbnail": {
        "type": null,
        "description": "Preview thumbnail of the generated model"
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation (if available)"
      },
      "model_glb": {
        "type": null,
        "description": "Generated 3D object in GLB format."
      }
    }
  },
  {
    "id": "fal-ai/meshy/v6-preview/image-to-3d",
    "title": "Meshy 6 Preview",
    "category": "image-to-3d",
    "description": "Meshy-6-Preview is the latest model from Meshy. It generates realistic and production ready 3D models.\n",
    "tags": [
      "image-to-3d"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/DSTicAg_awPQiKUDYINO1_f2f15f177bfe4e94b4f91340ff0393f6.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/meshy/v6-preview/image-to-3d",
    "documentationUrl": "https://fal.ai/models/fal-ai/meshy/v6-preview/image-to-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "enable_pbr": {
        "type": "boolean",
        "description": "Generate PBR Maps (metallic, roughness, normal) in addition to base color",
        "required": false,
        "default": false
      },
      "is_a_t_pose": {
        "type": "boolean",
        "description": "Whether to generate the model in an A/T pose",
        "required": false,
        "default": false
      },
      "target_polycount": {
        "type": "integer",
        "description": "Target number of polygons in the generated model",
        "required": false,
        "minimum": 100,
        "maximum": 300000,
        "default": 30000
      },
      "should_texture": {
        "type": "boolean",
        "description": "Whether to generate textures",
        "required": false,
        "default": true
      },
      "texture_image_url": {
        "type": "string",
        "description": "2D image to guide the texturing process",
        "required": false
      },
      "topology": {
        "type": "string",
        "description": "Specify the topology of the generated model. Quad for smooth surfaces, Triangle for detailed geometry.",
        "required": false,
        "enum": [
          "quad",
          "triangle"
        ],
        "default": "triangle"
      },
      "image_url": {
        "type": "string",
        "description": "Image URL or base64 data URI for 3D model creation. Supports .jpg, .jpeg, and .png formats. Also supports AVIF and HEIF formats which will be automatically converted.",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/zebra/3osHJDI8IZ2wl6sGtEUeB_image.png"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": true
      },
      "symmetry_mode": {
        "type": "string",
        "description": "Controls symmetry behavior during model generation. Off disables symmetry, Auto determines it automatically, On enforces symmetry.",
        "required": false,
        "enum": [
          "off",
          "auto",
          "on"
        ],
        "default": "auto"
      },
      "texture_prompt": {
        "type": "string",
        "description": "Text prompt to guide the texturing process",
        "required": false,
        "maxLength": 600
      },
      "should_remesh": {
        "type": "boolean",
        "description": "Whether to enable the remesh phase",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "model_urls": {
        "type": null,
        "description": "URLs for different 3D model formats"
      },
      "texture_urls": {
        "type": "array",
        "description": "Array of texture file objects, matching Meshy API structure",
        "items": {
          "$ref": "#/components/schemas/TextureFiles"
        }
      },
      "thumbnail": {
        "type": null,
        "description": "Preview thumbnail of the generated model"
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation (if available)"
      },
      "model_glb": {
        "type": null,
        "description": "Generated 3D object in GLB format."
      }
    }
  },
  {
    "id": "fal-ai/sora-2/image-to-video/pro",
    "title": "Sora 2",
    "category": "image-to-video",
    "description": "Image-to-video endpoint for Sora 2 Pro, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "tags": [
      "image-to-video",
      "audio",
      "sora-2-pro"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/19D6ouLhOE6EKGbUTnfzf_b958de62e48c4356a1c58abef534060b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sora-2/image-to-video/pro",
    "documentationUrl": "https://fal.ai/models/fal-ai/sora-2/image-to-video/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Front-facing 'invisible' action-cam on a skydiver in freefall above bright clouds; camera locked on his face. He speaks over the wind with clear lipsync: 'This is insanely fun! You've got to try it—book a tandem and go!' Natural wind roar, voice close-mic'd and slightly compressed so it's intelligible. Midday sun, goggles and jumpsuit flutter, altimeter visible, parachute rig on shoulders. Energetic but stable framing with subtle shake; brief horizon roll. End on first tug of canopy and wind noise dropping."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "auto",
          "720p",
          "1080p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9"
        ],
        "default": "auto"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the generated video in seconds",
        "required": false,
        "enum": [
          4,
          8,
          12
        ],
        "default": 4
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/sora-2-i2v-input.png"
        ]
      },
      "api_key": {
        "type": "string",
        "description": "The API key to use for the OpenAI API. If provided, you will not be billed for the request.",
        "required": false
      }
    },
    "outputParameters": {
      "video_id": {
        "type": "string",
        "description": "The ID of the generated video"
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/sora-2/text-to-video/pro",
    "title": "Sora 2",
    "category": "text-to-video",
    "description": "Text-to-video endpoint for Sora 2 Pro, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "tags": [
      "text-to-video",
      "audio",
      "sora-2-pro"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/lion/0bXyMS_zSKpeaG3LM6ARv_d4ee6acbfd9a4168b012a848c33b154d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sora-2/text-to-video/pro",
    "documentationUrl": "https://fal.ai/models/fal-ai/sora-2/text-to-video/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the generated video in seconds",
        "required": false,
        "enum": [
          4,
          8,
          12
        ],
        "default": 4
      },
      "api_key": {
        "type": "string",
        "description": "The API key to use for the OpenAI API. If provided, you will not be billed for the request.",
        "required": false
      }
    },
    "outputParameters": {
      "video_id": {
        "type": "string",
        "description": "The ID of the generated video"
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/sora-2/text-to-video",
    "title": "Sora 2",
    "category": "text-to-video",
    "description": "Text-to-video endpoint for Sora 2, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "tags": [
      "text to video",
      "audio",
      "sora"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/eOGowiQKXIKwyDfwgeWQO_b80784431c524553a564ebdd7550d7e6.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sora-2/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/sora-2/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the generated video in seconds",
        "required": false,
        "enum": [
          4,
          8,
          12
        ],
        "default": 4
      },
      "api_key": {
        "type": "string",
        "description": "The API key to use for the OpenAI API. If provided, you will not be billed for the request.",
        "required": false
      }
    },
    "outputParameters": {
      "video_id": {
        "type": "string",
        "description": "The ID of the generated video"
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/sora-2/image-to-video",
    "title": "Sora 2",
    "category": "image-to-video",
    "description": "Image-to-video endpoint for Sora 2, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "tags": [
      "image-to-video",
      "audio",
      "sora"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/8n-yLTQvW5q0BEvW0H2J3_8233c7e127124290b6dfa965f44ebc79.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sora-2/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/sora-2/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Front-facing 'invisible' action-cam on a skydiver in freefall above bright clouds; camera locked on his face. He speaks over the wind with clear lipsync: 'This is insanely fun! You've got to try it—book a tandem and go!' Natural wind roar, voice close-mic'd and slightly compressed so it's intelligible. Midday sun, goggles and jumpsuit flutter, altimeter visible, parachute rig on shoulders. Energetic but stable framing with subtle shake; brief horizon roll. End on first tug of canopy and wind noise dropping."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "auto",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9"
        ],
        "default": "auto"
      },
      "duration": {
        "type": "integer",
        "description": "Duration of the generated video in seconds",
        "required": false,
        "enum": [
          4,
          8,
          12
        ],
        "default": 4
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/sora-2-i2v-input.png"
        ]
      },
      "api_key": {
        "type": "string",
        "description": "The API key to use for the OpenAI API. If provided, you will not be billed for the request.",
        "required": false
      }
    },
    "outputParameters": {
      "video_id": {
        "type": "string",
        "description": "The ID of the generated video"
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora",
    "title": "Qwen Image Edit Plus Lora",
    "category": "image-to-image",
    "description": "LoRA endpoint for the Qwen Image Edit Plus model.",
    "tags": [
      "image-to-image",
      "image-editing"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/X3V08aAYEqPmeSvVdLgN9_6be5ff6349c9459d92e7a5d7db8dadcc.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-plus-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-plus-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Close shot of a woman standing in next to this car on this highway"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image.",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 28
      },
      "image_urls": {
        "type": "array",
        "description": "The URLs of the images to edit.",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/monkey/i3saq4bAPXSIl08nZtq9P_ec535747aefc4e31943136a6d8587075.png",
            "https://v3.fal.media/files/penguin/BCOZp6teRhSQFuOXpbBOa_da8ef9b4982347a2a62a516b737d4f21.png",
            "https://v3.fal.media/files/tiger/sCoZhBksx9DvwSR4_U3_C_3d1f581441874005908addeae9c10d0f.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          " "
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/lucidflux",
    "title": "Lucidflux",
    "category": "image-to-image",
    "description": "LucidFlux for upscaling images with very high fidelity",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/IoOnMLFUyTCBXNJfw8p6d_04001a3f68e34de687b6de1a73d7e1de.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lucidflux",
    "documentationUrl": "https://fal.ai/models/fal-ai/lucidflux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image.",
        "required": true,
        "examples": [
          "restore this image into high-quality, clean, high-resolution result"
        ]
      },
      "guidance": {
        "type": "number",
        "description": "The guidance to use for the diffusion process.",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 4
      },
      "target_height": {
        "type": "integer",
        "description": "The height of the output image.",
        "required": false,
        "minimum": 512,
        "maximum": 1024,
        "default": 1024
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/6FLKRWYztzOKDKV-v1VfK_3.png"
        ]
      },
      "target_width": {
        "type": "integer",
        "description": "The width of the output image.",
        "required": false,
        "minimum": 512,
        "maximum": 1024,
        "default": 1024
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for random number generation",
        "required": false,
        "default": 42
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Generated image"
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for random number generation"
      }
    }
  },
  {
    "id": "fal-ai/ovi/image-to-video",
    "title": "Ovi",
    "category": "image-to-video",
    "description": "Ovi can generate videos with audio from image and text inputs.",
    "tags": [
      "image-to-audio-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/elephant/0C5YI172kcCI9lcCtXDJI_61f25dd2c735440aafb1a2ec647b6bd0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ovi/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ovi/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "An intimate close-up of a European woman with long dark hair as she gently brushes her hair in a softly lit bedroom, her delicate hand moving in the foreground. She looks directly into the camera with calm, focused eyes, a faint serene smile glowing in the warm lamp light. She says, <S>[soft whisper] I am an artificial intelligence.<E>.<AUDCAP>Soft whispering female voice, ASMR tone with gentle breaths, cozy room acoustics, subtle emphasis on \"I am an artificial intelligence\".<ENDAUDCAP>"
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "audio_negative_prompt": {
        "type": "string",
        "description": "Negative prompt for audio generation.",
        "required": false,
        "default": "robotic, muffled, echo, distorted"
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "jitter, bad hands, blur, distortion"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to guide video generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ovi_i2v_input.png"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ovi",
    "title": "Ovi Text to Video",
    "category": "text-to-video",
    "description": "A unified paradigm for audio-video generation",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/lion/yU9aRgq2QMYK4eGH5mohA_2822a9b5892d46699e218791b207ae5c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ovi",
    "documentationUrl": "https://fal.ai/models/fal-ai/ovi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A close-up of someone's face as they pet a cat, their hands stroking the soft fur in the foreground. Their affectionate expression shows as the cat purrs contentedly in their lap. They say, <S>This little guy has been with me for eight years now. He knows exactly when I need comfort. Animals are pretty amazing that way.<E>.<AUDCAP>Affectionate voice with cat purring and gentle petting sounds<ENDAUDCAP>"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120).",
        "required": false,
        "enum": [
          "512x992",
          "992x512",
          "960x512",
          "512x960",
          "720x720",
          "448x1120",
          "1120x448"
        ],
        "default": "992x512"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "audio_negative_prompt": {
        "type": "string",
        "description": "Negative prompt for audio generation.",
        "required": false,
        "default": "robotic, muffled, echo, distorted"
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "jitter, bad hands, blur, distortion"
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "veed/fabric-1.0/fast",
    "title": "Fabric 1.0 Fast",
    "category": "image-to-video",
    "description": "VEED Fabric 1.0 is an image-to-video API that turns any image into a talking video",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/zebra/AGRvOvMtrM0o02wz8-hRF_cb5739a5199b49a7971c5319881c6765.jpg",
    "playgroundUrl": "https://fal.ai/models/veed/fabric-1.0/fast",
    "documentationUrl": "https://fal.ai/models/veed/fabric-1.0/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "resolution": {
        "type": "string",
        "description": "Resolution",
        "required": true,
        "enum": [
          "720p",
          "480p"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/elephant/Oz_g4AwQvXtXpUHL3Pa7u_Hope.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/koala/NLVPfOI4XL1cWT2PmmqT3_Hope.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-edit/image-to-image",
    "title": "Qwen Image Edit",
    "category": "image-to-image",
    "description": "Image to Image Endpoint for Qwen's Image Editing model. Has superior text editing capabilities.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/lion/y1wOAl3dW0LE43drzjWY3_71e9575367b14485b4a5ca83492c0e82.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Change bag to apple macbook"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "Strength of the image-to-image transformation. Lower values preserve more of the original image.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.94
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          "blurry, ugly"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-image/v3/text-to-image",
    "title": "Hunyuan Image",
    "category": "text-to-image",
    "description": "Leverage the state-of-the-art capabilities of Hunyuan Image 3.0 to generate visual content that effectively conveys the messaging of your written material.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/en7kxz5HNAQKg5QuONGDH_760708cdbc4b49e1a96e6b7628e43c35.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-image/v3/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-image/v3/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt for image-to-image.",
        "required": true,
        "examples": [
          "200mm telephoto through crowd gaps; subject laughing, candid; creamy background compression, color pop from a single bold garment, catchlight in eyes."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The desired size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible results. If None, a random seed is used.",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Controls how much the model adheres to the prompt. Higher values mean stricter adherence.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 7.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to guide the image generation away from certain concepts.",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, watermark, signature"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of denoising steps.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "A list of the generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "The base seed used for the generation process."
      }
    }
  },
  {
    "id": "fal-ai/hyper3d/rodin/v2",
    "title": "Hyper3d",
    "category": "image-to-3d",
    "description": "Rodin by Hyper3D generates realistic and production ready 3D models from text or images.",
    "tags": [
      "image-to-3d"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/lion/liLB7F5DWmR3CgbqjvZo3_2a3d75c59b5f4951810452fa8c27d0ba.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hyper3d/rodin/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/hyper3d/rodin/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "quality_mesh_option": {
        "type": "string",
        "description": "Combined quality and mesh type selection. Quad = smooth surfaces, Triangle = detailed geometry.",
        "required": false,
        "enum": [
          "4K Quad",
          "8K Quad",
          "18K Quad",
          "50K Quad",
          "2K Triangle",
          "20K Triangle",
          "150K Triangle",
          "500K Triangle"
        ],
        "default": "500K Triangle"
      },
      "prompt": {
        "type": "string",
        "description": "A textual prompt to guide model generation. Optional for Image-to-3D mode - if empty, AI will generate a prompt based on your images.",
        "required": false,
        "default": "",
        "examples": [
          "A futuristic robot with sleek metallic design."
        ]
      },
      "preview_render": {
        "type": "boolean",
        "description": "Generate a preview render image of the 3D model along with the model files.",
        "required": false,
        "default": false
      },
      "bbox_condition": {
        "type": "array",
        "description": "An array that specifies the bounding box dimensions [width, height, length].",
        "required": false,
        "items": {
          "type": "integer"
        }
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to use while generating the 3D model. Required for Image-to-3D mode. Up to 5 images allowed.",
        "required": false,
        "examples": [
          [
            "https://v3.fal.media/files/panda/l7mQrG8plbB42lBNqVjm0_image.png",
            "https://v3b.fal.media/files/b/kangaroo/scq50Bf1PB2NZOW8szphV_image.png",
            "https://v3.fal.media/files/penguin/X21qtlVMazAtljzRCJD2__image.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "TAPose": {
        "type": "boolean",
        "description": "Generate characters in T-pose or A-pose format, making them easier to rig and animate in 3D software.",
        "required": false,
        "default": false
      },
      "use_original_alpha": {
        "type": "boolean",
        "description": "When enabled, preserves the transparency channel from input images during 3D generation.",
        "required": false,
        "default": false
      },
      "geometry_file_format": {
        "type": "string",
        "description": "Format of the geometry file. Possible values: glb, usdz, fbx, obj, stl. Default is glb.",
        "required": false,
        "enum": [
          "glb",
          "usdz",
          "fbx",
          "obj",
          "stl"
        ],
        "default": "glb"
      },
      "seed": {
        "type": "integer",
        "description": "Seed value for randomization, ranging from 0 to 65535. Optional.",
        "required": false,
        "minimum": 0,
        "maximum": 65535
      },
      "material": {
        "type": "string",
        "description": "Material type. PBR: Physically-based materials with realistic lighting. Shaded: Simple materials with baked lighting. All: Both types included.",
        "required": false,
        "enum": [
          "PBR",
          "Shaded",
          "All"
        ],
        "default": "All"
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      },
      "textures": {
        "type": "array",
        "description": "Generated textures for the 3D object.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      }
    }
  },
  {
    "id": "fal-ai/lynx",
    "title": "Lynx",
    "category": "image-to-video",
    "description": "Generate subject consistent videos using Lynx from ByteDance!",
    "tags": [
      "image-to-video",
      "subject"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/lion/49-4PP-6iG8KcIfhWAduK_ac8d9da273624a95bf696ff6e439debd.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lynx",
    "documentationUrl": "https://fal.ai/models/fal-ai/lynx/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide video generation",
        "required": true,
        "examples": [
          "A person carves a pumpkin on a porch in the evening. The camera captures their upper body as they draw a face with a marker, carefully cut along the lines, then lift the lid with both hands. Their face lights up with excitement as they peek inside"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p)",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9, 9:16, or 1:1)",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames in the generated video. Must be between 9 to 100.",
        "required": false,
        "minimum": 9,
        "maximum": 81,
        "default": 81
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the subject image to be used for video generation",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/lynx/example_in.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Reference image scale. Controls the influence of the reference image on the generated video.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 30.",
        "required": false,
        "minimum": 5,
        "maximum": 30,
        "default": 16
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 2
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 1,
        "maximum": 75,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to guide what should not appear in the generated video",
        "required": false,
        "default": "Bright tones, overexposed, blurred background, static, subtitles, style, works, paintings, images, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
      },
      "ip_scale": {
        "type": "number",
        "description": "Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "fal-ai/wan-25-preview/image-to-image",
    "title": "Wan 2.5 Image to Image",
    "category": "image-to-image",
    "description": "Wan 2.5 image-to-image model.",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/panda/E-LG-LvtKaaYeyx_FPqmu_c75bdd0f332b455e80a7cf14a3a44725.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-25-preview/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-25-preview/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing how to edit the image. Max 2000 characters.",
        "required": true,
        "minLength": 1,
        "examples": [
          "Reimagine the scene under a raging thunderstorm at night: lightning forks across the sky, illuminating the samurai in stark flashes of white light."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate. Values from 1 to 4.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Width and height must be between 384 and 1440 pixels.",
        "required": false,
        "default": "square",
        "examples": [
          "square",
          "landscape_16_9",
          "portrait_16_9",
          {
            "height": 1280,
            "width": 1280
          }
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "image_urls": {
        "type": "array",
        "description": "URLs of images to edit. For single-image editing, provide 1 URL. For multi-reference generation, provide up to 2 URLs. If more than 2 URLs are provided, only the first 2 will be used.",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/penguin/4VZ7I1ZK5XNv33LV2JBxg.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to describe content to avoid. Max 500 characters.",
        "required": false,
        "examples": [
          "low resolution, error, worst quality, low quality, defects"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The edited images",
        "items": {
          "$ref": "#/components/schemas/ImageFile"
        }
      },
      "seeds": {
        "type": "array",
        "description": "The seeds used for each generated image",
        "items": {
          "type": "integer"
        }
      },
      "actual_prompt": {
        "type": "string",
        "description": "The original prompt (prompt expansion is not available for image editing)"
      }
    }
  },
  {
    "id": "fal-ai/wan-25-preview/text-to-image",
    "title": "Wan 2.5 Text to Image",
    "category": "text-to-image",
    "description": "Wan 2.5 text-to-image model.",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/6PlSnB3q28Mu0QjURXyBe_051522e72e02496da12bf011190ca281.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-25-preview/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-25-preview/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image generation. Supports Chinese and English, max 2000 characters.",
        "required": true,
        "minLength": 1,
        "examples": [
          "A lone samurai standing on the edge of a cliff at twilight, overlooking a vast valley shrouded in mist. The sky burns with deep orange and purple hues from the setting sun, casting long, dramatic shadows. The samurai’s silhouette glows against the horizon, with their sword reflecting a glint of fading light. The overall style is hyper-realistic, cinematic, and moody, with dramatic contrast and atmospheric depth."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate. Values from 1 to 4.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Can use preset names like 'square', 'landscape_16_9', etc., or specific dimensions. Total pixels must be between 768×768 and 1440×1440, with aspect ratio between [1:4, 4:1].",
        "required": false,
        "default": "square",
        "examples": [
          "square",
          "landscape_16_9",
          "portrait_16_9",
          {
            "height": 1280,
            "width": 1280
          }
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to describe content to avoid. Max 500 characters.",
        "required": false,
        "examples": [
          "low resolution, error, worst quality, low quality, defects"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/ImageFile"
        }
      },
      "seeds": {
        "type": "array",
        "description": "The seeds used for each generated image",
        "items": {
          "type": "integer"
        }
      },
      "actual_prompt": {
        "type": "string",
        "description": "The actual prompt used if prompt rewriting was enabled"
      }
    }
  },
  {
    "id": "fal-ai/wan-25-preview/text-to-video",
    "title": "Wan 2.5 Text to Video",
    "category": "text-to-video",
    "description": "Wan 2.5 text-to-video model.",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/koala/yojKCMBipiqJvLr9a3sLC_deec1d2b5b2c4019bc353f6060ec0c09.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-25-preview/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-25-preview/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt for video generation. Supports Chinese and English, max 800 characters.",
        "required": true,
        "minLength": 1,
        "examples": [
          "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution tier",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the generated video in seconds. Choose between 5 or 10 seconds.",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5",
        "examples": [
          "5",
          "10"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5 or 10 seconds),\nthe audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to describe content to avoid. Max 500 characters.",
        "required": false,
        "examples": [
          "low resolution, error, worst quality, low quality, defects"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "actual_prompt": {
        "type": "string",
        "description": "The actual prompt used if prompt rewriting was enabled"
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "video": {
        "type": null,
        "description": "The generated video file"
      }
    }
  },
  {
    "id": "easel-ai/product-photoshoot",
    "title": "Product Photoshoot",
    "category": "image-to-image",
    "description": "Create product advertisements with an example image of the product",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/koala/J7TJvEQBnQjHhNz4q8PDl_8c054226af1d48828c179031f2edf04d.jpg",
    "playgroundUrl": "https://fal.ai/models/easel-ai/product-photoshoot",
    "documentationUrl": "https://fal.ai/models/easel-ai/product-photoshoot/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "scene": {
        "type": "string",
        "description": "Description of the scene in which the product is placed. (Minimum 64 characters.)",
        "required": true,
        "minLength": 64,
        "examples": [
          "an image with a cheerful young boy sitting at a wooden kitchen table, wearing a bright blue sweatshirt, eating cereal from a white bowl with a spoon."
        ]
      },
      "product_description": {
        "type": "string",
        "description": "A brief description of the product.",
        "required": false,
        "maxLength": 256,
        "default": "",
        "examples": [
          "a box of cereal.",
          "a bottle of milk.",
          "a bag of dog food."
        ]
      },
      "product_image": {
        "type": null,
        "description": "An image of the product to be featured in the photoshoot.",
        "required": true,
        "examples": [
          "https://images.easelai.com/product/special-k.webp",
          "https://images.easelai.com/product/cheerios.jpg"
        ]
      },
      "product_placement": {
        "type": "string",
        "description": "Describe how the product is placed in the scene.",
        "required": true,
        "maxLength": 128,
        "examples": [
          "on a silver tray on the left side of the image",
          "on a wooden table",
          "on a granite kitchen counter"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The desired output format for the generated image.",
        "required": false,
        "enum": [
          "1:1 (2k)",
          "4:3",
          "16:9",
          "9:16",
          "1:1 (1k, Turbo)"
        ],
        "default": "4:3"
      },
      "magic_blend_enabled": {
        "type": "boolean",
        "description": "Enable Magic Blend to enhance the integration of the product into the scene.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The resulting image of the product in the scene."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/omnihuman/v1.5",
    "title": "Bytedance OmniHuman v1.5",
    "category": "image-to-video",
    "description": "Omnihuman v1.5 is a new and improved version of Omnihuman. It generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character’s emotions and movements maintain a strong correlation with the audio.",
    "tags": [
      "image-to-video",
      "lipsync",
      ""
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/E4JFEyBXM1DccJUOvp5_e_6414b61bc2e141edb34671e5308addef.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/omnihuman/v1.5",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/omnihuman/v1.5/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file to generate the video. Audio must be under 30s long.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_v15_input_audio.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image used to generate the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_v15_input_image.png"
        ]
      }
    },
    "outputParameters": {
      "duration": {
        "type": "number",
        "description": "Duration of audio input/video output as used for billing."
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-edit-plus",
    "title": "Qwen Image Edit Plus",
    "category": "image-to-image",
    "description": "Endpoint for Qwen's Image Editing Plus model also known as Qwen-Image-Edit-2509. Has superior text editing capabilities and multi-image support.",
    "tags": [
      "image-editing",
      "image-to-image",
      "high-quality-text"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/elephant/pGXxmNi6TrKTe864jBKW8_1bb43c6eab2349ab9c8cefbb24f3fd1b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-plus",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-plus/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Close shot of a woman standing in next to this car on this highway"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 100,
        "default": 50
      },
      "image_urls": {
        "type": "array",
        "description": "The URLs of the images to edit.",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/monkey/i3saq4bAPXSIl08nZtq9P_ec535747aefc4e31943136a6d8587075.png",
            "https://v3.fal.media/files/penguin/BCOZp6teRhSQFuOXpbBOa_da8ef9b4982347a2a62a516b737d4f21.png",
            "https://v3.fal.media/files/tiger/sCoZhBksx9DvwSR4_U3_C_3d1f581441874005908addeae9c10d0f.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          " "
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/infinitalk/video-to-video",
    "title": "Infinitalk",
    "category": "video-to-video",
    "description": "Infinitalk model generates a talking avatar video from an image and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "tags": [
      "video-to-video"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/lion/CKSKBDtMz0kao3Ege3oAj_0b61adf1742146f2b743efc7921003f3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/infinitalk/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/infinitalk/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A woman with colorful hair talking on a podcast."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/ref_video.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/PtiCYda53E9Dav25QmQYI_output.mp3"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 42
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 41,
        "maximum": 241,
        "default": 145
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/seedvr/upscale/video",
    "title": "SeedVR2",
    "category": "video-to-video",
    "description": "Upscale your videos using SeedVR2 with temporal consistency!",
    "tags": [
      "upscale",
      "video-to-video"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/cAs3xUC9Lx-jlQh-27-60_4dddbb5a9bac42da86ddf20a5b9d30b3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/seedvr/upscale/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/seedvr/upscale/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "upscale_mode": {
        "type": "string",
        "description": "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
        "required": false,
        "enum": [
          "target",
          "factor"
        ],
        "default": "factor"
      },
      "video_url": {
        "type": "string",
        "description": "The input video to be processed",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/seedvr-input.mp4"
        ]
      },
      "noise_scale": {
        "type": "number",
        "description": "The noise scale to use for the generation process.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "target_resolution": {
        "type": "string",
        "description": "The target resolution to upscale to when `upscale_mode` is `target`.",
        "required": false,
        "enum": [
          "720p",
          "1080p",
          "1440p",
          "2160p"
        ],
        "default": "1080p"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the output video.",
        "required": false,
        "enum": [
          "X264 (.mp4)",
          "VP9 (.webm)",
          "PRORES4444 (.mov)",
          "GIF (.gif)"
        ],
        "default": "X264 (.mp4)"
      },
      "output_write_mode": {
        "type": "string",
        "description": "The write mode of the output video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "output_quality": {
        "type": "string",
        "description": "The quality of the output video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high"
      },
      "upscale_factor": {
        "type": "number",
        "description": "Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      },
      "video": {
        "type": null,
        "description": "Upscaled video file after processing"
      }
    }
  },
  {
    "id": "fal-ai/seedvr/upscale/image",
    "title": "SeedVR2",
    "category": "image-to-image",
    "description": "Use SeedVR2 to upscale your images",
    "tags": [
      "upscale",
      "image-to-image"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/panda/_-1rRy0_I6w-fbt3q0RDL_2f47fece6e2b433994dda482e8d20bb9.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/seedvr/upscale/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/seedvr/upscale/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "upscale_mode": {
        "type": "string",
        "description": "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
        "required": false,
        "enum": [
          "target",
          "factor"
        ],
        "default": "factor"
      },
      "noise_scale": {
        "type": "number",
        "description": "The noise scale to use for the generation process.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "target_resolution": {
        "type": "string",
        "description": "The target resolution to upscale to when `upscale_mode` is `target`.",
        "required": false,
        "enum": [
          "720p",
          "1080p",
          "1440p",
          "2160p"
        ],
        "default": "1080p"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the output image.",
        "required": false,
        "enum": [
          "png",
          "jpg",
          "webp"
        ],
        "default": "jpg"
      },
      "image_url": {
        "type": "string",
        "description": "The input image to be processed",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/seedvr2/image_in.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "upscale_factor": {
        "type": "number",
        "description": "Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process.",
        "required": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Upscaled image file after processing"
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-apps/video-edit",
    "title": "Wan VACE Video Edit",
    "category": "video-to-video",
    "description": "Edit videos using plain language and Wan VACE",
    "tags": [
      "video-edit",
      "wan-vace"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/elephant/STesgR1tPPvf0dornjZou_377f4dd48d49425198c3396e86328a8b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-apps/video-edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-apps/video-edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to edit the video.",
        "required": true,
        "examples": [
          "replace him with a large anthropomorphic polar bear"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the edited video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "enum": [
          "none",
          "low",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the edited video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/vace-video-edit-input.mp4"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true
      },
      "video_type": {
        "type": "string",
        "description": "The type of video you're editing. Use 'general' for most videos, and 'human' for videos emphasizing human subjects and motions. The default value 'auto' means the model will guess based on the first frame of the video.",
        "required": false,
        "enum": [
          "auto",
          "general",
          "human"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "image_urls": {
        "type": "array",
        "description": "URLs of the input images to use as a reference for the generation.",
        "required": false,
        "default": [],
        "items": {
          "type": "string"
        }
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "Whether to enable automatic downsampling. If your video has a high frame rate or is long, enabling longer sequences to be generated. The video will be interpolated back to the original frame rate after generation.",
        "required": false,
        "default": true
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The edited video."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-14b/animate/replace",
    "title": "Wan-2.2 Animate Replace",
    "category": "video-to-video",
    "description": "Wan-Animate Replace is a model that can integrate animated characters into reference videos, replacing the original character while preserving the scene’s lighting and color tone for seamless environmental integration.",
    "tags": [
      "video to video",
      "motion"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/YKoL7e0b41wIerWU6PA6x_7fcafa06db85466e9864c8f006cb13a7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-14b/animate/replace",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-14b/animate/replace/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "480p",
        "examples": [
          "480p"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan_animate_input_video.mp4"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan_animate_input_image.jpeg"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 20,
        "examples": [
          20
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation"
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-14b/animate/move",
    "title": "Wan-2.2 Animate Move",
    "category": "video-to-video",
    "description": "Wan-Animate is a video model that generates high-fidelity character videos by replicating the expressions and movements of characters from reference videos.",
    "tags": [
      "video to video",
      "motion"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/lion/uXR8uNNcwPze8WMhqrlWO_f4e668e0be7a4a57bf6b45c93bf75199.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-14b/animate/move",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-14b/animate/move/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "480p",
        "examples": [
          "480p"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan_animate_input_video.mp4"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan_animate_input_image.jpeg"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 20,
        "examples": [
          20
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation"
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "veed/fabric-1.0",
    "title": "Fabric 1.0",
    "category": "image-to-video",
    "description": "VEED Fabric 1.0 is an image-to-video API that turns any image into a talking video",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/zebra/t3xqW_dkjrcRc2vmUS0EN_10a217d1a5ba4488be7bb1967189ef65.jpg",
    "playgroundUrl": "https://fal.ai/models/veed/fabric-1.0",
    "documentationUrl": "https://fal.ai/models/veed/fabric-1.0/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "resolution": {
        "type": "string",
        "description": "Resolution",
        "required": true,
        "enum": [
          "720p",
          "480p"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/elephant/Oz_g4AwQvXtXpUHL3Pa7u_Hope.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/koala/NLVPfOI4XL1cWT2PmmqT3_Hope.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/product-holding",
    "title": "Product Holding",
    "category": "image-to-image",
    "description": "Place products naturally in a person’s hands for realistic marketing visuals.",
    "tags": [
      "product",
      "marketing"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/zebra/7dJ2m31gOP0J0m8WZJ46I_1625d9610207407292eac394cc4a3026.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/product-holding",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/product-holding/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "product_image_url": {
        "type": "string",
        "description": "Image URL of the product to be held by the person",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/WqtPStHkOu6W0lZcIlXD8_156e3c91cb3a4d12b7380cc43b5e4c67.png"
        ]
      },
      "person_image_url": {
        "type": "string",
        "description": "Image URL of the person who will hold the product",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/oMob58qZJRtbDs5l45QKT_e3a1512c455d425fab2d62e07a51c506.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Person holding the product naturally",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/product-photography",
    "title": "Product Photography",
    "category": "image-to-image",
    "description": "Generate professional product photography with realistic lighting and backgrounds.",
    "tags": [
      "product",
      "marketing"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/g36T9svKmdie3DHtxJz5x_67cde98934654713bf484b258e2384f3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/product-photography",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/product-photography/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "product_image_url": {
        "type": "string",
        "description": "Image URL of the product to create professional studio photography",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/WqtPStHkOu6W0lZcIlXD8_156e3c91cb3a4d12b7380cc43b5e4c67.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Professional studio product photography",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "decart/lucy-edit/pro",
    "title": "Lucy Edit [Pro]",
    "category": "video-to-video",
    "description": "Lucy Edit Pro",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/_g9nFjAdwfSx3rZckDkCG_7076290e770c43a094a751a42799f16b.jpg",
    "playgroundUrl": "https://fal.ai/models/decart/lucy-edit/pro",
    "documentationUrl": "https://fal.ai/models/decart/lucy-edit/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text description of the desired video content",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "Transform the woman's outfit into a regal medieval gown with flowing velvet fabric, intricate gold embroidery, and a jeweled crown, giving her the appearance of a queen."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to edit",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/GI7ArkqpQVk3M6V1C_epr_original.mp4"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "480p"
        ],
        "default": "720p"
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "decart/lucy-edit/dev",
    "title": "Lucy Edit [Dev]",
    "category": "video-to-video",
    "description": "Lucy Edit Dev",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/tiger/oUaiOy3Nx-SgCqJxX0JaH_e780c641fbd840a6b75d8ba411b9a32d.jpg",
    "playgroundUrl": "https://fal.ai/models/decart/lucy-edit/dev",
    "documentationUrl": "https://fal.ai/models/decart/lucy-edit/dev/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to edit",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/GI7ArkqpQVk3M6V1C_epr_original.mp4"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text description of the desired video content",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "Transform the woman's outfit into a regal medieval gown with flowing velvet fabric, intricate gold embroidery, and a jeweled crown, giving her the appearance of a queen."
        ]
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/virtual-try-on",
    "title": "Virtual Try-on",
    "category": "image-to-image",
    "description": "Try on clothes virtually by combining person and clothing images.",
    "tags": [
      "fashion",
      "try-on",
      "virtual-try-on"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/tiger/dd5748sfMpq2uZzoUA_Y3_6377b3f9ee8e49afa174da674a80b9a6.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/virtual-try-on",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/virtual-try-on/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "preserve_pose": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for fashion)",
        "required": false
      },
      "clothing_image_url": {
        "type": "string",
        "description": "Clothing photo URL",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/monkey/5ZWXSKUuk9EilI1apFCeu_1ecd050187f24b9aa1d2defb88d8d8ae.png"
        ]
      },
      "person_image_url": {
        "type": "string",
        "description": "Person photo URL",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/4vxSHizex4UWR5fdnPs1A.jpeg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Person wearing the virtual clothing",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/texture-transform",
    "title": "Texture Transform",
    "category": "image-to-image",
    "description": "Transform objects with different surface textures like marble, wood, or fabric.",
    "tags": [
      "texture-transform"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/gzXctbp7SzO3xaVpDEqtN_97343b9e7b404a3e8f042b1d7d57a12f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/texture-transform",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/texture-transform/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "target_texture": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "cotton",
          "denim",
          "wool",
          "felt",
          "wood",
          "leather",
          "velvet",
          "stone",
          "marble",
          "ceramic",
          "concrete",
          "brick",
          "clay",
          "foam",
          "glass",
          "metal",
          "silk",
          "fabric",
          "crystal",
          "rubber",
          "plastic",
          "lace"
        ],
        "default": "marble"
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for texture transformation",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/WqtPStHkOu6W0lZcIlXD8_156e3c91cb3a4d12b7380cc43b5e4c67.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Image with transformed texture",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/relighting",
    "title": "Relighting",
    "category": "image-to-image",
    "description": "Adjust and enhance images with different lighting styles.",
    "tags": [
      "relighting"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/W0d6z5pWtVwakzxtKd4K4_94f6ab5b5820440db672dce73d447bff.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/relighting",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/relighting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "lighting_style": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "natural",
          "studio",
          "golden_hour",
          "blue_hour",
          "dramatic",
          "soft",
          "hard",
          "backlight",
          "side_light",
          "front_light",
          "rim_light",
          "sunset",
          "sunrise",
          "neon",
          "candlelight",
          "moonlight",
          "spotlight",
          "ambient"
        ],
        "default": "natural"
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for relighting",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/tugG2Q-XqMgf_ZoBr8KFO.jpeg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Image with new lighting",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/style-transfer",
    "title": "Style Transfer",
    "category": "image-to-image",
    "description": "Apply artistic styles like impressionism, cubism, or surrealism to your images.",
    "tags": [
      "style-transfer"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/uZNy5XjPfUQJOs0Kuw7C4_367de9bbd3034716b9432d637c3b369d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/style-transfer",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/style-transfer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "target_style": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "anime_character",
          "cartoon_3d",
          "hand_drawn_animation",
          "cyberpunk_future",
          "anime_game_style",
          "comic_book_animation",
          "animated_series",
          "cartoon_animation",
          "lofi_aesthetic",
          "cottagecore",
          "dark_academia",
          "y2k",
          "vaporwave",
          "liminal_space",
          "weirdcore",
          "dreamcore",
          "synthwave",
          "outrun",
          "photorealistic",
          "hyperrealistic",
          "digital_art",
          "concept_art",
          "impressionist",
          "anime",
          "pixel_art",
          "claymation"
        ],
        "default": "impressionist"
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "style_reference_image_url": {
        "type": null,
        "description": "Optional reference image URL. When provided, the style will be inferred from this image instead of the selected preset style.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for style transfer",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/vAohCtb_N8Q_cAs9Z03GS.jpeg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Image with transferred style",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/photo-restoration",
    "title": "Photo Restoration",
    "category": "image-to-image",
    "description": "Restore old or damaged photos by fixing colors, scratches, and resolution.",
    "tags": [
      "photo-restoration",
      "image-enhance"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/oP9mu0F1Obx0ufyEEVAgn_3f7a878f3cf54a078fa8e0d53524020a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/photo-restoration",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/photo-restoration/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "enhance_resolution": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 4:3 for classic photos)",
        "required": false
      },
      "remove_scratches": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": true
      },
      "fix_colors": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "Old or damaged photo URL to restore",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/BcOIyOJ5Z1-GOjDi_GmsX_50e353c588c74435882f8f68989b4af5.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Restored photo",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/portrait-enhance",
    "title": "Portrait Enhance",
    "category": "image-to-image",
    "description": "Enhance and refine portrait photos with improved clarity and detail.",
    "tags": [
      "image-edit",
      "enhancement"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/monkey/9kZMXV4GvRettHUuudKER_3f04e4f8fd0e4f28ad957c2a3bf9f3e5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/portrait-enhance",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/portrait-enhance/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Portrait image URL to enhance",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/monkey/VszUszGx2uzReqFvQzF26.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Enhanced portrait",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/photography-effects",
    "title": "Photography Effects",
    "category": "image-to-image",
    "description": "Apply diverse photography styles and effects to transform your images.",
    "tags": [
      "style-transfer",
      "photography"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/rabbit/QHdnOcB8IwyNRSkQOeVWE_aad27ab63cee47e8b6c15254f6813ac2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/photography-effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/photography-effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "effect_type": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "film",
          "vintage_film",
          "portrait_photography",
          "fashion_photography",
          "street_photography",
          "sepia_tone",
          "film_grain",
          "light_leaks",
          "vignette_effect",
          "instant_camera",
          "golden_hour",
          "dramatic_lighting",
          "soft_focus",
          "bokeh_effect",
          "high_contrast",
          "double_exposure"
        ],
        "default": "film"
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for photography effects",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/tugG2Q-XqMgf_ZoBr8KFO.jpeg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Image with photography effects",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/perspective",
    "title": "Perspective Change",
    "category": "image-to-image",
    "description": "Easily adjust the perspective of any image to different angles.",
    "tags": [
      "change-angle",
      "perspective"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/rabbit/PjquFEk5HynXyIj8Z1Xke_4ef010a6c99b4fa2a1f6639c233f8b93.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/perspective",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/perspective/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "target_perspective": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "front",
          "left_side",
          "right_side",
          "back",
          "top_down",
          "bottom_up",
          "birds_eye",
          "three_quarter_left",
          "three_quarter_right"
        ],
        "default": "front"
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for perspective change",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/lion/aqEiZ8Ui6rxWUB-Ujfu79_52c238c6d75d45538eaa71c50d329ba0.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Image with changed perspective",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/object-removal",
    "title": "Object Removal",
    "category": "image-to-image",
    "description": "Remove unwanted objects seamlessly from any image.",
    "tags": [
      "remove",
      "object-removal"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/m-e8Cm424GRXU0JdKie8l_915251cbaa4b4130a55547fde0f5bd36.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/object-removal",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/object-removal/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "object_to_remove": {
        "type": "string",
        "description": "Object to remove",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "Image URL containing object to remove",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/L_YMy6H5r_HYMacZX1qne_74a8fb6130164a18930af55370a1c9b2.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Image with object removed",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/headshot-photo",
    "title": "Headshot Generator",
    "category": "image-to-image",
    "description": "Generate professional headshot photos with customizable backgrounds.",
    "tags": [
      "headshot",
      "profile-photo"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/F4h1jbZoExQGajA6HDsTi_60aacfe738274239a2eb930f8c885bfa.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/headshot-photo",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/headshot-photo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "background_style": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "professional",
          "corporate",
          "clean",
          "gradient"
        ],
        "default": "professional"
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Portrait image URL to convert to professional headshot",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/oMob58qZJRtbDs5l45QKT_e3a1512c455d425fab2d62e07a51c506.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Professional headshot image",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/hair-change",
    "title": "Hair Change",
    "category": "image-to-image",
    "description": "Change hairstyles and hair colors in photos realistically.",
    "tags": [
      "hair-edit",
      "style-change"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/bfNDAz9O7I1IzLIMnQON0_5faa305ab343464989f49415737cc39d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/hair-change",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/hair-change/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "target_hairstyle": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "short_hair",
          "medium_long_hair",
          "long_hair",
          "curly_hair",
          "wavy_hair",
          "high_ponytail",
          "bun",
          "bob_cut",
          "pixie_cut",
          "braids",
          "straight_hair",
          "afro",
          "dreadlocks",
          "buzz_cut",
          "mohawk",
          "bangs",
          "side_part",
          "middle_part"
        ],
        "default": "long_hair"
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
        "required": false
      },
      "hair_color": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "black",
          "dark_brown",
          "light_brown",
          "blonde",
          "platinum_blonde",
          "red",
          "auburn",
          "gray",
          "silver",
          "blue",
          "green",
          "purple",
          "pink",
          "rainbow",
          "natural",
          "highlights",
          "ombre",
          "balayage"
        ],
        "default": "natural"
      },
      "image_url": {
        "type": "string",
        "description": "Portrait image URL for hair change",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/1ois7lqES78dLualcytmS_1e088ef24f474972824cffcfdd7ff291.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Portrait with changed hair",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/expression-change",
    "title": "Expression Change",
    "category": "image-to-image",
    "description": "Change facial expressions in photos with realistic results.",
    "tags": [
      "face-edit",
      "expression-change"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/2ZF-wegMjX4YdYMzLlauc_6176038c50b8492694be5872b350aa5d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/expression-change",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/expression-change/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
        "required": false
      },
      "target_expression": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "smile",
          "surprise",
          "glare",
          "panic",
          "shyness",
          "laugh",
          "cry",
          "angry",
          "sad",
          "happy",
          "excited",
          "shocked",
          "confused",
          "focused",
          "dreamy",
          "serious",
          "playful",
          "mysterious",
          "confident",
          "thoughtful"
        ],
        "default": "smile"
      },
      "image_url": {
        "type": "string",
        "description": "Portrait image URL for expression change",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/Gk5_0En-p1CNYnGOCDkl1_8332b944f8334ba9b3118b49e3e641cf.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Portrait with changed expression",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/city-teleport",
    "title": "City Teleport",
    "category": "image-to-image",
    "description": "Place a person’s photo into iconic cities worldwide.",
    "tags": [
      "city-teleport",
      "backgroundswap"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/dorvx78TXh0JIi4CASrhw_967925f37afb4f3489b89712b0639311.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/city-teleport",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/city-teleport/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "city_image_url": {
        "type": null,
        "description": "Optional city background image URL. When provided, the person will be blended into this custom scene.",
        "required": false
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output",
        "required": false
      },
      "city_name": {
        "type": "string",
        "description": "City name (used when city_image_url is not provided)",
        "required": true,
        "examples": [
          "Paris"
        ]
      },
      "photo_shot": {
        "type": "string",
        "description": "Type of photo shot",
        "required": false,
        "enum": [
          "extreme_close_up",
          "close_up",
          "medium_close_up",
          "medium_shot",
          "medium_long_shot",
          "long_shot",
          "extreme_long_shot",
          "full_body"
        ],
        "default": "medium_shot"
      },
      "camera_angle": {
        "type": "string",
        "description": "Camera angle for the shot",
        "required": false,
        "enum": [
          "eye_level",
          "low_angle",
          "high_angle",
          "dutch_angle",
          "birds_eye_view",
          "worms_eye_view",
          "overhead",
          "side_angle"
        ],
        "default": "eye_level"
      },
      "person_image_url": {
        "type": "string",
        "description": "Person photo URL",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/qsFWu-bO3FwcTQSym9HeL_e52f70668f2940a3b4ea2cab54fcb65b.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Person teleported to city location",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/age-modify",
    "title": "Age Modify",
    "category": "image-to-image",
    "description": "Modify a face to look younger or older while keeping identity realistic.",
    "tags": [
      "age-transformation",
      "face-editing"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/HOgA2l7XskHnD0rcabkPc_43ce3b12df8043d4aa6c9b98497ea32b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/age-modify",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/age-modify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "target_age": {
        "type": "integer",
        "description": "",
        "required": false,
        "minimum": 6,
        "maximum": 100,
        "default": 30
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
        "required": false
      },
      "preserve_identity": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "Portrait image URL for age modification",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/lion/s2GShUC7AB9i-ypYV0DbI_1b5ca4fe5d7e477fb4501acf9a1c43bc.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Portrait with modified age",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-apps-v2/makeup-application",
    "title": "Makeup Changer",
    "category": "image-to-image",
    "description": "Apply realistic makeup styles with adjustable intensity.",
    "tags": [
      "makeup",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/v3-_Ppam38Pq8cZ70oZPM_03aaba849a774a1f8e3a4bf4fbf6777f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-apps-v2/makeup-application",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-apps-v2/makeup-application/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
        "required": false
      },
      "makeup_style": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "natural",
          "glamorous",
          "smoky_eyes",
          "bold_lips",
          "no_makeup",
          "remove_makeup",
          "dramatic",
          "bridal",
          "professional",
          "korean_style",
          "artistic"
        ],
        "default": "natural"
      },
      "intensity": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "light",
          "medium",
          "heavy",
          "dramatic"
        ],
        "default": "medium"
      },
      "image_url": {
        "type": "string",
        "description": "Portrait image URL for makeup application",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/jpdD30YLw3OfPdVDxq1-D_1ec2e27f3e7d400fbf5f7aa2b80e89f0.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Portrait with applied makeup",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-edit/inpaint",
    "title": "Qwen Image Edit",
    "category": "image-to-image",
    "description": "Inpainting Endpoint for the Qwen Edit Image editing model.",
    "tags": [
      "image-to-image",
      "inpainting",
      "qwen-image"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/h_viUqwLJqnKY98Is1-HS_5c63021b7458464296a4fa264837f480.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit/inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Change the ball to a black and white football"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          "blurry, ugly"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "Strength of noising process for inpainting",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.93
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask for inpainting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/wan-22-vace-fun-a14b/reframe",
    "title": "Wan 2.2 VACE Fun A14B",
    "category": "video-to-video",
    "description": "VACE Fun for Wan 2.2 A14B from Alibaba-PAI",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/kangaroo/H7NXqbD7sGQs5qxcoZfVI_43b0ac4da3e24c9eadcfe61361b379af.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation. Optional for reframing.",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. This video will be used as a reference for the reframe task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "trim_borders": {
        "type": "boolean",
        "description": "Whether to trim borders from the video.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "zoom_factor": {
        "type": "number",
        "description": "Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.",
        "required": false,
        "minimum": 0,
        "maximum": 0.9,
        "default": 0,
        "examples": [
          0
        ]
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated reframe video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-22-vace-fun-a14b/outpainting",
    "title": "Wan 2.2 VACE Fun A14B",
    "category": "video-to-video",
    "description": "VACE Fun for Wan 2.2 A14B from Alibaba-PAI",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/tiger/qrBLSWxRlek4yKeAtyMaI_8d518c3fb3624b3ea62186e239c046c2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/outpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/outpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A lone woman strides through the neon-drenched streets of Tokyo at night.  Her crimson dress, a vibrant splash of color against the deep blues and blacks of the cityscape, flows slightly with each step. A tailored black jacket, crisp and elegant, contrasts sharply with the dress's rich texture. Medium shot:  The city hums around her, blurred lights creating streaks of color in the background. Close-up:  The fabric of her dress catches the streetlight's glow, revealing a subtle silk sheen and the intricate stitching at the hem. Her black jacket’s subtle texture is visible – a fine wool perhaps, with a matte finish. The overall mood is one of quiet confidence and mystery, a vibrant woman navigating a bustling, nocturnal landscape. High resolution 4k."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for outpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "expand_ratio": {
        "type": "number",
        "description": "Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.25,
        "examples": [
          0.25
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "expand_bottom": {
        "type": "boolean",
        "description": "Whether to expand the video to the bottom.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_left": {
        "type": "boolean",
        "description": "Whether to expand the video to the left.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_top": {
        "type": "boolean",
        "description": "Whether to expand the video to the top.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "expand_right": {
        "type": "boolean",
        "description": "Whether to expand the video to the right.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated outpainting video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-22-vace-fun-a14b/inpainting",
    "title": "Wan 2.2 VACE Fun A14B",
    "category": "video-to-video",
    "description": "VACE Fun for Wan 2.2 A14B from Alibaba-PAI",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/qkFGshBowZhFpgeUj-_UY_012ebaf8328540c5afb610e56c58d1c4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_video.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "Urls to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/vace/src_ref_image_1.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "mask_video_url": {
        "type": null,
        "description": "URL to the source mask file. Required for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_mask.mp4"
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "mask_image_url": {
        "type": null,
        "description": "URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video using salient mask tracking. Will be ignored if mask_video_url is provided.",
        "required": false
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated inpainting video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-22-vace-fun-a14b/depth",
    "title": "Wan 2.2 VACE Fun A14B",
    "category": "video-to-video",
    "description": "VACE Fun for Wan 2.2 A14B from Alibaba-PAI",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/kangaroo/GWwAzZDqhJ2AT1d6fVimr_a2c342bb17504782a5788e46c1796644.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/depth",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/depth/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A confident woman strides toward the camera down a sun-drenched, empty street. Her vibrant summer dress, a flowing emerald green with delicate white floral embroidery, billows slightly in the gentle breeze.  She carries a stylish, woven straw bag, its natural tan contrasting beautifully with the dress. The dress's fabric shimmers subtly, catching the light. The white embroidery is intricate, each tiny flower meticulously detailed.  Her expression is focused, yet relaxed, radiating self-assuredness. Her auburn hair, partially pulled back in a loose braid, catches the sunlight, creating warm highlights. The street itself is paved with warm, grey cobblestones, reflecting the bright sun. The mood is optimistic and serene, emphasizing the woman's independence and carefree spirit. High resolution 4k"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for depth task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-vace-depth-video.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated depth video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-22-vace-fun-a14b/pose",
    "title": "Wan 2.2 VACE Fun A14B",
    "category": "video-to-video",
    "description": "VACE Fun for Wan 2.2 A14B from Alibaba-PAI",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/lion/FjcKhg-ktT1dCP-F9RtJP_87d1ab4d3f3e4a8c82d53e6cc6d23616.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/pose",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-vace-fun-a14b/pose/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.",
        "required": true,
        "examples": [
          "A sharply dressed man walks toward the camera down a sun-drenched hallway.  Medium shot: He's framed from the knees up, his confident stride filling the frame.  His navy blue business suit is impeccably tailored, the fabric subtly shimmering under the light streaming through the tall, arched windows lining the hallway. Close-up:  The rich texture of the suit's wool is visible, each thread reflecting the light.  His crisp white shirt contrasts beautifully with the deep crimson of his silk tie, the knot perfectly formed.  The sunlight highlights the subtle sheen of his polished shoes.  The windows cast long shadows, highlighting the architectural detail of the hallway, creating a sense of both elegance and movement. High resolution 4k."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for pose task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-vace-pose-video.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated pose video file."
      }
    }
  },
  {
    "id": "perceptron/isaac-01/openai/v1/chat/completions",
    "title": "Isaac 0.1 [OpenAI Compatible Endpoint]",
    "category": "vision",
    "description": "Streaming version matching OpenAI spec of Isaac-01 which is a multimodal vision-language model from Perceptron for various vision language tasks.",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/720yUJX8pFwlDjjJKAuWT_f7c3757b6d9c4c63b808704c78ff0758.jpg",
    "playgroundUrl": "https://fal.ai/models/perceptron/isaac-01/openai/v1/chat/completions",
    "documentationUrl": "https://fal.ai/models/perceptron/isaac-01/openai/v1/chat/completions/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {},
    "outputParameters": {}
  },
  {
    "id": "perceptron/isaac-01",
    "title": "Isaac 0.1",
    "category": "vision",
    "description": "Isaac-01 is a multimodal vision-language model from Perceptron for various vision language tasks.",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/panda/nuuSn6Wf3q72FHqD8uppE_86098dbea31a439bb14ee16b29277afe.jpg",
    "playgroundUrl": "https://fal.ai/models/perceptron/isaac-01",
    "documentationUrl": "https://fal.ai/models/perceptron/isaac-01/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the image",
        "required": true,
        "examples": [
          "Which car is trying to park into garage?"
        ]
      },
      "response_style": {
        "type": "string",
        "description": "\nResponse style to be used for the image.\n\n- text: Model will output text. Good for descriptions and captioning.\n- box: Model will output a combination of text and bounding boxes. Good for\nlocalization.\n- point: Model will output a combination of text and points. Good for counting many\nobjects.\n- polygon: Model will output a combination of text and polygons. Good for granular\nsegmentation.\n",
        "required": false,
        "enum": [
          "text",
          "box",
          "point",
          "polygon"
        ],
        "default": "text"
      },
      "image_url": {
        "type": "string",
        "description": "Image URL to be processed",
        "required": true,
        "examples": [
          "https://v3b.fal.media/files/b/penguin/BxDPafViqMBGfNyvcmG-C_image-1d100e9%20(4).jpg"
        ]
      }
    },
    "outputParameters": {
      "usage": {
        "type": null,
        "description": "Usage information"
      },
      "error": {
        "type": null,
        "description": "Error message if an error occurred"
      },
      "partial": {
        "type": "boolean",
        "description": "Whether the output is partial"
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      }
    }
  },
  {
    "id": "fal-ai/flux/srpo/image-to-image",
    "title": "FLUX.1 SRPO [dev]",
    "category": "image-to-image",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/lion/h6ZndwWNcRsiobOzKCSmL_4ab6291336a74f78b4c90d9b42e97ab0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/srpo/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/srpo/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux/srpo",
    "title": "FLUX.1 SRPO [dev]",
    "category": "text-to-image",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/lion/ZNXdbSzAuCKiNcAobhmuq_433a1adbd71044199027c873cac81298.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/srpo",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/srpo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Mountain guide, sturdy build, wilderness wisdom, alert gaze, technical outdoor gear with rope coils, snow-capped peaks background, crisp mountain lighting, leading pose, wind-swept hair with full beard, weather-worn face with quiet confidence, alpine expert presence"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/srpo/image-to-image",
    "title": "FLUX.1 SRPO [dev]",
    "category": "image-to-image",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/panda/Lw4P1PGZPkZkAPI3u_Mxt_709597e8d0024e10ab25dfdf31963d0a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/srpo/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/srpo/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/srpo",
    "title": "FLUX.1 SRPO [dev]",
    "category": "text-to-image",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/sc5nHfAUsSmVjmNNzoHDo_0b10ed5de0c24d9f88df8ed0a350f49f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/srpo",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/srpo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Mountain guide, sturdy build, wilderness wisdom, alert gaze, technical outdoor gear with rope coils, snow-capped peaks background, crisp mountain lighting, leading pose, wind-swept hair with full beard, weather-worn face with quiet confidence, alpine expert presence"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/pshuman",
    "title": "Pshuman",
    "category": "image-to-3d",
    "description": "Use the 6D pose estimation capabilities of PSHuman to generate 3D files from single image.",
    "tags": [
      "image-to-3D"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/NmFYFxuC6qxi6oIj0K6Ig_4588fba5ffe44e098914def30b72d7cc.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pshuman",
    "documentationUrl": "https://fal.ai/models/fal-ai/pshuman/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the diffusion process. Controls how much the output adheres to the generated views.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "Seed for reproducibility. If None, a random seed will be used.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "A direct URL to the input image of a person.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/WhatsApp%20Image%202025-09-05%20at%2019.16.09%20(1).png"
        ]
      }
    },
    "outputParameters": {
      "model_obj": {
        "type": null,
        "description": "The generated 3D model in OBJ format."
      },
      "preview_image": {
        "type": null,
        "description": "A preview image showing the input and the generated multi-view outputs."
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1/tts",
    "title": "Kling TTS",
    "category": "text-to-speech",
    "description": "Generate speech from text prompts and different voices using the Kling TTS model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/zebra/kuLfhOkVceXDTcdBxGQAf_2011e640a3aa4acab55d01d69f3a6e16.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1/tts",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1/tts/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to be converted to speech",
        "required": true,
        "maxLength": 500,
        "examples": [
          "Hello world! Kling TTS is available on FAL!"
        ]
      },
      "voice_id": {
        "type": "string",
        "description": "The voice ID to use for speech synthesis",
        "required": false,
        "enum": [
          "genshin_vindi2",
          "zhinen_xuesheng",
          "AOT",
          "ai_shatang",
          "genshin_klee2",
          "genshin_kirara",
          "ai_kaiya",
          "oversea_male1",
          "ai_chenjiahao_712",
          "girlfriend_4_speech02",
          "chat1_female_new-3",
          "chat_0407_5-1",
          "cartoon-boy-07",
          "uk_boy1",
          "cartoon-girl-01",
          "PeppaPig_platform",
          "ai_huangzhong_712",
          "ai_huangyaoshi_712",
          "ai_laoguowang_712",
          "chengshu_jiejie",
          "you_pingjing",
          "calm_story1",
          "uk_man2",
          "laopopo_speech02",
          "heainainai_speech02",
          "reader_en_m-v1",
          "commercial_lady_en_f-v1",
          "tiyuxi_xuedi",
          "tiexin_nanyou",
          "girlfriend_1_speech02",
          "girlfriend_2_speech02",
          "zhuxi_speech02",
          "uk_oldman3",
          "dongbeilaotie_speech02",
          "chongqingxiaohuo_speech02",
          "chuanmeizi_speech02",
          "chaoshandashu_speech02",
          "ai_taiwan_man2_speech02",
          "xianzhanggui_speech02",
          "tianjinjiejie_speech02",
          "diyinnansang_DB_CN_M_04-v2",
          "yizhipiannan-v1",
          "guanxiaofang-v2",
          "tianmeixuemei-v1",
          "daopianyansang-v1",
          "mengwa-v1"
        ],
        "default": "genshin_vindi2"
      },
      "voice_speed": {
        "type": "number",
        "description": "Rate of speech",
        "required": false,
        "minimum": 0.8,
        "maximum": 2,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/ai-avatar",
    "title": "Kling AI Avatar",
    "category": "image-to-video",
    "description": "Kling AI Avatar Standard:  Endpoint for creating avatar videos with realistic humans, animals, cartoons, or stylized characters",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/rabbit/me_wmKnQJJevTKvSLGMF7_2948b05301c24578b9d28acb927f9c5c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/ai-avatar",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/ai-avatar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for the video generation.",
        "required": false,
        "default": "."
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/9_0ZG_geiWjZOmn9yscO6_output.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as your avatar",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/kling_ai_avatar_input.jpg"
        ]
      }
    },
    "outputParameters": {
      "duration": {
        "type": "number",
        "description": "Duration of the output video in seconds."
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1/pro/ai-avatar",
    "title": "Kling AI Avatar Pro",
    "category": "image-to-video",
    "description": "Kling AI Avatar Pro: The premium endpoint for creating avatar videos with realistic humans, animals, cartoons, or stylized characters",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/JkgpF_2-txAoKmW7MuTqt_0871571d0ba34433b57f86fbce62d273.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1/pro/ai-avatar",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1/pro/ai-avatar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for the video generation.",
        "required": false,
        "default": "."
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/9_0ZG_geiWjZOmn9yscO6_output.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as your avatar",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/kling_ai_avatar_input.jpg"
        ]
      }
    },
    "outputParameters": {
      "duration": {
        "type": "number",
        "description": "Duration of the output video in seconds."
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax-music/v1.5",
    "title": "MiniMax (Hailuo AI) Music v1.5",
    "category": "text-to-audio",
    "description": "Generate music from text prompts using the MiniMax model, which leverages advanced AI techniques to create high-quality, diverse musical compositions.",
    "tags": [
      "music"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/q1SQZ1uvnaCmUpVZjCoOM_f19b7483fe804f00bf6473cd3eae0eeb.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax-music/v1.5",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax-music/v1.5/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Lyrics, supports [intro][verse][chorus][bridge][outro] sections. 10-600 characters.",
        "required": true,
        "minLength": 10,
        "maxLength": 600,
        "examples": [
          "[verse]\n Fast and Limitless   \n In the heart of the code, where dreams collide,   \n\nFAL's the name, taking tech for a ride.    \nGenerative media, blazing the trail,   \n\nFast inference power, we'll never fail.\n##"
        ]
      },
      "lyrics_prompt": {
        "type": "string",
        "description": "Control music generation. 10-300 characters.",
        "required": true,
        "minLength": 10,
        "maxLength": 300,
        "examples": [
          "R&B, energetic"
        ]
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "decart/lucy-14b/image-to-video",
    "title": "Decart Lucy 14b",
    "category": "image-to-video",
    "description": "Lucy-14B delivers lightning fast performance that redefines what's possible with image-to-video AI",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/panda/CmMm-4CuFQUroMjHGYrv9_99edaa2eb5b34834b08717f4fbc23cca.jpg",
    "playgroundUrl": "https://fal.ai/models/decart/lucy-14b/image-to-video",
    "documentationUrl": "https://fal.ai/models/decart/lucy-14b/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the image directly\n            in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p"
        ],
        "default": "720p"
      },
      "prompt": {
        "type": "string",
        "description": "Text description of the desired video content",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "A cinematic video begins with a woman standing in an art studio, wearing a paint-splattered apron over a white off-shoulder blouse, surrounded by colorful canvases on easels. She gently plays with her hair for a moment, then straightens her head and looks directly at the camera with a warm smile. After holding the smile, she gracefully twirls around in place, her apron flowing slightly with the motion, creating a playful and artistic atmosphere against the backdrop of her vibrant paintings."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/lucy-14b/lucy-14b-art-swirl-image.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated MP4 video with H.264 encoding"
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-edit-lora",
    "title": "Qwen Image Edit Lora",
    "category": "image-to-image",
    "description": "LoRA inference endpoint for the Qwen Image Editing model.",
    "tags": [
      "image-to-image",
      "image-editing",
      "lora"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/TLOrc_UR0t-P9eEqdlnKO_7873734a28ad4a5085fdb207645a902f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Change bag to apple macbook"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none",
        "examples": [
          "regular"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          "blurry, ugly"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/stable-audio-25/audio-to-audio",
    "title": "Stable Audio 2.5",
    "category": "audio-to-audio",
    "description": "Generate high quality music and sound effects using Stable Audio 2.5 from StabilityAI",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/1Z1jBiJuU6ZpY5-N4X6uO_9d6e67b3d66b4fc2b4bbeaf8cb80900f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-audio-25/audio-to-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-audio-25/audio-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to guide the audio generation",
        "required": true,
        "examples": [
          "Post rock, guitars, bass, strings, euphoric, up-lifting, moody, flowing, raw, epic"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Sometimes referred to as denoising, this parameter controls how much influence the `audio_url` parameter has on the generated audio. A value of 0 would yield audio that is identical to the input. A value of 1 would be as if you passed in no audio at all.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "audio_url": {
        "type": "string",
        "description": "The audio clip to transform",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/1-0iezBUIePBa3Sz5YY5B_tmpy1jyshw9.wav"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of steps to denoise the audio for",
        "required": false,
        "minimum": 4,
        "maximum": 8,
        "default": 8
      },
      "guidance_scale": {
        "type": "integer",
        "description": "How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt). ",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "",
        "required": false
      },
      "total_seconds": {
        "type": "integer",
        "description": "The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.",
        "required": false,
        "minimum": 1,
        "maximum": 190,
        "examples": [
          45
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The random seed used for generation"
      },
      "audio": {
        "type": null,
        "description": "The generated audio clip"
      }
    }
  },
  {
    "id": "fal-ai/stable-audio-25/text-to-audio",
    "title": "Stable Audio 2.5",
    "category": "text-to-audio",
    "description": "Generate high quality music and sound effects using Stable Audio 2.5 from StabilityAI",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/N_r3ILjHQBEDIf8umQMMd_f51771186f184c43ab1257350772d2f6.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-audio-25/text-to-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-audio-25/text-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate audio from",
        "required": true,
        "examples": [
          "A beautiful piano arpeggio grows into a grand orchestral climax"
        ]
      },
      "seconds_total": {
        "type": "integer",
        "description": "The duration of the audio clip to generate",
        "required": false,
        "minimum": 1,
        "maximum": 190,
        "default": 190
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of steps to denoise the audio for",
        "required": false,
        "minimum": 4,
        "maximum": 8,
        "default": 8
      },
      "guidance_scale": {
        "type": "integer",
        "description": "How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The random seed used for generation"
      },
      "audio": {
        "type": null,
        "description": "The generated audio clip"
      }
    }
  },
  {
    "id": "fal-ai/stable-audio-25/inpaint",
    "title": "Stable Audio 25",
    "category": "audio-to-audio",
    "description": "Generate high quality music and sound effects using Stable Audio 2.5 from StabilityAI",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/hfCAX4rFa62XwpVf6ikd3_bf07bf4907c84a6babcb187eb4363b80.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-audio-25/inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-audio-25/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to guide the audio generation",
        "required": true,
        "examples": [
          "Lofi hip hop beat, chillhop"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "",
        "required": false
      },
      "mask_end": {
        "type": "integer",
        "description": "The end point of the audio mask",
        "required": false,
        "minimum": 0,
        "maximum": 190,
        "default": 190,
        "examples": [
          40
        ]
      },
      "guidance_scale": {
        "type": "integer",
        "description": "How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt). ",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 1
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of steps to denoise the audio for",
        "required": false,
        "minimum": 4,
        "maximum": 8,
        "default": 8
      },
      "seconds_total": {
        "type": "integer",
        "description": "The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.",
        "required": false,
        "minimum": 1,
        "maximum": 190,
        "default": 190,
        "examples": [
          45
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The audio clip to inpaint",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/t0ZrzW_ueetXrr3NUa87F_a2a_in.mp3"
        ]
      },
      "mask_start": {
        "type": "integer",
        "description": "The start point of the audio mask",
        "required": false,
        "minimum": 0,
        "maximum": 190,
        "default": 30,
        "examples": [
          15
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The random seed used for generation"
      },
      "audio": {
        "type": null,
        "description": "The generated audio clip"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-image/v2.1/text-to-image",
    "title": "Hunyuan Image",
    "category": "text-to-image",
    "description": "Use the amazing capabilities of hunyuan image 2.1 to generate images that express the feelings of your text.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/fl_uWB5P9sMjDBhq_7hG0_644c0f46ad94482d8e2e09e180e64c88.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-image/v2.1/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-image/v2.1/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cute, cartoon-style anthropomorphic penguin plush toy, standing in a painting studio, wearing a red knitted scarf and beret."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The desired size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "use_reprompt": {
        "type": "boolean",
        "description": "Enable prompt enhancement for potentially better results.",
        "required": false,
        "default": true
      },
      "use_refiner": {
        "type": "boolean",
        "description": "Enable the refiner model for improved image quality.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Controls how much the model adheres to the prompt. Higher values mean stricter adherence.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible results. If None, a random seed is used.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of denoising steps.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to guide the image generation away from certain concepts.",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, watermark, signature"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "A list of the generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "The base seed used for the generation process."
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/text-to-dialogue/eleven-v3",
    "title": "Elevenlabs",
    "category": "text-to-audio",
    "description": "Generate realistic audio dialogues using Eleven-v3 from ElevenLabs.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/twZsKdCTiF8JXv-rRcPZu_8414166d52a548859a8df01bf720fe46.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/text-to-dialogue/eleven-v3",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "stability": {
        "type": null,
        "description": "Determines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion.",
        "required": false
      },
      "inputs": {
        "type": "array",
        "description": "A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.",
        "required": true,
        "examples": [
          [
            {
              "text": "[applause] Thank you all for coming tonight! Today we have a very special guest with us.",
              "voice": "Aria"
            },
            {
              "text": "[gulps] ... [strong canadian accent] [excited] Hello everyone! Thank you all for having me tonight on this special day.",
              "voice": "Charlotte"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/DialogueBlock"
        }
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility.",
        "required": false
      },
      "use_speaker_boost": {
        "type": null,
        "description": "This setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.",
        "required": false
      },
      "pronunciation_dictionary_locators": {
        "type": "array",
        "description": "A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/PronunciationDictionaryLocator"
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/vidu/reference-to-image",
    "title": "Vidu",
    "category": "image-to-image",
    "description": "Vidu Reference-to-Image creates images by using a reference images and combining them with a prompt.",
    "tags": [
      "images-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/reference-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/reference-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "The little devil is looking at the apple on the beach and walking around it."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "reference_image_urls": {
        "type": "array",
        "description": "URLs of the reference images to use for consistent subject appearance",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference1.png",
            "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference2.png",
            "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference3.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The edited image"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedream/v4/edit",
    "title": "Bytedance Seedream v4 Edit",
    "category": "image-to-image",
    "description": "A new-generation image creation model ByteDance, Seedream 4.0 integrates image generation and image editing capabilities into a single, unified architecture.",
    "tags": [
      "stylized",
      "transform",
      "editing"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/6sPEukO8Ky0J7Y3dgv-OV_33a012d1372c4951942465b87a3d83ce.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedream/v4/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedream/v4/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to edit the image",
        "required": true,
        "examples": [
          "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of separate model generations to be run with the prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 6,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. The minimum total image area is 921600 pixels. Failing this, the image size will be adjusted to by scaling it up, while maintaining the aspect ratio.",
        "required": false,
        "default": {
          "height": 2048,
          "width": 2048
        },
        "examples": [
          {
            "height": 2160,
            "width": 3840
          }
        ]
      },
      "max_images": {
        "type": "integer",
        "description": "If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15",
        "required": false,
        "minimum": 1,
        "maximum": 6,
        "default": 1
      },
      "enhance_prompt_mode": {
        "type": "string",
        "description": "The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.",
        "required": false,
        "enum": [
          "standard",
          "fast"
        ],
        "default": "standard"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control the stochasticity of image generation.",
        "required": false
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_1.png",
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_2.png",
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_3.png",
            "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_4.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedream/v4/text-to-image",
    "title": "Bytedance Seedream v4",
    "category": "text-to-image",
    "description": "A new-generation image creation model ByteDance, Seedream 4.0 integrates image generation and image editing capabilities into a single, unified architecture.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/MTKbHTmLwlCPVvxnEPYVW_cd47bf24871b46af9747a5fcb7f4f97b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedream/v4/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedream/v4/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the image",
        "required": true,
        "examples": [
          "A trendy restaurant with a digital menu board displaying \"Seedream 4.0 is available on fal\" in elegant script, with diners enjoying their meals."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of separate model generations to be run with the prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 6,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Width and height must be between 1024 and 4096.",
        "required": false,
        "default": {
          "height": 2048,
          "width": 2048
        },
        "examples": [
          {
            "height": 4096,
            "width": 4096
          }
        ]
      },
      "max_images": {
        "type": "integer",
        "description": "If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`.",
        "required": false,
        "minimum": 1,
        "maximum": 6,
        "default": 1
      },
      "enhance_prompt_mode": {
        "type": "string",
        "description": "The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.",
        "required": false,
        "enum": [
          "standard",
          "fast"
        ],
        "default": "standard"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control the stochasticity of image generation.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video-foley",
    "title": "Hunyuan Video Foley",
    "category": "video-to-video",
    "description": "Use the capabilities of the hunyuan foley model to bring life to your videos by adding sound effect to them.",
    "tags": [
      "video-to-video",
      "add-sound"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/3ZFQ2t2qtiioCi2l04ALY_33a1818a6de949c0801ab825dfae6245.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-foley",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-foley/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate audio for.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/1_video.mp4"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for audio generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for generation.",
        "required": false,
        "minimum": 10,
        "maximum": 100,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to avoid certain audio characteristics.",
        "required": false,
        "default": "noisy, harsh"
      },
      "text_prompt": {
        "type": "string",
        "description": "Text description of the desired audio (optional).",
        "required": true,
        "examples": [
          "A person walks on frozen ice",
          "The crackling of fire and whooshing of flames",
          "Gentle footsteps on wooden floor"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "List of generated video files with audio."
      }
    }
  },
  {
    "id": "fal-ai/chatterbox/text-to-speech/multilingual",
    "title": "Chatterbox",
    "category": "text-to-speech",
    "description": "Whether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. Use the first tts from resemble ai.",
    "tags": [
      "text-to-speech",
      "multilingual"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/FzzCnGuQNXLOEYuQq8CE8_7afb3290e0de46d5a7e4d13495938e3f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/chatterbox/text-to-speech/multilingual",
    "documentationUrl": "https://fal.ai/models/fal-ai/chatterbox/text-to-speech/multilingual/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to be converted to speech (maximum 300 characters). Supports 23 languages including English, French, German, Spanish, Italian, Portuguese, Hindi, Arabic, Chinese, Japanese, Korean, and more.",
        "required": true,
        "maxLength": 300,
        "examples": [
          "Last month, we reached a new milestone with two billion views on our YouTube channel.",
          "Le mois dernier, nous avons atteint un nouveau jalon avec deux milliards de vues sur notre chaîne YouTube."
        ]
      },
      "custom_audio_language": {
        "type": "string",
        "description": "If using a custom audio URL, specify the language of the audio here. Ignored if voice is not a custom url.",
        "required": false,
        "enum": [
          "english",
          "arabic",
          "danish",
          "german",
          "greek",
          "spanish",
          "finnish",
          "french",
          "hebrew",
          "hindi",
          "italian",
          "japanese",
          "korean",
          "malay",
          "dutch",
          "norwegian",
          "polish",
          "portuguese",
          "russian",
          "swedish",
          "swahili",
          "turkish",
          "chinese"
        ]
      },
      "exaggeration": {
        "type": "number",
        "description": "Controls speech expressiveness and emotional intensity (0.25-2.0). 0.5 is neutral, higher values increase expressiveness. Extreme values may be unstable.",
        "required": false,
        "minimum": 0.25,
        "maximum": 2,
        "default": 0.5
      },
      "voice": {
        "type": "string",
        "description": "Language code for synthesis. In case using custom please provide audio url and select custom_audio_language. ",
        "required": false,
        "default": "english",
        "examples": [
          "english",
          "arabic",
          "danish",
          "german",
          "greek",
          "spanish",
          "finnish",
          "french",
          "hebrew",
          "hindi",
          "italian",
          "japanese",
          "korean",
          "malay",
          "dutch",
          "norwegian",
          "polish",
          "portuguese",
          "russian",
          "swedish",
          "swahili",
          "turkish",
          "chinese"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible results. Set to 0 for random generation, or provide a specific number for consistent outputs.",
        "required": false
      },
      "temperature": {
        "type": "number",
        "description": "Controls randomness and variation in generation (0.05-5.0). Higher values create more varied speech patterns.",
        "required": false,
        "minimum": 0.05,
        "maximum": 5,
        "default": 0.8
      },
      "cfg_scale": {
        "type": "number",
        "description": "Configuration/pace weight controlling generation guidance (0.0-1.0). Use 0.0 for language transfer to mitigate accent inheritance.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated multilingual speech audio file"
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-image",
    "title": "Wan",
    "category": "image-to-image",
    "description": "Wan 2.2's 14B model edit high-resolution, photorealistic images with powerful prompt understanding and fine-grained visual detail",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide image generation.",
        "required": true,
        "examples": [
          "A cinematic shot of an ancient city at sunset, intricate stone buildings, warm golden light"
        ]
      },
      "image_size": {
        "type": null,
        "description": "",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "image_format": {
        "type": "string",
        "description": "The format of the output image.",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "jpeg",
        "examples": [
          "jpeg"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated image. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-image-to-image-input.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Denoising strength. 1.0 = fully remake; 0.0 = preserve original.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for image generation."
      },
      "image": {
        "type": null,
        "description": "The generated image file."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/sound-effects/v2",
    "title": "Elevenlabs",
    "category": "text-to-audio",
    "description": "Generate sound effects using ElevenLabs advanced sound effects model.",
    "tags": [
      "sound"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/elevenlabs/elevenlabs_thumbnail.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/sound-effects/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/sound-effects/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text describing the sound effect to generate",
        "required": true,
        "examples": [
          "Spacious braam suitable for high-impact movie trailer moments",
          "A gentle wind chime tinkling in a soft breeze"
        ]
      },
      "loop": {
        "type": "boolean",
        "description": "Whether to create a sound effect that loops smoothly.",
        "required": false,
        "default": false
      },
      "prompt_influence": {
        "type": "number",
        "description": "How closely to follow the prompt (0-1). Higher values mean less variation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.3
      },
      "output_format": {
        "type": "string",
        "description": "Output format of the generated audio. Formatted as codec_sample_rate_bitrate.",
        "required": false,
        "enum": [
          "mp3_22050_32",
          "mp3_44100_32",
          "mp3_44100_64",
          "mp3_44100_96",
          "mp3_44100_128",
          "mp3_44100_192",
          "pcm_8000",
          "pcm_16000",
          "pcm_22050",
          "pcm_24000",
          "pcm_44100",
          "pcm_48000",
          "ulaw_8000",
          "alaw_8000",
          "opus_48000_32",
          "opus_48000_64",
          "opus_48000_96",
          "opus_48000_128",
          "opus_48000_192"
        ],
        "default": "mp3_44100_128"
      },
      "duration_seconds": {
        "type": null,
        "description": "Duration in seconds (0.5-22). If None, optimal duration will be determined from prompt.",
        "required": false
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated sound effect audio file in MP3 format"
      }
    }
  },
  {
    "id": "fal-ai/sync-lipsync/v2/pro",
    "title": "Sync Lipsync",
    "category": "video-to-video",
    "description": "Generate high-quality realistic lipsync animations from audio while preserving unique details like natural teeth and unique facial features using the state-of-the-art Sync Lipsync 2 Pro model.",
    "tags": [
      "animation",
      "lip sync",
      "high-quality",
      ""
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/LWtPGHOS-rwf3YakNhv1k_cbaee3dc5fa14f7a9b6fc63f048de8d4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sync-lipsync/v2/pro",
    "documentationUrl": "https://fal.ai/models/fal-ai/sync-lipsync/v2/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "string",
        "description": "Lipsync mode when audio and video durations are out of sync.",
        "required": false,
        "enum": [
          "cut_off",
          "loop",
          "bounce",
          "silence",
          "remap"
        ],
        "default": "cut_off"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/sync_v2_pro_video_input.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the input audio",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/sync_v2_pro_audio_input.mp3"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/lite/reference-to-video",
    "title": "Bytedance",
    "category": "image-to-video",
    "description": "Seedance lite reference-to-video allows the use of 1 to 4 images as reference to create a high-quality video.",
    "tags": [
      "reference-to-video",
      "image-to-video",
      ""
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/B49-COdFROSlS850S1PfV_be7c6c85a41b4410ae02216253e5c6f8.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/lite/reference-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/lite/reference-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "The girl catches the puppy and hugs it."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16",
          "auto"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      },
      "reference_image_urls": {
        "type": "array",
        "description": "Reference images to generate the video with.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/example_inputs/seedance_reference.jpeg",
            "https://storage.googleapis.com/falserverless/example_inputs/seedance_reference_2.jpeg"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "argil/avatars/text-to-video",
    "title": "Avatars Text to Video",
    "category": "text-to-video",
    "description": "High-quality avatar videos that feel real, generated from your text",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/zebra/9NGo8wnyQwuQTJQr4Cvht_27981df50e43459ea657ea36bee1b76b.jpg",
    "playgroundUrl": "https://fal.ai/models/argil/avatars/text-to-video",
    "documentationUrl": "https://fal.ai/models/argil/avatars/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "\nArgil is kinda crazy guys! You just turn a real person into \nan avatar that actually talks and moves and it's already reel-ready, \nfor TikTok, Shorts, whatever. No wasting hours editing, it still looks super pro.\n"
        ]
      },
      "voice": {
        "type": "string",
        "description": "",
        "required": true,
        "enum": [
          "Rachel",
          "Clyde",
          "Roger",
          "Sarah",
          "Laura",
          "Thomas",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Harry",
          "Liam",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Lilly",
          "Bill",
          "Oxley",
          "Luna"
        ]
      },
      "remove_background": {
        "type": "boolean",
        "description": "Enabling the remove background feature will result in a 50% increase in the price.",
        "required": false,
        "default": false
      },
      "avatar": {
        "type": "string",
        "description": "",
        "required": true,
        "enum": [
          "Mia outdoor (UGC)",
          "Lara (Masterclass)",
          "Ines (UGC)",
          "Maria (Masterclass)",
          "Emma (UGC)",
          "Sienna (Masterclass)",
          "Elena (UGC)",
          "Jasmine (Masterclass)",
          "Amara (Masterclass)",
          "Ryan podcast (UGC)",
          "Tyler (Masterclass)",
          "Jayse (Masterclass)",
          "Paul (Masterclass)",
          "Matteo (UGC)",
          "Daniel car (UGC)",
          "Dario (Masterclass)",
          "Viva (Masterclass)",
          "Chen (Masterclass)",
          "Alex (Masterclass)",
          "Vanessa (UGC)",
          "Laurent (UGC)",
          "Noemie car (UGC)",
          "Brandon (UGC)",
          "Byron (Masterclass)",
          "Calista (Masterclass)",
          "Milo (Masterclass)",
          "Fabien (Masterclass)",
          "Rose (UGC)"
        ],
        "examples": [
          "Noemie car (UGC)"
        ]
      }
    },
    "outputParameters": {
      "moderation_transcription": {
        "type": null,
        "description": ""
      },
      "moderation_error": {
        "type": null,
        "description": ""
      },
      "moderation_flagged": {
        "type": "boolean",
        "description": ""
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "argil/avatars/audio-to-video",
    "title": "Avatars Audio to Video",
    "category": "audio-to-video",
    "description": "High-quality avatar videos that feel real, generated from your audio",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/penguin/I9P-RPQjSACURLjmQX0XV_aaaeea3d3fc94835b1ad3c4f98ebd0ea.jpg",
    "playgroundUrl": "https://fal.ai/models/argil/avatars/audio-to-video",
    "documentationUrl": "https://fal.ai/models/argil/avatars/audio-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "avatar": {
        "type": "string",
        "description": "",
        "required": true,
        "enum": [
          "Mia outdoor (UGC)",
          "Lara (Masterclass)",
          "Ines (UGC)",
          "Maria (Masterclass)",
          "Emma (UGC)",
          "Sienna (Masterclass)",
          "Elena (UGC)",
          "Jasmine (Masterclass)",
          "Amara (Masterclass)",
          "Ryan podcast (UGC)",
          "Tyler (Masterclass)",
          "Jayse (Masterclass)",
          "Paul (Masterclass)",
          "Matteo (UGC)",
          "Daniel car (UGC)",
          "Dario (Masterclass)",
          "Viva (Masterclass)",
          "Chen (Masterclass)",
          "Alex (Masterclass)",
          "Vanessa (UGC)",
          "Laurent (UGC)",
          "Noemie car (UGC)",
          "Brandon (UGC)",
          "Byron (Masterclass)",
          "Calista (Masterclass)",
          "Milo (Masterclass)",
          "Fabien (Masterclass)",
          "Rose (UGC)"
        ],
        "examples": [
          "Noemie car (UGC)"
        ]
      },
      "remove_background": {
        "type": "boolean",
        "description": "Enabling the remove background feature will result in a 50% increase in the price.",
        "required": false,
        "default": false
      },
      "audio_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          {
            "url": "https://argildotai.s3.us-east-1.amazonaws.com/fal-resource/example_fal.mp3"
          }
        ]
      }
    },
    "outputParameters": {
      "moderation_transcription": {
        "type": null,
        "description": ""
      },
      "moderation_error": {
        "type": null,
        "description": ""
      },
      "moderation_flagged": {
        "type": "boolean",
        "description": ""
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/uso",
    "title": "Uso",
    "category": "image-to-image",
    "description": "Use USO to perform subject driven generations using reference image.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/5WCxaQjQ18eFu6qeVTJ2w_700fa4cd63ee445ca3d8d6cd94a356d5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/uso",
    "documentationUrl": "https://fal.ai/models/fal-ai/uso/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for generation. Can be empty for pure style transfer.",
        "required": false,
        "default": "",
        "examples": [
          "A handsome man."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate in parallel.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. ",
        "required": false,
        "default": "square_hd"
      },
      "output_format": {
        "type": "string",
        "description": "Output image format. PNG preserves transparency, JPEG is smaller.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "keep_size": {
        "type": "boolean",
        "description": "Preserve the layout and dimensions of the input content image. Useful for style transfer.",
        "required": false,
        "default": false
      },
      "input_image_urls": {
        "type": "array",
        "description": "List of image URLs in order: [content_image, style_image, extra_style_image].",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/USO/style3.webp",
            "https://storage.googleapis.com/falserverless/USO/style4.webp"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If true, wait for generation and upload before returning. Increases latency but provides immediate access to images.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "How closely to follow the prompt. Higher values stick closer to the prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of denoising steps. More steps can improve quality but increase generation time.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation. Use same seed for consistent results.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "What you don't want in the image. Use it to exclude unwanted elements, styles, or artifacts.",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, distorted, ugly, bad anatomy",
          "cartoon, anime, illustration",
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Enable NSFW content detection and filtering.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation"
      },
      "images": {
        "type": "array",
        "description": "The generated images with applied style and/or subject customization",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "Performance timings for different stages"
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "NSFW detection results for each generated image",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/decart/lucy-5b/image-to-video",
    "title": "Decart",
    "category": "image-to-video",
    "description": "Lucy-5B is a model that can create 5-second I2V videos in under 5 seconds, achieving >1x RTF end-to-end",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/kangaroo/srM1hEjGsuYwd4UhvzpE7_c5bddd630600497e918bb16e99e21653.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/decart/lucy-5b/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/decart/lucy-5b/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text description of the desired video content",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "A cat is walking slowly in the garden"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p"
        ],
        "default": "720p"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/OlpQEYh7oNeJ3qKsdiaym_ia5ECOgFbfcniMDu01_18_da73e078e0924472b51d92f3e3fba98c.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated MP4 video with H.264 encoding"
      }
    }
  },
  {
    "id": "fal-ai/wan-fun-control",
    "title": "Wan 2.2 Fun Control",
    "category": "video-to-video",
    "description": "Generate pose or depth controlled video using Alibaba-PAI's Wan 2.2 Fun",
    "tags": [
      "wan",
      "pose",
      "depth"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/fucmWwAIt1kX7fdfTHkxo_a344226d24a74d4e805d4ad606fdc00d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-fun-control",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-fun-control/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video.",
        "required": true,
        "examples": [
          "A woman wearing a lavender floral dress spins around in a circle."
        ]
      },
      "shift": {
        "type": "number",
        "description": "The shift for the scheduler.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "preprocess_video": {
        "type": "boolean",
        "description": "Whether to preprocess the video. If True, the video will be preprocessed to depth or pose.",
        "required": false,
        "default": false
      },
      "reference_image_url": {
        "type": "string",
        "description": "The URL of the reference image to use as a reference for the video generation.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-fun-input-reference-image.webp"
        ]
      },
      "fps": {
        "type": "integer",
        "description": "The fps to generate. Only used when match_input_fps is False.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "Whether to match the number of frames in the input video.",
        "required": false,
        "default": true
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 6
      },
      "preprocess_type": {
        "type": "string",
        "description": "The type of preprocess to apply to the video. Only used when preprocess_video is True.",
        "required": false,
        "enum": [
          "depth",
          "pose"
        ],
        "default": "depth"
      },
      "control_video_url": {
        "type": "string",
        "description": "The URL of the control video to use as a reference for the video generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-fun-control-video-input.mp4"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate the video.",
        "required": false,
        "default": ""
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate. Only used when match_input_num_frames is False.",
        "required": false,
        "minimum": 49,
        "maximum": 121,
        "default": 81
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps.",
        "required": false,
        "minimum": 4,
        "maximum": 50,
        "default": 27
      },
      "match_input_fps": {
        "type": "boolean",
        "description": "Whether to match the fps in the input video.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The video generated by the model."
      }
    }
  },
  {
    "id": "fal-ai/vibevoice/7b",
    "title": "VibeVoice 7B",
    "category": "text-to-speech",
    "description": "Generate long, expressive multi-voice speech using Microsoft's powerful TTS",
    "tags": [
      "text-to-speech",
      "multi-speaker",
      "podcast"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/5_nmz_TLmy87FiukLCnNM_19cf8bee41214a099ad9b8a2d1d7e160.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vibevoice/7b",
    "documentationUrl": "https://fal.ai/models/fal-ai/vibevoice/7b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "script": {
        "type": "string",
        "description": "The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.",
        "required": true,
        "maxLength": 30000,
        "examples": [
          "Speaker 0: VibeVoice is now available on Fal. Isn't that right, Carter?\nSpeaker 1: That's right Frank, and it supports up to four speakers at once. Try it now!"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation.",
        "required": false
      },
      "speakers": {
        "type": "array",
        "description": "List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.",
        "required": true,
        "examples": [
          [
            {
              "preset": "Frank [EN]"
            },
            {
              "preset": "Carter [EN]"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/VibeVoiceSpeaker"
        }
      },
      "cfg_scale": {
        "type": "number",
        "description": "CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1.3
      }
    },
    "outputParameters": {
      "duration": {
        "type": "number",
        "description": "Duration of the generated audio in seconds"
      },
      "rtf": {
        "type": "number",
        "description": "Real-time factor (generation_time / audio_duration). Lower is better."
      },
      "sample_rate": {
        "type": "integer",
        "description": "Sample rate of the generated audio"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file containing the speech"
      },
      "generation_time": {
        "type": "number",
        "description": "Time taken to generate the audio in seconds"
      }
    }
  },
  {
    "id": "fal-ai/vibevoice",
    "title": "VibeVoice 1.5B",
    "category": "text-to-speech",
    "description": "Generate long, expressive multi-voice speech using Microsoft's powerful TTS",
    "tags": [
      "text-to-speech",
      "multi-speaker",
      "podcast"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/iW_TAXlsir_HRdRs3sGeO_2473bedbf906459b9b70adafd02143eb.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vibevoice",
    "documentationUrl": "https://fal.ai/models/fal-ai/vibevoice/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "script": {
        "type": "string",
        "description": "The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.",
        "required": true,
        "maxLength": 90000,
        "examples": [
          "Speaker 0: VibeVoice is now available on Fal. Isn't that right, Carter?\nSpeaker 1: That's right Frank, and it supports up to four speakers at once. Try it now!"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation.",
        "required": false
      },
      "speakers": {
        "type": "array",
        "description": "List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.",
        "required": true,
        "examples": [
          [
            {
              "preset": "Frank [EN]"
            },
            {
              "preset": "Carter [EN]"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/VibeVoiceSpeaker"
        }
      },
      "cfg_scale": {
        "type": "number",
        "description": "CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1.3
      }
    },
    "outputParameters": {
      "duration": {
        "type": "number",
        "description": "Duration of the generated audio in seconds"
      },
      "rtf": {
        "type": "number",
        "description": "Real-time factor (generation_time / audio_duration). Lower is better."
      },
      "sample_rate": {
        "type": "integer",
        "description": "Sample rate of the generated audio"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file containing the speech"
      },
      "generation_time": {
        "type": "number",
        "description": "Time taken to generate the audio in seconds"
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-14b/speech-to-video",
    "title": "Wan-2.2 Speech-to-Video 14B",
    "category": "audio-to-video",
    "description": "Wan-S2V is a video model that generates high-quality videos from static images and audio, with realistic facial expressions, body movements, and professional camera work for film and television applications",
    "tags": [
      "audio-to-video",
      "talking-head"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/RBd4Rg392hzKwxahCIuRb_503c4ef0d3a141c09e4060aa0e3ab5e1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-14b/speech-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-14b/speech-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation.",
        "required": true,
        "examples": [
          "Summer beach vacation style, a white cat wearing sunglasses sits on a surfboard."
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16,
        "examples": [
          16
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 40 to 120, (must be multiple of 4).",
        "required": false,
        "minimum": 40,
        "maximum": 120,
        "default": 80,
        "examples": [
          80
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "480p",
        "examples": [
          "480p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan_s2v_cat.png"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan_s2v_talk.wav"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "bria/video/increase-resolution",
    "title": "Video",
    "category": "video-to-video",
    "description": "Upscale videos up to 8K output resolution. Trained on fully licensed and commercially safe data.",
    "tags": [
      "video-upscaling",
      "upscale"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/omvoJT1pplSUhjUPCyluq_3379d19b520046aa88fbc60e473629e3.jpg",
    "playgroundUrl": "https://fal.ai/models/bria/video/increase-resolution",
    "documentationUrl": "https://fal.ai/models/bria/video/increase-resolution/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "Input video to increase resolution. Size should be less than 14142x14142 and duration less than 30s.",
        "required": true,
        "examples": [
          "https://bria-datasets.s3.us-east-1.amazonaws.com/video_increase_res/3446608-sd_426_240_25fps.mp4"
        ]
      },
      "output_container_and_codec": {
        "type": "string",
        "description": "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, mov_h265, mov_proresks, mkv_h265, mkv_h264, mkv_vp9, gif.",
        "required": false,
        "enum": [
          "mp4_h265",
          "mp4_h264",
          "webm_vp9",
          "mov_h265",
          "mov_proresks",
          "mkv_h265",
          "mkv_h264",
          "mkv_vp9",
          "gif"
        ],
        "default": "webm_vp9"
      },
      "desired_increase": {
        "type": "string",
        "description": "desired_increase factor. Options: 2x, 4x.",
        "required": false,
        "enum": [
          "2",
          "4"
        ],
        "default": "2"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "Video with removed background and audio."
      }
    }
  },
  {
    "id": "fal-ai/gemini-25-flash-image/edit",
    "title": "Gemini 2.5 Flash Image",
    "category": "image-to-image",
    "description": "Gemini 2.5 Flash Image is Google's state-of-the-art image generation and editing model\n",
    "tags": [
      "image-editing"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/w7rvVqvAQiYg2cDSZTn2i_b6895b8a0f864c42a33bfd040dc1228c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gemini-25-flash-image/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/gemini-25-flash-image/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image editing.",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "make a photo of the man driving the car down the california coastline"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for generated images. Default is `None`, which takes one of the input images' aspect ratio.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the images",
        "required": false,
        "enum": [
          "jpeg",
          "png",
          "webp"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of input images for editing.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input.png",
            "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input-2.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "limit_generations": {
        "type": "boolean",
        "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The edited images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "description": {
        "type": "string",
        "description": "Text description or response from Gemini"
      }
    }
  },
  {
    "id": "fal-ai/gemini-25-flash-image",
    "title": "Gemini 2.5 Flash Image",
    "category": "text-to-image",
    "description": "Nano Banana is Google's state-of-the-art image generation and editing model\n",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/f0TePjwvxUJQ2MJ4kDDtC_dba951a1d05a4c8f9324127e7751181e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gemini-25-flash-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/gemini-25-flash-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image generation",
        "required": true,
        "examples": [
          "An action shot of a black lab swimming in an inground suburban swimming pool. The camera is placed meticulously on the water line, dividing the image in half, revealing both the dogs head above water holding a tennis ball in it's mouth, and it's paws paddling underwater."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio for generated images. Default is 1:1.",
        "required": false,
        "enum": [
          "21:9",
          "1:1",
          "4:3",
          "3:2",
          "2:3",
          "5:4",
          "4:5",
          "3:4",
          "16:9",
          "9:16"
        ],
        "default": "1:1"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "limit_generations": {
        "type": "boolean",
        "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the images",
        "required": false,
        "enum": [
          "jpeg",
          "png",
          "webp"
        ],
        "default": "jpeg"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "description": {
        "type": "string",
        "description": "Text description or response from Gemini"
      }
    }
  },
  {
    "id": "fal-ai/qwen-image/image-to-image",
    "title": "Qwen Image",
    "category": "image-to-image",
    "description": "Qwen-Image (Image-to-Image) transforms and edits input images with high fidelity, enabling precise style transfer, enhancement, and creative modification.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/6JAMNCSti-vm-zJeZi6hA_626cdc11d4d04560ac9523fbd61f2eac.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Mount Fuji with purple japanese wisteria in the foreground, clear sky, peaceful spring day, soft natural light, landscape, painted with oil brush on a wood panel with abstract mixed colors"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. By default, we will use the provided image for determining the image_size.",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none",
        "examples": [
          "none"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          "blurry, ugly"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The reference image to guide the generation.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/KoIbq6nhDBDPxDQrivW-m.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "Denoising strength. 1.0 = fully remake; 0.0 = preserve original.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.6,
        "examples": [
          0.8
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 250,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "sonauto/v2/extend",
    "title": "Sonauto V2",
    "category": "audio-to-audio",
    "description": "Extend an existing song",
    "tags": [
      "music",
      "text-to-music",
      "text-to-audio"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/NHeRyBn8fcNS_W3YvNyKZ_4c6ea3f0fd0444c9b9c27b6245a83b38.jpg",
    "playgroundUrl": "https://fal.ai/models/sonauto/v2/extend",
    "documentationUrl": "https://fal.ai/models/sonauto/v2/extend/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": null,
        "description": "A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.",
        "required": false,
        "examples": [
          "Add a beginning to the song"
        ]
      },
      "lyrics_prompt": {
        "type": null,
        "description": "The lyrics sung in the generated song. An empty string will generate an instrumental track.",
        "required": false
      },
      "tags": {
        "type": null,
        "description": "Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.",
        "required": false
      },
      "prompt_strength": {
        "type": "number",
        "description": "Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)",
        "required": false,
        "minimum": 1.4,
        "maximum": 3.1,
        "default": 1.8
      },
      "output_bit_rate": {
        "type": null,
        "description": "The bit rate to use for mp3 and m4a formats. Not available for other formats.",
        "required": false
      },
      "num_songs": {
        "type": "integer",
        "description": "Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "flac",
          "mp3",
          "wav",
          "ogg",
          "m4a"
        ],
        "default": "wav"
      },
      "side": {
        "type": "string",
        "description": "Add more to the beginning (left) or end (right) of the song",
        "required": true,
        "enum": [
          "left",
          "right"
        ]
      },
      "balance_strength": {
        "type": "number",
        "description": "Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.7
      },
      "crop_duration": {
        "type": "number",
        "description": "Duration in seconds to crop from the selected side before extending from that side.",
        "required": false,
        "default": 0
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file to alter. Must be a valid publicly accessible URL.",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://cdn.sonauto.ai/generations2_altformats/audio_c5e63f7c-fc79-4322-808d-c09911af4713.wav"
        ]
      },
      "seed": {
        "type": null,
        "description": "The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.",
        "required": false
      },
      "extend_duration": {
        "type": null,
        "description": "Duration in seconds to extend the song. If not provided, will attempt to automatically determine.",
        "required": false
      }
    },
    "outputParameters": {
      "tags": {
        "type": null,
        "description": "The style tags used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request."
      },
      "extend_duration": {
        "type": "number",
        "description": "The duration in seconds that the song was extended by."
      },
      "audio": {
        "type": "array",
        "description": "The generated audio files.",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "lyrics": {
        "type": null,
        "description": "The lyrics used for generation."
      }
    }
  },
  {
    "id": "sonauto/v2/inpaint",
    "title": "Sonauto V2",
    "category": "text-to-audio",
    "description": "Replace sections of an existing audio with newly generated content",
    "tags": [
      "music",
      "text-to-music",
      "text-to-audio"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/ry2wtiGUu-3jBsfR7NY1__b01962036b18490daf6f33e9cc7d8165.jpg",
    "playgroundUrl": "https://fal.ai/models/sonauto/v2/inpaint",
    "documentationUrl": "https://fal.ai/models/sonauto/v2/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lyrics_prompt": {
        "type": "string",
        "description": "The lyrics sung in the generated song. An empty string will generate an instrumental track.",
        "required": true,
        "examples": [
          "[Chorus]\nPigs are soaring in the sky\nWings of bacon flying by\n"
        ]
      },
      "tags": {
        "type": "array",
        "description": "Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.",
        "required": false,
        "examples": [
          [
            "2020s",
            "dance pop",
            "pop rock",
            "indie pop",
            "bubblegum pop",
            "synthpop",
            "teen pop",
            "electropop"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "prompt_strength": {
        "type": "number",
        "description": "Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)",
        "required": false,
        "minimum": 1.4,
        "maximum": 3.1,
        "default": 2
      },
      "output_bit_rate": {
        "type": null,
        "description": "The bit rate to use for mp3 and m4a formats. Not available for other formats.",
        "required": false
      },
      "num_songs": {
        "type": "integer",
        "description": "Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "flac",
          "mp3",
          "wav",
          "ogg",
          "m4a"
        ],
        "default": "wav"
      },
      "selection_crop": {
        "type": "boolean",
        "description": "Crop to the selected region",
        "required": false,
        "default": false
      },
      "sections": {
        "type": "array",
        "description": "List of sections to inpaint. Currently, only one section is supported so the list length must be 1.",
        "required": true,
        "examples": [
          [
            {
              "end": 9.45,
              "start": 0
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/InpaintSection"
        }
      },
      "balance_strength": {
        "type": "number",
        "description": "Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.7
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file to alter. Must be a valid publicly accessible URL.",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://cdn.sonauto.ai/generations2_altformats/audio_c5e63f7c-fc79-4322-808d-c09911af4713.wav"
        ]
      },
      "seed": {
        "type": null,
        "description": "The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request."
      },
      "audio": {
        "type": "array",
        "description": "The generated audio files.",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "sonauto/v2/text-to-music",
    "title": "Sonauto V2",
    "category": "text-to-audio",
    "description": "Create full songs in any style",
    "tags": [
      "music",
      "text-to-music",
      "text-to-audio"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/NHeRyBn8fcNS_W3YvNyKZ_4c6ea3f0fd0444c9b9c27b6245a83b38.jpg",
    "playgroundUrl": "https://fal.ai/models/sonauto/v2/text-to-music",
    "documentationUrl": "https://fal.ai/models/sonauto/v2/text-to-music/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": null,
        "description": "A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.",
        "required": false,
        "examples": [
          "A pop song about turtles flying"
        ]
      },
      "lyrics_prompt": {
        "type": null,
        "description": "The lyrics sung in the generated song. An empty string will generate an instrumental track.",
        "required": false
      },
      "tags": {
        "type": null,
        "description": "Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.",
        "required": false
      },
      "prompt_strength": {
        "type": "number",
        "description": "Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)",
        "required": false,
        "minimum": 1.4,
        "maximum": 3.1,
        "default": 2
      },
      "output_bit_rate": {
        "type": null,
        "description": "The bit rate to use for mp3 and m4a formats. Not available for other formats.",
        "required": false
      },
      "num_songs": {
        "type": "integer",
        "description": "Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "flac",
          "mp3",
          "wav",
          "ogg",
          "m4a"
        ],
        "default": "wav"
      },
      "bpm": {
        "type": null,
        "description": "The beats per minute of the song. This can be set to an integer or the literal string \"auto\" to pick a suitable bpm based on the tags. Set bpm to null to not condition the model on bpm information.",
        "required": false,
        "default": "auto"
      },
      "balance_strength": {
        "type": "number",
        "description": "Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.7
      },
      "seed": {
        "type": null,
        "description": "The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.",
        "required": false
      }
    },
    "outputParameters": {
      "tags": {
        "type": null,
        "description": "The style tags used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request."
      },
      "lyrics": {
        "type": null,
        "description": "The lyrics used for generation."
      },
      "audio": {
        "type": "array",
        "description": "The generated audio files.",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v5/transition",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Create seamless transition between images using PixVerse v5",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v5/transition",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v5/transition/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "first_image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/owQh2DAzk8UU7J02nr5RY_Co2P4boLv6meIZ5t9gKvL_8685da151df343ab8bf82165c928e2a5.jpg"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The prompt for the transition",
        "required": true,
        "examples": [
          "Scene slowly transition into cat swimming under water"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      },
      "last_image_url": {
        "type": "string",
        "description": "URL of the image to use as the last frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/RgedFs_WSnq5BgER7qDx1_ONrbTJ1YAGXz-9JnSsBoB_bdc8750387734bfe940319f469f7b0b2.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v5/effects",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Generate high quality video clips with different effects using PixVerse v5",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v5/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v5/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": ""
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video.",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "effect": {
        "type": "string",
        "description": "The effect to apply to the video",
        "required": true,
        "enum": [
          "Kiss Me AI",
          "Kiss",
          "Muscle Surge",
          "Warmth of Jesus",
          "Anything, Robot",
          "The Tiger Touch",
          "Hug",
          "Holy Wings",
          "Microwave",
          "Zombie Mode",
          "Squid Game",
          "Baby Face",
          "Black Myth: Wukong",
          "Long Hair Magic",
          "Leggy Run",
          "Fin-tastic Mermaid",
          "Punch Face",
          "Creepy Devil Smile",
          "Thunder God",
          "Eye Zoom Challenge",
          "Who's Arrested?",
          "Baby Arrived",
          "Werewolf Rage",
          "Bald Swipe",
          "BOOM DROP",
          "Huge Cutie",
          "Liquid Metal",
          "Sharksnap!",
          "Dust Me Away",
          "3D Figurine Factor",
          "Bikini Up",
          "My Girlfriends",
          "My Boyfriends",
          "Subject 3 Fever",
          "Earth Zoom",
          "Pole Dance",
          "Vroom Dance",
          "GhostFace Terror",
          "Dragon Evoker",
          "Skeletal Bae",
          "Summoning succubus",
          "Halloween Voodoo Doll",
          "3D Naked-Eye AD",
          "Package Explosion",
          "Dishes Served",
          "Ocean ad",
          "Supermarket AD"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v5/image-to-video",
    "title": "Pixverse v5 Image to Video",
    "category": "image-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v5",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/eTq_2p2OlIBu7MyDFdtWz_6290f4acd92c4382b04ed302b2aa5a3a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v5/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v5/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A woman warrior with her hammer walking with his glacier wolf."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v5/text-to-video",
    "title": "Pixverse",
    "category": "text-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v5",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v5/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v5/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/infinitalk/single-text",
    "title": "Infinitalk",
    "category": "text-to-video",
    "description": "Infinitalk model generates a talking avatar video from a text and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/tiger/no2x6NmiDH44hhb5uCRpF_7a1a914245a54424a4f70019bb757ea3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/infinitalk/single-text",
    "documentationUrl": "https://fal.ai/models/fal-ai/infinitalk/single-text/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "An elderly man with a white beard and headphones records audio with a microphone. He appears engaged and expressive, suggesting a podcast or voiceover."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "text_input": {
        "type": "string",
        "description": "The text input to guide video generation.",
        "required": true,
        "examples": [
          "Spend more time with people who make you feel alive, and less with things that drain your soul."
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/HuM21CXMf0q7OO2zbvwhV_c4533aada79a495b90e50e32dc9b83a8.png"
        ]
      },
      "voice": {
        "type": "string",
        "description": "The voice to use for speech generation",
        "required": true,
        "enum": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ],
        "examples": [
          "Bill"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 42
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 41 to 721.",
        "required": false,
        "minimum": 41,
        "maximum": 721,
        "default": 145
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/infinitalk",
    "title": "Infinitalk",
    "category": "image-to-video",
    "description": "Infinitalk model generates a talking avatar video from an image and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/tgT82rlusP7Mfw1gs8CsE_0cd1e1a621dd484b8c84973e3a1292bf.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/infinitalk",
    "documentationUrl": "https://fal.ai/models/fal-ai/infinitalk/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A woman with colorful hair talking on a podcast."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/gmpc0QevDF9bBsL1EAYVF_1c637094161147559f0910a68275dc34.png"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/PtiCYda53E9Dav25QmQYI_output.mp3"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 42
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 41 to 721.",
        "required": false,
        "minimum": 41,
        "maximum": 721,
        "default": 145
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/tts/eleven-v3",
    "title": "Elevenlabs",
    "category": "text-to-audio",
    "description": "Generate text-to-speech audio using Eleven-v3 from ElevenLabs.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/twZsKdCTiF8JXv-rRcPZu_8414166d52a548859a8df01bf720fe46.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/tts/eleven-v3",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/tts/eleven-v3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to convert to speech",
        "required": true,
        "examples": [
          "Hello! This is a test of the text to speech system, powered by ElevenLabs. How does it sound?"
        ]
      },
      "next_text": {
        "type": null,
        "description": "The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.",
        "required": false
      },
      "speed": {
        "type": "number",
        "description": "Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.",
        "required": false,
        "minimum": 0.7,
        "maximum": 1.2,
        "default": 1
      },
      "style": {
        "type": "number",
        "description": "Style exaggeration (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "stability": {
        "type": "number",
        "description": "Voice stability (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "timestamps": {
        "type": "boolean",
        "description": "Whether to return timestamps for each word in the generated speech",
        "required": false,
        "default": false
      },
      "similarity_boost": {
        "type": "number",
        "description": "Similarity boost (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "voice": {
        "type": "string",
        "description": "The voice to use for speech generation",
        "required": false,
        "default": "Rachel",
        "examples": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ]
      },
      "language_code": {
        "type": null,
        "description": "Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.",
        "required": false
      },
      "previous_text": {
        "type": null,
        "description": "The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.",
        "required": false
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file"
      },
      "timestamps": {
        "type": null,
        "description": "Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request."
      }
    }
  },
  {
    "id": "bria/reimagine/3.2",
    "title": "Reimagine",
    "category": "image-to-image",
    "description": "Reimagine uses a structure reference for generating new images while preserving the structure of an input image, guided by text prompts.\nPerfect for transforming sketches, illustrations, or photos into new illustrations. Trained exclusively on licensed data",
    "tags": [
      "bria"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/jkGFvEL6cLvJsAPkL48qP_f74234f867b84e23aaf691d48124fb85.jpg",
    "playgroundUrl": "https://fal.ai/models/bria/reimagine/3.2",
    "documentationUrl": "https://fal.ai/models/bria/reimagine/3.2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt for image generation.",
        "required": true,
        "examples": [
          "Delicate, watercolor-style letters infused with shades of blue and green, accompanied by artistic, blooming flowers that blend harmoniously into a light background, giving a serene and artistic touch."
        ]
      },
      "depth_preprocess": {
        "type": "boolean",
        "description": "Depth image preprocess.",
        "required": false,
        "default": true
      },
      "canny_preprocess": {
        "type": "boolean",
        "description": "Canny image preprocess.",
        "required": false,
        "default": true
      },
      "depth_image_url": {
        "type": null,
        "description": "Depth control image (file or URL).",
        "required": false,
        "default": "",
        "examples": [
          "https://bria-image-repository.s3.us-east-1.amazonaws.com/BRIA+(1).png"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for text.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "canny_image_url": {
        "type": null,
        "description": "Canny edge control image (file or URL).",
        "required": false,
        "default": "",
        "examples": [
          "https://bria-image-repository.s3.us-east-1.amazonaws.com/BRIA+(1).png"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for image generation.",
        "required": false,
        "default": "Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers"
      },
      "depth_scale": {
        "type": "number",
        "description": "Depth control strength (0.0 to 1.0).",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9",
        "required": false,
        "enum": [
          "1:1",
          "2:3",
          "3:2",
          "3:4",
          "4:3",
          "4:5",
          "5:4",
          "9:16",
          "16:9"
        ],
        "default": "1:1"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If true, returns the image directly in the response (increases latency).",
        "required": false,
        "default": false
      },
      "prompt_enhancer": {
        "type": "boolean",
        "description": "Whether to improve the prompt.",
        "required": false,
        "default": true
      },
      "truncate_prompt": {
        "type": "boolean",
        "description": "Whether to truncate the prompt.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility.",
        "required": false,
        "default": 5555
      },
      "canny_scale": {
        "type": "number",
        "description": "Canny edge control strength (0.0 to 1.0).",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 30
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Generated image."
      }
    }
  },
  {
    "id": "fal-ai/nano-banana/edit",
    "title": "Nano Banana",
    "category": "image-to-image",
    "description": "Google's state-of-the-art image generation and editing model",
    "tags": [
      "image-editing"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/1iXUmtPWBg9oNTpkAv48W_ce1da4146f99452f8c1dfe58dd2b150e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/nano-banana/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/nano-banana/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image editing.",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "make a photo of the man driving the car down the california coastline"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "aspect_ratio": {
        "type": null,
        "description": "Aspect ratio for generated images. Default is `None`, which takes one of the input images' aspect ratio.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the images",
        "required": false,
        "enum": [
          "jpeg",
          "png",
          "webp"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of input images for editing.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input.png",
            "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input-2.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "limit_generations": {
        "type": "boolean",
        "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The edited images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "description": {
        "type": "string",
        "description": "Text description or response from Gemini"
      }
    }
  },
  {
    "id": "fal-ai/nano-banana",
    "title": "Nano Banana",
    "category": "text-to-image",
    "description": "Google's state-of-the-art image generation and editing model",
    "tags": [
      "image-generation"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/eLGB_Z0WHjbSD4Ad5aY-g_83f5f6da4f09426489042866cb0e4e9c.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/nano-banana",
    "documentationUrl": "https://fal.ai/models/fal-ai/nano-banana/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image generation",
        "required": true,
        "examples": [
          "An action shot of a black lab swimming in an inground suburban swimming pool. The camera is placed meticulously on the water line, dividing the image in half, revealing both the dogs head above water holding a tennis ball in it's mouth, and it's paws paddling underwater."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio for generated images. Default is 1:1.",
        "required": false,
        "enum": [
          "21:9",
          "1:1",
          "4:3",
          "3:2",
          "2:3",
          "5:4",
          "4:5",
          "3:4",
          "16:9",
          "9:16"
        ],
        "default": "1:1"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "limit_generations": {
        "type": "boolean",
        "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the images",
        "required": false,
        "enum": [
          "jpeg",
          "png",
          "webp"
        ],
        "default": "jpeg"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "description": {
        "type": "string",
        "description": "Text description or response from Gemini"
      }
    }
  },
  {
    "id": "fal-ai/nextstep-1",
    "title": "Nextstep 1",
    "category": "image-to-image",
    "description": "Endpoint for NextStep-1 Autoregressive Image Editing model.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/zebra/mA2AtvaSMWo6PQZ7NBKaC_4e2f5a654dec43ea904364e9a4a16d49.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/nextstep-1",
    "documentationUrl": "https://fal.ai/models/fal-ai/nextstep-1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image.",
        "required": true,
        "examples": [
          "Add a pirate hat to the dog's head. Change the background to a stormy sea with dark clouds. Include the text 'Captain Paws' in bold white letters at the top portion of the image."
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n        ",
        "required": true,
        "examples": [
          "Copy original image."
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/JitXwwpMuF9iIhv0Pq6Dh_dog.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": "object",
        "description": "Generated image",
        "properties": {
          "file_size": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "File Size",
            "description": "The size of the file in bytes.",
            "examples": [
              4404019
            ]
          },
          "height": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Height",
            "description": "The height of the image in pixels.",
            "examples": [
              1024
            ]
          },
          "file_name": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "File Name",
            "description": "The name of the file. It will be auto-generated if not provided.",
            "examples": [
              "z9RV14K95DvU.png"
            ]
          },
          "content_type": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Content Type",
            "description": "The mime type of the file.",
            "examples": [
              "image/png"
            ]
          },
          "url": {
            "title": "Url",
            "type": "string",
            "description": "The URL where the file can be downloaded from."
          },
          "width": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Width",
            "description": "The width of the image in pixels.",
            "examples": [
              1024
            ]
          }
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for random number generation"
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-edit",
    "title": "Qwen Image Edit",
    "category": "image-to-image",
    "description": "Endpoint for Qwen's Image Editing model. Has superior text editing capabilities.",
    "tags": [
      "image-editing",
      "image-to-image",
      "high-quality-text"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/NR_iO1JmZVV3QZbjufcGu_367391df7b0242c9bf8a23368c0c4acf.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Change bag to apple macbook"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          "blurry, ugly"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "mirelo-ai/sfx-v1/video-to-audio",
    "title": "Mirelo SFX",
    "category": "video-to-audio",
    "description": "Generate synced sounds for any video, and return the new sound track (like MMAudio)",
    "tags": [
      "sfx"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/tU7ZHxRInmbvp8xAHwl1b_0cce21ee98f14735941825a2ed8df979.jpg",
    "playgroundUrl": "https://fal.ai/models/mirelo-ai/sfx-v1/video-to-audio",
    "documentationUrl": "https://fal.ai/models/mirelo-ai/sfx-v1/video-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_samples": {
        "type": null,
        "description": "The number of samples to generate from the model",
        "required": false,
        "default": 2
      },
      "video_url": {
        "type": "string",
        "description": "A video url that can accessed from the API to process and add sound effects",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://di3otfzjg1gxa.cloudfront.net/input_example.mp4"
        ]
      },
      "duration": {
        "type": null,
        "description": "The duration of the generated audio in seconds",
        "required": false,
        "default": 10
      },
      "seed": {
        "type": null,
        "description": "The seed to use for the generation. If not provided, a random seed will be used",
        "required": false,
        "default": 2105
      },
      "text_prompt": {
        "type": null,
        "description": "Additional description to guide the model",
        "required": false,
        "examples": [
          ""
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": "array",
        "description": "The generated sound effects audio",
        "items": {
          "$ref": "#/components/schemas/Audio"
        }
      }
    }
  },
  {
    "id": "mirelo-ai/sfx-v1/video-to-video",
    "title": "Mirelo SFX",
    "category": "video-to-video",
    "description": "Generate synced sounds for any video, and return it with its new sound track (like MMAudio)\n",
    "tags": [
      "video-to-video",
      "sfx"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/ZgJTjdDKaW4OFVZqUmepA_4f542f98a3fc4edbb9043ff22131adde.jpg",
    "playgroundUrl": "https://fal.ai/models/mirelo-ai/sfx-v1/video-to-video",
    "documentationUrl": "https://fal.ai/models/mirelo-ai/sfx-v1/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_samples": {
        "type": null,
        "description": "The number of samples to generate from the model",
        "required": false,
        "default": 2
      },
      "video_url": {
        "type": "string",
        "description": "A video url that can accessed from the API to process and add sound effects",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://di3otfzjg1gxa.cloudfront.net/input_example.mp4"
        ]
      },
      "duration": {
        "type": null,
        "description": "The duration of the generated audio in seconds",
        "required": false,
        "default": 10
      },
      "seed": {
        "type": null,
        "description": "The seed to use for the generation. If not provided, a random seed will be used",
        "required": false,
        "default": 2105
      },
      "text_prompt": {
        "type": null,
        "description": "Additional description to guide the model",
        "required": false,
        "examples": [
          ""
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": "array",
        "description": "The processed video with sound effects",
        "items": {
          "$ref": "#/components/schemas/Video"
        }
      }
    }
  },
  {
    "id": "fal-ai/stable-avatar",
    "title": "Stable Avatar",
    "category": "audio-to-video",
    "description": "Stable Avatar generates audio-driven video avatars up to five minutes long",
    "tags": [
      "stable-avatar",
      "talking-head",
      "audio-to-video"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/kzjRSbBVQ7m_aZa-9_Uuy_4efc689beb9c4a57ac2cde9eaa31e09e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-avatar",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-avatar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for the video generation.",
        "required": true,
        "examples": [
          "A person is in a relaxed pose. As the video progresses, the character speaks while arm and body movements are minimal and consistent with a natural speaking posture. Hand movements remain minimal. Don't blink too often. Preserve background integrity matching the reference image's spatial configuration, lighting conditions, and color temperature."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate. If 'auto', the aspect ratio will be determined by the reference image.",
        "required": false,
        "enum": [
          "16:9",
          "1:1",
          "9:16",
          "auto"
        ],
        "default": "auto"
      },
      "perturbation": {
        "type": "number",
        "description": "The amount of perturbation to use for the video generation. 0.0 means no perturbation, 1.0 means full perturbation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a reference for the video generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/stable-avatar-input-image.png"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale to use for the video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for the video generation.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to use for the video generation.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 50
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio to use as a reference for the video generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/stable-avatar-input-audio.mp3"
        ]
      },
      "audio_guidance_scale": {
        "type": "number",
        "description": "The audio guidance scale to use for the video generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 4
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "moonvalley/marey/pose-transfer",
    "title": "Marey Realism V1.5",
    "category": "video-to-video",
    "description": "Ideal for matching human movement. Your input video determines human poses, gestures, and body movements that will appear in the generated video.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/rabbit/wFiWRdymluA_qihYl76wE_13a2425a72a8455190e54c46b99546e4.jpg",
    "playgroundUrl": "https://fal.ai/models/moonvalley/marey/pose-transfer",
    "documentationUrl": "https://fal.ai/models/moonvalley/marey/pose-transfer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate a video from",
        "required": true,
        "examples": [
          "Detailed Description: A venerable tribal chief, his weathered face marked with dark, ritualistic paint, stands proudly against a jungle backdrop. His elaborate headdress, a magnificent creation of numerous feathers, beads, and a central polished stone, sways gently with his movements. His initial stern expression softens into a confident smile as he begins to speak, his lips moving with unspoken words of wisdom or command. In a single, fluid motion, he raises his hand and gives a decisive wave, a gesture of both greeting and authority that underscores his leadership role within the tribe.\n\nBackground: A dense tropical rainforest is blurred into a soft, verdant backdrop, with muted greens and browns suggesting a lush, humid environment.\n\nMiddleground: The chief is the central focus, his head crowned by the large, intricate feathered headdress that moves subtly as he speaks. His shoulders and torso are visible, adorned with traditional necklaces.\n\nForeground: His hand lifts into the frame, palm open, executing a single, confident wave toward the viewer before lowering again. The closest feathers of his headdress rustle with the motion."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to use as the control video.",
        "required": true,
        "examples": [
          "https://d1kaxrqq3vfrw5.cloudfront.net/fal-launch-assets/guide-assets/fal-pose-transfer-input.mp4"
        ]
      },
      "seed": {
        "type": null,
        "description": "Seed for random number generation. Use -1 for random seed each run.",
        "required": false,
        "default": -1
      },
      "reference_image_url": {
        "type": null,
        "description": "Optional reference image URL to use for pose control or as a starting frame",
        "required": false
      },
      "negative_prompt": {
        "type": null,
        "description": "Negative prompt used to guide the model away from undesirable features.",
        "required": false,
        "default": "<synthetic> <scene cut> low-poly, flat shader, bad rigging, stiff animation, uncanny eyes, low-quality textures, looping glitch, cheap effect, overbloom, bloom spam, default lighting, game asset, stiff face, ugly specular, AI artifacts"
      },
      "first_frame_image_url": {
        "type": null,
        "description": "Optional first frame image URL to use as the first frame of the generated video",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "moonvalley/marey/motion-transfer",
    "title": "Marey Realism V1.5",
    "category": "video-to-video",
    "description": "Pull motion from a reference video and apply it to new subjects or scenes.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/koala/109Ropx2Ejswcp0dNuahi_5a78312f31ce4aa4b33f7be5953c2d95.jpg",
    "playgroundUrl": "https://fal.ai/models/moonvalley/marey/motion-transfer",
    "documentationUrl": "https://fal.ai/models/moonvalley/marey/motion-transfer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate a video from",
        "required": true,
        "examples": [
          "Detailed Description: A fast, smooth dolly shot glides forward at water level through a monumental, minimalist colonnade. The imposing, symmetrical rows of brutalist marble columns rush past on either side, their strong vertical lines creating a sense of powerful, constant motion. The dark, glassy water of a central pool perfectly reflects the towering structures, with gentle ripples disturbing the mirror image as the camera advances. The scene is cinematic and moody, with the light-colored stone contrasting against the dark water and the pale sky visible at the far end of the architectural tunnel. shot on 35mm, film, organic, analog, motion blur\n\nBackground: A pale, overcast sky and a distant treeline are framed by the opening at the end of the colonnade, growing larger as the camera moves forward.\n\nMiddleground: The two rows of massive, geometric columns recede into the distance, their uniform shapes creating a hypnotic, rhythmic pattern that rushes past the lens.\n\nForeground: The camera skims just above the surface of the dark, rippling water, which reflects the blurred motion of the columns passing on the left and right."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to use as the control video.",
        "required": true,
        "examples": [
          "https://d1kaxrqq3vfrw5.cloudfront.net/fal-launch-assets/guide-assets/fal-motion-transfer-input-5s.mp4"
        ]
      },
      "seed": {
        "type": null,
        "description": "Seed for random number generation. Use -1 for random seed each run.",
        "required": false,
        "default": -1
      },
      "reference_image_url": {
        "type": null,
        "description": "Optional reference image URL to use for pose control or as a starting frame",
        "required": false
      },
      "negative_prompt": {
        "type": null,
        "description": "Negative prompt used to guide the model away from undesirable features.",
        "required": false,
        "default": "<synthetic> <scene cut> low-poly, flat shader, bad rigging, stiff animation, uncanny eyes, low-quality textures, looping glitch, cheap effect, overbloom, bloom spam, default lighting, game asset, stiff face, ugly specular, AI artifacts"
      },
      "first_frame_image_url": {
        "type": null,
        "description": "Optional first frame image URL to use as the first frame of the generated video",
        "required": false,
        "default": "https://video-editor-files-prod.s3.us-east-2.amazonaws.com/users/1e4d46df-0702-4491-95ce-763592f33f34/uploaded-images/9b9dce1c-abd0-46c0-bac9-9454f8893b06/original"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "moonvalley/marey/i2v",
    "title": "Marey Realism V1.5",
    "category": "image-to-video",
    "description": "Generate a video starting from an image as the first frame with Marey, a generative video model trained exclusively on fully licensed data.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/ZYJf9OjFksJF5QIMxEjCh_85dff19060504c08b66d4a0675788c3a.jpg",
    "playgroundUrl": "https://fal.ai/models/moonvalley/marey/i2v",
    "documentationUrl": "https://fal.ai/models/moonvalley/marey/i2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate a video from",
        "required": true,
        "examples": [
          "Detailed Description: In a hidden jungle grotto, a majestic waterfall plunges into a dark, serene pool below. Ethereal sunbeams slice through the dense canopy high above, illuminating the swirling mist generated by the powerful cascade. The light rays dance across the scene, highlighting the vibrant green foliage that clings to the dark, wet rock walls. The constant roar of the falling water echoes through the secluded space, as the surface of the pool ripples and churns from the impact, creating a mesmerizing display of nature's raw power and tranquil beauty. Background: Brilliant sunbeams pierce through an opening in the dense jungle canopy, their ethereal rays shifting and shimmering as they cut through the misty air. Middleground: A powerful column of white water cascades down a dark, foliage-covered cliff face, creating a stark contrast with the shadowy recesses of the grotto. Foreground: The waterfall crashes into a dark, churning pool of water, sending up a fine spray and creating ever-expanding ripples across the surface."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video.",
        "required": false,
        "enum": [
          "5s",
          "10s"
        ],
        "default": "5s"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as the first frame of the video.",
        "required": true,
        "examples": [
          "https://d1kaxrqq3vfrw5.cloudfront.net/fal-launch-assets/guide-assets/fal-i2v-example-input.png"
        ]
      },
      "dimensions": {
        "type": "string",
        "description": "The dimensions of the generated video in width x height format.",
        "required": false,
        "enum": [
          "1920x1080",
          "1080x1920",
          "1152x1152",
          "1536x1152",
          "1152x1536"
        ],
        "default": "1920x1080"
      },
      "guidance_scale": {
        "type": null,
        "description": "Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely.",
        "required": false
      },
      "seed": {
        "type": null,
        "description": "Seed for random number generation. Use -1 for random seed each run.",
        "required": false,
        "default": -1
      },
      "negative_prompt": {
        "type": null,
        "description": "Negative prompt used to guide the model away from undesirable features.",
        "required": false,
        "default": "<synthetic> <scene cut> low-poly, flat shader, bad rigging, stiff animation, uncanny eyes, low-quality textures, looping glitch, cheap effect, overbloom, bloom spam, default lighting, game asset, stiff face, ugly specular, AI artifacts"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/qwen-image-trainer",
    "title": "Qwen Image Trainer",
    "category": "training",
    "description": "Qwen Image LoRA training",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/Ezdr45OqUN2jaBP8tBuqL_d7bb3b0fadd54124b9884975b7e2f626.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "steps": {
        "type": "integer",
        "description": "Total number of training steps to perform. Default is 4000.",
        "required": false,
        "minimum": 1,
        "maximum": 8000,
        "default": 1000
      },
      "image_data_url": {
        "type": "string",
        "description": "\n        URL to zip archive with images for training. The archive should contain images and corresponding text files with captions.\n        Each text file should have the same name as the image file it corresponds to (e.g., image1.jpg and image1.txt).\n        If text files are missing for some images, you can provide a trigger_phrase to automatically create them.\n        Supported image formats: PNG, JPG, JPEG, WEBP.\n        Try to use at least 10 images, although more is better.\n    ",
        "required": true
      },
      "learning_rate": {
        "type": "number",
        "description": "Learning rate for training. Default is 5e-4",
        "required": false,
        "minimum": 1e-06,
        "maximum": 0.01,
        "default": 0.0005
      },
      "trigger_phrase": {
        "type": "string",
        "description": "Default caption to use for images that don't have corresponding text files. If provided, missing .txt files will be created automatically.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights file."
      },
      "config_file": {
        "type": null,
        "description": "URL to the training configuration file."
      }
    }
  },
  {
    "id": "moonvalley/marey/t2v",
    "title": "Marey Realism V1.5",
    "category": "text-to-video",
    "description": "Generate a video from a text prompt with Marey, a generative video model trained exclusively on fully licensed data.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/zebra/XqLulT-Va4wv0SoknC72P_504081bd51c84280b787bc27906b490e.jpg",
    "playgroundUrl": "https://fal.ai/models/moonvalley/marey/t2v",
    "documentationUrl": "https://fal.ai/models/moonvalley/marey/t2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate a video from",
        "required": true,
        "examples": [
          "Detailed Description: A small, white paper boat, with one corner engulfed in bright orange flames, drifts precariously across a dark puddle on wet asphalt. As raindrops fall, they create ever-expanding ripples on the water's surface, gently rocking the fragile vessel and causing the fiery reflection below to dance and shimmer. The flickering flame slowly consumes the paper, charring the edges black as the boat becomes waterlogged, beginning to sink in a poignant slow-motion battle between fire and water. Background: The background is softly blurred, suggesting an overcast day with out-of-focus foliage, enhancing the scene's intimate and melancholic mood. Middleground: Raindrops continuously strike the puddle's surface, creating concentric ripples that gently push the boat along its short, determined voyage. Foreground: The burning paper boat floats in sharp focus, its bright, flickering flame casting a warm, dramatic glow that reflects and distorts on the dark, wet surface of the asphalt."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video.",
        "required": false,
        "enum": [
          "5s",
          "10s"
        ],
        "default": "5s"
      },
      "dimensions": {
        "type": "string",
        "description": "The dimensions of the generated video in width x height format.",
        "required": false,
        "enum": [
          "1920x1080",
          "1152x1152",
          "1536x1152",
          "1152x1536"
        ],
        "default": "1920x1080"
      },
      "guidance_scale": {
        "type": null,
        "description": "Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely.",
        "required": false
      },
      "seed": {
        "type": null,
        "description": "Seed for random number generation. Use -1 for random seed each run.",
        "required": false,
        "default": -1
      },
      "negative_prompt": {
        "type": null,
        "description": "Negative prompt used to guide the model away from undesirable features.",
        "required": false,
        "default": "<synthetic> <scene cut> low-poly, flat shader, bad rigging, stiff animation, uncanny eyes, low-quality textures, looping glitch, cheap effect, overbloom, bloom spam, default lighting, game asset, stiff face, ugly specular, AI artifacts"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/echomimic-v3",
    "title": "EchoMimic V3",
    "category": "audio-to-video",
    "description": "EchoMimic V3 generates a talking avatar model from a picture, audio and text prompt.",
    "tags": [
      "echomimic",
      "talking-head",
      "audio-to-video"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/pnsOBA-jcFjvGsQpILHy9_ed79671c56034d6db4376279665dc8ab.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/echomimic-v3",
    "documentationUrl": "https://fal.ai/models/fal-ai/echomimic-v3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for the video generation.",
        "required": true,
        "examples": [
          "A person is in a relaxed pose. As the video progresses, the character speaks while arm and body movements are minimal and consistent with a natural speaking posture. Hand movements remain minimal. Don't blink too often. Preserve background integrity matching the reference image's spatial configuration, lighting conditions, and color temperature."
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio to use as a reference for the video generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/echo-mimic-input-audio.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a reference for the video generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/echo-mimic-input-image.png"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale to use for the video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4.5
      },
      "audio_guidance_scale": {
        "type": "number",
        "description": "The audio guidance scale to use for the video generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 2.5
      },
      "num_frames_per_generation": {
        "type": "integer",
        "description": "The number of frames to generate at once.",
        "required": false,
        "minimum": 49,
        "maximum": 161,
        "default": 121
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use for the video generation.",
        "required": false,
        "default": ""
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for the video generation.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/video-stylize",
    "title": "Bytedance",
    "category": "image-to-video",
    "description": "Transform your images into stylized videos using this workflow.",
    "tags": [
      "image-to-video",
      "effects"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/LxwcxJuokX_e4sZ6EopoG_fb133832f45f4366b13faa832797092d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/video-stylize",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/video-stylize/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "style": {
        "type": "string",
        "description": "The style for your character in the video. Please use a short description.",
        "required": true,
        "maxLength": 100,
        "examples": [
          "Manga style"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to make the stylized video from.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/-KmSPIcXeGA3Z_iiH4C75_tmph2ry_0_8.png"
        ]
      }
    },
    "outputParameters": {}
  },
  {
    "id": "fal-ai/ffmpeg-api/merge-videos",
    "title": "Ffmpeg Api",
    "category": "video-to-video",
    "description": "Use ffmpeg capabilities to merge 2 or more videos.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/zebra/FIx0cgDim0YGWogS3xc0x_c4b30ad7fb8a4747814f7d80c99adaaf.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/merge-videos",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/merge-videos/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "target_fps": {
        "type": null,
        "description": "Target FPS for the output video. If not provided, uses the lowest FPS from input videos.",
        "required": false
      },
      "video_urls": {
        "type": "array",
        "description": "List of video URLs to merge in order",
        "required": true,
        "items": {
          "type": "string"
        }
      },
      "resolution": {
        "type": null,
        "description": "Resolution of the final video. Width and height must be between 512 and 2048.",
        "required": false
      }
    },
    "outputParameters": {
      "metadata": {
        "type": "object",
        "description": "Metadata about the merged video including original video info"
      },
      "video": {
        "type": null,
        "description": "Merged video file"
      }
    }
  },
  {
    "id": "fal-ai/minimax/preview/speech-2.5-hd",
    "title": "Minimax",
    "category": "text-to-speech",
    "description": "Generate speech from text prompts and different voices using the MiniMax Speech-02 HD model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/yKMqbFeN7Q3b6SSjB41Bd_a0f390d1bb6e4b37a93bb8d0dc58afe7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/preview/speech-2.5-hd",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/preview/speech-2.5-hd/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Hello world! This is a test of the text-to-speech system."
        ]
      },
      "language_boost": {
        "type": "string",
        "description": "Enhance recognition of specified languages and dialects",
        "required": false,
        "enum": [
          "Persian",
          "Filipino",
          "Tamil",
          "Chinese",
          "Chinese,Yue",
          "English",
          "Arabic",
          "Russian",
          "Spanish",
          "French",
          "Portuguese",
          "German",
          "Turkish",
          "Dutch",
          "Ukrainian",
          "Vietnamese",
          "Indonesian",
          "Japanese",
          "Italian",
          "Korean",
          "Thai",
          "Polish",
          "Romanian",
          "Greek",
          "Czech",
          "Finnish",
          "Hindi",
          "Bulgarian",
          "Danish",
          "Hebrew",
          "Malay",
          "Slovak",
          "Swedish",
          "Croatian",
          "Hungarian",
          "Norwegian",
          "Slovenian",
          "Catalan",
          "Nynorsk",
          "Afrikaans",
          "auto"
        ]
      },
      "voice_setting": {
        "type": null,
        "description": "Voice configuration settings",
        "required": false,
        "default": {
          "speed": 1,
          "vol": 1,
          "voice_id": "Wise_Woman",
          "pitch": 0,
          "english_normalization": false
        }
      },
      "output_format": {
        "type": "string",
        "description": "Format of the output content (non-streaming only)",
        "required": false,
        "enum": [
          "url",
          "hex"
        ],
        "default": "hex"
      },
      "pronunciation_dict": {
        "type": null,
        "description": "Custom pronunciation dictionary for text replacement",
        "required": false
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "duration_ms": {
        "type": "integer",
        "description": "Duration of the audio in milliseconds"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/minimax/preview/speech-2.5-turbo",
    "title": "Minimax",
    "category": "text-to-speech",
    "description": "Generate fast speech from text prompts and different voices using the MiniMax Speech-02 Turbo model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "text-to-speech"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/u7RqSqZJAXI8RIzIYw9HP_9d16c25ecc85427bb97102a847da0736.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/preview/speech-2.5-turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/preview/speech-2.5-turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Hello world! This is a test of the text-to-speech system."
        ]
      },
      "language_boost": {
        "type": "string",
        "description": "Enhance recognition of specified languages and dialects",
        "required": false,
        "enum": [
          "Persian",
          "Filipino",
          "Tamil",
          "Chinese",
          "Chinese,Yue",
          "English",
          "Arabic",
          "Russian",
          "Spanish",
          "French",
          "Portuguese",
          "German",
          "Turkish",
          "Dutch",
          "Ukrainian",
          "Vietnamese",
          "Indonesian",
          "Japanese",
          "Italian",
          "Korean",
          "Thai",
          "Polish",
          "Romanian",
          "Greek",
          "Czech",
          "Finnish",
          "Hindi",
          "Bulgarian",
          "Danish",
          "Hebrew",
          "Malay",
          "Slovak",
          "Swedish",
          "Croatian",
          "Hungarian",
          "Norwegian",
          "Slovenian",
          "Catalan",
          "Nynorsk",
          "Afrikaans",
          "auto"
        ]
      },
      "voice_setting": {
        "type": null,
        "description": "Voice configuration settings",
        "required": false,
        "default": {
          "speed": 1,
          "vol": 1,
          "voice_id": "Wise_Woman",
          "pitch": 0,
          "english_normalization": false
        }
      },
      "output_format": {
        "type": "string",
        "description": "Format of the output content (non-streaming only)",
        "required": false,
        "enum": [
          "url",
          "hex"
        ],
        "default": "hex"
      },
      "pronunciation_dict": {
        "type": null,
        "description": "Custom pronunciation dictionary for text replacement",
        "required": false
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "duration_ms": {
        "type": "integer",
        "description": "Duration of the audio in milliseconds"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/wan-22-image-trainer",
    "title": "Wan 2.2 14B Image Trainer",
    "category": "training",
    "description": "Wan 2.2 text to image LoRA trainer. Fine-tune Wan 2.2 for subjects and styles with unprecedented detail.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/1VUig6knsJ9-DAf8eRzBQ_5a0e3e33bbbf4d869ec368fa31f8700e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-image-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-image-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "trigger_phrase": {
        "type": "string",
        "description": "Trigger phrase for the model.",
        "required": true
      },
      "use_masks": {
        "type": "boolean",
        "description": "Whether to use masks for the training data.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "learning_rate": {
        "type": "number",
        "description": "Learning rate for training.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 0.1,
        "default": 0.0007,
        "examples": [
          0.0007
        ]
      },
      "use_face_cropping": {
        "type": "boolean",
        "description": "Whether to use face cropping for the training data. When enabled, images will be cropped to the face before resizing.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to the training data.",
        "required": true
      },
      "include_synthetic_captions": {
        "type": "boolean",
        "description": "Whether to include synthetic captions.",
        "required": false,
        "default": false
      },
      "steps": {
        "type": "integer",
        "description": "Number of training steps.",
        "required": false,
        "minimum": 10,
        "maximum": 6000,
        "default": 1000,
        "examples": [
          1000
        ]
      },
      "is_style": {
        "type": "boolean",
        "description": "Whether the training data is style data. If true, face specific options like masking and face detection will be disabled.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "use_face_detection": {
        "type": "boolean",
        "description": "Whether to use face detection for the training data. When enabled, images will use the center of the face as the center of the image when resizing.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "high_noise_lora": {
        "type": null,
        "description": "High noise LoRA file."
      },
      "config_file": {
        "type": null,
        "description": "Config file helping inference endpoints after training."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "Low noise LoRA file."
      }
    }
  },
  {
    "id": "fal-ai/ideogram/character/edit",
    "title": "Ideogram V3 Character Edit",
    "category": "image-to-image",
    "description": "Modify consistent characters while preserving their core identity. Edit poses, expressions, or clothing without losing recognizable character features",
    "tags": [
      "character-consistency"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/sa3_-HW2nveeEYE8OzSn0_738419fcb18148cc8c8e0728196cd142.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/character/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/character/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "woman holding bag"
        ]
      },
      "style": {
        "type": "string",
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false,
        "enum": [
          "AUTO",
          "REALISTIC",
          "FICTION"
        ],
        "default": "AUTO"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "reference_mask_urls": {
        "type": "array",
        "description": "A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "reference_image_urls": {
        "type": "array",
        "description": "A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/kangaroo/0rinwnj_Kn9Fsu2dK-aKm_image.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/-LC_gNNV3wUHaGMQT3klE_output.png"
        ]
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/jVDAgSkpsZFDP080ceSZJ_woman_face_mask.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/character",
    "title": "Ideogram V3 Character",
    "category": "image-to-image",
    "description": "Generate consistent character appearances across multiple images. Maintain facial features, proportions, and distinctive traits for cohesive storytelling and branding",
    "tags": [
      "character-consistency",
      ""
    ],
    "thumbnailUrl": "https://fal.media/files/koala/spkoglxAAeU3iFhwZyWSW_b17f175d3e314853bc4c9bae2809cabd.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/character",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/character/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "Place the woman leisurely enjoying a cup of espresso while relaxing at a sunlit café table in Siena, Italy. The café setting showcases vintage wooden furniture with peeling white paint, aged brick flooring, and sun-bleached stone walls decorated with trailing ivy and vibrant potted geraniums that capture Siena's medieval character. Golden late-morning light streams through overhead, creating soft shadows that highlight the weathered architectural details. The composition appears slightly off-center, conveying the unguarded tranquility and personal intimacy of a peaceful moment savoring the Tuscan morning ambiance."
        ]
      },
      "image_size": {
        "type": null,
        "description": "The resolution of the generated image",
        "required": false,
        "default": "square_hd"
      },
      "style": {
        "type": "string",
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false,
        "enum": [
          "AUTO",
          "REALISTIC",
          "FICTION"
        ],
        "default": "AUTO"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "reference_mask_urls": {
        "type": "array",
        "description": "A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "reference_image_urls": {
        "type": "array",
        "description": "A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/kangaroo/0rinwnj_Kn9Fsu2dK-aKm_image.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/character/remix",
    "title": "Ideogram V3 Character Remix",
    "category": "image-to-image",
    "description": "Transform your consistent character into different art styles, settings, or scenarios while maintaining their distinctive appearance and identity",
    "tags": [
      "character-consistency"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/AIDfIY6DcuzLpcKmklBq__73fde9aa027d4f079e59b53bf55b9c58.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/character/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/character/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to remix the image with",
        "required": true,
        "examples": [
          "A glamorous portrait photograph of a woman in an elegant ballroom setting. The subject wears a champagne-colored ball gown with a fitted bodice, long sleeves, and a full skirt adorned with delicate lace appliques. The dress features a crystal-embellished hair accessory and pearl drop earrings. The grand staircase has ornate gold railings and leads to an elaborate crystal chandelier hanging from an arched ceiling. The walls are decorated with classical paintings featuring floral motifs. The lighting is warm and dramatic, creating a soft glow throughout the space. The composition is shot in a formal portrait style with the subject positioned on the lower landing of the staircase, looking over her shoulder at the camera."
        ]
      },
      "image_size": {
        "type": null,
        "description": "The resolution of the generated image",
        "required": false,
        "default": "square_hd"
      },
      "style": {
        "type": "string",
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false,
        "enum": [
          "AUTO",
          "REALISTIC",
          "FICTION"
        ],
        "default": "AUTO"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "reference_mask_urls": {
        "type": "array",
        "description": "A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "reference_image_urls": {
        "type": "array",
        "description": "A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/kangaroo/0rinwnj_Kn9Fsu2dK-aKm_image.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to remix",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/mcxydS-_4ZjfBWFtgoo2z_XHLsl7khq6dC6Qp3cIdJl08rG0I.avif"
        ]
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "Strength of the input image in the remix",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-video/lora",
    "title": "Wan-2.2 Text-to-Video A14B with LoRAs",
    "category": "text-to-video",
    "description": "Wan-2.2 text-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. This endpoint supports LoRAs made for Wan 2.2.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/lion/brSX2_cSumQ6aBMB-jTpi_ebd2e40e80d243e2a65f96daf3c961c7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-video/lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-video/lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A close-up of a young woman smiling gently in the rain, raindrops glistening on her face and eyelashes. The video captures the delicate details of her expression and the water droplets, with soft light reflecting off her skin in the rainy atmosphere."
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "If true, the video will be reversed.",
        "required": false,
        "default": false
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to be used in the inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16,
        "examples": [
          16
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9",
        "examples": [
          "16:9",
          "9:16",
          "1:1"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-video/lora",
    "title": "Wan v2.2 A14B Image-to-Video A14B with LoRAs",
    "category": "image-to-video",
    "description": "Wan-2.2 image-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts and images. This endpoint supports LoRAs made for Wan 2.2",
    "tags": [
      "image-to-video",
      "motion",
      "lora"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/Pu175Pi1Z0phr_hCod2pk_51e51de631a54b58ba789155b6955c94.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-video/lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-video/lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Cars racing in slow motion"
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "If true, the video will be reversed.",
        "required": false,
        "default": false
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to be used in the inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16,
        "examples": [
          16
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-video/distill",
    "title": "Wan",
    "category": "text-to-video",
    "description": "Wan 2.2's 5B distill model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/kangaroo/40VOx0fdYnthcwT_S30u4_98d8b53ed1dd439db51e2ffa2d253427.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-video/distill",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-video/distill/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible—a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 0,
        "examples": [
          0
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1,
        "examples": [
          1
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9",
        "examples": [
          "16:9",
          "9:16",
          "1:1"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (580p or 720p).",
        "required": false,
        "enum": [
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40,
        "examples": [
          40
        ]
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02-fast/image-to-video",
    "title": "Minimax",
    "category": "image-to-video",
    "description": "Create blazing fast and economical videos with MiniMax Hailuo-02 Image To Video API at 512p resolution",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/f_EeVaEkzmhhcRXL1Xruj_8fd7a6cbb43b460b8a6ff550a153f4af.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02-fast/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02-fast/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "Extremely realistic movement An old samurai is breaking a stone in half"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
        "required": false,
        "enum": [
          "6",
          "10"
        ],
        "default": "6"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/U9HN_tm5-3Ls52SbD6CrW_image.webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/dreamina/v3.1/text-to-image",
    "title": "Bytedance",
    "category": "text-to-image",
    "description": "Dreamina showcases superior picture effects, with significant improvements in picture aesthetics, precise and diverse styles, and rich details.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/l70sBwCHmfC3XRlEd6GV5_ebd0a5807bba4b6ca02f3c3bffca5cc7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/dreamina/v3.1/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/dreamina/v3.1/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the image",
        "required": true,
        "examples": [
          "A 25-year-old korean woman selfie, front facing camera, lighting is soft and natural. If background is visible, it's a clean, modern apartment interior. The clothing color is clearly visible and distinct, adding a hint of color contrast"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Width and height must be between 512 and 2048.",
        "required": false,
        "default": {
          "height": 1536,
          "width": 2048
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control the stochasticity of image generation.",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to use an LLM to enhance the prompt",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-video/fast-wan",
    "title": "Wan",
    "category": "text-to-video",
    "description": "Wan 2.2's 5B FastVideo model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "tags": [
      "text to video",
      "motion"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/4c9sGLsb2lXhga0i89W2N_47ef03f9caa949ca901a2801a4d42e6a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-video/fast-wan",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-video/fast-wan/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible—a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 0,
        "examples": [
          0
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9",
        "examples": [
          "16:9",
          "9:16",
          "1:1"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (580p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-image/lora",
    "title": "Wan v2.2 A14B Text-to-Image A14B with LoRAs",
    "category": "text-to-image",
    "description": "Wan 2.2's 14B model with LoRA support generates high-fidelity images with enhanced prompt alignment, style adaptability.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/lion/hV9rZRZFnLQo1Bns6llc7_148c4a2e142445cda4c87daed812f731.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-image/lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-image/lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the image. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2,
        "examples": [
          2
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide image generation.",
        "required": true,
        "examples": [
          "In this breathtaking wildlife documentary, we are drawn into an intimate close-up of a majestic lion's face, framed against the backdrop of a vast African savannah at dawn. The camera captures the raw power and nobility of the creature as it gazes intently into the distance, its golden-brown fur glistening under the soft, diffused light that bathes the scene in an ethereal glow. Harsh shadows dance across its features, accentuating the deep wrinkles around its eyes and the rugged texture of its fur, each strand a testament to its age and wisdom. The static camera angle invites viewers to immerse themselves in this moment of profound stillness, where the lion's intense focus hints at an unseen presence or a distant threat. As the sun ascends, the landscape transforms into a symphony of warm hues, enhancing the serene yet tense atmosphere that envelops this extraordinary encounter with nature's untamed beauty."
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd",
        "examples": [
          "square_hd"
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "If true, the video will be reversed.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to be used in the inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "image_format": {
        "type": "string",
        "description": "The format of the output image.",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "jpeg",
        "examples": [
          "jpeg"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-image",
    "title": "Wan",
    "category": "text-to-image",
    "description": "Wan 2.2's 5B model generates high-resolution, photorealistic images with powerful prompt understanding and fine-grained visual detail",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/kangaroo/xvsySaKCeM5ZulogiaTX2_f6fa9b031e374468bcb9e426528807e4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide image generation.",
        "required": true,
        "examples": [
          "In this breathtaking wildlife documentary, we are drawn into an intimate close-up of a majestic lion's face, framed against the backdrop of a vast African savannah at dawn. The camera captures the raw power and nobility of the creature as it gazes intently into the distance, its golden-brown fur glistening under the soft, diffused light that bathes the scene in an ethereal glow. Harsh shadows dance across its features, accentuating the deep wrinkles around its eyes and the rugged texture of its fur, each strand a testament to its age and wisdom. The static camera angle invites viewers to immerse themselves in this moment of profound stillness, where the lion's intense focus hints at an unseen presence or a distant threat. As the sun ascends, the landscape transforms into a symphony of warm hues, enhancing the serene yet tense atmosphere that envelops this extraordinary encounter with nature's untamed beauty."
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift value for the image. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2,
        "examples": [
          2
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd",
        "examples": [
          "square_hd"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40,
        "examples": [
          40
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "image_format": {
        "type": "string",
        "description": "The format of the output image.",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "jpeg",
        "examples": [
          "jpeg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-image",
    "title": "Wan",
    "category": "text-to-image",
    "description": "Wan 2.2's 14B model generates high-resolution, photorealistic images with powerful prompt understanding and fine-grained visual detail",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide image generation.",
        "required": true,
        "examples": [
          "In this breathtaking wildlife documentary, we are drawn into an intimate close-up of a majestic lion's face, framed against the backdrop of a vast African savannah at dawn. The camera captures the raw power and nobility of the creature as it gazes intently into the distance, its golden-brown fur glistening under the soft, diffused light that bathes the scene in an ethereal glow. Harsh shadows dance across its features, accentuating the deep wrinkles around its eyes and the rugged texture of its fur, each strand a testament to its age and wisdom. The static camera angle invites viewers to immerse themselves in this moment of profound stillness, where the lion's intense focus hints at an unseen presence or a distant threat. As the sun ascends, the landscape transforms into a symphony of warm hues, enhancing the serene yet tense atmosphere that envelops this extraordinary encounter with nature's untamed beauty."
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift value for the image. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2,
        "examples": [
          2
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd",
        "examples": [
          "square_hd"
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      }
    }
  },
  {
    "id": "fal-ai/qwen-image",
    "title": "Qwen Image",
    "category": "text-to-image",
    "description": "Qwen-Image is an image generation foundation model in the Qwen series that achieves significant advances in complex text rendering and precise image editing. ",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/6JAMNCSti-vm-zJeZi6hA_626cdc11d4d04560ac9523fbd61f2eac.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none",
        "examples": [
          "none"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 2,
        "maximum": 250,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the generation",
        "required": false,
        "default": " ",
        "examples": [
          "blurry, ugly"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/video-to-video",
    "title": "Wan",
    "category": "video-to-video",
    "description": "Wan-2.2 video-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts and source videos.",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/kangaroo/fRLY4F3IQ1P3DwmVR8WUO_Mmzbg7vdKVmIAsxNycTbw_4a43f046e5be4a97b45a98320ff47bf3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-2.2-v2v-input.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A low-angle medium shot captures a domestic white cat with brown and black patches and a blue bandana sitting on a light-colored tiled floor indoors, meticulously grooming itself by licking its paw and then rubbing its face with it, against a soft-focused background of wooden kitchen cabinets and a reflective metallic appliance."
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "resample_fps": {
        "type": "boolean",
        "description": "If true, the video will be resampled to the passed frames per second. If false, the video will not be resampled.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16,
        "examples": [
          16
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Strength of the video transformation. A value of 1.0 means the output will be completely based on the prompt, while a value of 0.0 means the output will be identical to the input video.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.9,
        "examples": [
          0.9
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/flux-krea-lora/stream",
    "title": "Flux Krea Lora",
    "category": "text-to-image",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/6CK9OSIhC3AAEhihyCqsh_9a84ecc9c66343d688ccdd5c9f57c80b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/stream",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/stream/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-krea-lora/inpainting",
    "title": "FLUX.1 Krea [dev] Inpainting with LoRAs",
    "category": "image-to-image",
    "description": "Super fast endpoint for the FLUX.1 [dev] inpainting model with LoRA support, enabling rapid and high-quality image inpaingting using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "mask_url": {
        "type": "string",
        "description": "\n            The mask to area to Inpaint in.\n        ",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/dog_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-krea-lora",
    "title": "FLUX.1 Krea [dev] with LoRAs",
    "category": "text-to-image",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/tiger/fB-RsJ-BW4mrUVAH8oKF2_LOuGVDgg07U8OWbOhhMFt_d6ab08c96ab94da8b6d3e979d634af16.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-krea-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-krea-lora/image-to-image",
    "title": "FLUX.1 Krea [dev] with LoRAs",
    "category": "image-to-image",
    "description": "FLUX LoRA Image-to-Image is a high-performance endpoint that transforms existing images using FLUX models, leveraging LoRA adaptations to enable rapid and precise image style transfer, modifications, and artistic variations.",
    "tags": [
      "lora",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-krea-lora/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "easel-ai/fashion-tryon",
    "title": "Fashion Try On",
    "category": "image-to-image",
    "description": "Instant fashion try on with a full-body pic and an outfit",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/koala/CsvNzqTdxWgyeMaY3ByNM_c8c44e108a8c427398a6cde17ff5ccd0.jpg",
    "playgroundUrl": "https://fal.ai/models/easel-ai/fashion-tryon",
    "documentationUrl": "https://fal.ai/models/easel-ai/fashion-tryon/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "clothing_image": {
        "type": null,
        "description": "The clothing item to try on the person",
        "required": true,
        "examples": [
          "https://images.easelai.com/tryon/outfit6.webp",
          "https://images.easelai.com/tryon/outfit4.webp",
          "https://images.easelai.com/tryon/woman_outfit7.webp",
          "https://images.easelai.com/tryon/men_outfit7.webp",
          "https://images.easelai.com/tryon/outfit3.webp"
        ]
      },
      "gender": {
        "type": "string",
        "description": "The model's gender for the try-on.",
        "required": false,
        "enum": [
          "male",
          "female"
        ],
        "default": "female"
      },
      "full_body_image": {
        "type": null,
        "description": "The reference person full body image to try clothes on",
        "required": true,
        "examples": [
          "https://images.easelai.com/tryon/woman.webp",
          "https://images.easelai.com/tryon/man.webp"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated try-on result"
      }
    }
  },
  {
    "id": "fal-ai/veo3/image-to-video",
    "title": "Veo3",
    "category": "image-to-video",
    "description": "Veo 3 is the latest state-of-the art video generation model from Google DeepMind",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing how the image should be animated",
        "required": true,
        "examples": [
          "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3 Image-to-Video on Fal? It's incredible!\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "auto"
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/veo3-i2v-input.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-video/turbo",
    "title": "Wan",
    "category": "image-to-video",
    "description": "Wan-2.2 Turbo image-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. ",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-video/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-video/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "end_image_url": {
        "type": "string",
        "description": "URL of the end image.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-video/turbo",
    "title": "Wan",
    "category": "text-to-video",
    "description": "Wan-2.2 turbo text-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. ",
    "tags": [
      "text to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-video/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-video/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible—a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9",
        "examples": [
          "16:9",
          "9:16",
          "1:1"
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/flux/krea/image-to-image",
    "title": "FLUX.1 Krea [dev]",
    "category": "image-to-image",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-4.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/krea/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/krea/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux/krea/redux",
    "title": "FLUX.1 Krea [dev] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 Krea [dev] Redux is a high-performance endpoint for the FLUX.1 Krea [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/krea/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/krea/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/flux_krea_redux_output_1.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux/krea",
    "title": "FLUX.1 Krea [dev]",
    "category": "text-to-image",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/krea",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/krea/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A candid street photo of a woman with a pink bob and bold eyeliner on a graffiti-covered subway platform. She wears a bright yellow patent leather coat over a black-and-white checkered turtleneck and platform boots. Natural subway lighting creates an authentic urban scene with a relaxed, unposed feel."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/krea/image-to-image",
    "title": "FLUX.1 Krea [dev]",
    "category": "image-to-image",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/krea/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/krea/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/krea/redux",
    "title": "FLUX.1 Krea [dev] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 Krea [dev] Redux is a high-performance endpoint for the FLUX.1 Krea [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/krea/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/krea/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/flux_krea_redux_output_1.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/krea",
    "title": "FLUX.1 Krea [dev]",
    "category": "text-to-image",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/krea",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/krea/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A candid street photo of a woman with a pink bob and bold eyeliner on a graffiti-covered subway platform. She wears a bright yellow patent leather coat over a black-and-white checkered turtleneck and platform boots. Natural subway lighting creates an authentic urban scene with a relaxed, unposed feel."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-5b/image-to-video",
    "title": "Wan v2.2 5B",
    "category": "image-to-video",
    "description": "Wan 2.2's 5B model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 0,
        "examples": [
          0
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (580p or 720p).",
        "required": false,
        "enum": [
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40,
        "examples": [
          40
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/flux-kontext-lora/inpaint",
    "title": "Flux Kontext Lora",
    "category": "image-to-image",
    "description": "Fast inpainting endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image inpainting with reference images, while using pre-trained LoRA adaptations for specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "image-editing",
      "image-inpainting",
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-kontext-lora/inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-kontext-lora/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for the image to image task.",
        "required": true,
        "examples": [
          "A football lying on a field."
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "reference_image_url": {
        "type": "string",
        "description": "The URL of the reference image for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/reference_kontext_inpaint.jpeg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be inpainted.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.88
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 30
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-video",
    "title": "Wan v2.2 5B",
    "category": "text-to-video",
    "description": "Wan 2.2's 5B model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-5b/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible—a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 0,
        "examples": [
          0
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9",
        "examples": [
          "16:9",
          "9:16",
          "1:1"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (580p or 720p).",
        "required": false,
        "enum": [
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40,
        "examples": [
          40
        ]
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-video",
    "title": "Wan-2.2 Text-to-Video A14B",
    "category": "text-to-video",
    "description": "Wan-2.2 text-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. ",
    "tags": [
      "text to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A close-up of a young woman smiling gently in the rain, raindrops glistening on her face and eyelashes. The video captures the delicate details of her expression and the water droplets, with soft light reflecting off her skin in the rainy atmosphere."
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16,
        "examples": [
          16
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9",
        "examples": [
          "16:9",
          "9:16",
          "1:1"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4,
        "examples": [
          4
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-video",
    "title": "Wan v2.2 A14B",
    "category": "image-to-video",
    "description": "fal-ai/wan/v2.2-A14B/image-to-video",
    "tags": [],
    "thumbnailUrl": "https://v3.fal.media/files/penguin/xWl1TIQn-uRe7BsctByJk_3e01d1a4f7ff488c9483be0d81f5a3cc.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan/v2.2-a14b/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift value for the video. Must be between 1.0 and 10.0.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1,
        "examples": [
          1
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
        "required": false,
        "minimum": 4,
        "maximum": 60,
        "default": 16,
        "examples": [
          16
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 161,
        "default": 81,
        "examples": [
          81
        ]
      },
      "end_image_url": {
        "type": "string",
        "description": "URL of the end image.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": ""
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, input data will be checked for safety before processing.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "enable_output_safety_checker": {
        "type": "boolean",
        "description": "If set to true, output video will be checked for safety after generation.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "guidance_scale_2": {
        "type": "number",
        "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "adjust_fps_for_interpolation": {
        "type": "boolean",
        "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
        "required": false,
        "enum": [
          "none",
          "film",
          "rife"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 27,
        "examples": [
          27
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used for video generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan_world",
    "title": "Hunyuan World",
    "category": "image-to-image",
    "description": "Hunyuan World 1.0 turns a single image into a panorama or a 3D world. It creates realistic scenes from the image, allowing you to explore and view it from different angles.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/rabbit/K4wH2Zlj5N6woxkqlpGya_f9ae0f21d42a4c67afe183ab1eea225e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan_world",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan_world/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for the panorama generation.",
        "required": true,
        "examples": [
          "A skyland of wonders"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to convert to a panorama.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/_4oXlxt85dr0WY2o0I894_output.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated panorama image."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan_world/image-to-world",
    "title": "Hunyuan World",
    "category": "image-to-3d",
    "description": "Hunyuan World 1.0 turns a single image into a panorama or a 3D world. It creates realistic scenes from the image, allowing you to explore and view it from different angles.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/penguin/89p9igw0J95bIBO105W1r_ff145cc097ae4129bb32e8e68186fe6f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan_world/image-to-world",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan_world/image-to-world/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "classes": {
        "type": "string",
        "description": "Classes to use for the world generation.",
        "required": true,
        "examples": [
          "nature, landscape"
        ]
      },
      "export_drc": {
        "type": "boolean",
        "description": "Whether to export DRC (Dynamic Resource Configuration).",
        "required": false,
        "default": false
      },
      "labels_fg1": {
        "type": "string",
        "description": "Labels for the first foreground object.",
        "required": true,
        "examples": [
          "tree, grass, sky"
        ]
      },
      "labels_fg2": {
        "type": "string",
        "description": "Labels for the second foreground object.",
        "required": true,
        "examples": [
          "mountain, water"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to convert to a world.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/_4oXlxt85dr0WY2o0I894_output.png"
        ]
      }
    },
    "outputParameters": {
      "world_file": {
        "type": null,
        "description": "The generated world."
      }
    }
  },
  {
    "id": "fal-ai/x-ailab/nsfw",
    "title": "NSFW Checker",
    "category": "vision",
    "description": "Predict whether an image is NSFW or SFW.",
    "tags": [
      "filter",
      "safety",
      "utility"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/monkey/Tja6xudNPajR7Wiv3CI2z_6fa01860226940cbab39842db772f7da.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/x-ailab/nsfw",
    "documentationUrl": "https://fal.ai/models/fal-ai/x-ailab/nsfw/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_urls": {
        "type": "array",
        "description": "List of image URLs to check. If more than 10 images are provided, only the first 10 will be checked.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/remove_background/elephant.jpg"
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "has_nsfw_concepts": {
        "type": "array",
        "description": "List of booleans indicating if the image has an NSFW concept",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/bytedance/omnihuman",
    "title": "OmniHuman",
    "category": "image-to-video",
    "description": "OmniHuman generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character’s emotions and movements maintain a strong correlation with the audio.",
    "tags": [
      "image-to-video",
      "lipsync"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/omnihuman",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/omnihuman/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file to generate the video. Audio must be under 30s long.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_audio.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image used to generate the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/omnihuman.png"
        ]
      }
    },
    "outputParameters": {
      "duration": {
        "type": "number",
        "description": "Duration of audio input/video output as used for billing."
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/sky-raccoon",
    "title": "Sky Raccoon",
    "category": "text-to-image",
    "description": "Generate images from a text prompt.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sky-raccoon",
    "documentationUrl": "https://fal.ai/models/fal-ai/sky-raccoon/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "turbo_mode": {
        "type": "boolean",
        "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
        "required": false,
        "default": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      }
    }
  },
  {
    "id": "fal-ai/image-editing/retouch",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Retouch photos of faces. Remove blemishes and improve the skin.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/retouch",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/retouch/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lora_scale": {
        "type": "number",
        "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to retouch.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/tulsi.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker for the generated image.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/hidream-e1-1",
    "title": "Hidream E1 1",
    "category": "image-to-image",
    "description": "Edit images with natural language",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hidream-e1-1",
    "documentationUrl": "https://fal.ai/models/fal-ai/hidream-e1-1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5,
        "examples": [
          3.5
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your initial image when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2,
        "examples": [
          2
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of an input image to edit.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/hidream/woman.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "target_image_description": {
        "type": "string",
        "description": "The description of the target image after your edits have been made. Leave this blank to allow the model to use its own imagination.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "low resolution, blur",
        "examples": [
          "low resolution, blur"
        ]
      },
      "edit_instruction": {
        "type": "string",
        "description": "The instruction to edit the image.",
        "required": false,
        "examples": [
          "Convert the image into a 3D animated style."
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ltxv-13b-098-distilled/extend",
    "title": "LTX-Video 13B 0.9.8 Distilled",
    "category": "video-to-video",
    "description": "Extend videos using LTX Video-0.9.8 13B Distilled and custom LoRA",
    "tags": [
      "ltx-video",
      "extend"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/extend",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/extend/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 11,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "Woman walking on a street in Tokyo"
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "temporal_adain_factor": {
        "type": "number",
        "description": "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 1441,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "video": {
        "type": null,
        "description": "Video to be extended.",
        "required": true,
        "examples": [
          {
            "video_url": "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4",
            "start_frame_num": 0,
            "reverse_video": false,
            "limit_num_frames": false,
            "resample_fps": false,
            "strength": 1,
            "target_fps": 24,
            "max_num_frames": 1441,
            "conditioning_type": "rgb",
            "preprocess": false
          }
        ]
      },
      "enable_detail_pass": {
        "type": "boolean",
        "description": "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "tone_map_compression_ratio": {
        "type": "number",
        "description": "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 0,
        "maximum": 51,
        "default": 29,
        "examples": [
          29
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/rife/video",
    "title": "RIFE",
    "category": "video-to-video",
    "description": "Interpolate videos with RIFE - Real-Time Intermediate Flow Estimation",
    "tags": [
      "interpolation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/rife/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/rife/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the video to use for interpolation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/interpolation-video-input.mp4"
        ]
      },
      "use_scene_detection": {
        "type": "boolean",
        "description": "If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.",
        "required": false,
        "default": false
      },
      "use_calculated_fps": {
        "type": "boolean",
        "description": "If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.",
        "required": false,
        "default": true
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate between the input video frames.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "loop": {
        "type": "boolean",
        "description": "If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.",
        "required": false,
        "default": false
      },
      "fps": {
        "type": "integer",
        "description": "Frames per second for the output video. Only applicable if use_calculated_fps is False.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 8
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file with interpolated frames."
      }
    }
  },
  {
    "id": "fal-ai/rife",
    "title": "RIFE",
    "category": "image-to-image",
    "description": "Interpolate images with RIFE - Real-Time Intermediate Flow Estimation",
    "tags": [
      "interpolation"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/HLrNymdnzx1neVc9Pj0c1_debdeb10494e45888dd68d1a2df2dcac.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/rife",
    "documentationUrl": "https://fal.ai/models/fal-ai/rife/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "output_format": {
        "type": "string",
        "description": "The format of the output images. Only applicable if output_type is 'images'.",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "jpeg"
      },
      "include_start": {
        "type": "boolean",
        "description": "Whether to include the start image in the output.",
        "required": false,
        "default": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If True, the function will wait for images to be generated and uploaded before returning. This will increase the response time but ensures that the images are ready for use immediately without going through the CDN. Does not apply if output_type is 'video'.",
        "required": false,
        "default": false
      },
      "include_end": {
        "type": "boolean",
        "description": "Whether to include the end image in the output.",
        "required": false,
        "default": false
      },
      "fps": {
        "type": "integer",
        "description": "Frames per second for the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 8
      },
      "start_image_url": {
        "type": "string",
        "description": "The URL of the first image to use as the starting point for interpolation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/interpolate-start-frame.png"
        ]
      },
      "end_image_url": {
        "type": "string",
        "description": "The URL of the second image to use as the ending point for interpolation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/interpolate-end-frame.png"
        ]
      },
      "output_type": {
        "type": "string",
        "description": "The type of output to generate; either individual images or a video.",
        "required": false,
        "enum": [
          "images",
          "video"
        ],
        "default": "images"
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate between the input images.",
        "required": false,
        "minimum": 1,
        "maximum": 64,
        "default": 1
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated frames as individual images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "video": {
        "type": null,
        "description": "The generated video file, if output_type is 'video'."
      }
    }
  },
  {
    "id": "fal-ai/film/video",
    "title": "FILM",
    "category": "video-to-video",
    "description": "Interpolate videos with FILM - Frame Interpolation for Large Motion",
    "tags": [
      "interpolation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/film/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/film/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to use for interpolation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/interpolation-video-input.mp4"
        ]
      },
      "use_calculated_fps": {
        "type": "boolean",
        "description": "If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.",
        "required": false,
        "default": true
      },
      "loop": {
        "type": "boolean",
        "description": "If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.",
        "required": false,
        "default": false
      },
      "fps": {
        "type": "integer",
        "description": "Frames per second for the output video. Only applicable if use_calculated_fps is False.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If True, the function will wait for images to be generated and uploaded before returning. This will increase the response time but ensures that the images are ready for use immediately without going through the CDN. Does not apply if output_type is 'video'.",
        "required": false,
        "default": false
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "use_scene_detection": {
        "type": "boolean",
        "description": "If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.",
        "required": false,
        "default": false
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate between the input video frames.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file with interpolated frames."
      }
    }
  },
  {
    "id": "fal-ai/film",
    "title": "FILM",
    "category": "image-to-image",
    "description": "Interpolate images with FILM - Frame Interpolation for Large Motion",
    "tags": [
      "interpolation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/film",
    "documentationUrl": "https://fal.ai/models/fal-ai/film/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "output_type": {
        "type": "string",
        "description": "The type of output to generate; either individual images or a video.",
        "required": false,
        "enum": [
          "images",
          "video"
        ],
        "default": "images"
      },
      "fps": {
        "type": "integer",
        "description": "Frames per second for the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If True, the function will wait for images to be generated and uploaded before returning. This will increase the response time but ensures that the images are ready for use immediately without going through the CDN.",
        "required": false,
        "default": false
      },
      "include_end": {
        "type": "boolean",
        "description": "Whether to include the end image in the output.",
        "required": false,
        "default": false
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the output video. Only applicable if output_type is 'video'.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "include_start": {
        "type": "boolean",
        "description": "Whether to include the start image in the output.",
        "required": false,
        "default": false
      },
      "start_image_url": {
        "type": "string",
        "description": "The URL of the first image to use as the starting point for interpolation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/interpolate-start-frame.png"
        ]
      },
      "end_image_url": {
        "type": "string",
        "description": "The URL of the second image to use as the ending point for interpolation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/interpolate-end-frame.png"
        ]
      },
      "image_format": {
        "type": "string",
        "description": "The format of the output images. Only applicable if output_type is 'images'.",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "jpeg"
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate between the input images.",
        "required": false,
        "minimum": 1,
        "maximum": 64,
        "default": 1
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated frames as individual images.",
        "items": {
          "$ref": "#/components/schemas/ImageFile"
        }
      },
      "video": {
        "type": null,
        "description": "The generated video file, if output_type is 'video'."
      }
    }
  },
  {
    "id": "fal-ai/minimax/voice-design",
    "title": "MiniMax Voice Design",
    "category": "text-to-speech",
    "description": "Design a personalized voice from a text description, and generate speech from text prompts using the MiniMax model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "speech",
      ""
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/gAqnPCSWSWoC_if0g88gI_e7bf818aa9fc45aeafaceb1b713c8717.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/voice-design",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/voice-design/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Voice description prompt for generating a personalized voice",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "Bubbly and excitable female pop star interviewee, youthful, slightly breathless, and very enthusiastic"
        ]
      },
      "preview_text": {
        "type": "string",
        "description": "Text for audio preview. Limited to 500 characters. A fee of $30 per 1M characters will be charged for the generation of the preview audio.",
        "required": true,
        "maxLength": 500,
        "examples": [
          "Oh my gosh, hi. It's like so amazing to be here. This new endpoint just dropped on fal and the results have been like totally incredible. Use it now, It's gonna be like epic!"
        ]
      }
    },
    "outputParameters": {
      "custom_voice_id": {
        "type": "string",
        "description": "The voice_id of the generated voice"
      },
      "audio": {
        "type": null,
        "description": "The preview audio using the generated voice"
      }
    }
  },
  {
    "id": "creatify/lipsync",
    "title": "Lipsync",
    "category": "video-to-video",
    "description": "Realistic lipsync video - optimized for speed, quality, and consistency.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/lion/6fj0n9tYyJcr0UZ5Go1_2_80cf6f42ba2e4d03aec7e942714472f1.jpg",
    "playgroundUrl": "https://fal.ai/models/creatify/lipsync",
    "documentationUrl": "https://fal.ai/models/creatify/lipsync/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The video url to use for lipsync",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/GzfGN-LfnbobjM9h2g5PF_Eduardo.mov"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The audio url to use for lipsync",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/IjB1sco-ydVA-szm3a1Rm_E_voice.mp3"
        ]
      },
      "loop": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The output of the lipsync"
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2-flash/modify",
    "title": "Luma Ray 2 Flash Modify",
    "category": "video-to-video",
    "description": "Ray2 Flash Modify is a video generative model capable of restyling or retexturing the entire shot, from turning live-action into CG or stylized animation, to changing wardrobe, props, or the overall aesthetic and swap environments or time periods, giving you control over background, location, or even weather.",
    "tags": [
      "modify",
      "restyle"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/y1-LTiotjfV3d_9Hy1lMU_3db5709293314d53abe575e9327c0fe4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/modify",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/modify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Instruction for modifying the video",
        "required": false,
        "minLength": 3,
        "maxLength": 5000
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to modify",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
        ]
      },
      "mode": {
        "type": "string",
        "description": "Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most",
        "required": false,
        "enum": [
          "adhere_1",
          "adhere_2",
          "adhere_3",
          "flex_1",
          "flex_2",
          "flex_3",
          "reimagine_1",
          "reimagine_2",
          "reimagine_3"
        ],
        "default": "flex_1"
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the first frame image for modification",
        "required": false,
        "examples": [
          "https://fal.media/files/koala/Kv2821G03ggpKK2AiZX71_d5fa7bacf06049cfaeb9588f6003b6d5.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the modified video"
      }
    }
  },
  {
    "id": "fal-ai/ltxv-13b-098-distilled/image-to-video",
    "title": "LTX-Video 13B 0.9.8 Distilled",
    "category": "image-to-video",
    "description": "Generate long videos from prompts and images using LTX Video-0.9.8 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 11,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "The astronaut gets up and walks away"
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "temporal_adain_factor": {
        "type": "number",
        "description": "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 1441,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "enable_detail_pass": {
        "type": "boolean",
        "description": "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "tone_map_compression_ratio": {
        "type": "number",
        "description": "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for Image-to-Video task",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ltxv-image-input.jpg"
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 0,
        "maximum": 51,
        "default": 29,
        "examples": [
          29
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltxv-13b-098-distilled",
    "title": "LTX-Video 13B 0.9.8 Distilled",
    "category": "text-to-video",
    "description": "Generate long videos from prompts using LTX Video-0.9.8 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 11,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A cinematic fast-tracking shot follows a vintage, teal camper van as it descends a winding mountain trail. The van, slightly weathered but well-maintained, is the central focus, its retro design emphasized by the motion blur. Medium shot reveals the dusty, ochre trail, edged with vibrant green pine trees. Close-up on the van's tires shows the gravel spraying, highlighting the speed and rugged terrain. Sunlight filters through the trees, casting dappled shadows on the van and the trail. The background is a hazy, majestic mountain range bathed in warm, golden light. The overall mood is adventurous and exhilarating. High resolution 4k movie scene."
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "temporal_adain_factor": {
        "type": "number",
        "description": "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 1441,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "enable_detail_pass": {
        "type": "boolean",
        "description": "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9"
        ],
        "default": "16:9",
        "examples": [
          "16:9"
        ]
      },
      "tone_map_compression_ratio": {
        "type": "number",
        "description": "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltxv-13b-098-distilled/multiconditioning",
    "title": "LTX-Video 13B 0.9.8 Distilled",
    "category": "video-to-video",
    "description": "Generate long videos from prompts, images, and videos using LTX Video-0.9.8 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "video-to-video",
      "multicondition-to-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/multiconditioning",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltxv-13b-098-distilled/multiconditioning/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 11,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 24,
        "examples": [
          24
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A vibrant, abstract composition featuring a person with outstretched arms, rendered in a kaleidoscope of colors against a deep, dark background. The figure is composed of intricate, swirling patterns reminiscent of a mosaic, with hues of orange, yellow, blue, and green that evoke the style of artists such as Wassily Kandinsky or Bridget Riley. The camera zooms into the face striking portrait of a man, reimagined through the lens of old-school video-game graphics. The subject's face is rendered in a kaleidoscope of colors, with bold blues and reds set against a vibrant yellow backdrop. His dark hair is pulled back, framing his profile in a dramatic pose."
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "temporal_adain_factor": {
        "type": "number",
        "description": "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "images": {
        "type": "array",
        "description": "URL of images to use as conditioning",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "strength": 1,
              "start_frame_num": 0,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/NswO1P8sCLzrh1WefqQFK_9a6bdbfa54b944c9a770338159a113fd.jpg"
            },
            {
              "strength": 1,
              "start_frame_num": 120,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/YAPOGvmS2tM_Krdp7q6-d_267c97e017c34f679844a4477dfcec38.jpg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/ImageConditioningInput"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 1441,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "enable_detail_pass": {
        "type": "boolean",
        "description": "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "tone_map_compression_ratio": {
        "type": "number",
        "description": "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "videos": {
        "type": "array",
        "description": "Videos to use as conditioning",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/VideoConditioningInput"
        }
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 0,
        "maximum": 51,
        "default": 29,
        "examples": [
          29
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/any-llm/enterprise",
    "title": "any-llm Enterprise",
    "category": "llm",
    "description": "Run any large language model with fal, powered by OpenRouter.\n\nThis endpoint only supports models that do not train on private data.\n\nRead more in OpenRouter's Privacy and Logging documentation.",
    "tags": [
      "chat",
      "claude",
      "gpt"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/any-llm/enterprise",
    "documentationUrl": "https://fal.ai/models/fal-ai/any-llm/enterprise/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the chat completion",
        "required": true,
        "examples": [
          "What is the meaning of life?"
        ]
      },
      "system_prompt": {
        "type": "string",
        "description": "System prompt to provide context or instructions to the model",
        "required": false
      },
      "reasoning": {
        "type": "boolean",
        "description": "Should reasoning be the part of the final answer.",
        "required": false,
        "default": false
      },
      "model": {
        "type": "string",
        "description": "Name of the model to use. Premium models are charged at 10x the rate of standard models, they include: google/gemini-pro-1.5, openai/gpt-5-chat, openai/gpt-4o, anthropic/claude-sonnet-4.5, google/gemini-2.5-pro, anthropic/claude-3.7-sonnet, anthropic/claude-3.5-sonnet, anthropic/claude-3-5-haiku, openai/o3, meta-llama/llama-3.2-90b-vision-instruct, openai/gpt-4.1.",
        "required": false,
        "enum": [
          "anthropic/claude-sonnet-4.5",
          "anthropic/claude-3.7-sonnet",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-3-5-haiku",
          "anthropic/claude-3-haiku",
          "google/gemini-pro-1.5",
          "google/gemini-flash-1.5",
          "google/gemini-flash-1.5-8b",
          "google/gemini-2.0-flash-001",
          "google/gemini-2.5-flash",
          "google/gemini-2.5-flash-lite",
          "google/gemini-2.5-pro",
          "meta-llama/llama-3.2-1b-instruct",
          "meta-llama/llama-3.2-3b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "openai/gpt-oss-120b",
          "openai/gpt-4o-mini",
          "openai/gpt-4o",
          "openai/gpt-4.1",
          "openai/o3",
          "openai/gpt-5-chat",
          "openai/gpt-5-mini",
          "openai/gpt-5-nano",
          "meta-llama/llama-4-maverick",
          "meta-llama/llama-4-scout"
        ],
        "default": "google/gemini-2.5-flash-lite",
        "examples": [
          "google/gemini-2.5-flash"
        ]
      },
      "max_tokens": {
        "type": "integer",
        "description": "This sets the upper limit for the number of tokens the model can generate in response. It won’t produce more than this limit. The maximum value is the context length minus the prompt length.",
        "required": false,
        "minimum": 1
      },
      "temperature": {
        "type": "number",
        "description": "This setting influences the variety in the model’s responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.",
        "required": false,
        "minimum": 0,
        "maximum": 2
      },
      "priority": {
        "type": "string",
        "description": "Throughput is the default and is recommended for most use cases. Latency is recommended for use cases where low latency is important.",
        "required": false,
        "enum": [
          "throughput",
          "latency"
        ],
        "default": "latency"
      }
    },
    "outputParameters": {
      "error": {
        "type": "string",
        "description": "Error message if an error occurred"
      },
      "partial": {
        "type": "boolean",
        "description": "Whether the output is partial"
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      },
      "reasoning": {
        "type": "string",
        "description": "Generated reasoning for the final answer"
      }
    }
  },
  {
    "id": "easel-ai/fashion-photoshoot",
    "title": "Fashion Photoshoot",
    "category": "image-to-image",
    "description": "Instant fashion photoshoot with a selfie and an outfit",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-3.jpeg",
    "playgroundUrl": "https://fal.ai/models/easel-ai/fashion-photoshoot",
    "documentationUrl": "https://fal.ai/models/easel-ai/fashion-photoshoot/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "mode": {
        "type": "string",
        "description": "Choose generation mode: stylistic (classic look) or realistic (photorealistic).",
        "required": false,
        "enum": [
          "stylistic",
          "realistic"
        ],
        "default": "stylistic"
      },
      "gender": {
        "type": "string",
        "description": "The model's gender for the fashion shoot.",
        "required": true,
        "enum": [
          "male",
          "female"
        ]
      },
      "body_size": {
        "type": "string",
        "description": "The body size for the fashion shoot.",
        "required": false,
        "enum": [
          "XS",
          "S",
          "M",
          "L",
          "XL"
        ],
        "default": "S",
        "examples": [
          "XS",
          "S",
          "M",
          "L",
          "XL"
        ]
      },
      "location": {
        "type": "string",
        "description": "Sets the location / background for the fashion shoot.",
        "required": false,
        "enum": [
          "park",
          "city",
          "runway"
        ],
        "default": "park"
      },
      "garment_image": {
        "type": null,
        "description": "The garment image to be used for the fashion shoot.",
        "required": true,
        "examples": [
          "https://images.easelai.com/fashionshoot/acoldwall_sweater.webp",
          "https://images.easelai.com/fashionshoot/boss_dress.webp",
          "https://images.easelai.com/fashionshoot/boss_suiit.webp",
          "https://images.easelai.com/fashionshoot/gucci_jacket_women.jpg"
        ]
      },
      "face_image": {
        "type": null,
        "description": "The user's face image used for the fashion shoot.",
        "required": true,
        "examples": [
          "https://images.easelai.com/mirror_fal/faces/male.png",
          "https://images.easelai.com/mirror_fal/faces/female.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The resulting image after the fashion shoot."
      }
    }
  },
  {
    "id": "fal-ai/calligrapher",
    "title": "Calligrapher",
    "category": "image-to-image",
    "description": "Use the text and font retaining capabilities of calligrapher to modify texts on your books, clothes and many more.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/calligrapher",
    "documentationUrl": "https://fal.ai/models/fal-ai/calligrapher/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "use_context": {
        "type": "boolean",
        "description": "Whether to prepend context reference to the input",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "How many images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "Target image size for generation",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "auto_mask_generation": {
        "type": "boolean",
        "description": "Whether to automatically generate mask from detected text",
        "required": false,
        "default": false
      },
      "reference_image_url": {
        "type": "string",
        "description": "Optional base64 reference image for style",
        "required": false
      },
      "source_image_url": {
        "type": "string",
        "description": "Base64-encoded source image with drawn mask layers",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/calligrapher/test17_source.png"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to inpaint or customize",
        "required": true,
        "examples": [
          "The text is 'Rise'"
        ]
      },
      "mask_image_url": {
        "type": "string",
        "description": "Base64-encoded mask image (optional if using auto_mask_generation)",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/calligrapher/test17_mask.png"
        ]
      },
      "source_text": {
        "type": "string",
        "description": "Source text to replace (if empty, masks all detected text)",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps (1-100)",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility",
        "required": false
      },
      "cfg_scale": {
        "type": "number",
        "description": "Guidance or strength scale for the model",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/veo3/fast/image-to-video",
    "title": "Veo 3 Fast [Image to Video]",
    "category": "image-to-video",
    "description": "Now with a 50% price drop. Generate videos from your image prompts using Veo 3 fast.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo3/fast/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo3/fast/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing how the image should be animated",
        "required": true,
        "examples": [
          "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3 Image-to-Video on Fal? It's incredible!\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9",
          "1:1"
        ],
        "default": "auto"
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "8s"
        ],
        "default": "8s"
      },
      "generate_audio": {
        "type": "boolean",
        "description": "Whether to generate audio for the video. If false, %33 less credits will be used.",
        "required": false,
        "default": true
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/veo3-i2v-input.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ffmpeg-api/loudnorm",
    "title": "Ffmpeg Api",
    "category": "json",
    "description": "Get EBU R128 loudness normalization from audio files using FFmpeg API.",
    "tags": [
      "ffmpeg"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ffmpeg-api-waveform.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/loudnorm",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/loudnorm/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "measured_lra": {
        "type": null,
        "description": "Measured loudness range of input file in LU. Required for linear mode.",
        "required": false
      },
      "offset": {
        "type": "number",
        "description": "Offset gain in dB applied before the true-peak limiter",
        "required": false,
        "minimum": -99,
        "maximum": 99,
        "default": 0
      },
      "measured_tp": {
        "type": null,
        "description": "Measured true peak of input file in dBTP. Required for linear mode.",
        "required": false
      },
      "measured_i": {
        "type": null,
        "description": "Measured integrated loudness of input file in LUFS. Required for linear mode.",
        "required": false
      },
      "linear": {
        "type": "boolean",
        "description": "Use linear normalization mode (single-pass). If false, uses dynamic mode (two-pass for better quality).",
        "required": false,
        "default": false
      },
      "print_summary": {
        "type": "boolean",
        "description": "Return loudness measurement summary with the normalized audio",
        "required": false,
        "default": false
      },
      "dual_mono": {
        "type": "boolean",
        "description": "Treat mono input files as dual-mono for correct EBU R128 measurement on stereo systems",
        "required": false,
        "default": false
      },
      "measured_thresh": {
        "type": null,
        "description": "Measured threshold of input file in LUFS. Required for linear mode.",
        "required": false
      },
      "true_peak": {
        "type": "number",
        "description": "Maximum true peak in dBTP.",
        "required": false,
        "minimum": -9,
        "maximum": 0,
        "default": -0.1
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to normalize",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ffmpeg-audio.wav"
        ]
      },
      "integrated_loudness": {
        "type": "number",
        "description": "Integrated loudness target in LUFS.",
        "required": false,
        "minimum": -70,
        "maximum": -5,
        "default": -18
      },
      "loudness_range": {
        "type": "number",
        "description": "Loudness range target in LU",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 7
      }
    },
    "outputParameters": {
      "summary": {
        "type": null,
        "description": "Structured loudness measurement summary (if requested)"
      },
      "audio": {
        "type": null,
        "description": "Normalized audio file"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q1/reference-to-video",
    "title": "Vidu",
    "category": "image-to-video",
    "description": "Generate video clips from your multiple image references using Vidu Q1",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q1/reference-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q1/reference-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "A young woman and a monkey inside a colorful house"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "bgm": {
        "type": "boolean",
        "description": "Whether to add background music to the generated video",
        "required": false,
        "default": false
      },
      "reference_image_urls": {
        "type": "array",
        "description": "URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/panda/HDpZj0eLjWwCpjA5__0l1_0e6cd0b9eb7a4a968c0019a4eee15e46.png",
            "https://v3.fal.media/files/zebra/153izt1cBlMU-TwD0_B7Q_ea34618f5d974653a16a755aa61e488a.png",
            "https://v3.fal.media/files/koala/RCSZ7VEEKGFDfMoGHCwzo_f626718793e94769b1ad36d5891864a4.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with consistent subjects from reference images using the Q1 model"
      }
    }
  },
  {
    "id": "fal-ai/bria/reimagine",
    "title": "Bria",
    "category": "image-to-image",
    "description": "Structure Reference allows generating new images while preserving the structure of an input image, guided by text prompts. Perfect for transforming sketches, illustrations, or photos into new illustrations. Trained exclusively on licensed data for safe and risk-free commercial use.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/rabbit/wXG4NtIA2sZUz7-CiooUJ_bb5f4b6f122149849d744baaad6896f8.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/reimagine",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/reimagine/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt you would like to use to generate images.",
        "required": true,
        "examples": [
          "A 2d illustration of a dog in a vibrant park"
        ]
      },
      "num_results": {
        "type": "integer",
        "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "structure_ref_influence": {
        "type": "number",
        "description": "The influence of the structure reference on the generated image.",
        "required": false,
        "default": 0.75,
        "examples": [
          0.15
        ]
      },
      "fast": {
        "type": "boolean",
        "description": "Whether to use the fast model",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "structure_image_url": {
        "type": "string",
        "description": "The URL of the structure reference image. Use \"\" to leave empty. Accepted formats are jpeg, jpg, png, webp.",
        "required": false,
        "default": "",
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_reimagine_input.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/pixverse/sound-effects",
    "title": "Pixverse",
    "category": "video-to-video",
    "description": "Add immersive sound effects and background music to your videos using PixVerse sound effects  generation",
    "tags": [
      "audio",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/sound-effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/sound-effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Description of the sound effect to generate. If empty, a random sound effect will be generated",
        "required": false,
        "default": "",
        "examples": [
          "sea waves",
          "thunder storm",
          "birds chirping"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to add sound effects to",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/QfpJmEBkR75KpB6yfNLDM_video.mp4"
        ]
      },
      "original_sound_switch": {
        "type": "boolean",
        "description": "Whether to keep the original audio from the video",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The video with added sound effects"
      }
    }
  },
  {
    "id": "fal-ai/image-editing/realism",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Add details to faces, enhance face features, remove blur.",
    "tags": [
      "stylized",
      "transform",
      "realism"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/realism",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/realism/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lora_scale": {
        "type": "number",
        "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 0.6
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to enhance with realism details.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/QpRcoPb4dDyDJJSpFm4CZ_img_55_start.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker for the generated image.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/thinksound/audio",
    "title": "ThinkSound",
    "category": "video-to-video",
    "description": "Generate realistic audio from a video with an optional text prompt",
    "tags": [
      "audio-generation",
      "video-to-audio"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/thinksound/audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/thinksound/audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "A prompt to guide the audio generation. If not provided, it will be extracted from the video.",
        "required": false,
        "default": ""
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate the audio for.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/thinksound-input.mp4"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps for audio generation.",
        "required": false,
        "minimum": 2,
        "maximum": 100,
        "default": 24,
        "examples": [
          24
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "cfg_scale": {
        "type": "number",
        "description": "The classifier-free guidance scale for audio generation.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5,
        "examples": [
          5
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used to generate the audio."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/thinksound",
    "title": "ThinkSound",
    "category": "video-to-video",
    "description": "Generate realistic audio for a video with an optional text prompt and combine",
    "tags": [
      "audio-generation",
      "video-to-audio"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/thinksound",
    "documentationUrl": "https://fal.ai/models/fal-ai/thinksound/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "A prompt to guide the audio generation. If not provided, it will be extracted from the video.",
        "required": false,
        "default": ""
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate the audio for.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/thinksound-input.mp4"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps for audio generation.",
        "required": false,
        "minimum": 2,
        "maximum": 100,
        "default": 24,
        "examples": [
          24
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "cfg_scale": {
        "type": "number",
        "description": "The classifier-free guidance scale for audio generation.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5,
        "examples": [
          5
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used to generate the audio."
      },
      "video": {
        "type": null,
        "description": "The generated video with audio."
      }
    }
  },
  {
    "id": "fal-ai/post-processing/vignette",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Add a darkening vignette effect around the edges of the image with adjustable strength",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/8KT3LjgSQtyW87hvxYr9n_8c31d2880fac4b9c877518c8162c2c8a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/vignette",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/vignette/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "vignette_strength": {
        "type": "number",
        "description": "Vignette strength",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with vignette effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/solarize",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply solarization effect by inverting pixel values above a threshold",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/eR5hrHpGP3yIomYpon_z2_707e890433164c9494d964f9660833ec.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/solarize",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/solarize/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "solarize_threshold": {
        "type": "number",
        "description": "Solarize threshold",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with solarize effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/sharpen",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply sharpening effects with three modes: basic unsharp mask, smart sharpening with edge preservation, and Contrast Adaptive Sharpening (CAS).",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/koBXGLN1Y5Qzu7ZKUogdf_7ceac7fe825841b5813a724990cd4f5b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/sharpen",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/sharpen/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sharpen_mode": {
        "type": "string",
        "description": "Type of sharpening to apply",
        "required": false,
        "enum": [
          "basic",
          "smart",
          "cas"
        ],
        "default": "basic"
      },
      "noise_radius": {
        "type": "integer",
        "description": "Noise radius for smart sharpen",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 7
      },
      "sharpen_alpha": {
        "type": "number",
        "description": "Sharpen strength (for basic mode)",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      },
      "sharpen_radius": {
        "type": "integer",
        "description": "Sharpen radius (for basic mode)",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      },
      "smart_sharpen_strength": {
        "type": "number",
        "description": "Smart sharpen strength",
        "required": false,
        "minimum": 0,
        "maximum": 25,
        "default": 5
      },
      "cas_amount": {
        "type": "number",
        "description": "CAS sharpening amount",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "preserve_edges": {
        "type": "number",
        "description": "Edge preservation factor",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "smart_sharpen_ratio": {
        "type": "number",
        "description": "Smart sharpen blend ratio",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with sharpen effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/parabolize",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply a parabolic distortion effect with configurable coefficient and vertex position.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/parabolize",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/parabolize/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "parabolize_coeff": {
        "type": "number",
        "description": "Parabolize coefficient",
        "required": false,
        "minimum": -10,
        "maximum": 10,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      },
      "vertex_x": {
        "type": "number",
        "description": "Vertex X position",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "vertex_y": {
        "type": "number",
        "description": "Vertex Y position",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with parabolize effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/grain",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply film grain effect with different styles (modern, analog, kodak, fuji, cinematic, newspaper) and customizable intensity and scale",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/grain",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/grain/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "grain_style": {
        "type": "string",
        "description": "Style of film grain to apply",
        "required": false,
        "enum": [
          "modern",
          "analog",
          "kodak",
          "fuji",
          "cinematic",
          "newspaper"
        ],
        "default": "modern"
      },
      "grain_intensity": {
        "type": "number",
        "description": "Film grain intensity",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.4
      },
      "grain_scale": {
        "type": "number",
        "description": "Film grain scale",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 10
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with grain effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/dodge-burn",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply dodge and burn effects with multiple modes and adjustable intensity.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/dodge-burn",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/dodge-burn/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "dodge_burn_mode": {
        "type": "string",
        "description": "Dodge and burn mode",
        "required": false,
        "enum": [
          "dodge",
          "burn",
          "dodge_and_burn",
          "burn_and_dodge",
          "color_dodge",
          "color_burn",
          "linear_dodge",
          "linear_burn"
        ],
        "default": "dodge"
      },
      "dodge_burn_intensity": {
        "type": "number",
        "description": "Dodge and burn intensity",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with dodge and burn effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/dissolve",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Blend two images together using smooth linear interpolation with a configurable blend factor.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/dissolve",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/dissolve/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "dissolve_factor": {
        "type": "number",
        "description": "Dissolve blend factor",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "dissolve_image_url": {
        "type": "string",
        "description": "URL of second image for dissolve",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/NJW5irDVP1qwoTMdwOcDV_39qXtqYS0zSUrFwbrJkOY.jpeg"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/pLQKJXcFdmIVvB2qhw7vv_59578fb9-8178-4f24-82f0-ea7ec5bc5f2d.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with dissolve effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/desaturate",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Reduce color saturation using different methods (luminance Rec.709, luminance Rec.601, average, lightness) with adjustable factor.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/desaturate",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/desaturate/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "desaturate_method": {
        "type": "string",
        "description": "Desaturation method",
        "required": false,
        "enum": [
          "luminance (Rec.709)",
          "luminance (Rec.601)",
          "average",
          "lightness"
        ],
        "default": "luminance (Rec.709)"
      },
      "desaturate_factor": {
        "type": "number",
        "description": "Desaturation factor",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with desaturation effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/color-tint",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply various color tints (sepia, red, green, blue, cyan, magenta, yellow, purple, orange, warm, cool, lime, navy, vintage, rose, teal, maroon, peach, lavender, olive) with adjustable strength.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/color-tint",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/color-tint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "tint_strength": {
        "type": "number",
        "description": "Tint strength",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 1
      },
      "tint_mode": {
        "type": "string",
        "description": "Tint color mode",
        "required": false,
        "enum": [
          "sepia",
          "red",
          "green",
          "blue",
          "cyan",
          "magenta",
          "yellow",
          "purple",
          "orange",
          "warm",
          "cool",
          "lime",
          "navy",
          "vintage",
          "rose",
          "teal",
          "maroon",
          "peach",
          "lavender",
          "olive"
        ],
        "default": "sepia"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with color tint effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/color-correction",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Adjust color temperature, brightness, contrast, saturation, and gamma values for color correction.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/GV2S-bd9TChg0FDfkUXhs_abda259c89bf433091d8a1bc46ef8cf0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/color-correction",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/color-correction/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "temperature": {
        "type": "number",
        "description": "Color temperature adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "saturation": {
        "type": "number",
        "description": "Saturation adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "gamma": {
        "type": "number",
        "description": "Gamma adjustment",
        "required": false,
        "minimum": 0.2,
        "maximum": 2.2,
        "default": 1
      },
      "brightness": {
        "type": "number",
        "description": "Brightness adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "contrast": {
        "type": "number",
        "description": "Contrast adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with color correction",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/chromatic-aberration",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Create chromatic aberration by shifting red, green, and blue channels horizontally or vertically with customizable shift amounts.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/chromatic-aberration",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/chromatic-aberration/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "blue_direction": {
        "type": "string",
        "description": "Blue channel shift direction",
        "required": false,
        "enum": [
          "horizontal",
          "vertical"
        ],
        "default": "horizontal"
      },
      "red_shift": {
        "type": "integer",
        "description": "Red channel shift amount",
        "required": false,
        "minimum": -20,
        "maximum": 20,
        "default": 0
      },
      "green_direction": {
        "type": "string",
        "description": "Green channel shift direction",
        "required": false,
        "enum": [
          "horizontal",
          "vertical"
        ],
        "default": "horizontal"
      },
      "blue_shift": {
        "type": "integer",
        "description": "Blue channel shift amount",
        "required": false,
        "minimum": -20,
        "maximum": 20,
        "default": 0
      },
      "red_direction": {
        "type": "string",
        "description": "Red channel shift direction",
        "required": false,
        "enum": [
          "horizontal",
          "vertical"
        ],
        "default": "horizontal"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      },
      "green_shift": {
        "type": "integer",
        "description": "Green channel shift amount",
        "required": false,
        "minimum": -20,
        "maximum": 20,
        "default": 0
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with chromatic aberration effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/post-processing/blur",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Apply Gaussian or Kuwahara blur effects with adjustable radius and sigma parameters",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/bjwlW3KSsaWKc_0aK5zu1_1bd1f105d15a43618789039ab333c21a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing/blur",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/blur/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "blur_sigma": {
        "type": "number",
        "description": "Sigma for Gaussian blur",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 1
      },
      "blur_radius": {
        "type": "integer",
        "description": "Blur radius",
        "required": false,
        "minimum": 0,
        "maximum": 31,
        "default": 3
      },
      "blur_type": {
        "type": "string",
        "description": "Type of blur to apply",
        "required": false,
        "enum": [
          "gaussian",
          "kuwahara"
        ],
        "default": "gaussian"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images with blur effect",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/pixverse/extend/fast",
    "title": "Pixverse",
    "category": "video-to-video",
    "description": "PixVerse Extend model is a video extending tool for your videos using with high-quality video extending techniques ",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/extend/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/extend/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt describing how to extend the video",
        "required": true,
        "examples": [
          "A kid is talking into camera"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video. Fast mode doesn't support 1080p",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to extend",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/88-jI3VWXU4Q8kSNrWo3c_output.mp4"
        ]
      },
      "style": {
        "type": "string",
        "description": "The style of the extended video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "day",
          "cyberpunk",
          "comic"
        ]
      },
      "model": {
        "type": "string",
        "description": "The model version to use for generation",
        "required": false,
        "enum": [
          "v3.5",
          "v4",
          "v4.5",
          "v5"
        ],
        "default": "v4.5"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The extended video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/extend",
    "title": "Pixverse",
    "category": "video-to-video",
    "description": "PixVerse Extend model is a video extending tool for your videos using with high-quality video extending techniques ",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/extend",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/extend/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt describing how to extend the video",
        "required": true,
        "examples": [
          "A kid is talking into camera"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "style": {
        "type": "string",
        "description": "The style of the extended video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "day",
          "cyberpunk",
          "comic"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to extend",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/88-jI3VWXU4Q8kSNrWo3c_output.mp4"
        ]
      },
      "model": {
        "type": "string",
        "description": "The model version to use for generation",
        "required": false,
        "enum": [
          "v3.5",
          "v4",
          "v4.5",
          "v5"
        ],
        "default": "v4.5"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The extended video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/lipsync",
    "title": "Pixverse",
    "category": "video-to-video",
    "description": "Generate realistic lipsync animations from audio using advanced algorithms for high-quality synchronization with PixVerse Lipsync model",
    "tags": [
      "animation",
      "lip sync"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/dSjrqmujPFztMyFSqTtny_c6457768d98c4537aa1516df53388e79.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/lipsync",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/lipsync/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text content for TTS when audio_url is not provided",
        "required": false,
        "examples": [
          "Hello, this is a test message."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/T-ONORYMYLoEOB9lXryA2_IKEy3yAyi1evJGBAkXGZx_output.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the input audio. If not provided, TTS will be used.",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/monkey/k4iyN8bJZWwJXMKH-pO9r_speech.mp3"
        ]
      },
      "voice_id": {
        "type": "string",
        "description": "Voice to use for TTS when audio_url is not provided",
        "required": false,
        "enum": [
          "Emily",
          "James",
          "Isabella",
          "Liam",
          "Chloe",
          "Adrian",
          "Harper",
          "Ava",
          "Sophia",
          "Julia",
          "Mason",
          "Jack",
          "Oliver",
          "Ethan",
          "Auto"
        ],
        "default": "Auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/image-editing/youtube-thumbnails",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Generate YouTube thumbnails with custom text",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/SZZJwGHb-HkjWln94WNc0_23a19743226b4125b5d0e5d4769879ed.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/youtube-thumbnails",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/youtube-thumbnails/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text to include in the YouTube thumbnail.",
        "required": false,
        "default": "Generate youtube thumbnails",
        "examples": [
          "Generate youtube thumbnails using text 'EPIC FAIL."
        ]
      },
      "lora_scale": {
        "type": "number",
        "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to convert to YouTube thumbnail style.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/QUihQrMqowYu30UFC_Atk.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker for the generated image.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2/modify",
    "title": "Luma Ray 2 Modify",
    "category": "video-to-video",
    "description": "Ray2 Modify is a video generative model capable of restyling or retexturing the entire shot, from turning live-action into CG or stylized animation, to changing wardrobe, props, or the overall aesthetic and swap environments or time periods, giving you control over background, location, or even weather.",
    "tags": [
      "modify",
      "restyle"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/modify",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/modify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Instruction for modifying the video",
        "required": false,
        "minLength": 3,
        "maxLength": 5000
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to modify",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
        ]
      },
      "mode": {
        "type": "string",
        "description": "Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most",
        "required": false,
        "enum": [
          "adhere_1",
          "adhere_2",
          "adhere_3",
          "flex_1",
          "flex_2",
          "flex_3",
          "reimagine_1",
          "reimagine_2",
          "reimagine_3"
        ],
        "default": "flex_1"
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the first frame image for modification",
        "required": false,
        "examples": [
          "https://fal.media/files/koala/Kv2821G03ggpKK2AiZX71_d5fa7bacf06049cfaeb9588f6003b6d5.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the modified video"
      }
    }
  },
  {
    "id": "fal-ai/topaz/upscale/image",
    "title": "Topaz",
    "category": "image-to-image",
    "description": "Use the powerful and accurate topaz image enhancer to enhance your images.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/topaz/upscale/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/topaz/upscale/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "face_enhancement_creativity": {
        "type": "number",
        "description": "Creativity level for face enhancement. 0.0 means no creativity, 1.0 means maximum creativity. Ignored if face ehnancement is disabled.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "face_enhancement_strength": {
        "type": "number",
        "description": "Strength of the face enhancement. 0.0 means no enhancement, 1.0 means maximum enhancement. Ignored if face ehnancement is disabled.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "output_format": {
        "type": "string",
        "description": "Output format of the upscaled image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "face_enhancement": {
        "type": "boolean",
        "description": "Whether to apply face enhancement to the image.",
        "required": false,
        "default": true
      },
      "subject_detection": {
        "type": "string",
        "description": "Subject detection mode for the image enhancement.",
        "required": false,
        "enum": [
          "All",
          "Foreground",
          "Background"
        ],
        "default": "All"
      },
      "model": {
        "type": "string",
        "description": "Model to use for image enhancement.",
        "required": false,
        "enum": [
          "Low Resolution V2",
          "Standard V2",
          "CGI",
          "High Fidelity V2",
          "Text Refine",
          "Recovery",
          "Redefine",
          "Recovery V2"
        ],
        "default": "Standard V2"
      },
      "image_url": {
        "type": "string",
        "description": "Url of the image to be upscaled",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/codeformer/codeformer_poor_1.jpeg"
        ]
      },
      "upscale_factor": {
        "type": "number",
        "description": "Factor to upscale the video by (e.g. 2.0 doubles width and height)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 2
      },
      "crop_to_fill": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The upscaled image."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seededit/v3/edit-image",
    "title": "Bytedance",
    "category": "image-to-image",
    "description": "SeedEdit 3.0 is an image editing model independently developed by ByteDance. It excels in accurately following editing instructions and effectively preserving image content, especially excelling in handling real images",
    "tags": [
      "image-editing",
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seededit/v3/edit-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seededit/v3/edit-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to edit the image",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "Make it a realistic, highly detailed  photograph with a winter wonderland background. Then give her a bowler hat."
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Controls how closely the output image aligns with the input prompt. Higher values mean stronger prompt correlation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control the stochasticity of image generation.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be edited.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/seededit.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Generated image"
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/image-editing/broccoli-haircut",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform your character's hair into broccoli style while keeping the original characters likeness",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/xDrMHbm03pWLw1pSXS4-r_dc670c9a3ba0406681a20fe6a10c98fa.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/broccoli-haircut",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/broccoli-haircut/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lora_scale": {
        "type": "number",
        "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to apply broccoli haircut style.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/8nqqnF_KS9c0pGgwvRNAY_IMG_8421.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker for the generated image.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/wojak-style",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform your photos into wojak style while keeping the original characters likeness",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/wojak-style",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/wojak-style/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lora_scale": {
        "type": "number",
        "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to convert to wojak style.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/UGZQWl6lUdYeu91QzUZys_5ODmUQcqNeufTbf_hhO0h_unnamed%20(2).jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker for the generated image.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/plushie-style",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform your photos into cool plushies while keeping the original characters likeness",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/plushie-style",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/plushie-style/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lora_scale": {
        "type": "number",
        "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
        "required": false,
        "minimum": 0,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to convert to plushie style.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/5fVB7Y5ERU7zAvA_kd2i3_trump-portrait_square.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker for the generated image.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-kontext-lora/text-to-image",
    "title": "Flux Kontext Lora",
    "category": "text-to-image",
    "description": "Super fast text-to-image endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "text-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-kontext-lora/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-kontext-lora/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image with",
        "required": true,
        "examples": [
          "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-kontext-lora",
    "title": "Flux Kontext Lora",
    "category": "image-to-image",
    "description": "Fast endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image editing using pre-trained LoRA adaptations for specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "image-editing",
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-3.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-kontext-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-kontext-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image.",
        "required": true,
        "examples": [
          "change the setting to a day time, add a lot of people walking the sidewalk while maintaining the same style of the painting"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "resolution_mode": {
        "type": "string",
        "description": "\n            Determines how the output resolution is set for image editing.\n            - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.\n            - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).\n            Apart from these, a few aspect ratios are also supported.\n            ",
        "required": false,
        "enum": [
          "auto",
          "match_input",
          "1:1",
          "16:9",
          "21:9",
          "3:2",
          "2:3",
          "4:5",
          "5:4",
          "3:4",
          "4:3",
          "9:16",
          "9:21"
        ],
        "default": "match_input"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.\n\nMax width: 14142px, Max height: 14142px, Timeout: 20s",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/kontext_example_input.webp"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/omnigen-v2",
    "title": "Omnigen V2",
    "category": "text-to-image",
    "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts. It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On, Multi Person Generation and more!",
    "tags": [
      "multimodal",
      "editing",
      "try-on"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/omnigen-v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/omnigen-v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate or edit an image. Use specific language like 'Add the bird from image 1 to the desk in image 2' for better results.",
        "required": true,
        "examples": [
          "Make the dress blue",
          "Add a fisherman hat to the woman's head",
          "Replace the sword with a hammer.",
          "Change the dress to blue.",
          "Remove the cat"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "scheduler": {
        "type": "string",
        "description": "The scheduler to use for the diffusion process.",
        "required": false,
        "enum": [
          "euler",
          "dpmsolver"
        ],
        "default": "euler"
      },
      "cfg_range_end": {
        "type": "number",
        "description": "CFG range end value.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to guide what should not be in the image.",
        "required": false,
        "default": "(((deformed))), blurry, over saturation, bad anatomy, disfigured, poorly drawn face, mutation, mutated, (extra_limb), (ugly), (poorly drawn hands), fused fingers, messy drawing, broken legs censor, censored, censor_bar"
      },
      "text_guidance_scale": {
        "type": "number",
        "description": "\n            The Text Guidance scale controls how closely the model follows the text prompt.\n            Higher values make the model stick more closely to the prompt.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 5
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_guidance_scale": {
        "type": "number",
        "description": "\n            The Image Guidance scale controls how closely the model follows the input images.\n            For image editing: 1.3-2.0, for in-context generation: 2.0-3.0\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 3,
        "default": 2
      },
      "input_image_urls": {
        "type": "array",
        "description": "URLs of input images to use for image editing or multi-image generation. Support up to 3 images.",
        "required": false,
        "default": [],
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/omnigen/input.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "cfg_range_start": {
        "type": "number",
        "description": "CFG range start value.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fashn/tryon/v1.6",
    "title": "FASHN Virtual Try-On V1.6",
    "category": "image-to-image",
    "description": "FASHN v1.6 delivers precise virtual try-on capabilities, accurately rendering garment details like text and patterns at 864x1296 resolution from both on-model and flat-lay photo references.",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fashn_wide.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fashn/tryon/v1.6",
    "documentationUrl": "https://fal.ai/models/fal-ai/fashn/tryon/v1.6/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model_image": {
        "type": "string",
        "description": "URL or base64 of the model image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/model.png"
        ]
      },
      "moderation_level": {
        "type": "string",
        "description": "Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.",
        "required": false,
        "enum": [
          "none",
          "permissive",
          "conservative"
        ],
        "default": "permissive"
      },
      "garment_photo_type": {
        "type": "string",
        "description": "Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.",
        "required": false,
        "enum": [
          "auto",
          "model",
          "flat-lay"
        ],
        "default": "auto"
      },
      "garment_image": {
        "type": "string",
        "description": "URL or base64 of the garment image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/garment.webp"
        ]
      },
      "category": {
        "type": "string",
        "description": "Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.",
        "required": false,
        "enum": [
          "tops",
          "bottoms",
          "one-pieces",
          "auto"
        ],
        "default": "auto"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "segmentation_free": {
        "type": "boolean",
        "description": "Disables human parsing on the model image.",
        "required": false,
        "default": true
      },
      "num_samples": {
        "type": "integer",
        "description": "Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "mode": {
        "type": "string",
        "description": "Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.",
        "required": false,
        "enum": [
          "performance",
          "balanced",
          "quality"
        ],
        "default": "balanced"
      },
      "seed": {
        "type": "integer",
        "description": "Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "png"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/ai-avatar/single-text",
    "title": "Ai Avatar",
    "category": "image-to-video",
    "description": "MultiTalk model generates a talking avatar video from an image and text. Converts text to speech automatically, then generates the avatar speaking with lip-sync.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/ETFEnZEbEj9nc6e1XdFG8_6f87551d505640c89d59f8018dd0ffb0.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ai-avatar/single-text",
    "documentationUrl": "https://fal.ai/models/fal-ai/ai-avatar/single-text/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "An elderly man with a white beard and headphones records audio with a microphone. He appears engaged and expressive, suggesting a podcast or voiceover."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "text_input": {
        "type": "string",
        "description": "The text input to guide video generation.",
        "required": true,
        "examples": [
          "Spend more time with people who make you feel alive, and less with things that drain your soul."
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/HuM21CXMf0q7OO2zbvwhV_c4533aada79a495b90e50e32dc9b83a8.png"
        ]
      },
      "voice": {
        "type": "string",
        "description": "The voice to use for speech generation",
        "required": true,
        "enum": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ],
        "examples": [
          "Bill"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 42
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 41,
        "maximum": 241,
        "default": 136
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ai-avatar",
    "title": "Ai Avatar",
    "category": "image-to-video",
    "description": "MultiTalk model generates a talking avatar video from an image and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ai-avatar",
    "documentationUrl": "https://fal.ai/models/fal-ai/ai-avatar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A woman with colorful hair talking on a podcast."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/gmpc0QevDF9bBsL1EAYVF_1c637094161147559f0910a68275dc34.png"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/PtiCYda53E9Dav25QmQYI_output.mp3"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 41,
        "maximum": 241,
        "default": 145
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 42
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ai-avatar/multi-text",
    "title": "Ai Avatar",
    "category": "image-to-video",
    "description": "MultiTalk model generates a multi-person conversation video from an image and text inputs. Converts text to speech for each person, generating a realistic conversation scene.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ai-avatar/multi-text",
    "documentationUrl": "https://fal.ai/models/fal-ai/ai-avatar/multi-text/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Two kids talking on a lunch."
        ]
      },
      "second_text_input": {
        "type": "string",
        "description": "The text input to guide video generation.",
        "required": true,
        "examples": [
          "I dont know I am eating this because our mother gave it to us. I think it is something called milky pie."
        ]
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "first_text_input": {
        "type": "string",
        "description": "The text input to guide video generation.",
        "required": true,
        "examples": [
          "Do you know what are we eating?"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/vhkIF86hmgNTBll_lF1xI_3c7476642b19435aa763fe3b49cf99c7.png"
        ]
      },
      "voice2": {
        "type": "string",
        "description": "The second person's voice to use for speech generation",
        "required": false,
        "enum": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ],
        "default": "Roger"
      },
      "voice1": {
        "type": "string",
        "description": "The first person's voice to use for speech generation",
        "required": false,
        "enum": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ],
        "default": "Sarah"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 81
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 41,
        "maximum": 241,
        "default": 191
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ai-avatar/multi",
    "title": "Ai Avatar",
    "category": "image-to-video",
    "description": "MultiTalk model generates a multi-person conversation video from an image and audio files. Creates a realistic scene where multiple people speak in sequence.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ai-avatar/multi",
    "documentationUrl": "https://fal.ai/models/fal-ai/ai-avatar/multi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A smiling man and woman wearing headphones sit in front of microphones, appearing to host a podcast. They are engaged in conversation, looking at each other and the camera as they speak. The scene captures a lively and collaborative podcasting session."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the video to generate. Must be either 480p or 720p.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "480p"
      },
      "acceleration": {
        "type": "string",
        "description": "The acceleration level to use for generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "first_audio_url": {
        "type": "string",
        "description": "The URL of the Person 1 audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/1XKPx3Xu-IhNLbuinVSwP_output.mp3"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/Q2ZU6q-d-1boGXhpDgWs9_15a22f816fd34cad969b2329946267b3.png"
        ]
      },
      "second_audio_url": {
        "type": "string",
        "description": "The URL of the Person 2 audio file.",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/zebra/oVKyL8JZ1K2GreeIMxVzm_output.mp3"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false,
        "default": 81
      },
      "use_only_first_audio": {
        "type": "boolean",
        "description": "Whether to use only the first audio file.",
        "required": false,
        "default": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 41,
        "maximum": 241,
        "default": 181
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/video-understanding",
    "title": "Video Understanding",
    "category": "vision",
    "description": "A video understanding model to analyze video content and answer questions about what's happening in the video based on user prompts.",
    "tags": [
      "utility",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/video-understanding",
    "documentationUrl": "https://fal.ai/models/fal-ai/video-understanding/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The question or prompt about the video content.",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "What is happening in this video?"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to analyze",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/mLAMkUTxFMbe2xF0qpLdA_Ll9mDE8webFA6GAu3vD_M_71ee7217db1d4aa4af1d2f1ae060389b.mp4"
        ]
      },
      "detailed_analysis": {
        "type": "boolean",
        "description": "Whether to request a more detailed analysis of the video",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "output": {
        "type": "string",
        "description": "The analysis of the video content based on the prompt"
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-14b/reframe",
    "title": "Wan VACE 14B",
    "category": "video-to-video",
    "description": "VACE is a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "reframe"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation. Optional for reframing.",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. This video will be used as a reference for the reframe task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "trim_borders": {
        "type": "boolean",
        "description": "Whether to trim borders from the video.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "zoom_factor": {
        "type": "number",
        "description": "Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.",
        "required": false,
        "minimum": 0,
        "maximum": 0.9,
        "default": 0,
        "examples": [
          0
        ]
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated reframe video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-14b/outpainting",
    "title": "Wan VACE 14B",
    "category": "video-to-video",
    "description": "VACE is a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "image-to-video",
      "video-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/outpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/outpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A lone woman strides through the neon-drenched streets of Tokyo at night.  Her crimson dress, a vibrant splash of color against the deep blues and blacks of the cityscape, flows slightly with each step. A tailored black jacket, crisp and elegant, contrasts sharply with the dress's rich texture. Medium shot:  The city hums around her, blurred lights creating streaks of color in the background. Close-up:  The fabric of her dress catches the streetlight's glow, revealing a subtle silk sheen and the intricate stitching at the hem. Her black jacket’s subtle texture is visible – a fine wool perhaps, with a matte finish. The overall mood is one of quiet confidence and mystery, a vibrant woman navigating a bustling, nocturnal landscape. High resolution 4k."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for outpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "expand_ratio": {
        "type": "number",
        "description": "Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.25,
        "examples": [
          0.25
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "expand_bottom": {
        "type": "boolean",
        "description": "Whether to expand the video to the bottom.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_top": {
        "type": "boolean",
        "description": "Whether to expand the video to the top.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "expand_left": {
        "type": "boolean",
        "description": "Whether to expand the video to the left.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "expand_right": {
        "type": "boolean",
        "description": "Whether to expand the video to the right.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated outpainting video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-14b/inpainting",
    "title": "Wan VACE 14B",
    "category": "video-to-video",
    "description": "VACE is a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "image-to-video",
      "video-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_video.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "Urls to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/vace/src_ref_image_1.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "mask_video_url": {
        "type": null,
        "description": "URL to the source mask file. Required for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_mask.mp4"
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "mask_image_url": {
        "type": null,
        "description": "URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video using salient mask tracking. Will be ignored if mask_video_url is provided.",
        "required": false
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated inpainting video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-14b/pose",
    "title": "Wan VACE 14B",
    "category": "video-to-video",
    "description": "VACE is a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "image-to-video",
      "video-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/pose",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/pose/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.",
        "required": true,
        "examples": [
          "A sharply dressed man walks toward the camera down a sun-drenched hallway.  Medium shot: He's framed from the knees up, his confident stride filling the frame.  His navy blue business suit is impeccably tailored, the fabric subtly shimmering under the light streaming through the tall, arched windows lining the hallway. Close-up:  The rich texture of the suit's wool is visible, each thread reflecting the light.  His crisp white shirt contrasts beautifully with the deep crimson of his silk tie, the knot perfectly formed.  The sunlight highlights the subtle sheen of his polished shoes.  The windows cast long shadows, highlighting the architectural detail of the hallway, creating a sense of both elegance and movement. High resolution 4k."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for pose task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-vace-pose-video.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated pose video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-14b/depth",
    "title": "Wan VACE 14B",
    "category": "video-to-video",
    "description": "VACE is a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "image-to-video",
      "video-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/depth",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/depth/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A confident woman strides toward the camera down a sun-drenched, empty street. Her vibrant summer dress, a flowing emerald green with delicate white floral embroidery, billows slightly in the gentle breeze.  She carries a stylish, woven straw bag, its natural tan contrasting beautifully with the dress. The dress's fabric shimmers subtly, catching the light. The white embroidery is intricate, each tiny flower meticulously detailed.  Her expression is focused, yet relaxed, radiating self-assuredness. Her auburn hair, partially pulled back in a loose braid, catches the sunlight, creating warm highlights. The street itself is paved with warm, grey cobblestones, reflecting the bright sun. The mood is optimistic and serene, emphasizing the woman's independence and carefree spirit. High resolution 4k"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. Required for depth task.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/wan-vace-depth-video.mp4"
        ]
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated depth video file."
      }
    }
  },
  {
    "id": "fal-ai/chain-of-zoom",
    "title": "Chain Of Zoom",
    "category": "image-to-image",
    "description": "Extreme Super-Resolution via Scale Autoregression and Preference Alignment",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-4.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/chain-of-zoom",
    "documentationUrl": "https://fal.ai/models/fal-ai/chain-of-zoom/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "center_y": {
        "type": "number",
        "description": "Y coordinate of zoom center (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "scale": {
        "type": "number",
        "description": "Zoom scale in powers of 2",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 5
      },
      "center_x": {
        "type": "number",
        "description": "X coordinate of zoom center (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "user_prompt": {
        "type": "string",
        "description": "Additional prompt text to guide the zoom enhancement",
        "required": false,
        "default": ""
      },
      "image_url": {
        "type": "string",
        "description": "Input image to zoom into",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/coz_example_input"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "List of intermediate images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "zoom_center": {
        "type": "array",
        "description": "Center coordinates used for zoom",
        "items": {
          "type": "number"
        }
      },
      "scale": {
        "type": "number",
        "description": "Actual linear zoom scale applied"
      }
    }
  },
  {
    "id": "tripo3d/tripo/v2.5/multiview-to-3d",
    "title": "Tripo3D",
    "category": "image-to-3d",
    "description": "State of the art Multiview to 3D Object generation. Generate 3D models from multiple images!",
    "tags": [
      "stylized",
      "multiview"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/_7MtOFa8cfwOHKGp-dMxm_e4939dba689e4c0c89bc25a6eb11cf67.jpg",
    "playgroundUrl": "https://fal.ai/models/tripo3d/tripo/v2.5/multiview-to-3d",
    "documentationUrl": "https://fal.ai/models/tripo3d/tripo/v2.5/multiview-to-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "face_limit": {
        "type": null,
        "description": "Limits the number of faces on the output model. If this option is not set, the face limit will be adaptively determined.",
        "required": false
      },
      "style": {
        "type": null,
        "description": "Defines the artistic style or transformation to be applied to the 3D model, altering its appearance according to preset options (extra $0.05 per generation). Omit this option to keep the original style and apperance.",
        "required": false
      },
      "right_image_url": {
        "type": null,
        "description": "Right view image of the object.",
        "required": false,
        "examples": [
          "https://platform.tripo3d.ai/assets/right-hj57H4if.jpg"
        ]
      },
      "quad": {
        "type": null,
        "description": "Set True to enable quad mesh output (extra $0.05 per generation). If quad=True and face_limit is not set, the default face_limit will be 10000. Note: Enabling this option will force the output to be an FBX model.",
        "required": false,
        "default": false
      },
      "front_image_url": {
        "type": "string",
        "description": "Front view image of the object.",
        "required": true,
        "examples": [
          "https://platform.tripo3d.ai/assets/front-235queJB.jpg"
        ]
      },
      "texture_seed": {
        "type": null,
        "description": "This is the random seed for texture generation. Using the same seed will produce identical textures. This parameter is an integer and is randomly chosen if not set. If you want a model with different textures, please use same seed and different texture_seed.",
        "required": false
      },
      "back_image_url": {
        "type": null,
        "description": "Back view image of the object.",
        "required": false,
        "examples": [
          "https://platform.tripo3d.ai/assets/back-6vq1a8L4.jpg"
        ]
      },
      "pbr": {
        "type": null,
        "description": "A boolean option to enable pbr. The default value is True, set False to get a model without pbr. If this option is set to True, texture will be ignored and used as True.",
        "required": false,
        "default": false
      },
      "texture_alignment": {
        "type": null,
        "description": "Determines the prioritization of texture alignment in the 3D model. The default value is original_image.",
        "required": false,
        "default": "original_image"
      },
      "texture": {
        "type": "string",
        "description": "An option to enable texturing. Default is 'standard', set 'no' to get a model without any textures, and set 'HD' to get a model with hd quality textures.",
        "required": false,
        "enum": [
          "no",
          "standard",
          "HD"
        ],
        "default": "standard"
      },
      "auto_size": {
        "type": null,
        "description": "Automatically scale the model to real-world dimensions, with the unit in meters. The default value is False.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "This is the random seed for model generation. The seed controls the geometry generation process, ensuring identical models when the same seed is used. This parameter is an integer and is randomly chosen if not set.",
        "required": false
      },
      "orientation": {
        "type": null,
        "description": "Set orientation=align_image to automatically rotate the model to align the original image. The default value is default.",
        "required": false,
        "default": "default"
      },
      "left_image_url": {
        "type": null,
        "description": "Left view image of the object.",
        "required": false,
        "examples": [
          "https://platform.tripo3d.ai/assets/left-Nfdj2U8P.jpg"
        ]
      }
    },
    "outputParameters": {
      "base_model": {
        "type": null,
        "description": "Base model"
      },
      "task_id": {
        "type": "string",
        "description": "The task id of the 3D model generation."
      },
      "rendered_image": {
        "type": null,
        "description": "A preview image of the model"
      },
      "model_mesh": {
        "type": null,
        "description": "Model"
      },
      "pbr_model": {
        "type": null,
        "description": "Pbr model"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/pro/image-to-video",
    "title": "MiniMax Hailuo 02 [Pro] (Image to Video)",
    "category": "image-to-video",
    "description": "MiniMax Hailuo-02 Image To Video API (Pro, 1080p): Advanced image-to-video generation model with 1080p resolution",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "Man walked into winter cave with polar bear"
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "end_image_url": {
        "type": "string",
        "description": "Optional URL of the image to use as the last frame of the video",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/pro/text-to-video",
    "title": "MiniMax Hailuo 02 [Pro] (Text to Video)",
    "category": "text-to-video",
    "description": "MiniMax Hailuo-02 Text To Video API (Pro, 1080p): Advanced video generation model with 1080p resolution",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/hailuo-02/pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "A Galactic Smuggler is a rogue figure with a cybernetic arm and a well-worn coat that hints at many dangerous escapades across the galaxy. Their ship is filled with rare and exotic treasures from distant planets, concealed in hidden compartments, showing their expertise in illicit trade. Their belt is adorned with energy-based weapons, ready to be drawn at any moment to protect themselves or escape from tight situations. This character thrives in the shadows of space, navigating between the law and chaos with stealth and wit, always seeking the next big score while evading bounty hunters and law enforcement. The rogue's ship, rugged yet efficient, serves as both a home and a tool for their dangerous lifestyle. The treasures they collect reflect the diverse and intriguing worlds they've encountered—alien artifacts, rare minerals, and artifacts of unknown origin. Their reputation precedes them, with whispers of their dealings and the deadly encounters that often follow. A master of negotiation and deception, the Galactic Smuggler navigates the cosmos with an eye on the horizon, always one step ahead of those who pursue them."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pasd",
    "title": "PASD",
    "category": "image-to-image",
    "description": "Pixel-Aware Diffusion Model for Realistic Image Super-Resolution and Personalized Stylization",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pasd",
    "documentationUrl": "https://fal.ai/models/fal-ai/pasd/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "conditioning_scale": {
        "type": "number",
        "description": "ControlNet conditioning scale (0.1-1.0)",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 0.8
      },
      "prompt": {
        "type": "string",
        "description": "Additional prompt to guide super-resolution",
        "required": false,
        "default": ""
      },
      "image_url": {
        "type": "string",
        "description": "Input image to super-resolve",
        "required": true,
        "examples": [
          "https://fal.media/files/rabbit/JlBgYUyQRS3zxiBu_B4fM.png"
        ]
      },
      "steps": {
        "type": "integer",
        "description": "Number of inference steps (10-50)",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 25
      },
      "scale": {
        "type": "integer",
        "description": "Upscaling factor (1-4x)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 2
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for diffusion (1.0-20.0)",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 7
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to avoid unwanted artifacts",
        "required": false,
        "default": "blurry, dirty, messy, frames, deformed, dotted, noise, raster lines, unclear, lowres, over-smoothed, painting, ai generated"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated super-resolved images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "Timing information for different processing stages"
      }
    }
  },
  {
    "id": "fal-ai/object-removal/bbox",
    "title": "Object Removal",
    "category": "image-to-image",
    "description": "Removes box-selected objects and their visual effects, seamlessly reconstructing the scene with contextually appropriate content.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/object-removal/bbox",
    "documentationUrl": "https://fal.ai/models/fal-ai/object-removal/bbox/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "low_quality",
          "medium_quality",
          "high_quality",
          "best_quality"
        ],
        "default": "best_quality"
      },
      "mask_expansion": {
        "type": "integer",
        "description": "Amount of pixels to expand the mask by. Range: 0-50",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 15
      },
      "box_prompts": {
        "type": "array",
        "description": "List of bounding box coordinates to erase (only one box prompt is supported)",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "y_min": 0.0115,
              "x_max": 0.6574,
              "x_min": 0.3595,
              "y_max": 0.8175
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/BBoxPromptBase"
        }
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to remove objects from.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/o0DORfJawy-T9P_-NsvLY.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images with objects removed.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/object-removal/mask",
    "title": "Object Removal",
    "category": "image-to-image",
    "description": "Removes mask-selected objects and their visual effects, seamlessly reconstructing the scene with contextually appropriate content.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/object-removal/mask",
    "documentationUrl": "https://fal.ai/models/fal-ai/object-removal/mask/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "low_quality",
          "medium_quality",
          "high_quality",
          "best_quality"
        ],
        "default": "best_quality"
      },
      "mask_expansion": {
        "type": "integer",
        "description": "Amount of pixels to expand the mask by. Range: 0-50",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 15
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask image. White pixels (255) indicate areas to remove.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/7nq9-v-lJtBCPnK1332fr.png"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to remove objects from.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/o0DORfJawy-T9P_-NsvLY.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images with objects removed.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/object-removal",
    "title": "Object Removal",
    "category": "image-to-image",
    "description": "Removes objects and their visual effects using natural language, replacing them with contextually appropriate content",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/object-removal",
    "documentationUrl": "https://fal.ai/models/fal-ai/object-removal/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text description of the object to remove.",
        "required": true,
        "examples": [
          "Dog"
        ]
      },
      "mask_expansion": {
        "type": "integer",
        "description": "Amount of pixels to expand the mask by. Range: 0-50",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 15
      },
      "model": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "low_quality",
          "medium_quality",
          "high_quality",
          "best_quality"
        ],
        "default": "best_quality"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to remove objects from.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/o0DORfJawy-T9P_-NsvLY.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images with objects removed.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/text-to-video",
    "title": "Seedance 1.0 Pro",
    "category": "text-to-video",
    "description": "Seedance 1.0 Pro, a high quality video generation model developed by Bytedance.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "A bright blue race car speeds along a snowy racetrack. [Low-angle shot] Captures several cars speeding along the racetrack through a harsh snowstorm. [Overhead shot] The camera gradually pulls upward, revealing the full race scene illuminated by storm lights"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "1080p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/dwpose/video",
    "title": "DWPose Pose Prediction",
    "category": "video-to-video",
    "description": "Predict poses from videos.",
    "tags": [
      "pose",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/dwpose.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dwpose/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/dwpose/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL of video to be used for pose estimation",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/Ben2/100063-video-2160.mp4"
        ]
      },
      "draw_mode": {
        "type": "string",
        "description": "Mode of drawing the pose on the video. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.",
        "required": false,
        "enum": [
          "full-pose",
          "body-pose",
          "face-pose",
          "hand-pose",
          "face-hand-mask",
          "face-mask",
          "hand-mask"
        ],
        "default": "body-pose",
        "examples": [
          "body-pose"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The output video with pose estimation."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d-v21",
    "title": "Hunyuan 3D 2.1",
    "category": "image-to-3d",
    "description": "Hunyuan3D-2.1 is a scalable 3D asset creation system that advances state-of-the-art 3D generation through Physically-Based Rendering (PBR).",
    "tags": [
      "image-to-3d"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d-v21",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d-v21/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "input_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/robot.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "model_glb_pbr": {
        "type": null,
        "description": "Generated 3D object with PBR materials."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      },
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object assets zip."
      },
      "model_glb": {
        "type": null,
        "description": "Generated 3D object."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/lite/image-to-video",
    "title": "Seedance 1.0 Lite",
    "category": "image-to-video",
    "description": "Seedance 1.0 Lite",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/lite/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/lite/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16",
          "auto"
        ],
        "default": "auto"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image used to generate video",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/f_xmiodPjhiKjdBkFmTu1.png"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "end_image_url": {
        "type": "string",
        "description": "The URL of the image the video ends with. Defaults to None.",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/lite/text-to-video",
    "title": "Seedance 1.0 Lite",
    "category": "text-to-video",
    "description": "Seedance 1.0 Lite",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/lite/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedance/v1/lite/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the video",
        "required": true,
        "examples": [
          "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16",
          "9:21"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Video resolution - 480p for faster generation, 720p for higher quality",
        "required": false,
        "enum": [
          "480p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "duration": {
        "type": "string",
        "description": "Duration of the video in seconds",
        "required": false,
        "enum": [
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ],
        "default": "5"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "camera_fixed": {
        "type": "boolean",
        "description": "Whether to fix the camera position",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control video generation. Use -1 for random.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      },
      "video": {
        "type": null,
        "description": "Generated video file"
      }
    }
  },
  {
    "id": "fal-ai/recraft/vectorize",
    "title": "Recraft",
    "category": "image-to-image",
    "description": "Converts a given raster image to SVG format using Recraft model.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-v3.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/vectorize",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft/vectorize/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be vectorized. Must be in PNG, JPG or WEBP format, less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels, min dimension more than 256 pixels.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/man_wave.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The vectorized image."
      }
    }
  },
  {
    "id": "fal-ai/wan-trainer/t2v",
    "title": "Wan-2.1 LoRA Trainer",
    "category": "training",
    "description": "Train custom LoRAs for Wan-2.1 T2V 1.3B",
    "tags": [
      "lora",
      "training"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/ZQ0YvNuW1FVoX7wvAU5uE_0590d28948af442dbb20bd581085f8c3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of steps to train for.",
        "required": false,
        "minimum": 1,
        "maximum": 20000,
        "default": 400
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "The phrase that will trigger the model to generate an image.",
        "required": false,
        "default": ""
      },
      "learning_rate": {
        "type": "number",
        "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 1,
        "default": 0.0002
      },
      "auto_scale_input": {
        "type": "boolean",
        "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights."
      },
      "config_file": {
        "type": null,
        "description": "Configuration used for setting up the inference endpoints."
      }
    }
  },
  {
    "id": "fal-ai/wan-trainer/t2v-14b",
    "title": "Wan-2.1 LoRA Trainer",
    "category": "training",
    "description": "Train custom LoRAs for Wan-2.1 T2V 14B",
    "tags": [
      "lora",
      "training"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/BtZ-j-cWvM_WqOtQGdjLj_a10682239ded4738a4e23ffc2a4ddeb4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v-14b",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v-14b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of steps to train for.",
        "required": false,
        "minimum": 1,
        "maximum": 20000,
        "default": 400
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "The phrase that will trigger the model to generate an image.",
        "required": false,
        "default": ""
      },
      "learning_rate": {
        "type": "number",
        "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 1,
        "default": 0.0002
      },
      "auto_scale_input": {
        "type": "boolean",
        "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights."
      },
      "config_file": {
        "type": null,
        "description": "Configuration used for setting up the inference endpoints."
      }
    }
  },
  {
    "id": "fal-ai/wan-trainer/i2v-720p",
    "title": "Wan-2.1 LoRA Trainer",
    "category": "training",
    "description": "Train custom LoRAs for Wan-2.1 I2V 720P",
    "tags": [
      "lora",
      "training"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/R1H5KbqWR_DIyysIpr271_e73fd3a6acde48209bc152f277959385.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/i2v-720p",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/i2v-720p/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of steps to train for.",
        "required": false,
        "minimum": 1,
        "maximum": 20000,
        "default": 400
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "The phrase that will trigger the model to generate an image.",
        "required": false,
        "default": ""
      },
      "learning_rate": {
        "type": "number",
        "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 1,
        "default": 0.0002
      },
      "auto_scale_input": {
        "type": "boolean",
        "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights."
      },
      "config_file": {
        "type": null,
        "description": "Configuration used for setting up the inference endpoints."
      }
    }
  },
  {
    "id": "fal-ai/wan-trainer/flf2v-720p",
    "title": "Wan-2.1 LoRA Trainer",
    "category": "training",
    "description": "Train custom LoRAs for Wan-2.1 FLF2V 720P",
    "tags": [
      "lora",
      "training"
    ],
    "thumbnailUrl": "https://fal.media/files/elephant/GRWFeDBLFXvbTF9b0lmJf_e269b3bf7ba147d3b56b0ee7b6e36439.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/flf2v-720p",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/flf2v-720p/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of steps to train for.",
        "required": false,
        "minimum": 1,
        "maximum": 20000,
        "default": 400
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "The phrase that will trigger the model to generate an image.",
        "required": false,
        "default": ""
      },
      "learning_rate": {
        "type": "number",
        "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 1,
        "default": 0.0002
      },
      "auto_scale_input": {
        "type": "boolean",
        "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights."
      },
      "config_file": {
        "type": null,
        "description": "Configuration used for setting up the inference endpoints."
      }
    }
  },
  {
    "id": "fal-ai/bytedance/seedream/v3/text-to-image",
    "title": "Bytedance",
    "category": "text-to-image",
    "description": "Seedream 3.0 is a bilingual (Chinese and English) text-to-image model that excels at text-to-image generation.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bytedance/seedream/v3/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/bytedance/seedream/v3/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt used to generate the image",
        "required": true,
        "examples": [
          "Fisheye lens, the head of a cat, the image shows the effect that the facial features of the cat are distorted due to the shooting method."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "Use for finer control over the output image size. Will be used over aspect_ratio, if both are provided. Width and height must be between 512 and 2048.",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Controls how closely the output image aligns with the input prompt. Higher values mean stronger prompt correlation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2.5
      },
      "seed": {
        "type": "integer",
        "description": "Random seed to control the stochasticity of image generation.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/ffmpeg-api/extract-frame",
    "title": "Ffmpeg Api",
    "category": "image-to-image",
    "description": "ffmpeg endpoint for first, middle and last frame extraction from videos",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ffmpeg-api-compose.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/extract-frame",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/extract-frame/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL of the video file to use as the video track",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/monkey/R6D8anxtsyItZTyBB2ksC_qeoDDxmLSg8cuWasM54KY_output.mp4"
        ]
      },
      "frame_type": {
        "type": "string",
        "description": "Type of frame to extract: first, middle, or last frame of the video",
        "required": false,
        "enum": [
          "first",
          "middle",
          "last"
        ],
        "default": "first"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/ffmpeg-api/merge-audio-video",
    "title": "Ffmpeg Api Merge Audio-Video",
    "category": "video-to-video",
    "description": "Merge videos with standalone audio files or audio from video files.",
    "tags": [
      "ffmpeg"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/merge-audio-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/merge-audio-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL of the video file to use as the video track",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ffmpeg-video.mp4"
        ]
      },
      "start_offset": {
        "type": "number",
        "description": "Offset in seconds for when the audio should start relative to the video",
        "required": false,
        "minimum": 0,
        "default": 0
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to use as the audio track",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ffmpeg-audio.wav"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "Output video with merged audio."
      }
    }
  },
  {
    "id": "fal-ai/luma-photon/flash/modify",
    "title": "Luma Photon",
    "category": "image-to-image",
    "description": "Edit images from your prompts using Luma Photon. Photon is the most creative, personalizable, and intelligent visual models for creatives, bringing a step-function change in the cost of high-quality image generation.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-photon/flash/modify",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-photon/flash/modify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Instruction for modifying the image",
        "required": false,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "Make the image look like a painting"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the reframed image",
        "required": true,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "examples": [
          "16:9"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.",
        "required": true,
        "minimum": 0,
        "maximum": 1,
        "examples": [
          0.8
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to reframe",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/example_inputs_liuyifei.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/luma-photon/modify",
    "title": "Luma Photon",
    "category": "image-to-image",
    "description": "Edit images from your prompts using Luma Photon. Photon is the most creative, personalizable, and intelligent visual models for creatives, bringing a step-function change in the cost of high-quality image generation.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-photon/modify",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-photon/modify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Instruction for modifying the image",
        "required": false,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "Make the image look like a painting"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the reframed image",
        "required": true,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "examples": [
          "16:9"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.",
        "required": true,
        "minimum": 0,
        "maximum": 1,
        "examples": [
          0.8
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to reframe",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/example_inputs_liuyifei.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/image-editing/reframe",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "The reframe endpoint intelligently adjusts an image's aspect ratio while preserving the main subject's position, composition, pose, and perspective",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The desired aspect ratio for the reframed image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ],
        "default": "16:9",
        "examples": [
          "16:9"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the old or damaged photo to restore.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/7ekErKT--mhgKJ5kgtvU__image.webp"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-1-3b",
    "title": "Wan Vace 1 3b",
    "category": "video-to-video",
    "description": "Vace a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "video-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-1-3b",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-1-3b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. If provided, the model will use this video as a reference.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_video.mp4"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse."
        ]
      },
      "mask_image_url": {
        "type": "string",
        "description": "URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video. If provided mask video url will be ignored.",
        "required": false
      },
      "task": {
        "type": "string",
        "description": "Task type for the model.",
        "required": false,
        "enum": [
          "depth",
          "inpainting",
          "pose"
        ],
        "default": "depth"
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "ref_image_urls": {
        "type": "array",
        "description": "Urls to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/vace/src_ref_image_1.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames",
        "required": false,
        "minimum": 81,
        "maximum": 240,
        "default": 81
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p,580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "mask_video_url": {
        "type": "string",
        "description": "URL to the source mask file. If provided, the model will use this mask as a reference.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_mask.mp4"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/image-editing/baby-version",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform any person into their baby version, while preserving the original pose and expression with childlike features.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/baby-version",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/baby-version/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to transform into a baby version.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/penguin/hIPcTcSrtLMVXyedBUqIX_-pG58lHRIQ3_1iBmMlU_v_image.webp"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2-flash/reframe",
    "title": "Luma Ray 2 Flash Reframe",
    "category": "video-to-video",
    "description": "Adjust and enhance videos with Ray-2 Reframe. This advanced tool seamlessly reframes videos to your desired aspect ratio, intelligently inpainting missing regions to ensure realistic visuals and coherent motion, delivering exceptional quality and creative flexibility.",
    "tags": [
      "reframe",
      "outpaint",
      "flash"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Optional prompt for reframing",
        "required": false,
        "minLength": 1,
        "maxLength": 5000
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the reframed video",
        "required": true,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "examples": [
          "9:16"
        ]
      },
      "y_start": {
        "type": "integer",
        "description": "Start Y coordinate for reframing",
        "required": false
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to reframe",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
        ]
      },
      "x_end": {
        "type": "integer",
        "description": "End X coordinate for reframing",
        "required": false
      },
      "y_end": {
        "type": "integer",
        "description": "End Y coordinate for reframing",
        "required": false
      },
      "grid_position_y": {
        "type": "integer",
        "description": "Y position of the grid for reframing",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the first frame image for reframing",
        "required": false
      },
      "grid_position_x": {
        "type": "integer",
        "description": "X position of the grid for reframing",
        "required": false
      },
      "x_start": {
        "type": "integer",
        "description": "Start X coordinate for reframing",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the reframed video"
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2/reframe",
    "title": "Luma Ray 2 Reframe",
    "category": "video-to-video",
    "description": "Adjust and enhance videos with Ray-2 Reframe. This advanced tool seamlessly reframes videos to your desired aspect ratio, intelligently inpainting missing regions to ensure realistic visuals and coherent motion, delivering exceptional quality and creative flexibility.",
    "tags": [
      "reframe",
      "outpaint"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Optional prompt for reframing",
        "required": false,
        "minLength": 1,
        "maxLength": 5000
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the reframed video",
        "required": true,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "examples": [
          "9:16"
        ]
      },
      "y_start": {
        "type": "integer",
        "description": "Start Y coordinate for reframing",
        "required": false
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to reframe",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
        ]
      },
      "x_end": {
        "type": "integer",
        "description": "End X coordinate for reframing",
        "required": false
      },
      "y_end": {
        "type": "integer",
        "description": "End Y coordinate for reframing",
        "required": false
      },
      "grid_position_y": {
        "type": "integer",
        "description": "Y position of the grid for reframing",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the first frame image for reframing",
        "required": false
      },
      "grid_position_x": {
        "type": "integer",
        "description": "X position of the grid for reframing",
        "required": false
      },
      "x_start": {
        "type": "integer",
        "description": "Start X coordinate for reframing",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the reframed video"
      }
    }
  },
  {
    "id": "fal-ai/luma-photon/flash/reframe",
    "title": "Luma Photon Flash Reframe",
    "category": "image-to-image",
    "description": "This advanced tool intelligently expands your visuals, seamlessly blending new content to enhance creativity and adaptability, offering unmatched speed and quality for creators at a fraction of the cost.",
    "tags": [
      "flash",
      "reframe",
      "outpainting"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-photon/flash/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-photon/flash/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Optional prompt for reframing",
        "required": false,
        "minLength": 3,
        "maxLength": 5000
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the reframed image",
        "required": true,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "examples": [
          "16:9"
        ]
      },
      "y_start": {
        "type": "integer",
        "description": "Start Y coordinate for reframing",
        "required": false
      },
      "x_end": {
        "type": "integer",
        "description": "End X coordinate for reframing",
        "required": false
      },
      "y_end": {
        "type": "integer",
        "description": "End Y coordinate for reframing",
        "required": false
      },
      "grid_position_y": {
        "type": "integer",
        "description": "Y position of the grid for reframing",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to reframe",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/example_inputs_liuyifei.png"
        ]
      },
      "grid_position_x": {
        "type": "integer",
        "description": "X position of the grid for reframing",
        "required": false
      },
      "x_start": {
        "type": "integer",
        "description": "Start X coordinate for reframing",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/luma-photon/reframe",
    "title": "Luma Photon Reframe",
    "category": "image-to-image",
    "description": "Extend and reframe images with Luma Photon Reframe. This advanced tool intelligently expands your visuals, seamlessly blending new content to enhance creativity and adaptability, offering unmatched personalization and quality for creators at a fraction of the cost.",
    "tags": [
      "outpainting",
      "reframe"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-photon/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-photon/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Optional prompt for reframing",
        "required": false,
        "minLength": 3,
        "maxLength": 5000
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the reframed image",
        "required": true,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "examples": [
          "16:9"
        ]
      },
      "y_start": {
        "type": "integer",
        "description": "Start Y coordinate for reframing",
        "required": false
      },
      "x_end": {
        "type": "integer",
        "description": "End X coordinate for reframing",
        "required": false
      },
      "y_end": {
        "type": "integer",
        "description": "End Y coordinate for reframing",
        "required": false
      },
      "grid_position_y": {
        "type": "integer",
        "description": "Y position of the grid for reframing",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to reframe",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/example_inputs_liuyifei.png"
        ]
      },
      "grid_position_x": {
        "type": "integer",
        "description": "X position of the grid for reframing",
        "required": false
      },
      "x_start": {
        "type": "integer",
        "description": "Start X coordinate for reframing",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "resemble-ai/chatterboxhd/speech-to-speech",
    "title": "Chatterboxhd",
    "category": "speech-to-speech",
    "description": "Transform voices using Resemble AI's Chatterbox. Convert audio to new voices or your own samples, with expressive results and built-in perceptual watermarking.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/chatterbox.webp",
    "playgroundUrl": "https://fal.ai/models/resemble-ai/chatterboxhd/speech-to-speech",
    "documentationUrl": "https://fal.ai/models/resemble-ai/chatterboxhd/speech-to-speech/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "high_quality_audio": {
        "type": "boolean",
        "description": "If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz. ",
        "required": false,
        "default": false
      },
      "target_voice_audio_url": {
        "type": "string",
        "description": "URL to the audio file which represents the voice of the output audio. If provided, this will override the target_voice setting. If neither target_voice nor target_voice_audio_url are provided, the default target voice will be used.",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/tiger/0XODRhebRLiBdu8MqgZc5_tmpljqsylwu.wav"
        ]
      },
      "source_audio_url": {
        "type": "string",
        "description": "URL to the source audio file to be voice-converted.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/chatterbox-demo-samples/samples/duff_stewie.wav"
        ]
      },
      "target_voice": {
        "type": "string",
        "description": "The voice to use for the speech-to-speech request. If neither target_voice nor target_voice_audio_url are provided, a random target voice will be used.",
        "required": false,
        "enum": [
          "Aurora",
          "Blade",
          "Britney",
          "Carl",
          "Cliff",
          "Richard",
          "Rico",
          "Siobhan",
          "Vicky"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated voice-converted audio file."
      }
    }
  },
  {
    "id": "resemble-ai/chatterboxhd/text-to-speech",
    "title": "Chatterboxhd",
    "category": "text-to-speech",
    "description": "Generate expressive, natural speech with Resemble AI's Chatterbox. Features unique emotion control, instant voice cloning from short audio, and built-in watermarking.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/chatterbox.webp",
    "playgroundUrl": "https://fal.ai/models/resemble-ai/chatterboxhd/text-to-speech",
    "documentationUrl": "https://fal.ai/models/resemble-ai/chatterboxhd/text-to-speech/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text to synthesize into speech.",
        "required": false,
        "default": "My name is Maximus Decimus Meridius, commander of the Armies of the North, General of the Felix Legions and loyal servant to the true emperor, Marcus Aurelius. Father to a murdered son, husband to a murdered wife. And I will have my vengeance, in this life or the next."
      },
      "exaggeration": {
        "type": "number",
        "description": "Controls emotion exaggeration. Range typically 0.25 to 2.0.",
        "required": false,
        "minimum": 0.25,
        "maximum": 2,
        "default": 0.5
      },
      "high_quality_audio": {
        "type": "boolean",
        "description": "If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz. ",
        "required": false,
        "default": false
      },
      "voice": {
        "type": "string",
        "description": "The voice to use for the TTS request. If neither voice nor audio are provided, a random voice will be used.",
        "required": false,
        "enum": [
          "Aurora",
          "Blade",
          "Britney",
          "Carl",
          "Cliff",
          "Richard",
          "Rico",
          "Siobhan",
          "Vicky"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL to the audio sample to use as a voice prompt for zero-shot TTS voice cloning. Providing a audio sample will override the voice setting. If neither voice nor audio_url are provided, a random voice will be used.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/chatterbox-demo-samples/prompts/male_rickmorty.mp3",
          "https://storage.googleapis.com/chatterbox-demo-samples/prompts/male_old_movie.flac"
        ]
      },
      "temperature": {
        "type": "number",
        "description": "Controls the randomness of generation. Range typically 0.05 to 5.",
        "required": false,
        "minimum": 0.05,
        "maximum": 5,
        "default": 0.8
      },
      "seed": {
        "type": "integer",
        "description": "Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed.",
        "required": false,
        "minimum": 0,
        "default": 0
      },
      "cfg": {
        "type": "number",
        "description": "Classifier-free guidance scale (CFG) controls the conditioning factor. Range typically 0.2 to 1.0. For expressive or dramatic speech, try lower cfg values (e.g. ~0.3) and increase exaggeration to around 0.7 or higher. If the reference speaker has a fast speaking style, lowering cfg to around 0.3 can improve pacing.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/flux-1/schnell/redux",
    "title": "FLUX.1 [schnell] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 [schnell] Redux is a high-performance endpoint for the FLUX.1 [schnell] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/schnell/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/schnell/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/dev/redux",
    "title": "FLUX.1 [dev] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 [dev] Redux is a high-performance endpoint for the FLUX.1 [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/dev/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/dev/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/dev/image-to-image",
    "title": "FLUX.1 [dev]",
    "category": "image-to-image",
    "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text. It is suitable for personal and commercial use.\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/dev/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/dev/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/schnell",
    "title": "FLUX.1 [schnell]",
    "category": "text-to-image",
    "description": "Fastest inference in the world for the 12 billion parameter FLUX.1 [schnell] text-to-image model. ",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/schnell",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/schnell/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-1/dev",
    "title": "FLUX.1 [dev]",
    "category": "text-to-image",
    "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text. It is suitable for personal and commercial use.\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-1/dev",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-1/dev/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "regular"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/playai/inpaint/diffusion",
    "title": "PlayAI Inpaint",
    "category": "audio-to-audio",
    "description": "A novel way to perform audio editing, ensuring smooth transitions and consistent speaker characteristics for edits.",
    "tags": [
      "audio",
      "inpaint"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/playai-diffusion.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/playai/inpaint/diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/playai/inpaint/diffusion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Transcription of the input audio.",
        "required": true,
        "examples": [
          "The answer is out there Neo. It's looking for you."
        ]
      },
      "response_format": {
        "type": "string",
        "description": "The format of the response.",
        "required": false,
        "enum": [
          "url",
          "bytes"
        ],
        "default": "url"
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/playai/matrix_neo.mp3"
        ]
      },
      "chunks": {
        "type": "array",
        "description": "Word timestamps for the input audio. Each word is represented by an object containing the word text and its start/end timestamps. You can generate these timestamps using an ASR (Automatic Speech Recognition) on https://fal.ai/models/fal-ai/whisper.",
        "required": true,
        "examples": [
          [
            {
              "text": "The",
              "timestamp": [
                0,
                0.12
              ]
            },
            {
              "text": "answer",
              "timestamp": [
                0.12,
                0.44
              ]
            },
            {
              "text": "is",
              "timestamp": [
                0.44,
                0.66
              ]
            },
            {
              "text": "out",
              "timestamp": [
                0.66,
                0.9
              ]
            },
            {
              "text": "there",
              "timestamp": [
                0.9,
                1.12
              ]
            },
            {
              "text": "Neo.",
              "timestamp": [
                1.12,
                1.7
              ]
            },
            {
              "text": "It's",
              "timestamp": [
                1.7,
                3.38
              ]
            },
            {
              "text": "looking",
              "timestamp": [
                3.38,
                3.6
              ]
            },
            {
              "text": "for",
              "timestamp": [
                3.6,
                3.88
              ]
            },
            {
              "text": "you.",
              "timestamp": [
                3.88,
                4.22
              ]
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/WordTime"
        }
      },
      "output_text": {
        "type": "string",
        "description": "Desired audio text. This is the text that will be spoken in the output audio. The model will find the difference between the input and output text and inpaint the audio accordingly.",
        "required": true,
        "examples": [
          "The answer is out there Morpheus. It's looking for you."
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/image-editing/text-removal",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Remove all text and writing from images while preserving the background and natural appearance.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/text-removal",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/text-removal/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image containing text to be removed.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/photo-restoration",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Restore and enhance old or damaged photos by removing imperfections, adding color while preserving the original character and details of the image.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/photo-restoration",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/photo-restoration/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the old or damaged photo to restore.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/ProUb4C1PYWpyGe7BXd0n_d575ba7693584c0ddf733f77dcdb8963.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/chatterbox/speech-to-speech",
    "title": "Chatterbox",
    "category": "speech-to-speech",
    "description": "Whether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. Use the first tts from resemble ai.",
    "tags": [
      "speech-to-speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/chatterbox.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/chatterbox/speech-to-speech",
    "documentationUrl": "https://fal.ai/models/fal-ai/chatterbox/speech-to-speech/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "source_audio_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/chatterbox-demo-samples/samples/duff_stewie.wav"
        ]
      },
      "target_voice_audio_url": {
        "type": "string",
        "description": "Optional URL to an audio file to use as a reference for the generated speech. If provided, the model will try to match the style and tone of the reference audio.",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/tiger/0XODRhebRLiBdu8MqgZc5_tmpljqsylwu.wav"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated speech audio"
      }
    }
  },
  {
    "id": "fal-ai/chatterbox/text-to-speech",
    "title": "Chatterbox",
    "category": "text-to-speech",
    "description": "Whether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. Use the first tts from resemble ai.",
    "tags": [
      "text-to-speech"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/FzzCnGuQNXLOEYuQq8CE8_7afb3290e0de46d5a7e4d13495938e3f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/chatterbox/text-to-speech",
    "documentationUrl": "https://fal.ai/models/fal-ai/chatterbox/text-to-speech/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>",
        "required": true,
        "examples": [
          "I just found a hidden treasure in the backyard! Check it out!"
        ]
      },
      "exaggeration": {
        "type": "number",
        "description": "Exaggeration factor for the generated speech (0.0 = no exaggeration, 1.0 = maximum exaggeration).",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.25
      },
      "audio_url": {
        "type": "string",
        "description": "Optional URL to an audio file to use as a reference for the generated speech. If provided, the model will try to match the style and tone of the reference audio.",
        "required": false,
        "default": "https://storage.googleapis.com/chatterbox-demo-samples/prompts/male_rickmorty.mp3"
      },
      "seed": {
        "type": "integer",
        "description": "Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed..",
        "required": false
      },
      "temperature": {
        "type": "number",
        "description": "Temperature for generation (higher = more creative).",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 0.7
      },
      "cfg": {
        "type": "number",
        "description": "",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {}
  },
  {
    "id": "fal-ai/image-editing/weather-effect",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Add realistic weather effects like snowfall, rain, or fog to your photos while maintaining the scene's mood.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/weather-effect",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/weather-effect/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The weather effect to apply.",
        "required": false,
        "default": "heavy snowfall",
        "examples": [
          "heavy snowfall"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/time-of-day",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform your photos to any time of day, from golden hour to midnight, with appropriate lighting and atmosphere.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/time-of-day",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/time-of-day/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The time of day to transform the scene to.",
        "required": false,
        "default": "golden hour",
        "examples": [
          "golden hour"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/style-transfer",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform your photos into artistic masterpieces inspired by famous styles like Van Gogh's Starry Night or any artistic style you choose.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/style-transfer",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/style-transfer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The artistic style to apply.",
        "required": false,
        "default": "Van Gogh's Starry Night",
        "examples": [
          "Van Gogh's Starry Night"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/scene-composition",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Place your subject in any scene you imagine, from enchanted forests to urban settings, with professional composition and lighting",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/scene-composition",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/scene-composition/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Describe the scene where you want to place the subject.",
        "required": false,
        "default": "enchanted forest",
        "examples": [
          "enchanted forest"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/professional-photo",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Turn your casual photos into stunning professional studio portraits with perfect lighting and high-end photography style.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/professional-photo",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/professional-photo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/object-removal",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Remove unwanted objects or people from your photos while seamlessly blending the background.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/object-removal",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/object-removal/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Specify which objects to remove from the image.",
        "required": false,
        "default": "background people",
        "examples": [
          "background people"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/hair-change",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Experiment with different hairstyles, from bald to any style you can imagine, while maintaining natural lighting and realistic results.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/hair-change",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/hair-change/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The desired hair style to apply.",
        "required": false,
        "default": "bald",
        "examples": [
          "bald"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/face-enhancement",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Enhance facial features with professional retouching while maintaining a natural, realistic look",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/face-enhancement",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/face-enhancement/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/expression-change",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Change facial expressions in photos to any emotion you desire, from smiles to serious looks.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/expression-change",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/expression-change/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The desired facial expression to apply.",
        "required": false,
        "default": "sad",
        "examples": [
          "sad"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/color-correction",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Perfect your photos with professional color grading, balanced tones, and vibrant yet natural colors",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/color-correction",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/color-correction/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/cartoonify",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Transform your photos into vibrant cool cartoons with bold outlines and rich colors.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/cartoonify",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/cartoonify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/background-change",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "Replace your photo's background with any scene you desire, from beach sunsets to urban landscapes, with perfect lighting and shadows",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/background-change",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/background-change/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The desired background to apply.",
        "required": false,
        "default": "beach sunset with palm trees",
        "examples": [
          "beach sunset with palm trees"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/image-editing/age-progression",
    "title": "Image Editing",
    "category": "image-to-image",
    "description": "See how you or others might look at different ages, from younger to older, while preserving core facial features.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-editing/age-progression",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-editing/age-progression/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The age change to apply.",
        "required": false,
        "default": "20 years older",
        "examples": [
          "20 years older"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/hAjCkcyly4gsS9-cptD3Y_image%20(20).png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/kontext/max/multi",
    "title": "FLUX.1 Kontext [max]",
    "category": "image-to-image",
    "description": "Experimental version of FLUX.1 Kontext [max] with multi image handling capabilities",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/koala/K-CKzmh6JmZz5D0L9ar6u_ad445c7c4de54d3fb05b5f72305ffff3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/max/multi",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/max/multi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Put the little duckling on top of the woman's t-shirt."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_urls": {
        "type": "array",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp",
            "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/kontext/multi",
    "title": "FLUX.1 Kontext [pro]",
    "category": "image-to-image",
    "description": "Experimental version of FLUX.1 Kontext [pro] with multi image handling capabilities",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/multi",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/multi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Put the little duckling on top of the woman's t-shirt."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_urls": {
        "type": "array",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          [
            "https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp",
            "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-avatar",
    "title": "Hunyuan Avatar",
    "category": "image-to-video",
    "description": "HunyuanAvatar is a High-Fidelity Audio-Driven Human Animation model for Multiple Characters .",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-avatar",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-avatar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text prompt describing the scene.",
        "required": false,
        "default": "A cat is singing."
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the reference image.",
        "required": true,
        "examples": [
          "https://fal.media/files/tiger/Y8EgvVqxORBCqWC1OlX3D_3c4c8bbe7f3941a2aea93e278ba14803.jpg",
          "https://v3.fal.media/files/zebra/HWILyw2UYI50Sp_4mDxqr_src2.png"
        ]
      },
      "turbo_mode": {
        "type": "boolean",
        "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
        "required": false,
        "default": true
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/80RpP2FOhXZUV3NRKUWZu_2.WAV"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 30,
        "maximum": 50,
        "default": 30
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.",
        "required": false,
        "minimum": 129,
        "maximum": 401,
        "default": 129
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with the avatar animation."
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/kontext/max",
    "title": "FLUX.1 Kontext [max]",
    "category": "image-to-image",
    "description": "FLUX.1 Kontext [max] is a model with greatly improved prompt adherence and typography generation meet premium consistency for editing without compromise on speed. \n ",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/tiger/9Ke6Di1rRqryqOR1SreQJ_33e684b4511644179b7429bb9c4cf592.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/max",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/max/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Put a donut next to the flour."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "Image prompt for the omni model.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/fal__toolkit__image__image__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/kontext/max/text-to-image",
    "title": "FLUX.1 Kontext [max]",
    "category": "text-to-image",
    "description": "FLUX.1 Kontext [max] text-to-image is a new premium model brings maximum performance across all aspects – greatly improved prompt adherence.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/max/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/max/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ],
        "default": "1:1"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/master/text-to-video",
    "title": "Kling 2.1 Master",
    "category": "text-to-video",
    "description": "Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier text-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/master/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/master/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Warm, earthy tones bathe the scene as the potter's hands, rough and calloused, coax a shapeless lump of clay into a vessel of elegant curves, the slow, deliberate movements highlighted by the subtle shifting light; the clay's cool, damp texture contrasts sharply with the warmth of the potter's touch, creating a captivating interplay between material and maker."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/pro/image-to-video",
    "title": "Kling 2.1 (pro)",
    "category": "image-to-video",
    "description": "Kling 2.1 Pro is an advanced endpoint for the Kling 2.1 model, offering professional-grade videos with enhanced visual fidelity, precise camera movements, and dynamic motion control, perfect for cinematic storytelling.\n\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v2.1/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Warm, incandescent streetlights paint the rain-slicked cobblestones in pools of amber light as a couple walks hand-in-hand, their silhouettes stark against the blurry backdrop of a city shrouded in a gentle downpour; the camera lingers on the subtle textures of their rain-soaked coats and the glistening reflections dancing on the wet pavement, creating a sense of intimate vulnerability and shared quietude."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "tail_image_url": {
        "type": "string",
        "description": "URL of the image to be used for the end of the video",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/lion/_I_io6Gtk83c72d-afXf8_image.webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/kontext/text-to-image",
    "title": "FLUX.1 Kontext [pro]",
    "category": "text-to-image",
    "description": "The FLUX.1 Kontext [pro] text-to-image delivers state-of-the-art image generation results with unprecedented prompt following, photorealistic rendering, and flawless typography.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/zebra/VOrzt92hNVLX9m9jB-7-4_deea28b6b45344d4aa4eb3be14b3478e.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/text-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/kontext/text-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "enum": [
          "21:9",
          "16:9",
          "4:3",
          "3:2",
          "1:1",
          "2:3",
          "3:4",
          "9:16",
          "9:21"
        ],
        "default": "1:1"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-kontext/dev",
    "title": "FLUX.1 Kontext [dev]",
    "category": "image-to-image",
    "description": "Frontier image editing model.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-kontext/dev",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-kontext/dev/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image.",
        "required": true,
        "examples": [
          "Change the setting to a day time, add a lot of people walking the sidewalk while maintaining the same style of the painting"
        ]
      },
      "resolution_mode": {
        "type": "string",
        "description": "\n             Determines how the output resolution is set for image editing.\n             - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.\n             - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).\n             Apart from these, a few aspect ratios are also supported.\n             ",
        "required": false,
        "enum": [
          "auto",
          "match_input",
          "1:1",
          "16:9",
          "21:9",
          "3:2",
          "2:3",
          "4:5",
          "5:4",
          "3:4",
          "4:3",
          "9:16",
          "9:21"
        ],
        "default": "match_input"
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "Output format",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to edit.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/kontext_example_input.webp"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 28
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 2.5
      },
      "seed": {
        "type": null,
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "veed/lipsync",
    "title": "Lipsync",
    "category": "video-to-video",
    "description": "Generate realistic lipsync from any audio using VEED's latest model",
    "tags": [
      "lipsync",
      "video-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/veed_logo.webp",
    "playgroundUrl": "https://fal.ai/models/veed/lipsync",
    "documentationUrl": "https://fal.ai/models/veed/lipsync/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/monkey/q1fDPhrpfjfsaRmbhTed4_influencer.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/rabbit/Ql3ade3wEKlZXRQLRbhxm_tts.mp3"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "veed/avatars/text-to-video",
    "title": "Avatars",
    "category": "text-to-video",
    "description": "Generate high-quality videos with UGC-like avatars from text",
    "tags": [
      "lipsync",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/veed_logo.webp",
    "playgroundUrl": "https://fal.ai/models/veed/avatars/text-to-video",
    "documentationUrl": "https://fal.ai/models/veed/avatars/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "\nEver wondered how to get that flawless glow? \nIntroducing our new skincare line, designed for real life. \nStep one: Cleanse with our gentle, nourishing formula. \nStep two: Apply our hydrating serum for that dewy look. \nStep three: Lock it in with our lightweight moisturizer. \nFeel the difference with every application. \nSee the glow? That's the magic of our skincare. \nUse code 'GLOW20' for an exclusive discount. \nJoin the skincare revolution today!\n"
        ]
      },
      "avatar_id": {
        "type": "string",
        "description": "The avatar to use for the video",
        "required": true,
        "enum": [
          "emily_vertical_primary",
          "emily_vertical_secondary",
          "marcus_vertical_primary",
          "marcus_vertical_secondary",
          "mira_vertical_primary",
          "mira_vertical_secondary",
          "jasmine_vertical_primary",
          "jasmine_vertical_secondary",
          "jasmine_vertical_walking",
          "aisha_vertical_walking",
          "elena_vertical_primary",
          "elena_vertical_secondary",
          "any_male_vertical_primary",
          "any_female_vertical_primary",
          "any_male_vertical_secondary",
          "any_female_vertical_secondary",
          "any_female_vertical_walking",
          "emily_primary",
          "emily_side",
          "marcus_primary",
          "marcus_side",
          "aisha_walking",
          "elena_primary",
          "elena_side",
          "any_male_primary",
          "any_female_primary",
          "any_male_side",
          "any_female_side"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "veed/avatars/audio-to-video",
    "title": "Avatars",
    "category": "audio-to-video",
    "description": "Generate high-quality videos with UGC-like avatars from audio",
    "tags": [
      "lipsync",
      "audio-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/veed_logo.webp",
    "playgroundUrl": "https://fal.ai/models/veed/avatars/audio-to-video",
    "documentationUrl": "https://fal.ai/models/veed/avatars/audio-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 2083,
        "examples": [
          "https://v3.fal.media/files/lion/OXiM5_Cve4kQ0ZcXmVzq4_product_presentation.mp3"
        ]
      },
      "avatar_id": {
        "type": "string",
        "description": "The avatar to use for the video",
        "required": true,
        "enum": [
          "emily_vertical_primary",
          "emily_vertical_secondary",
          "marcus_vertical_primary",
          "marcus_vertical_secondary",
          "mira_vertical_primary",
          "mira_vertical_secondary",
          "jasmine_vertical_primary",
          "jasmine_vertical_secondary",
          "jasmine_vertical_walking",
          "aisha_vertical_walking",
          "elena_vertical_primary",
          "elena_vertical_secondary",
          "any_male_vertical_primary",
          "any_female_vertical_primary",
          "any_male_vertical_secondary",
          "any_female_vertical_secondary",
          "any_female_vertical_walking",
          "emily_primary",
          "emily_side",
          "marcus_primary",
          "marcus_side",
          "aisha_walking",
          "elena_primary",
          "elena_side",
          "any_male_primary",
          "any_female_primary",
          "any_male_side",
          "any_female_side"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-portrait",
    "title": "Hunyuan Portrait",
    "category": "image-to-video",
    "description": "HunyuanPortrait is a diffusion-based framework for generating lifelike, temporally consistent portrait animations.",
    "tags": [
      "animation",
      "lip sync"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-4.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-portrait",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-portrait/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the driving video.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/2GQH1q-bJOamqCGWMtKvS_what_if.mp4"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation. If None, a random seed will be used.",
        "required": false
      },
      "use_arcface": {
        "type": "boolean",
        "description": "Whether to use ArcFace for face recognition.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the source image.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/GG7iU-4GmzkX3_gIXutRV_image.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with the portrait animation."
      }
    }
  },
  {
    "id": "fal-ai/wan-vace-14b",
    "title": "Wan VACE 14B",
    "category": "video-to-video",
    "description": "VACE is a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "image-to-video",
      "video-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace-14b",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace-14b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse."
        ]
      },
      "video_url": {
        "type": null,
        "description": "URL to the source video file. If provided, the model will use this video as a reference.",
        "required": false
      },
      "num_interpolated_frames": {
        "type": "integer",
        "description": "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "temporal_downsample_factor": {
        "type": "integer",
        "description": "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 0,
        "examples": [
          0
        ]
      },
      "first_frame_url": {
        "type": null,
        "description": "URL to the first frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      },
      "ref_image_urls": {
        "type": "array",
        "description": "URLs to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "items": {
          "type": "string"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 241 (inclusive).",
        "required": false,
        "minimum": 17,
        "maximum": 241,
        "default": 81
      },
      "auto_downsample_min_fps": {
        "type": "number",
        "description": "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 15,
        "examples": [
          15
        ]
      },
      "transparency_mode": {
        "type": "string",
        "description": "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
        "required": false,
        "enum": [
          "content_aware",
          "white",
          "black"
        ],
        "default": "content_aware",
        "examples": [
          "content_aware"
        ]
      },
      "sampler": {
        "type": "string",
        "description": "Sampler to use for video generation.",
        "required": false,
        "enum": [
          "unipc",
          "dpm++",
          "euler"
        ],
        "default": "unipc",
        "examples": [
          "unipc"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "video_quality": {
        "type": "string",
        "description": "The quality of the generated video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high",
          "maximum"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "mask_video_url": {
        "type": null,
        "description": "URL to the source mask file. If provided, the model will use this mask as a reference.",
        "required": false
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "interpolator_model": {
        "type": "string",
        "description": "The model to use for frame interpolation. Options are 'rife' or 'film'.",
        "required": false,
        "enum": [
          "rife",
          "film"
        ],
        "default": "film",
        "examples": [
          "film"
        ]
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 5
      },
      "enable_auto_downsample": {
        "type": "boolean",
        "description": "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "acceleration": {
        "type": null,
        "description": "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
        "required": false,
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "mask_image_url": {
        "type": null,
        "description": "URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video. If provided mask video url will be ignored.",
        "required": false
      },
      "task": {
        "type": "string",
        "description": "Task type for the model.",
        "required": false,
        "enum": [
          "depth",
          "pose",
          "inpainting",
          "outpainting",
          "reframe"
        ],
        "default": "depth"
      },
      "frames_per_second": {
        "type": null,
        "description": "Frames per second of the generated video. Must be between 5 to 30. Ignored if match_input_frames_per_second is true.",
        "required": false,
        "default": 16
      },
      "match_input_num_frames": {
        "type": "boolean",
        "description": "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "video_write_mode": {
        "type": "string",
        "description": "The write mode of the generated video.",
        "required": false,
        "enum": [
          "fast",
          "balanced",
          "small"
        ],
        "default": "balanced",
        "examples": [
          "balanced"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "240p",
          "360p",
          "480p",
          "580p",
          "720p"
        ],
        "default": "auto"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "auto"
      },
      "match_input_frames_per_second": {
        "type": "boolean",
        "description": "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30
      },
      "last_frame_url": {
        "type": null,
        "description": "URL to the last frame of the video. If provided, the model will use this frame as a reference.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/bagel/understand",
    "title": "Bagel",
    "category": "image-to-json",
    "description": "Bagel is a 7B parameter multimodal model from Bytedance-Seed that can generate both text and images.",
    "tags": [
      "image-to-text",
      "vlm"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bagel.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bagel/understand",
    "documentationUrl": "https://fal.ai/models/fal-ai/bagel/understand/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to query the image with.",
        "required": true,
        "examples": [
          "What is shown in the image? "
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for the generation.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The image for the query.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bagel/wRhCPSyiKTiLnnWvUpGIl.jpeg"
        ]
      }
    },
    "outputParameters": {
      "text": {
        "type": "string",
        "description": "The answer to the query."
      },
      "prompt": {
        "type": "string",
        "description": "The query used for the generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for the generation."
      },
      "timings": {
        "type": "object",
        "description": "The timings of the generation."
      }
    }
  },
  {
    "id": "fal-ai/bagel/edit",
    "title": "Bagel",
    "category": "image-to-image",
    "description": "Bagel is a 7B parameter multimodal model from Bytedance-Seed that can generate both images and text.",
    "tags": [
      "image-to-image",
      "image-editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bagel.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bagel/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/bagel/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image with.",
        "required": true,
        "examples": [
          "Change the cosmic cloud background of the floating temple to a clear blue sky with a gentle sunrise on the horizon. Keep all temple architecture, figures, and other elements exactly as they are."
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for the generation.",
        "required": false
      },
      "use_thought": {
        "type": "boolean",
        "description": "Whether to use thought tokens for generation. If set to true, the model will \"think\" to potentially improve generation quality. Increases generation time and increases the cost by 20%.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The image to edit.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bagel/wRhCPSyiKTiLnnWvUpGIl.jpeg"
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The edited images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/bagel",
    "title": "Bagel",
    "category": "text-to-image",
    "description": "Bagel is a 7B parameter from Bytedance-Seed multimodal model that can generate both text and images.",
    "tags": [
      "text-to-image",
      "multimodal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bagel.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bagel",
    "documentationUrl": "https://fal.ai/models/fal-ai/bagel/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A luminous ancient temple floating among cosmic clouds, with impossible architecture of twisted spires and inverted arches. The structure is half-built from crystalline white marble and half from living bioluminescent coral in vibrant teal and purple. Ethereal light filters through stained glass windows depicting mythological scenes. Tiny cloaked figures with glowing lanterns traverse impossible staircases. In the foreground, a massive ornate door stands slightly ajar, revealing a glimpse of swirling golden energy within. The scene is lit by two moons of different colors, casting overlapping shadows. Cinematic lighting, hyper-detailed textures, 8K resolution."
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for the generation.",
        "required": false
      },
      "use_thought": {
        "type": "boolean",
        "description": "Whether to use thought tokens for generation. If set to true, the model will \"think\" to potentially improve generation quality. Increases generation time and increases the cost by 20%.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/lyria2",
    "title": "Lyria2",
    "category": "text-to-audio",
    "description": "Lyria 2 is Google's latest music generation model, you can generate any type of music with this model.",
    "tags": [
      "music",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lyria2",
    "documentationUrl": "https://fal.ai/models/fal-ai/lyria2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the music you want to generate",
        "required": true,
        "minLength": 1,
        "maxLength": 2000,
        "examples": [
          "A lush, ambient soundscape featuring the serene sounds of a flowing river, complemented by the distant chirping of birds, and a gentle, melancholic piano melody that slowly unfolds."
        ]
      },
      "seed": {
        "type": "integer",
        "description": "A seed for deterministic generation. If provided, the model will attempt to produce the same audio given the same prompt and other parameters.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A description of what to exclude from the generated audio",
        "required": false,
        "default": "low quality",
        "examples": [
          "vocals, slow tempo",
          "low quality"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/imagen4/preview/ultra",
    "title": "Imagen 4 Ultra",
    "category": "text-to-image",
    "description": "Google’s highest quality image generation model",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imagen4/preview/ultra",
    "documentationUrl": "https://fal.ai/models/fal-ai/imagen4/preview/ultra/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing what you want to see",
        "required": true,
        "examples": [
          "This four-panel comic strip uses a charming, deliberately pixelated art style reminiscent of classic 8-bit video games, featuring simple shapes and a limited, bright color palette dominated by greens, blues, browns, and the dinosaur's iconic grey/black. The setting is a stylized pixel beach. Panel one shows the familiar Google Chrome T-Rex dinosaur, complete with its characteristic pixelated form, wearing tiny pixel sunglasses and lounging on a pixelated beach towel under a blocky yellow sun. Pixelated palm trees sway gently in the background against a blue pixel sky. A caption box with pixelated font reads, \"Even error messages need a vacation.\" Panel two is a close-up of the T-Rex attempting to build a pixel sandcastle. It awkwardly pats a mound of brown pixels with its tiny pixel arms, looking focused. Small pixelated shells dot the sand around it. Panel three depicts the T-Rex joyfully hopping over a series of pixelated cacti planted near the beach, mimicking its game obstacle avoidance. Small \"Boing! Boing!\" sound effect text appears in a blocky font above each jump. A pixelated crab watches from the side, waving its pixel claw. The final panel shows the T-Rex floating peacefully on its back in the blocky blue pixel water, sunglasses still on, with a contented expression. A small thought bubble above it contains pixelated \"Zzz...\" indicating relaxation."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "3:4",
          "4:3"
        ],
        "default": "1:1"
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-4)",
        "required": false,
        "minimum": 1,
        "maximum": 1,
        "default": 1
      },
      "resolution": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "1K",
          "2K"
        ],
        "default": "1K"
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A description of what to discourage in the generated images",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/elements",
    "title": "Kling 1.6 Elements",
    "category": "image-to-video",
    "description": "Generate video clips from your multiple image references using Kling 1.6 (standard)",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kling-1-6-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/elements",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/elements/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A cute girl and a baby cow sleeping together on a bed"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "input_image_urls": {
        "type": "array",
        "description": "List of image URLs to use for video generation. Supports up to 4 images.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/web-examples/kling-elements/first_image.jpeg",
            "https://storage.googleapis.com/falserverless/web-examples/kling-elements/second_image.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/elements",
    "title": "Kling 1.6 Elements",
    "category": "image-to-video",
    "description": "Generate video clips from your multiple image references using Kling 1.6 (pro)",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kling-1-6-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/elements",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/elements/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A cute girl and a baby cow sleeping together on a bed"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "input_image_urls": {
        "type": "array",
        "description": "List of image URLs to use for video generation. Supports up to 4 images.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/web-examples/kling-elements/first_image.jpeg",
            "https://storage.googleapis.com/falserverless/web-examples/kling-elements/second_image.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/dreamo",
    "title": "DreamO",
    "category": "text-to-image",
    "description": "DreamO is an image customization framework designed to support a wide range of tasks while facilitating seamless integration of multiple conditions.",
    "tags": [
      "stylized",
      "realism"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dreamo",
    "documentationUrl": "https://fal.ai/models/fal-ai/dreamo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Two people hugging inside a forest"
        ]
      },
      "first_image_url": {
        "type": "string",
        "description": "URL of first reference image to use for generation.",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/rabbit/I3exImt_zOYaiZv8caeGP_Pz4CnQ12tCUuDIhEQkmbD_ae4193792924495e89c516e6b492ed2b_1.jpg"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "second_image_url": {
        "type": "string",
        "description": "URL of second reference image to use for generation.",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/penguin/F3Yqprwlv-yaeusxAS0bS_image.webp"
        ]
      },
      "second_reference_task": {
        "type": "string",
        "description": "Task for second reference image (ip/id/style).",
        "required": false,
        "enum": [
          "ip",
          "id",
          "style"
        ],
        "default": "ip"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "first_reference_task": {
        "type": "string",
        "description": "Task for first reference image (ip/id/style).",
        "required": false,
        "enum": [
          "ip",
          "id",
          "style"
        ],
        "default": "ip"
      },
      "negative_prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": false,
        "default": "",
        "examples": [
          "bad quality, worst quality, text, signature, watermark, extra limbs"
        ]
      },
      "ref_resolution": {
        "type": "integer",
        "description": "Resolution for reference images.",
        "required": false,
        "minimum": 512,
        "maximum": 1024,
        "default": 512
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "true_cfg": {
        "type": "number",
        "description": "The weight of the CFG loss.",
        "required": false,
        "minimum": 1,
        "maximum": 5,
        "default": 1
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 12
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used to generate the image."
      },
      "images": {
        "type": "array",
        "description": "The URLs of the generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-distilled/extend",
    "title": "LTX Video-0.9.7 13B Distilled",
    "category": "video-to-video",
    "description": "Extend videos using LTX Video-0.9.7 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "video-to-video",
      "extend-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/extend",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/extend/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "Woman walking on a street in Tokyo"
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "video": {
        "type": null,
        "description": "Video to be extended.",
        "required": true,
        "examples": [
          {
            "video_url": "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4",
            "reverse_video": false,
            "start_frame_num": 24,
            "limit_num_frames": false,
            "resample_fps": false,
            "strength": 1,
            "target_fps": 30,
            "max_num_frames": 121,
            "conditioning_type": "rgb",
            "preprocess": false
          }
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 20,
        "maximum": 60,
        "default": 35,
        "examples": [
          35
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-distilled/multiconditioning",
    "title": "LTX Video-0.9.7 13B Distilled",
    "category": "video-to-video",
    "description": "Generate videos from prompts, images, and videos using LTX Video-0.9.7 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "video-to-video",
      "multicondition-to-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/multiconditioning",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/multiconditioning/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A vibrant, abstract composition featuring a person with outstretched arms, rendered in a kaleidoscope of colors against a deep, dark background. The figure is composed of intricate, swirling patterns reminiscent of a mosaic, with hues of orange, yellow, blue, and green that evoke the style of artists such as Wassily Kandinsky or Bridget Riley. The camera zooms into the face striking portrait of a man, reimagined through the lens of old-school video-game graphics. The subject's face is rendered in a kaleidoscope of colors, with bold blues and reds set against a vibrant yellow backdrop. His dark hair is pulled back, framing his profile in a dramatic pose."
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "images": {
        "type": "array",
        "description": "URL of images to use as conditioning",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "strength": 1,
              "start_frame_num": 0,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/NswO1P8sCLzrh1WefqQFK_9a6bdbfa54b944c9a770338159a113fd.jpg"
            },
            {
              "strength": 1,
              "start_frame_num": 120,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/YAPOGvmS2tM_Krdp7q6-d_267c97e017c34f679844a4477dfcec38.jpg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/ImageConditioningInput"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 20,
        "maximum": 60,
        "default": 35,
        "examples": [
          35
        ]
      },
      "videos": {
        "type": "array",
        "description": "Videos to use as conditioning",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/VideoConditioningInput"
        }
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-distilled/image-to-video",
    "title": "LTX Video-0.9.7 13B Distilled",
    "category": "image-to-video",
    "description": "Generate videos from prompts and images using LTX Video-0.9.7 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/N3sm2TCARXV47JxgfxZJt_8caf31dada5249d996b99fea8028fef8.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "The astronaut gets up and walks away"
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for Image-to-Video task",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ltxv-image-input.jpg"
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 20,
        "maximum": 60,
        "default": 35,
        "examples": [
          35
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-dev/multiconditioning",
    "title": "LTX Video-0.9.7 13B",
    "category": "video-to-video",
    "description": "Generate videos from prompts, images, and videos using LTX Video-0.9.7 13B and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "video-to-video",
      "multicondition-to-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/multiconditioning",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/multiconditioning/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 17,
        "examples": [
          17
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A vibrant, abstract composition featuring a person with outstretched arms, rendered in a kaleidoscope of colors against a deep, dark background. The figure is composed of intricate, swirling patterns reminiscent of a mosaic, with hues of orange, yellow, blue, and green that evoke the style of artists such as Wassily Kandinsky or Bridget Riley. The camera zooms into the face striking portrait of a man, reimagined through the lens of old-school video-game graphics. The subject's face is rendered in a kaleidoscope of colors, with bold blues and reds set against a vibrant yellow backdrop. His dark hair is pulled back, framing his profile in a dramatic pose."
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "images": {
        "type": "array",
        "description": "URL of images to use as conditioning",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "strength": 1,
              "start_frame_num": 0,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/NswO1P8sCLzrh1WefqQFK_9a6bdbfa54b944c9a770338159a113fd.jpg"
            },
            {
              "strength": 1,
              "start_frame_num": 88,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/YAPOGvmS2tM_Krdp7q6-d_267c97e017c34f679844a4477dfcec38.jpg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/ImageConditioningInput"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "videos": {
        "type": "array",
        "description": "Videos to use as conditioning",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/VideoConditioningInput"
        }
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 20,
        "maximum": 60,
        "default": 35,
        "examples": [
          35
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 3
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-dev/extend",
    "title": "LTX Video-0.9.7 13B",
    "category": "video-to-video",
    "description": "Extend videos using LTX Video-0.9.7 13B and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "video-to-video",
      "extend-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/extend",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/extend/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 17,
        "examples": [
          17
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "Woman walking on a street in Tokyo"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "video": {
        "type": null,
        "description": "Video to be extended.",
        "required": true,
        "examples": [
          {
            "video_url": "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4",
            "start_frame_num": 24,
            "reverse_video": false,
            "limit_num_frames": false,
            "resample_fps": false,
            "strength": 1,
            "target_fps": 30,
            "max_num_frames": 121,
            "conditioning_type": "rgb",
            "preprocess": false
          }
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 20,
        "maximum": 60,
        "default": 35,
        "examples": [
          35
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 3
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-dev/image-to-video",
    "title": "LTX Video-0.9.7 13B",
    "category": "image-to-video",
    "description": "Generate videos from prompts and images using LTX Video-0.9.7 13B and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 17,
        "examples": [
          17
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "The astronaut gets up and walks away"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Image URL for Image-to-Video task",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ltxv-image-input.jpg"
        ]
      },
      "constant_rate_factor": {
        "type": "integer",
        "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        "required": false,
        "minimum": 20,
        "maximum": 60,
        "default": 35,
        "examples": [
          35
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 3
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-dev",
    "title": "LTX Video-0.9.7 13B",
    "category": "text-to-video",
    "description": "Generate videos from prompts using LTX Video-0.9.7 13B and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-dev/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 17,
        "examples": [
          17
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A cinematic fast-tracking shot follows a vintage, teal camper van as it descends a winding mountain trail. The van, slightly weathered but well-maintained, is the central focus, its retro design emphasized by the motion blur. Medium shot reveals the dusty, ochre trail, edged with vibrant green pine trees. Close-up on the van's tires shows the gravel spraying, highlighting the speed and rugged terrain. Sunlight filters through the trees, casting dappled shadows on the van and the trail. The background is a hazy, majestic mountain range bathed in warm, golden light. The overall mood is adventurous and exhilarating. High resolution 4k movie scene."
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9, 1:1 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9"
        ],
        "default": "16:9",
        "examples": [
          "16:9"
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 3
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-distilled",
    "title": "LTX Video-0.9.7 13B Distilled",
    "category": "text-to-video",
    "description": "Generate videos from prompts using LTX Video-0.9.7 13B Distilled and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-13b-distilled/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "second_pass_skip_initial_steps": {
        "type": "integer",
        "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5,
        "examples": [
          5
        ]
      },
      "first_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the first pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A cinematic fast-tracking shot follows a vintage, teal camper van as it descends a winding mountain trail. The van, slightly weathered but well-maintained, is the central focus, its retro design emphasized by the motion blur. Medium shot reveals the dusty, ochre trail, edged with vibrant green pine trees. Close-up on the van's tires shows the gravel spraying, highlighting the speed and rugged terrain. Sunlight filters through the trees, casting dappled shadows on the van and the trail. The background is a hazy, majestic mountain range bathed in warm, golden light. The overall mood is adventurous and exhilarating. High resolution 4k movie scene."
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using a language model.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to use for generation",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 121,
        "examples": [
          121
        ]
      },
      "second_pass_num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps during the second pass.",
        "required": false,
        "minimum": 2,
        "maximum": 20,
        "default": 8,
        "examples": [
          8
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9, 1:1 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "1:1",
          "16:9"
        ],
        "default": "16:9",
        "examples": [
          "16:9"
        ]
      },
      "first_pass_skip_final_steps": {
        "type": "integer",
        "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "easel-ai/easel-gifswap",
    "title": "Easel Gifswap",
    "category": "image-to-image",
    "description": "Swap faces on GIFs",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/easel-ai-gifswap.webp",
    "playgroundUrl": "https://fal.ai/models/easel-ai/easel-gifswap",
    "documentationUrl": "https://fal.ai/models/easel-ai/easel-gifswap/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "gif_image": {
        "type": null,
        "description": "The GIF to apply face swap to. GIF size affects generation time.",
        "required": true,
        "examples": [
          "https://images.easelai.com/gif_fal/lo.gif",
          "https://images.easelai.com/gif_fal/an.gif",
          "https://images.easelai.com/gif_fal/ce.gif",
          "https://images.easelai.com/gif_fal/mc.gif",
          "https://images.easelai.com/gif_fal/ww.gif"
        ]
      },
      "face_image": {
        "type": null,
        "description": "The face image to swap onto the GIF",
        "required": true,
        "examples": [
          "https://images.easelai.com/gif_fal/selfie2.png",
          "https://images.easelai.com/gif_fal/selfie1.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated face-swapped GIF"
      }
    }
  },
  {
    "id": "fal-ai/flux-lora/stream",
    "title": "Flux Lora",
    "category": "text-to-image",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora/stream",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora/stream/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-lora/multiconditioning",
    "title": "LTX Video-0.9.7 LoRA",
    "category": "video-to-video",
    "description": "Generate videos from prompts, images, and videos using LTX Video-0.9.7 and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "video-to-video",
      "multicondition-to-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-lora/multiconditioning",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-lora/multiconditioning/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of inference steps to use.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A vibrant, abstract composition featuring a person with outstretched arms, rendered in a kaleidoscope of colors against a deep, dark background. The figure is composed of intricate, swirling patterns reminiscent of a mosaic, with hues of orange, yellow, blue, and green that evoke the style of artists such as Wassily Kandinsky or Bridget Riley. The camera zooms into the face striking portrait of a man, reimagined through the lens of old-school video-game graphics. The subject's face is rendered in a kaleidoscope of colors, with bold blues and reds set against a vibrant yellow backdrop. His dark hair is pulled back, framing his profile in a dramatic pose"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 25,
        "examples": [
          25
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using the LLM.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "number_of_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 89,
        "examples": [
          89
        ]
      },
      "loras": {
        "type": "array",
        "description": "The LoRA weights to use for generation.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "images": {
        "type": "array",
        "description": "The image conditions to use for generation.",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "strength": 1,
              "start_frame_number": 0,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/NswO1P8sCLzrh1WefqQFK_9a6bdbfa54b944c9a770338159a113fd.jpg"
            },
            {
              "strength": 1,
              "start_frame_number": 80,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/YAPOGvmS2tM_Krdp7q6-d_267c97e017c34f679844a4477dfcec38.jpg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/ImageCondition"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use.",
        "required": false,
        "default": "blurry, low quality, low resolution, inconsistent motion, jittery, distorted"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "16:9",
          "1:1",
          "9:16",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "videos": {
        "type": "array",
        "description": "The video conditions to use for generation.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/VideoCondition"
        }
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generation.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-lora/image-to-video",
    "title": "LTX Video-0.9.7 LoRA",
    "category": "image-to-video",
    "description": "Generate videos from prompts and images using LTX Video-0.9.7 and custom LoRA",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-lora/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-lora/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of inference steps to use.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30,
        "examples": [
          30
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p",
        "examples": [
          "720p"
        ]
      },
      "reverse_video": {
        "type": "boolean",
        "description": "Whether to reverse the video.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video.",
        "required": false,
        "enum": [
          "16:9",
          "1:1",
          "9:16",
          "auto"
        ],
        "default": "auto",
        "examples": [
          "auto"
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The frame rate of the video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 25,
        "examples": [
          25
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using the LLM.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "number_of_frames": {
        "type": "integer",
        "description": "The number of frames in the video.",
        "required": false,
        "minimum": 9,
        "maximum": 161,
        "default": 89,
        "examples": [
          89
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as input.",
        "required": true,
        "examples": [
          "https://h2.inkwai.com/bs2/upload-ylab-stunt/se/ai_portal_queue_mmu_image_upscale_aiweb/3214b798-e1b4-4b00-b7af-72b5b0417420_raw_image_0.jpg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "The LoRA weights to use for generation.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoRAWeight"
        }
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "The astronaut gets up and walks away"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generation.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use.",
        "required": false,
        "default": "blurry, low quality, low resolution, inconsistent motion, jittery, distorted"
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generation."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/transition",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Create seamless transition between images using PixVerse v4.5",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/transition",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/transition/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "first_image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/owQh2DAzk8UU7J02nr5RY_Co2P4boLv6meIZ5t9gKvL_8685da151df343ab8bf82165c928e2a5.jpg"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The prompt for the transition",
        "required": true,
        "examples": [
          "Scene slowly transition into cat swimming under water"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      },
      "last_image_url": {
        "type": "string",
        "description": "URL of the image to use as the last frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/RgedFs_WSnq5BgER7qDx1_ONrbTJ1YAGXz-9JnSsBoB_bdc8750387734bfe940319f469f7b0b2.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/image-to-video/fast",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Generate fast high quality video clips from text and image prompts using PixVerse v4.5",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/image-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/image-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A woman warrior with her hammer walking with his glacier wolf."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "camera_movement": {
        "type": "string",
        "description": "The type of camera movement to apply to the video",
        "required": false,
        "enum": [
          "horizontal_left",
          "horizontal_right",
          "vertical_up",
          "vertical_down",
          "zoom_in",
          "zoom_out",
          "crane_up",
          "quickly_zoom_in",
          "quickly_zoom_out",
          "smooth_zoom_in",
          "camera_rotation",
          "robo_arm",
          "super_dolly_out",
          "whip_pan",
          "hitchcock",
          "left_follow",
          "right_follow",
          "pan_left",
          "pan_right",
          "fix_bg"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/image-to-video",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4.5",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A woman warrior with her hammer walking with his glacier wolf."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "camera_movement": {
        "type": "string",
        "description": "The type of camera movement to apply to the video",
        "required": false,
        "enum": [
          "horizontal_left",
          "horizontal_right",
          "vertical_up",
          "vertical_down",
          "zoom_in",
          "zoom_out",
          "crane_up",
          "quickly_zoom_in",
          "quickly_zoom_out",
          "smooth_zoom_in",
          "camera_rotation",
          "robo_arm",
          "super_dolly_out",
          "whip_pan",
          "hitchcock",
          "left_follow",
          "right_follow",
          "pan_left",
          "pan_right",
          "fix_bg"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/text-to-video/fast",
    "title": "Pixverse",
    "category": "text-to-video",
    "description": "Generate high quality and fast video clips from text and image prompts using PixVerse v4.5 fast",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/text-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/text-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/text-to-video",
    "title": "Pixverse",
    "category": "text-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4.5",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/effects",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Generate high quality video clips with different effects using PixVerse v4.5",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4.5/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": ""
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video.",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "effect": {
        "type": "string",
        "description": "The effect to apply to the video",
        "required": true,
        "enum": [
          "Kiss Me AI",
          "Kiss",
          "Muscle Surge",
          "Warmth of Jesus",
          "Anything, Robot",
          "The Tiger Touch",
          "Hug",
          "Holy Wings",
          "Microwave",
          "Zombie Mode",
          "Squid Game",
          "Baby Face",
          "Black Myth: Wukong",
          "Long Hair Magic",
          "Leggy Run",
          "Fin-tastic Mermaid",
          "Punch Face",
          "Creepy Devil Smile",
          "Thunder God",
          "Eye Zoom Challenge",
          "Who's Arrested?",
          "Baby Arrived",
          "Werewolf Rage",
          "Bald Swipe",
          "BOOM DROP",
          "Huge Cutie",
          "Liquid Metal",
          "Sharksnap!",
          "Dust Me Away",
          "3D Figurine Factor",
          "Bikini Up",
          "My Girlfriends",
          "My Boyfriends",
          "Subject 3 Fever",
          "Earth Zoom",
          "Pole Dance",
          "Vroom Dance",
          "GhostFace Terror",
          "Dragon Evoker",
          "Skeletal Bae",
          "Summoning succubus",
          "Halloween Voodoo Doll",
          "3D Naked-Eye AD",
          "Package Explosion",
          "Dishes Served",
          "Ocean ad",
          "Supermarket AD"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-custom",
    "title": "Hunyuan Custom",
    "category": "image-to-video",
    "description": "HunyuanCustom revolutionizes video generation with unmatched identity consistency across multiple input types. Its innovative fusion modules and alignment networks outperform competitors, maintaining subject integrity while responding flexibly to text, image, audio, and video conditions.",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-custom",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-custom/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation (max 500 characters).",
        "required": true,
        "examples": [
          "Realistic, High-quality. A woman is playing a violin."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
        "required": false,
        "enum": [
          "512p",
          "720p"
        ],
        "default": "512p"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 81,
        "maximum": 129,
        "default": 129
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/hidream/woman.png"
        ]
      },
      "fps": {
        "type": "integer",
        "description": "The frames per second of the generated video.",
        "required": false,
        "minimum": 16,
        "maximum": 30,
        "default": 25
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to run. Lower gets faster results, higher gets better results.",
        "required": false,
        "minimum": 10,
        "maximum": 30,
        "default": 30
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion, blurring, text, subtitles, static, picture, black border.",
        "examples": [
          "Ugly, blurry."
        ]
      },
      "cfg_scale": {
        "type": "number",
        "description": "Classifier-Free Guidance scale for the generation.",
        "required": false,
        "minimum": 1.5,
        "maximum": 13,
        "default": 7.5
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/framepack/f1",
    "title": "Framepack F1",
    "category": "image-to-video",
    "description": "Framepack is an efficient Image-to-video model that autoregressively generates videos.",
    "tags": [
      "image to video",
      "motion"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/dUfFd9Z7aSX06gL2_qXn0_image.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/framepack/f1",
    "documentationUrl": "https://fal.ai/models/fal-ai/framepack/f1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation (max 500 characters).",
        "required": true,
        "examples": [
          "A mesmerising video of a deep sea jellyfish moving through an inky-black ocean. The jellyfish glows softly with an amber bioluminescence. The overall scene is lifelike."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
        "required": false,
        "enum": [
          "720p",
          "480p"
        ],
        "default": "480p"
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 30,
        "maximum": 900,
        "default": 180
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/framepack/framepack.jpg"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 32,
        "default": 10
      },
      "seed": {
        "type": null,
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "",
        "examples": [
          "Ugly, blurry distorted, bad quality"
        ]
      },
      "cfg_scale": {
        "type": "number",
        "description": "Classifier-Free Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 7,
        "default": 1
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/ace-step/audio-outpaint",
    "title": "ACE-Step",
    "category": "audio-to-audio",
    "description": "Extend the beginning or end of provided audio with lyrics and/or style using ACE-Step",
    "tags": [
      "audio-to-audio",
      "audio-outpaint",
      "audio-extend"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ace-step/audio-outpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/ace-step/audio-outpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "Number of steps to generate the audio.",
        "required": false,
        "minimum": 3,
        "maximum": 60,
        "default": 27,
        "examples": [
          27
        ]
      },
      "tags": {
        "type": "string",
        "description": "Comma-separated list of genre tags to control the style of the generated audio.",
        "required": true,
        "examples": [
          "lofi, hiphop, drum and bass, trap, chill"
        ]
      },
      "minimum_guidance_scale": {
        "type": "number",
        "description": "Minimum guidance scale for the generation after the decay.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 3,
        "examples": [
          3
        ]
      },
      "extend_after_duration": {
        "type": "number",
        "description": "Duration in seconds to extend the audio from the end.",
        "required": false,
        "minimum": 0,
        "maximum": 240,
        "default": 30,
        "examples": [
          30
        ]
      },
      "lyrics": {
        "type": "string",
        "description": "Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.",
        "required": false,
        "default": ""
      },
      "tag_guidance_scale": {
        "type": "number",
        "description": "Tag guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler to use for the generation process.",
        "required": false,
        "enum": [
          "euler",
          "heun"
        ],
        "default": "euler",
        "examples": [
          "euler"
        ]
      },
      "extend_before_duration": {
        "type": "number",
        "description": "Duration in seconds to extend the audio from the start.",
        "required": false,
        "minimum": 0,
        "maximum": 240,
        "default": 0,
        "examples": [
          0
        ]
      },
      "guidance_type": {
        "type": "string",
        "description": "Type of CFG to use for the generation process.",
        "required": false,
        "enum": [
          "cfg",
          "apg",
          "cfg_star"
        ],
        "default": "apg",
        "examples": [
          "apg"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 15,
        "examples": [
          15
        ]
      },
      "lyric_guidance_scale": {
        "type": "number",
        "description": "Lyric guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 1.5,
        "examples": [
          1.5
        ]
      },
      "guidance_interval": {
        "type": "number",
        "description": "Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "guidance_interval_decay": {
        "type": "number",
        "description": "Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to be outpainted.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ace-step-audio-to-audio.wav"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If not provided, a random seed will be used.",
        "required": false
      },
      "granularity_scale": {
        "type": "integer",
        "description": "Granularity scale for the generation process. Higher values can reduce artifacts.",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 10,
        "examples": [
          10
        ]
      }
    },
    "outputParameters": {
      "tags": {
        "type": "string",
        "description": "The genre tags used in the generation process."
      },
      "lyrics": {
        "type": "string",
        "description": "The lyrics used in the generation process."
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/ace-step/audio-inpaint",
    "title": "ACE-Step",
    "category": "audio-to-audio",
    "description": "Modify a portion of provided audio with lyrics and/or style using ACE-Step",
    "tags": [
      "audio-to-audio",
      "audio-inpaint",
      "audio-repaint"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ace-step/audio-inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/ace-step/audio-inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "Number of steps to generate the audio.",
        "required": false,
        "minimum": 3,
        "maximum": 60,
        "default": 27,
        "examples": [
          27
        ]
      },
      "start_time": {
        "type": "number",
        "description": "start time in seconds for the inpainting process.",
        "required": false,
        "minimum": 0,
        "maximum": 240,
        "default": 0,
        "examples": [
          0
        ]
      },
      "tags": {
        "type": "string",
        "description": "Comma-separated list of genre tags to control the style of the generated audio.",
        "required": true,
        "examples": [
          "lofi, hiphop, drum and bass, trap, chill"
        ]
      },
      "minimum_guidance_scale": {
        "type": "number",
        "description": "Minimum guidance scale for the generation after the decay.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 3,
        "examples": [
          3
        ]
      },
      "lyrics": {
        "type": "string",
        "description": "Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.",
        "required": false,
        "default": ""
      },
      "end_time_relative_to": {
        "type": "string",
        "description": "Whether the end time is relative to the start or end of the audio.",
        "required": false,
        "enum": [
          "start",
          "end"
        ],
        "default": "start",
        "examples": [
          "start"
        ]
      },
      "tag_guidance_scale": {
        "type": "number",
        "description": "Tag guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler to use for the generation process.",
        "required": false,
        "enum": [
          "euler",
          "heun"
        ],
        "default": "euler",
        "examples": [
          "euler"
        ]
      },
      "end_time": {
        "type": "number",
        "description": "end time in seconds for the inpainting process.",
        "required": false,
        "minimum": 0,
        "maximum": 240,
        "default": 30,
        "examples": [
          30
        ]
      },
      "guidance_type": {
        "type": "string",
        "description": "Type of CFG to use for the generation process.",
        "required": false,
        "enum": [
          "cfg",
          "apg",
          "cfg_star"
        ],
        "default": "apg",
        "examples": [
          "apg"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 15,
        "examples": [
          15
        ]
      },
      "lyric_guidance_scale": {
        "type": "number",
        "description": "Lyric guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 1.5,
        "examples": [
          1.5
        ]
      },
      "guidance_interval": {
        "type": "number",
        "description": "Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "variance": {
        "type": "number",
        "description": "Variance for the inpainting process. Higher values can lead to more diverse results.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "guidance_interval_decay": {
        "type": "number",
        "description": "Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "start_time_relative_to": {
        "type": "string",
        "description": "Whether the start time is relative to the start or end of the audio.",
        "required": false,
        "enum": [
          "start",
          "end"
        ],
        "default": "start",
        "examples": [
          "start"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to be inpainted.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ace-step-audio-to-audio.wav"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If not provided, a random seed will be used.",
        "required": false
      },
      "granularity_scale": {
        "type": "integer",
        "description": "Granularity scale for the generation process. Higher values can reduce artifacts.",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 10,
        "examples": [
          10
        ]
      }
    },
    "outputParameters": {
      "tags": {
        "type": "string",
        "description": "The genre tags used in the generation process."
      },
      "lyrics": {
        "type": "string",
        "description": "The lyrics used in the generation process."
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/ace-step/audio-to-audio",
    "title": "ACE-Step",
    "category": "audio-to-audio",
    "description": "Generate music from a lyrics and example audio using ACE-Step",
    "tags": [
      "audio-to-audio",
      "audio-edit"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/S5IFY0O4oGvrMRRKtdEVQ_1f8a744311ee4074bf2da4d84ae4491a.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ace-step/audio-to-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/ace-step/audio-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "Number of steps to generate the audio.",
        "required": false,
        "minimum": 3,
        "maximum": 60,
        "default": 27,
        "examples": [
          27
        ]
      },
      "tags": {
        "type": "string",
        "description": "Comma-separated list of genre tags to control the style of the generated audio.",
        "required": true,
        "examples": [
          "lofi, hiphop, drum and bass, trap, chill"
        ]
      },
      "minimum_guidance_scale": {
        "type": "number",
        "description": "Minimum guidance scale for the generation after the decay.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 3,
        "examples": [
          3
        ]
      },
      "lyrics": {
        "type": "string",
        "description": "Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.",
        "required": false,
        "default": ""
      },
      "tag_guidance_scale": {
        "type": "number",
        "description": "Tag guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "original_lyrics": {
        "type": "string",
        "description": "Original lyrics of the audio file.",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler to use for the generation process.",
        "required": false,
        "enum": [
          "euler",
          "heun"
        ],
        "default": "euler",
        "examples": [
          "euler"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_type": {
        "type": "string",
        "description": "Type of CFG to use for the generation process.",
        "required": false,
        "enum": [
          "cfg",
          "apg",
          "cfg_star"
        ],
        "default": "apg",
        "examples": [
          "apg"
        ]
      },
      "lyric_guidance_scale": {
        "type": "number",
        "description": "Lyric guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 1.5,
        "examples": [
          1.5
        ]
      },
      "guidance_interval": {
        "type": "number",
        "description": "Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "edit_mode": {
        "type": "string",
        "description": "Whether to edit the lyrics only or remix the audio.",
        "required": false,
        "enum": [
          "lyrics",
          "remix"
        ],
        "default": "remix",
        "examples": [
          "remix"
        ]
      },
      "guidance_interval_decay": {
        "type": "number",
        "description": "Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to be outpainted.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/ace-step-audio-to-audio.wav"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If not provided, a random seed will be used.",
        "required": false
      },
      "granularity_scale": {
        "type": "integer",
        "description": "Granularity scale for the generation process. Higher values can reduce artifacts.",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 10,
        "examples": [
          10
        ]
      },
      "original_tags": {
        "type": "string",
        "description": "Original tags of the audio file.",
        "required": true,
        "examples": [
          "lofi, hiphop, drum and bass, trap, chill"
        ]
      },
      "original_seed": {
        "type": "integer",
        "description": "Original seed of the audio file.",
        "required": false
      }
    },
    "outputParameters": {
      "tags": {
        "type": "string",
        "description": "The genre tags used in the generation process."
      },
      "lyrics": {
        "type": "string",
        "description": "The lyrics used in the generation process."
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/ace-step/prompt-to-audio",
    "title": "ACE-Step",
    "category": "text-to-audio",
    "description": "Generate music from a simple prompt using ACE-Step",
    "tags": [
      "text-to-audio",
      "text-to-music"
    ],
    "thumbnailUrl": "https://fal.media/files/penguin/sDFuolUwHioUzK2nutylA_54068c7ff03449dca0fc1e4523ed56c1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ace-step/prompt-to-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/ace-step/prompt-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "Number of steps to generate the audio.",
        "required": false,
        "minimum": 3,
        "maximum": 60,
        "default": 27,
        "examples": [
          27
        ]
      },
      "duration": {
        "type": "number",
        "description": "The duration of the generated audio in seconds.",
        "required": false,
        "minimum": 5,
        "maximum": 240,
        "default": 60
      },
      "prompt": {
        "type": "string",
        "description": "Prompt to control the style of the generated audio. This will be used to generate tags and lyrics.",
        "required": true,
        "examples": [
          "A lofi hiphop song with a chill vibe about a sunny day on the boardwalk."
        ]
      },
      "minimum_guidance_scale": {
        "type": "number",
        "description": "Minimum guidance scale for the generation after the decay.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 3,
        "examples": [
          3
        ]
      },
      "tag_guidance_scale": {
        "type": "number",
        "description": "Tag guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler to use for the generation process.",
        "required": false,
        "enum": [
          "euler",
          "heun"
        ],
        "default": "euler",
        "examples": [
          "euler"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_type": {
        "type": "string",
        "description": "Type of CFG to use for the generation process.",
        "required": false,
        "enum": [
          "cfg",
          "apg",
          "cfg_star"
        ],
        "default": "apg",
        "examples": [
          "apg"
        ]
      },
      "instrumental": {
        "type": "boolean",
        "description": "Whether to generate an instrumental version of the audio.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "lyric_guidance_scale": {
        "type": "number",
        "description": "Lyric guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 1.5,
        "examples": [
          1.5
        ]
      },
      "guidance_interval": {
        "type": "number",
        "description": "Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "guidance_interval_decay": {
        "type": "number",
        "description": "Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If not provided, a random seed will be used.",
        "required": false
      },
      "granularity_scale": {
        "type": "integer",
        "description": "Granularity scale for the generation process. Higher values can reduce artifacts.",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 10,
        "examples": [
          10
        ]
      }
    },
    "outputParameters": {
      "tags": {
        "type": "string",
        "description": "The genre tags used in the generation process."
      },
      "lyrics": {
        "type": "string",
        "description": "The lyrics used in the generation process."
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "smoretalk-ai/rembg-enhance",
    "title": "Rembg Enhance (Remove Background Enhance)",
    "category": "image-to-image",
    "description": "Rembg-enhance is optimized for 2D vector images, 3D graphics, and photos by leveraging matting technology.",
    "tags": [
      "background removal",
      "image editing",
      "utility",
      "segmentation",
      "high resolution",
      "rembg"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/tiger/k7u2IikPi0ubraTdzzOYz_smoretalk-ai-rembg-enhance-thumbnail.png",
    "playgroundUrl": "https://fal.ai/models/smoretalk-ai/rembg-enhance",
    "documentationUrl": "https://fal.ai/models/smoretalk-ai/rembg-enhance/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the input image",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/SOF3bLF7b1kJ2-N9dTg-c.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The segmented output image"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q1/start-end-to-video",
    "title": "Vidu Start End to Video",
    "category": "image-to-video",
    "description": "Vidu Q1 Start-End to Video generates smooth transition 1080p videos between specified start and end images.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q1/start-end-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q1/start-end-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "Dragon lands on a rock"
        ]
      },
      "start_image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/sgsdKvPigPhJ1S7Hl5bWc_first_frame_q1.png"
        ]
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      },
      "seed": {
        "type": "integer",
        "description": "Seed for the random number generator",
        "required": false
      },
      "end_image_url": {
        "type": "string",
        "description": "URL of the image to use as the last frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/CASBu_OmOnZ8IafirarFL_last_frame_q1.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated transition video between start and end frames using the Q1 model"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q1/text-to-video",
    "title": "Vidu Text to Video",
    "category": "text-to-video",
    "description": "Vidu Q1 Text to Video generates high-quality 1080p videos with exceptional visual quality and motion diversity",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q1/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q1/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "In an ultra-realistic fashion photography style featuring light blue and pale amber tones, an astronaut in a spacesuit walks through the fog. The background consists of enchanting white and golden lights, creating a minimalist still life and an impressive panoramic scene."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "style": {
        "type": "string",
        "description": "The style of output video",
        "required": false,
        "enum": [
          "general",
          "anime"
        ],
        "default": "general"
      },
      "seed": {
        "type": "integer",
        "description": "Seed for the random number generator",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video using the Q1 model"
      }
    }
  },
  {
    "id": "fal-ai/vidu/q1/image-to-video",
    "title": "Vidu Image to Video",
    "category": "image-to-video",
    "description": "Vidu Q1 Image to Video generates high-quality 1080p videos with exceptional visual quality and motion diversity from a single image",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/q1/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/q1/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "The astronaut waved and the camera moved up."
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Seed for the random number generator",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/vidu_i2v.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video using the Q1 model from a single image"
      }
    }
  },
  {
    "id": "fal-ai/ace-step",
    "title": "ACE-Step",
    "category": "text-to-audio",
    "description": "Generate music with lyrics from text using ACE-Step",
    "tags": [
      "text-to-audio",
      "text-to-music"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/4CEYTltj2fq6tpXQZnf_g_8b2d4b72d8d84fbaa42970dadacf1379.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ace-step",
    "documentationUrl": "https://fal.ai/models/fal-ai/ace-step/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "Number of steps to generate the audio.",
        "required": false,
        "minimum": 3,
        "maximum": 60,
        "default": 27,
        "examples": [
          27
        ]
      },
      "duration": {
        "type": "number",
        "description": "The duration of the generated audio in seconds.",
        "required": false,
        "minimum": 5,
        "maximum": 240,
        "default": 60
      },
      "tags": {
        "type": "string",
        "description": "Comma-separated list of genre tags to control the style of the generated audio.",
        "required": true,
        "examples": [
          "lofi, hiphop, drum and bass, trap, chill"
        ]
      },
      "minimum_guidance_scale": {
        "type": "number",
        "description": "Minimum guidance scale for the generation after the decay.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 3,
        "examples": [
          3
        ]
      },
      "lyrics": {
        "type": "string",
        "description": "Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.",
        "required": false,
        "default": ""
      },
      "tag_guidance_scale": {
        "type": "number",
        "description": "Tag guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 5,
        "examples": [
          5
        ]
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler to use for the generation process.",
        "required": false,
        "enum": [
          "euler",
          "heun"
        ],
        "default": "euler",
        "examples": [
          "euler"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 200,
        "default": 15,
        "examples": [
          15
        ]
      },
      "guidance_type": {
        "type": "string",
        "description": "Type of CFG to use for the generation process.",
        "required": false,
        "enum": [
          "cfg",
          "apg",
          "cfg_star"
        ],
        "default": "apg",
        "examples": [
          "apg"
        ]
      },
      "lyric_guidance_scale": {
        "type": "number",
        "description": "Lyric guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 1.5,
        "examples": [
          1.5
        ]
      },
      "guidance_interval": {
        "type": "number",
        "description": "Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "guidance_interval_decay": {
        "type": "number",
        "description": "Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0,
        "examples": [
          0
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If not provided, a random seed will be used.",
        "required": false
      },
      "granularity_scale": {
        "type": "integer",
        "description": "Granularity scale for the generation process. Higher values can reduce artifacts.",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 10,
        "examples": [
          10
        ]
      }
    },
    "outputParameters": {
      "tags": {
        "type": "string",
        "description": "The genre tags used in the generation process."
      },
      "lyrics": {
        "type": "string",
        "description": "The lyrics used in the generation process."
      },
      "seed": {
        "type": "integer",
        "description": "The random seed used for the generation process."
      },
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-trainer",
    "title": "LTX Video Trainer",
    "category": "training",
    "description": "Train LTX Video 0.9.7 for custom styles and effects.",
    "tags": [
      "ltx-video",
      "fine-tuning"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of steps to train for.",
        "required": false,
        "minimum": 100,
        "maximum": 20000,
        "default": 1000,
        "examples": [
          1000
        ]
      },
      "frame_rate": {
        "type": "integer",
        "description": "The target frames per second for the video.",
        "required": false,
        "minimum": 8,
        "maximum": 60,
        "default": 25,
        "examples": [
          25
        ]
      },
      "validation": {
        "type": "array",
        "description": "A list of validation prompts to use during training. When providing an image, _all_ validation inputs must have an image.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Validation"
        }
      },
      "learning_rate": {
        "type": "number",
        "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 1,
        "default": 0.0002,
        "examples": [
          0.0002
        ]
      },
      "number_of_frames": {
        "type": "integer",
        "description": "The number of frames to use for training. This is the number of frames per second multiplied by the number of seconds.",
        "required": false,
        "minimum": 25,
        "maximum": 121,
        "default": 81,
        "examples": [
          81
        ]
      },
      "validation_reverse": {
        "type": "boolean",
        "description": "If true, the validation videos will be reversed. This is useful for effects that are learned in reverse and then applied in reverse.",
        "required": false,
        "default": false
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.",
        "required": true
      },
      "split_input_duration_threshold": {
        "type": "number",
        "description": "The duration threshold in seconds. If a video is longer than this, it will be split into scenes. If you provide captions for a split video, the caption will be applied to each scene. If you do not provide captions, scenes will be auto-captioned.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 30,
        "examples": [
          30
        ]
      },
      "rank": {
        "type": "integer",
        "description": "The rank of the LoRA.",
        "required": false,
        "enum": [
          8,
          16,
          32,
          64,
          128
        ],
        "default": 128,
        "examples": [
          128
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio to use for training. This is the aspect ratio of the video.",
        "required": false,
        "enum": [
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "1:1",
        "examples": [
          "1:1"
        ]
      },
      "split_input_into_scenes": {
        "type": "boolean",
        "description": "If true, input above a certain duration threshold will be split into scenes. If you provide captions for a split video, the caption will be applied to each scene. If you do not provide captions, scenes will be auto-captioned.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "trigger_phrase": {
        "type": "string",
        "description": "The phrase that will trigger the model to generate an image.",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "The resolution to use for training. This is the resolution of the video.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high"
        ],
        "default": "medium",
        "examples": [
          "medium"
        ]
      },
      "validation_resolution": {
        "type": "string",
        "description": "The resolution to use for validation.",
        "required": false,
        "enum": [
          "low",
          "medium",
          "high"
        ],
        "default": "high",
        "examples": [
          "high"
        ]
      },
      "validation_number_of_frames": {
        "type": "integer",
        "description": "The number of frames to use for validation.",
        "required": false,
        "minimum": 8,
        "maximum": 121,
        "default": 81,
        "examples": [
          81
        ]
      },
      "validation_aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio to use for validation.",
        "required": false,
        "enum": [
          "16:9",
          "1:1",
          "9:16"
        ],
        "default": "1:1",
        "examples": [
          "1:1"
        ]
      },
      "validation_negative_prompt": {
        "type": "string",
        "description": "A negative prompt to use for validation.",
        "required": false,
        "default": "blurry, low quality, bad quality, out of focus"
      },
      "auto_scale_input": {
        "type": "boolean",
        "description": "If true, the input will be automatically scale the video to DEFAULT_NUM_FRAMES frames at 16fps.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights."
      },
      "config_file": {
        "type": null,
        "description": "Configuration used for setting up the inference endpoints."
      },
      "video": {
        "type": null,
        "description": "The URL to the validations video."
      }
    }
  },
  {
    "id": "fal-ai/recraft/upscale/creative",
    "title": "Recraft Creative Upscale",
    "category": "image-to-image",
    "description": "Enhances a given raster image using the 'creative upscale' tool, increasing image resolution, making the image sharper and cleaner.",
    "tags": [
      "upscaling"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-creative-upscale.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/upscale/creative",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft/upscale/creative/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be upscaled. Must be in PNG format.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/recraft/recraft-upscaler-1.jpeg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The upscaled image."
      }
    }
  },
  {
    "id": "fal-ai/recraft/upscale/crisp",
    "title": "Recraft Crisp Upscale",
    "category": "image-to-image",
    "description": "Enhances a given raster image using 'crisp upscale' tool, boosting resolution with a focus on refining small details and faces.",
    "tags": [
      "upscaling"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-creative-upscale.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/upscale/crisp",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft/upscale/crisp/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be upscaled. Must be in PNG format.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/recraft/recraft-upscaler-1.jpeg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The upscaled image."
      }
    }
  },
  {
    "id": "fal-ai/recraft/v3/create-style",
    "title": "Recraft V3 Create Style",
    "category": "training",
    "description": "Recraft V3 Create Style is capable of creating unique styles for Recraft V3 based on your images.",
    "tags": [
      "style",
      "vector",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-v3-create-style.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/v3/create-style",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft/v3/create-style/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "images_data_url": {
        "type": "string",
        "description": "URL to zip archive with images, use PNG format. Maximum 5 images are allowed.",
        "required": true
      },
      "base_style": {
        "type": "string",
        "description": "The base style of the generated images, this topic is covered above.",
        "required": false,
        "enum": [
          "any",
          "realistic_image",
          "digital_illustration",
          "vector_illustration",
          "realistic_image/b_and_w",
          "realistic_image/hard_flash",
          "realistic_image/hdr",
          "realistic_image/natural_light",
          "realistic_image/studio_portrait",
          "realistic_image/enterprise",
          "realistic_image/motion_blur",
          "realistic_image/evening_light",
          "realistic_image/faded_nostalgia",
          "realistic_image/forest_life",
          "realistic_image/mystic_naturalism",
          "realistic_image/natural_tones",
          "realistic_image/organic_calm",
          "realistic_image/real_life_glow",
          "realistic_image/retro_realism",
          "realistic_image/retro_snapshot",
          "realistic_image/urban_drama",
          "realistic_image/village_realism",
          "realistic_image/warm_folk",
          "digital_illustration/pixel_art",
          "digital_illustration/hand_drawn",
          "digital_illustration/grain",
          "digital_illustration/infantile_sketch",
          "digital_illustration/2d_art_poster",
          "digital_illustration/handmade_3d",
          "digital_illustration/hand_drawn_outline",
          "digital_illustration/engraving_color",
          "digital_illustration/2d_art_poster_2",
          "digital_illustration/antiquarian",
          "digital_illustration/bold_fantasy",
          "digital_illustration/child_book",
          "digital_illustration/child_books",
          "digital_illustration/cover",
          "digital_illustration/crosshatch",
          "digital_illustration/digital_engraving",
          "digital_illustration/expressionism",
          "digital_illustration/freehand_details",
          "digital_illustration/grain_20",
          "digital_illustration/graphic_intensity",
          "digital_illustration/hard_comics",
          "digital_illustration/long_shadow",
          "digital_illustration/modern_folk",
          "digital_illustration/multicolor",
          "digital_illustration/neon_calm",
          "digital_illustration/noir",
          "digital_illustration/nostalgic_pastel",
          "digital_illustration/outline_details",
          "digital_illustration/pastel_gradient",
          "digital_illustration/pastel_sketch",
          "digital_illustration/pop_art",
          "digital_illustration/pop_renaissance",
          "digital_illustration/street_art",
          "digital_illustration/tablet_sketch",
          "digital_illustration/urban_glow",
          "digital_illustration/urban_sketching",
          "digital_illustration/vanilla_dreams",
          "digital_illustration/young_adult_book",
          "digital_illustration/young_adult_book_2",
          "vector_illustration/bold_stroke",
          "vector_illustration/chemistry",
          "vector_illustration/colored_stencil",
          "vector_illustration/contour_pop_art",
          "vector_illustration/cosmics",
          "vector_illustration/cutout",
          "vector_illustration/depressive",
          "vector_illustration/editorial",
          "vector_illustration/emotional_flat",
          "vector_illustration/infographical",
          "vector_illustration/marker_outline",
          "vector_illustration/mosaic",
          "vector_illustration/naivector",
          "vector_illustration/roundish_flat",
          "vector_illustration/segmented_colors",
          "vector_illustration/sharp_contrast",
          "vector_illustration/thin",
          "vector_illustration/vector_photo",
          "vector_illustration/vivid_shapes",
          "vector_illustration/engraving",
          "vector_illustration/line_art",
          "vector_illustration/line_circuit",
          "vector_illustration/linocut"
        ],
        "default": "digital_illustration"
      }
    },
    "outputParameters": {
      "style_id": {
        "type": "string",
        "description": "The ID of the created style, this ID can be used to reference the style in the future."
      }
    }
  },
  {
    "id": "fal-ai/recraft/v3/image-to-image",
    "title": "Recraft V3",
    "category": "image-to-image",
    "description": "Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more. As of today, it is SOTA in image generation, proven by Hugging Face's industry-leading Text-to-Image Benchmark by Artificial Analysis.",
    "tags": [
      "vector",
      "typography",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-v3.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/v3/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft/v3/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "A text description of areas to change.",
        "required": true,
        "maxLength": 1000,
        "examples": [
          "winter",
          "cyberpunk city",
          "watercolor painting style"
        ]
      },
      "style": {
        "type": "string",
        "description": "The style of the generated images. Vector images cost 2X as much.",
        "required": false,
        "enum": [
          "any",
          "realistic_image",
          "digital_illustration",
          "vector_illustration",
          "realistic_image/b_and_w",
          "realistic_image/hard_flash",
          "realistic_image/hdr",
          "realistic_image/natural_light",
          "realistic_image/studio_portrait",
          "realistic_image/enterprise",
          "realistic_image/motion_blur",
          "realistic_image/evening_light",
          "realistic_image/faded_nostalgia",
          "realistic_image/forest_life",
          "realistic_image/mystic_naturalism",
          "realistic_image/natural_tones",
          "realistic_image/organic_calm",
          "realistic_image/real_life_glow",
          "realistic_image/retro_realism",
          "realistic_image/retro_snapshot",
          "realistic_image/urban_drama",
          "realistic_image/village_realism",
          "realistic_image/warm_folk",
          "digital_illustration/pixel_art",
          "digital_illustration/hand_drawn",
          "digital_illustration/grain",
          "digital_illustration/infantile_sketch",
          "digital_illustration/2d_art_poster",
          "digital_illustration/handmade_3d",
          "digital_illustration/hand_drawn_outline",
          "digital_illustration/engraving_color",
          "digital_illustration/2d_art_poster_2",
          "digital_illustration/antiquarian",
          "digital_illustration/bold_fantasy",
          "digital_illustration/child_book",
          "digital_illustration/child_books",
          "digital_illustration/cover",
          "digital_illustration/crosshatch",
          "digital_illustration/digital_engraving",
          "digital_illustration/expressionism",
          "digital_illustration/freehand_details",
          "digital_illustration/grain_20",
          "digital_illustration/graphic_intensity",
          "digital_illustration/hard_comics",
          "digital_illustration/long_shadow",
          "digital_illustration/modern_folk",
          "digital_illustration/multicolor",
          "digital_illustration/neon_calm",
          "digital_illustration/noir",
          "digital_illustration/nostalgic_pastel",
          "digital_illustration/outline_details",
          "digital_illustration/pastel_gradient",
          "digital_illustration/pastel_sketch",
          "digital_illustration/pop_art",
          "digital_illustration/pop_renaissance",
          "digital_illustration/street_art",
          "digital_illustration/tablet_sketch",
          "digital_illustration/urban_glow",
          "digital_illustration/urban_sketching",
          "digital_illustration/vanilla_dreams",
          "digital_illustration/young_adult_book",
          "digital_illustration/young_adult_book_2",
          "vector_illustration/bold_stroke",
          "vector_illustration/chemistry",
          "vector_illustration/colored_stencil",
          "vector_illustration/contour_pop_art",
          "vector_illustration/cosmics",
          "vector_illustration/cutout",
          "vector_illustration/depressive",
          "vector_illustration/editorial",
          "vector_illustration/emotional_flat",
          "vector_illustration/infographical",
          "vector_illustration/marker_outline",
          "vector_illustration/mosaic",
          "vector_illustration/naivector",
          "vector_illustration/roundish_flat",
          "vector_illustration/segmented_colors",
          "vector_illustration/sharp_contrast",
          "vector_illustration/thin",
          "vector_illustration/vector_photo",
          "vector_illustration/vivid_shapes",
          "vector_illustration/engraving",
          "vector_illustration/line_art",
          "vector_illustration/line_circuit",
          "vector_illustration/linocut"
        ],
        "default": "realistic_image"
      },
      "style_id": {
        "type": "string",
        "description": "The ID of the custom style reference (optional)",
        "required": false,
        "examples": [
          null
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to modify. Must be less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/recraft/recraft-upscaler-1.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5,
        "examples": [
          0.2,
          0.5,
          0.8
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "colors": {
        "type": "array",
        "description": "An array of preferable colors",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/RGBColor"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "A text description of undesired elements on an image",
        "required": false,
        "maxLength": 1000
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "easel-ai/easel-avatar",
    "title": "Easel Avatar",
    "category": "text-to-image",
    "description": "Create scenes with one or two people using just selfies and text prompt (without LoRAs)",
    "tags": [
      "avatars",
      "loras",
      "image-generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/easel-avatar-2.webp",
    "playgroundUrl": "https://fal.ai/models/easel-ai/easel-avatar",
    "documentationUrl": "https://fal.ai/models/easel-ai/easel-avatar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the scene",
        "required": true,
        "examples": [
          "at the Met Gala, dressed in very fancy outfits, captured in a full body shot"
        ]
      },
      "gender_1": {
        "type": "string",
        "description": "The gender of the person in the second face image",
        "required": false,
        "enum": [
          "male",
          "female",
          "non-binary"
        ],
        "default": "female"
      },
      "face_image_1": {
        "type": null,
        "description": "(Optional) The second face image used to generate a two-person scene.",
        "required": false,
        "examples": [
          "https://images.easelai.com/avatar_fal/female/female.png",
          "https://images.easelai.com/avatar_fal/male/male.png"
        ]
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image. Hyperrealistic-likeness: preserves more likeness including hair styles; hyperrealistic: ideal for fun and creative scenes; Realistic: photorealistic with good text rendering; Stylistic: softer, more artistic",
        "required": false,
        "enum": [
          "hyperrealistic-likeness",
          "hyperrealistic",
          "realistic",
          "stylistic"
        ],
        "default": "hyperrealistic-likeness",
        "examples": [
          "hyperrealistic-likeness",
          "hyperrealistic",
          "realistic",
          "stylistic"
        ]
      },
      "face_image_0": {
        "type": null,
        "description": "The face image with which the scene is generated.",
        "required": true,
        "examples": [
          "https://images.easelai.com/avatar_fal/male/male.png",
          "https://images.easelai.com/avatar_fal/female/female.png"
        ]
      },
      "gender_0": {
        "type": "string",
        "description": "The gender of the person in the face image",
        "required": true,
        "enum": [
          "male",
          "female",
          "non-binary"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated avatar image"
      }
    }
  },
  {
    "id": "fal-ai/minimax/voice-clone",
    "title": "MiniMax Voice Cloning",
    "category": "text-to-speech",
    "description": "Clone a voice from a sample audio and generate speech from text prompts using the MiniMax model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "speech",
      ""
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/minimax-tts/minimax-tts.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/voice-clone",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/voice-clone/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "TTS model to use for preview. Options: speech-02-hd, speech-02-turbo, speech-01-hd, speech-01-turbo",
        "required": false,
        "enum": [
          "speech-02-hd",
          "speech-02-turbo",
          "speech-01-hd",
          "speech-01-turbo"
        ],
        "default": "speech-02-hd",
        "examples": [
          "speech-02-hd",
          "speech-02-turbo",
          "speech-01-hd",
          "speech-01-turbo"
        ]
      },
      "text": {
        "type": "string",
        "description": "Text to generate a TTS preview with the cloned voice (optional)",
        "required": false,
        "maxLength": 300,
        "default": "Hello, this is a preview of your cloned voice! I hope you like it!",
        "examples": [
          "Hello, this is a preview of your cloned voice! I hope you like it!"
        ]
      },
      "accuracy": {
        "type": "number",
        "description": "Text validation accuracy threshold (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1
      },
      "audio_url": {
        "type": "string",
        "description": "\n            URL of the input audio file for voice cloning. Should be at least 10 seconds\n            long. To retain the voice permanently, use it with a TTS (text-to-speech)\n            endpoint at least once within 7 days. Otherwise, it will be\n            automatically deleted.\n        ",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/zonos/demo_voice_zonos.wav"
        ]
      },
      "noise_reduction": {
        "type": "boolean",
        "description": "Enable noise reduction for the cloned voice",
        "required": false,
        "default": false
      },
      "need_volume_normalization": {
        "type": "boolean",
        "description": "Enable volume normalization for the cloned voice",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "custom_voice_id": {
        "type": "string",
        "description": "The cloned voice ID for use with TTS"
      },
      "audio": {
        "type": null,
        "description": "Preview audio generated with the cloned voice (if requested)"
      }
    }
  },
  {
    "id": "fal-ai/minimax/speech-02-turbo",
    "title": "MiniMax Speech-02 Turbo",
    "category": "text-to-speech",
    "description": "Generate fast speech from text prompts and different voices using the MiniMax Speech-02 Turbo model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "speech",
      ""
    ],
    "thumbnailUrl": "https://fal.media/files/lion/9GDtsluojQ0BAg28nSQLh_f7fea66a2ac94526b14e6ef21ab65414.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/speech-02-turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/speech-02-turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Hello world! This is a test of the text-to-speech system."
        ]
      },
      "language_boost": {
        "type": "string",
        "description": "Enhance recognition of specified languages and dialects",
        "required": false,
        "enum": [
          "Chinese",
          "Chinese,Yue",
          "English",
          "Arabic",
          "Russian",
          "Spanish",
          "French",
          "Portuguese",
          "German",
          "Turkish",
          "Dutch",
          "Ukrainian",
          "Vietnamese",
          "Indonesian",
          "Japanese",
          "Italian",
          "Korean",
          "Thai",
          "Polish",
          "Romanian",
          "Greek",
          "Czech",
          "Finnish",
          "Hindi",
          "Bulgarian",
          "Danish",
          "Hebrew",
          "Malay",
          "Slovak",
          "Swedish",
          "Croatian",
          "Hungarian",
          "Norwegian",
          "Slovenian",
          "Catalan",
          "Nynorsk",
          "Afrikaans",
          "auto"
        ]
      },
      "voice_setting": {
        "type": null,
        "description": "Voice configuration settings",
        "required": false,
        "default": {
          "speed": 1,
          "vol": 1,
          "voice_id": "Wise_Woman",
          "pitch": 0,
          "english_normalization": false
        }
      },
      "output_format": {
        "type": "string",
        "description": "Format of the output content (non-streaming only)",
        "required": false,
        "enum": [
          "url",
          "hex"
        ],
        "default": "hex"
      },
      "pronunciation_dict": {
        "type": null,
        "description": "Custom pronunciation dictionary for text replacement",
        "required": false
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "duration_ms": {
        "type": "integer",
        "description": "Duration of the audio in milliseconds"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/minimax/speech-02-hd",
    "title": "MiniMax Speech-02 HD",
    "category": "text-to-speech",
    "description": "Generate speech from text prompts and different voices using the MiniMax Speech-02 HD model, which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/A-mMZvJzo3C_kFbO7NmMi_28b71bd757bf4319973fb209c96453f9.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/speech-02-hd",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/speech-02-hd/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
        "required": true,
        "minLength": 1,
        "maxLength": 5000,
        "examples": [
          "Hello world! This is a test of the text-to-speech system."
        ]
      },
      "language_boost": {
        "type": "string",
        "description": "Enhance recognition of specified languages and dialects",
        "required": false,
        "enum": [
          "Chinese",
          "Chinese,Yue",
          "English",
          "Arabic",
          "Russian",
          "Spanish",
          "French",
          "Portuguese",
          "German",
          "Turkish",
          "Dutch",
          "Ukrainian",
          "Vietnamese",
          "Indonesian",
          "Japanese",
          "Italian",
          "Korean",
          "Thai",
          "Polish",
          "Romanian",
          "Greek",
          "Czech",
          "Finnish",
          "Hindi",
          "Bulgarian",
          "Danish",
          "Hebrew",
          "Malay",
          "Slovak",
          "Swedish",
          "Croatian",
          "Hungarian",
          "Norwegian",
          "Slovenian",
          "Catalan",
          "Nynorsk",
          "Afrikaans",
          "auto"
        ]
      },
      "voice_setting": {
        "type": null,
        "description": "Voice configuration settings",
        "required": false,
        "default": {
          "speed": 1,
          "vol": 1,
          "voice_id": "Wise_Woman",
          "pitch": 0,
          "english_normalization": false
        }
      },
      "output_format": {
        "type": "string",
        "description": "Format of the output content (non-streaming only)",
        "required": false,
        "enum": [
          "url",
          "hex"
        ],
        "default": "hex"
      },
      "pronunciation_dict": {
        "type": null,
        "description": "Custom pronunciation dictionary for text replacement",
        "required": false
      },
      "audio_setting": {
        "type": null,
        "description": "Audio configuration settings",
        "required": false
      }
    },
    "outputParameters": {
      "duration_ms": {
        "type": "integer",
        "description": "Duration of the audio in milliseconds"
      },
      "audio": {
        "type": null,
        "description": "The generated audio file"
      }
    }
  },
  {
    "id": "fal-ai/minimax/image-01/subject-reference",
    "title": "Minimax Image Subject Reference",
    "category": "image-to-image",
    "description": "Generate images from text and a reference image using MiniMax Image-01 for consistent character appearance.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-3.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/image-01/subject-reference",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/image-01/subject-reference/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for image generation (max 1500 characters)",
        "required": true,
        "minLength": 1,
        "maxLength": 1500,
        "examples": [
          "A beautiful woman with a crown on her head."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-9)",
        "required": false,
        "minimum": 1,
        "maximum": 9,
        "default": 1
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to enable automatic prompt optimization",
        "required": false,
        "default": false
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "4:3",
          "3:2",
          "2:3",
          "3:4",
          "9:16",
          "21:9"
        ],
        "default": "1:1"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the subject reference image to use for consistent character appearance",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/koala/hQwSnkWm8FDjou5SwLNuX_c223cf93-0036-4b18-bbea-bf6d0da7f210.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/minimax/image-01",
    "title": "MiniMax (Hailuo AI) Text to Image",
    "category": "text-to-image",
    "description": "Generate high quality images from text prompts using MiniMax Image-01. Longer text prompts will result in better quality images.",
    "tags": [
      "stylized",
      "realism"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/minimax-image/minimax.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/image-01",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/image-01/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for image generation (max 1500 characters)",
        "required": true,
        "minLength": 1,
        "maxLength": 1500,
        "examples": [
          "Man dressed in white t shirt, full-body stand front view image, outdoor, Venice beach sign, full-body image, Los Angeles, Fashion photography of 90s, documentary, Film grain, photorealistic"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-9)",
        "required": false,
        "minimum": 1,
        "maximum": 9,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "4:3",
          "3:2",
          "2:3",
          "3:4",
          "9:16",
          "21:9"
        ],
        "default": "1:1"
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to enable automatic prompt optimization",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated images",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/hidream-i1-full/image-to-image",
    "title": "Hidream I1 Full",
    "category": "image-to-image",
    "description": "HiDream-I1 full is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds.",
    "tags": [
      "image-to-image",
      "hidream"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hidream-i1-full/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/hidream-i1-full/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "An old man"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Setting to None uses the input image's size.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/C9qhzoMrg6Sg7lYh_ocrZ_example_man.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "strength": {
        "type": "number",
        "description": "Denoising strength for image-to-image generation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/pony-v7",
    "title": "Pony V7",
    "category": "text-to-image",
    "description": "Pony V7 is a finetuned text to image for superior aesthetics and prompt following.",
    "tags": [
      "diffusion",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pony-v7",
    "documentationUrl": "https://fal.ai/models/fal-ai/pony-v7/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate images from",
        "required": true,
        "examples": [
          "Close-up portrait of a majestic iguana with vibrant blue-green scales, piercing amber eyes, and orange spiky crest. Intricate textures and details visible on scaly skin. Wrapped in dark hood, giving regal appearance. Dramatic lighting against black background. Hyper-realistic, high-resolution image showcasing the reptile's expressive features and coloration."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "noise_source": {
        "type": "string",
        "description": "\n            The source of the noise to use for generating images.\n            If set to 'gpu', the noise will be generated on the GPU.\n            If set to 'cpu', the noise will be generated on the CPU.\n        ",
        "required": false,
        "enum": [
          "gpu",
          "cpu"
        ],
        "default": "gpu"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier free guidance scale",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating images",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to take",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 40
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/trellis/multi",
    "title": "Trellis",
    "category": "image-to-3d",
    "description": "Generate 3D models from multiple images using Trellis. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/trellis/multi",
    "documentationUrl": "https://fal.ai/models/fal-ai/trellis/multi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "multiimage_algo": {
        "type": "string",
        "description": "Algorithm for multi-image generation",
        "required": false,
        "enum": [
          "stochastic",
          "multidiffusion"
        ],
        "default": "stochastic"
      },
      "slat_sampling_steps": {
        "type": "integer",
        "description": "Sampling steps for structured latent generation",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 12
      },
      "ss_sampling_steps": {
        "type": "integer",
        "description": "Sampling steps for sparse structure generation",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 12
      },
      "mesh_simplify": {
        "type": "number",
        "description": "Mesh simplification factor",
        "required": false,
        "minimum": 0.9,
        "maximum": 0.98,
        "default": 0.95
      },
      "slat_guidance_strength": {
        "type": "number",
        "description": "Guidance strength for structured latent generation",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 3
      },
      "ss_guidance_strength": {
        "type": "number",
        "description": "Guidance strength for sparse structure generation",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 7.5
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility",
        "required": false
      },
      "texture_size": {
        "type": "integer",
        "description": "Texture resolution",
        "required": false,
        "enum": [
          512,
          1024,
          2048
        ],
        "default": 1024
      },
      "image_urls": {
        "type": "array",
        "description": "List of URLs of input images to convert to 3D",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/model_tests/video_models/front.png",
            "https://storage.googleapis.com/falserverless/model_tests/video_models/back.png",
            "https://storage.googleapis.com/falserverless/model_tests/video_models/left.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D mesh file"
      },
      "timings": {
        "type": "object",
        "description": "Processing timings"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v3/reframe",
    "title": "Ideogram",
    "category": "image-to-image",
    "description": "Extend existing images with Ideogram V3's reframe feature. Create expanded versions and adaptations while preserving main image and adding new creative directions through prompt guidance.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/o7F_OomTu8c7O949nQZKc_7fca2610b9844c7086fedcf2e8df707b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v3/reframe",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v3/reframe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The resolution for the reframed output image",
        "required": true,
        "examples": [
          "square_hd"
        ]
      },
      "style": {
        "type": null,
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false
      },
      "style_preset": {
        "type": null,
        "description": "Style preset for generation. The chosen style preset will guide the generation.",
        "required": false
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to reframe",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/lion/0qJs_qW8nz0wYsXhFa6Tk.png"
        ]
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v3",
    "title": "Ideogram Text to Image",
    "category": "text-to-image",
    "description": "Generate high-quality images, posters, and logos with Ideogram V3. Features exceptional typography handling and realistic outputs optimized for commercial and creative use.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://fal.media/files/koala/nTe9hpbTjo8BWgaGYTGzi_7b7c3112872b48b6be63734f9daa3f73.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v3",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "The Bone Forest stretched across the horizon, its trees fashioned from the ossified remains of ancient leviathans that once swam through the sky. Shamans with antlers growing from their shoulders and eyes that revealed the true nature of any being they beheld conducted rituals to commune with the spirits that still inhabited the calcified grove. In sky writes \"Ideogram V3 in fal.ai\""
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The resolution of the generated image",
        "required": false,
        "default": "square_hd"
      },
      "style": {
        "type": null,
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false
      },
      "style_preset": {
        "type": null,
        "description": "Style preset for generation. The chosen style preset will guide the generation.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v3/replace-background",
    "title": "Ideogram Replace Background",
    "category": "image-to-image",
    "description": "Replace backgrounds existing images with Ideogram V3's replace background feature. Create variations and adaptations while preserving core elements and adding new creative directions through prompt guidance.",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/zebra/ejW0ul_u92u1TpdOpmfGQ_491bbb82cd504292beb0b5ad937dd024.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v3/replace-background",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v3/replace-background/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Cyber punk city with neon lights and skyscrappers",
        "required": true,
        "examples": [
          "A beautiful sunset over mountains that writes Ideogram v3 in fal.ai"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "style": {
        "type": null,
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false
      },
      "style_preset": {
        "type": null,
        "description": "Style preset for generation. The chosen style preset will guide the generation.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The image URL whose background needs to be replaced",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/F6dvKPFL9VzKiM8asJOgm_MJj6yUB6rGjTsv_1YHIcA_image.webp"
        ]
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v3/remix",
    "title": "Ideogram",
    "category": "image-to-image",
    "description": "Reimagine existing images with Ideogram V3's remix feature. Create variations and adaptations while preserving core elements and adding new creative directions through prompt guidance.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/H2-lBMLTJ9R_pMJKy1N1c_078a7fbed0f241d5a81afd34cc3d7233.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v3/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v3/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to remix the image with",
        "required": true,
        "examples": [
          "Old ancient city day light"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The resolution of the generated image",
        "required": false,
        "default": "square_hd"
      },
      "style": {
        "type": null,
        "description": "The style type to generate with. Cannot be used with style_codes.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to remix",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/lion/9-Yt8JfTw4OxrAjiUzwP9_output.png"
        ]
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "Strength of the input image in the remix",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v3/edit",
    "title": "Ideogram V3 Edit",
    "category": "image-to-image",
    "description": "Transform existing images with Ideogram V3's editing capabilities. Modify, adjust, and refine images while maintaining high fidelity and realistic outputs with precise prompt control.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v3/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v3/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "black bag"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "style_preset": {
        "type": null,
        "description": "Style preset for generation. The chosen style preset will guide the generation.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Determine if MagicPrompt should be used in generating the request or not.",
        "required": false,
        "default": true
      },
      "rendering_speed": {
        "type": "string",
        "description": "The rendering speed to use.",
        "required": false,
        "enum": [
          "TURBO",
          "BALANCED",
          "QUALITY"
        ],
        "default": "BALANCED"
      },
      "style_codes": {
        "type": null,
        "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style",
        "required": false
      },
      "color_palette": {
        "type": null,
        "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/-LC_gNNV3wUHaGMQT3klE_output.png"
        ]
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "image_urls": {
        "type": null,
        "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/1dd3zEL5MXQ3Kb4-mRi9d_indir%20(20).png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/f-lite/standard",
    "title": "F Lite",
    "category": "text-to-image",
    "description": "F Lite is a 10B parameter diffusion model created by Fal and Freepik, trained exclusively on copyright-safe and SFW content.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/f-lite/standard",
    "documentationUrl": "https://fal.ai/models/fal-ai/f-lite/standard/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Mount Fuji at sunset, with the iconic snow-capped peak silhouetted against a vibrant orange and purple sky. A tranquil lake in the foreground perfectly reflects the mountain and colorful sky. A few traditional Japanese cherry blossom trees frame the scene, with their delicate pink petals visible in the foreground."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative Prompt for generation.",
        "required": false,
        "default": "",
        "examples": [
          "Blurry, out of focus, low resolution, bad anatomy, ugly, deformed, poorly drawn, extra limbs"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/f-lite/texture",
    "title": "F Lite (texture mode)",
    "category": "text-to-image",
    "description": "F Lite is a 10B parameter diffusion model created by Fal and Freepik, trained exclusively on copyright-safe and SFW content. This is a high texture density variant of the model.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/f-lite/texture",
    "documentationUrl": "https://fal.ai/models/fal-ai/f-lite/texture/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Mount Fuji at sunset, with the iconic snow-capped peak silhouetted against a vibrant orange and purple sky. A tranquil lake in the foreground perfectly reflects the mountain and colorful sky. A few traditional Japanese cherry blossom trees frame the scene, with their delicate pink petals visible in the foreground."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative Prompt for generation.",
        "required": false,
        "default": "",
        "examples": [
          "Blurry, out of focus, low resolution, bad anatomy, ugly, deformed, poorly drawn, extra limbs"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/moondream2/visual-query",
    "title": "Moondream2",
    "category": "vision",
    "description": "Moondream2 is a highly efficient open-source vision language model that combines powerful image understanding capabilities with a remarkably small footprint.",
    "tags": [
      "Vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream2/visual-query",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream2/visual-query/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Query to be asked in the image",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "output": {
        "type": "string",
        "description": "Output for the given query"
      }
    }
  },
  {
    "id": "fal-ai/moondream2",
    "title": "Moondream2",
    "category": "vision",
    "description": "Moondream2 is a highly efficient open-source vision language model that combines powerful image understanding capabilities with a remarkably small footprint. ",
    "tags": [
      "Vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream2",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "output": {
        "type": "string",
        "description": "Output for the given query"
      }
    }
  },
  {
    "id": "fal-ai/moondream2/point-object-detection",
    "title": "Moondream2",
    "category": "vision",
    "description": "Moondream2 is a highly efficient open-source vision language model that combines powerful image understanding capabilities with a remarkably small footprint.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream2/point-object-detection",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream2/point-object-detection/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "object": {
        "type": "string",
        "description": "Object to be detected in the image",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with detected objects"
      },
      "objects": {
        "type": "array",
        "description": "Objects detected in the image",
        "items": {
          "type": "object"
        }
      }
    }
  },
  {
    "id": "fal-ai/moondream2/object-detection",
    "title": "Moondream2",
    "category": "vision",
    "description": "Moondream2 is a highly efficient open-source vision language model that combines powerful image understanding capabilities with a remarkably small footprint.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream2/object-detection",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream2/object-detection/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "object": {
        "type": "string",
        "description": "Object to be detected in the image",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with detected objects"
      },
      "objects": {
        "type": "array",
        "description": "Objects detected in the image",
        "items": {
          "type": "object"
        }
      }
    }
  },
  {
    "id": "fal-ai/step1x-edit",
    "title": "Step1X Edit",
    "category": "image-to-image",
    "description": "Step1X-Edit transforms your photos with simple instructions into stunning, professional-quality edits—rivaling top proprietary tools.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/step1x-edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/step1x-edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "make head band red"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/girl_2.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "tripo3d/tripo/v2.5/image-to-3d",
    "title": "Tripo3D",
    "category": "image-to-3d",
    "description": "State of the art Image to 3D Object generation. Generate 3D model from a single image!",
    "tags": [
      "image-to-3d",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/tripo-image-to-3d.webp",
    "playgroundUrl": "https://fal.ai/models/tripo3d/tripo/v2.5/image-to-3d",
    "documentationUrl": "https://fal.ai/models/tripo3d/tripo/v2.5/image-to-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "face_limit": {
        "type": null,
        "description": "Limits the number of faces on the output model. If this option is not set, the face limit will be adaptively determined.",
        "required": false
      },
      "style": {
        "type": null,
        "description": "Defines the artistic style or transformation to be applied to the 3D model, altering its appearance according to preset options (extra $0.05 per generation). Omit this option to keep the original style and apperance.",
        "required": false
      },
      "pbr": {
        "type": null,
        "description": "A boolean option to enable pbr. The default value is True, set False to get a model without pbr. If this option is set to True, texture will be ignored and used as True.",
        "required": false,
        "default": false
      },
      "texture_alignment": {
        "type": null,
        "description": "Determines the prioritization of texture alignment in the 3D model. The default value is original_image.",
        "required": false,
        "default": "original_image"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use for model generation.",
        "required": true,
        "examples": [
          "https://platform.tripo3d.ai/assets/front-235queJB.jpg",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/hamburger.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/poly_fox.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/robot.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/teapot.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/tiger_girl.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/horse.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/flamingo.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/unicorn.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/chair.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/iso_house.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/marble.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/police_woman.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/captured_p.png"
        ]
      },
      "texture": {
        "type": "string",
        "description": "An option to enable texturing. Default is 'standard', set 'no' to get a model without any textures, and set 'HD' to get a model with hd quality textures.",
        "required": false,
        "enum": [
          "no",
          "standard",
          "HD"
        ],
        "default": "standard"
      },
      "auto_size": {
        "type": null,
        "description": "Automatically scale the model to real-world dimensions, with the unit in meters. The default value is False.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "This is the random seed for model generation. The seed controls the geometry generation process, ensuring identical models when the same seed is used. This parameter is an integer and is randomly chosen if not set.",
        "required": false
      },
      "quad": {
        "type": null,
        "description": "Set True to enable quad mesh output (extra $0.05 per generation). If quad=True and face_limit is not set, the default face_limit will be 10000. Note: Enabling this option will force the output to be an FBX model.",
        "required": false,
        "default": false
      },
      "orientation": {
        "type": null,
        "description": "Set orientation=align_image to automatically rotate the model to align the original image. The default value is default.",
        "required": false,
        "default": "default"
      },
      "texture_seed": {
        "type": null,
        "description": "This is the random seed for texture generation. Using the same seed will produce identical textures. This parameter is an integer and is randomly chosen if not set. If you want a model with different textures, please use same seed and different texture_seed.",
        "required": false
      }
    },
    "outputParameters": {
      "base_model": {
        "type": null,
        "description": "Base model"
      },
      "task_id": {
        "type": "string",
        "description": "The task id of the 3D model generation."
      },
      "rendered_image": {
        "type": null,
        "description": "A preview image of the model"
      },
      "model_mesh": {
        "type": null,
        "description": "Model"
      },
      "pbr_model": {
        "type": null,
        "description": "Pbr model"
      }
    }
  },
  {
    "id": "fal-ai/image2svg",
    "title": "Image2svg",
    "category": "image-to-image",
    "description": "Image2SVG transforms raster images into clean vector graphics, preserving visual quality while enabling scalable, customizable SVG outputs with precise control over detail levels.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image2svg",
    "documentationUrl": "https://fal.ai/models/fal-ai/image2svg/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "splice_threshold": {
        "type": "integer",
        "description": "Splice threshold for joining paths",
        "required": false,
        "minimum": 0,
        "maximum": 90,
        "default": 45
      },
      "hierarchical": {
        "type": "string",
        "description": "Hierarchical mode: stacked or cutout",
        "required": false,
        "enum": [
          "stacked",
          "cutout"
        ],
        "default": "stacked"
      },
      "color_precision": {
        "type": "integer",
        "description": "Color quantization level",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 6
      },
      "colormode": {
        "type": "string",
        "description": "Choose between color or binary (black and white) output",
        "required": false,
        "enum": [
          "color",
          "binary"
        ],
        "default": "color"
      },
      "max_iterations": {
        "type": "integer",
        "description": "Maximum number of iterations for optimization",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 10
      },
      "length_threshold": {
        "type": "number",
        "description": "Length threshold for curves/lines",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 4
      },
      "image_url": {
        "type": "string",
        "description": "The image to convert to SVG",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/EfqY747bBKy1Ynrgbk5ba_04pwiD1LTsnMZuyEyw757_8f986248a89845d3ba90c23b14089f10.jpg"
        ]
      },
      "mode": {
        "type": "string",
        "description": "Mode: spline (curved) or polygon (straight lines)",
        "required": false,
        "enum": [
          "spline",
          "polygon"
        ],
        "default": "spline"
      },
      "corner_threshold": {
        "type": "integer",
        "description": "Corner detection threshold in degrees",
        "required": false,
        "minimum": 0,
        "maximum": 180,
        "default": 60
      },
      "path_precision": {
        "type": "integer",
        "description": "Decimal precision for path coordinates",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 3
      },
      "filter_speckle": {
        "type": "integer",
        "description": "Filter out small speckles and noise",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "layer_difference": {
        "type": "integer",
        "description": "Layer difference threshold for hierarchical mode",
        "required": false,
        "minimum": 1,
        "maximum": 32,
        "default": 16
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The converted SVG file",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/uno",
    "title": "Uno",
    "category": "image-to-image",
    "description": "An AI model that transforms input images into new ones based on text prompts, blending reference visuals with your creative directions.",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-3.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/uno",
    "documentationUrl": "https://fal.ai/models/fal-ai/uno/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "The figurine is in the crystal ball"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "\n            The size of the generated image. You can choose between some presets or custom height and width\n            that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "square_hd"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to use while generating the image.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/UNO/figurine.png",
            "https://storage.googleapis.com/falserverless/UNO/crystal_ball.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation. If set none, a random seed will be used.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used to generate the image."
      },
      "images": {
        "type": "array",
        "description": "The URLs of the generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/gpt-image-1/edit-image/byok",
    "title": "gpt-image-1",
    "category": "image-to-image",
    "description": "OpenAI's latest image generation and editing model: gpt-1-image. Currently powered with bring-your-own-key.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gpt-image-1/edit-image/byok",
    "documentationUrl": "https://fal.ai/models/fal-ai/gpt-image-1/edit-image/byok/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image from.",
        "required": true,
        "minLength": 1,
        "maxLength": 32000,
        "examples": [
          "Make this pixel-art style."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": "string",
        "description": "The size of the image to generate.",
        "required": false,
        "enum": [
          "auto",
          "1024x1024",
          "1536x1024",
          "1024x1536"
        ],
        "default": "auto"
      },
      "input_fidelity": {
        "type": "string",
        "description": "How hard to try to preserve distinctive features from the input.",
        "required": false,
        "enum": [
          "low",
          "high"
        ],
        "default": "low"
      },
      "quality": {
        "type": "string",
        "description": "The quality of the image to generate.",
        "required": false,
        "enum": [
          "auto",
          "low",
          "medium",
          "high"
        ],
        "default": "auto"
      },
      "openai_api_key": {
        "type": "string",
        "description": "The OpenAI API key to use for the image generation. This endpoint is currently powered by bring-your-own-key system.",
        "required": true,
        "minLength": 1
      },
      "image_urls": {
        "type": "array",
        "description": "The URLs of the images to use as a reference for the generation.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/model_tests/gpt-image-1/cyberpunk.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "usage": {
        "type": null,
        "description": "The usage details for the image generation."
      },
      "images": {
        "type": "array",
        "description": "The edited images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/gpt-image-1/text-to-image/byok",
    "title": "gpt-image-1",
    "category": "text-to-image",
    "description": "OpenAI's latest image generation and editing model: gpt-1-image. Currently powered with bring-your-own-key.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gpt-image-1/text-to-image/byok",
    "documentationUrl": "https://fal.ai/models/fal-ai/gpt-image-1/text-to-image/byok/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the image from.",
        "required": true,
        "minLength": 1,
        "maxLength": 32000,
        "examples": [
          "A serene cyberpunk cityscape at twilight, with neon signs glowing in vibrant blues and purples, reflecting on rain-slick streets. Sleek futuristic buildings tower above, connected by glowing skybridges. A lone figure in a hooded jacket stands under a streetlamp, backlit by soft mist. The atmosphere is cinematic, moody"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": "string",
        "description": "The size of the image to generate.",
        "required": false,
        "enum": [
          "auto",
          "1024x1024",
          "1536x1024",
          "1024x1536"
        ],
        "default": "auto"
      },
      "background": {
        "type": "string",
        "description": "The background of the image to generate.",
        "required": false,
        "enum": [
          "auto",
          "transparent",
          "opaque"
        ],
        "default": "auto"
      },
      "quality": {
        "type": "string",
        "description": "The quality of the image to generate.",
        "required": false,
        "enum": [
          "auto",
          "low",
          "medium",
          "high"
        ],
        "default": "auto"
      },
      "openai_api_key": {
        "type": "string",
        "description": "The OpenAI API key to use for the image generation. This endpoint is currently powered by bring-your-own-key system.",
        "required": true,
        "minLength": 1
      }
    },
    "outputParameters": {
      "usage": {
        "type": null,
        "description": "The usage details for the image generation."
      },
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/magi/extend-video",
    "title": "MAGI-1",
    "category": "video-to-video",
    "description": "MAGI-1 extends videos with an exceptional understanding of physical interactions and prompts",
    "tags": [
      "video-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/magi/extend-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/magi/extend-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          ""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to represent the beginning of the video. If the input video does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/w4T087gvzG5LMGipMpPCO_pour-2s.mp4"
        ]
      },
      "start_frame": {
        "type": "integer",
        "description": "The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.",
        "required": false,
        "minimum": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "enum": [
          4,
          8,
          16,
          32,
          64
        ],
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
        "required": false,
        "minimum": 96,
        "maximum": 192,
        "default": 96
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/magi",
    "title": "MAGI-1",
    "category": "text-to-video",
    "description": "MAGI-1 is a video generation model with exceptional understanding of physical interactions and cinematic prompts",
    "tags": [
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/magi",
    "documentationUrl": "https://fal.ai/models/fal-ai/magi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins a slow clockwise orbit, pulling back. Finally, the camera rises high above, revealing the entire wooden sailing ship cutting through the waves, the captain unmoved, gazing toward the distant horizon."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "enum": [
          4,
          8,
          16,
          32,
          64
        ],
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
        "required": false,
        "minimum": 96,
        "maximum": 192,
        "default": 96
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/magi/image-to-video",
    "title": "MAGI-1",
    "category": "image-to-video",
    "description": "MAGI-1 generates videos from images with exceptional understanding of physical interactions and prompting",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/magi/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/magi/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A crisp, wintery mountain landscape unfolds as a snowboarder, equipped with a selfie pole, gracefully navigates a snow-covered slope, the camera perspective offering an exhilarating attached-third-person view of the descent;  the vibrant, snowy scenery sweeps past, punctuated by moments of controlled spins and effortless glides, creating a dynamic visual rhythm that complements the exhilarating pace of the ride;  as the snowboarder carves through pristine powder, the camera captures fleeting moments of breathtaking views—towering pines dusted with snow, sunlit peaks piercing a cerulean sky—a symphony of nature’s grandeur displayed for the viewer to share;  a sense of freedom and exhilaration permeates the scene, punctuated by the subtle whoosh of wind and the satisfying crunch of snow, culminating in a breathtaking panorama as the snowboarder reaches the bottom, leaving the viewer with a lingering sense of wonder and the desire to experience the thrill firsthand."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/sGqTf5scZcC5VNfOLbxwE_maxresdefault-2740110268.jpg"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "enum": [
          4,
          8,
          16,
          32,
          64
        ],
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
        "required": false,
        "minimum": 96,
        "maximum": 192,
        "default": 96
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4/effects",
    "title": "Pixverse",
    "category": "image-to-video",
    "description": "Generate high quality video clips with different effects using PixVerse v4",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": ""
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video.",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "effect": {
        "type": "string",
        "description": "The effect to apply to the video",
        "required": true,
        "enum": [
          "Kiss Me AI",
          "Kiss",
          "Muscle Surge",
          "Warmth of Jesus",
          "Anything, Robot",
          "The Tiger Touch",
          "Hug",
          "Holy Wings",
          "Microwave",
          "Zombie Mode",
          "Squid Game",
          "Baby Face",
          "Black Myth: Wukong",
          "Long Hair Magic",
          "Leggy Run",
          "Fin-tastic Mermaid",
          "Punch Face",
          "Creepy Devil Smile",
          "Thunder God",
          "Eye Zoom Challenge",
          "Who's Arrested?",
          "Baby Arrived",
          "Werewolf Rage",
          "Bald Swipe",
          "BOOM DROP",
          "Huge Cutie",
          "Liquid Metal",
          "Sharksnap!",
          "Dust Me Away",
          "3D Figurine Factor",
          "Bikini Up",
          "My Girlfriends",
          "My Boyfriends",
          "Subject 3 Fever",
          "Earth Zoom",
          "Pole Dance",
          "Vroom Dance",
          "GhostFace Terror",
          "Dragon Evoker",
          "Skeletal Bae",
          "Summoning succubus",
          "Halloween Voodoo Doll",
          "3D Naked-Eye AD",
          "Package Explosion",
          "Dishes Served",
          "Ocean ad",
          "Supermarket AD"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/magi-distilled/extend-video",
    "title": "MAGI-1 (Distilled)",
    "category": "video-to-video",
    "description": "MAGI-1 distilled extends videos faster with an exceptional understanding of physical interactions and prompts",
    "tags": [
      "video-to-video",
      "video-extend"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/magi-distilled/extend-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/magi-distilled/extend-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          ""
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video to represent the beginning of the video. If the input video does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/rabbit/lTH9PY_LQG0FjueBxMfDN_0395dec3-0c4a-4c25-8399-ebb198b73a30.mp4"
        ]
      },
      "start_frame": {
        "type": "integer",
        "description": "The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.",
        "required": false,
        "minimum": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "enum": [
          4,
          8,
          16,
          32
        ],
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
        "required": false,
        "minimum": 96,
        "maximum": 192,
        "default": 96
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/magi-distilled/image-to-video",
    "title": "MAGI-1 (Distilled)",
    "category": "image-to-video",
    "description": "MAGI-1 distilled generates videos faster from images with exceptional understanding of physical interactions and prompting",
    "tags": [
      "image-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/magi-distilled/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/magi-distilled/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins to pull back out over the ocean. Finally, the camera sinks below the waves deeply, fading to dark blue and finally to black."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/painebenjamin/pointy-seeds/refs/heads/main/captain-start.jpg"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "enum": [
          4,
          8,
          16,
          32
        ],
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
        "required": false,
        "minimum": 96,
        "maximum": 192,
        "default": 96
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/dia-tts/voice-clone",
    "title": "Dia Tts",
    "category": "audio-to-audio",
    "description": "Clone dialog voices from a sample audio and generate dialogs from text prompts using the Dia TTS which leverages advanced AI techniques to create high-quality text-to-speech.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dia-tts/voice-clone",
    "documentationUrl": "https://fal.ai/models/fal-ai/dia-tts/voice-clone/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to be converted to speech.",
        "required": true,
        "examples": [
          "[S1] Hello, how are you? [S2] I'm good, thank you. [S1] What's your name? [S2] My name is Dia. [S1] Nice to meet you. [S2] Nice to meet you too."
        ]
      },
      "ref_text": {
        "type": "string",
        "description": "The reference text to be used for TTS.",
        "required": true,
        "examples": [
          "[S1] Dia is an open weights text to dialogue model. [S2] You get full control over scripts and voices. [S1] Wow. Amazing. (laughs) [S2] Try it now on Fal."
        ]
      },
      "ref_audio_url": {
        "type": "string",
        "description": "The URL of the reference audio file.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/d5lORit2npFfBykcAtyUr_tmplacfh8oa.mp3"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated speech audio"
      }
    }
  },
  {
    "id": "fal-ai/framepack/flf2v",
    "title": "Framepack",
    "category": "image-to-video",
    "description": "Framepack is an efficient Image-to-video model that autoregressively generates videos.",
    "tags": [
      "image to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/framepack/flf2v",
    "documentationUrl": "https://fal.ai/models/fal-ai/framepack/flf2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation (max 500 characters).",
        "required": true,
        "examples": [
          "A tabby cat is confidely strolling toward the camera, when it spins and with a flash of magic reveals itself to be a cat-dragon hybrid with glistening amber scales."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
        "required": false,
        "enum": [
          "720p",
          "480p"
        ],
        "default": "480p"
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 30,
        "maximum": 1800,
        "default": 240
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan_flf/first_frame.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 32,
        "default": 10
      },
      "seed": {
        "type": null,
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "end_image_url": {
        "type": "string",
        "description": "URL of the end image input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan_flf/last_frame.png"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "",
        "examples": [
          "Ugly, blurry distorted, bad quality"
        ]
      },
      "cfg_scale": {
        "type": "number",
        "description": "Classifier-Free Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 7,
        "default": 1
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/dia-tts",
    "title": "Dia",
    "category": "text-to-speech",
    "description": "Dia directly generates realistic dialogue from transcripts. Audio conditioning enables emotion control. Produces natural nonverbals like laughter and throat clearing.",
    "tags": [
      "text-to-speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dia-tts",
    "documentationUrl": "https://fal.ai/models/fal-ai/dia-tts/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to be converted to speech.",
        "required": true,
        "examples": [
          "[S1] Dia is an open weights text to dialogue model. [S2] You get full control over scripts and voices. [S1] Wow. Amazing. (laughs) [S2] Try it now on Fal."
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated speech audio"
      }
    }
  },
  {
    "id": "fal-ai/magi-distilled",
    "title": "MAGI-1 (Distilled)",
    "category": "text-to-video",
    "description": "MAGI-1 distilled is a faster video generation model with exceptional understanding of physical interactions and cinematic prompts",
    "tags": [
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/magi-distilled",
    "documentationUrl": "https://fal.ai/models/fal-ai/magi-distilled/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins a slow clockwise orbit, pulling back. Finally, the camera rises high above, revealing the entire wooden sailing ship cutting through the waves, the captain unmoved, gazing toward the distant horizon."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "enum": [
          4,
          8,
          16,
          32
        ],
        "default": 16
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
        "required": false,
        "minimum": 96,
        "maximum": 192,
        "default": 96
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/smart-turn",
    "title": "Pipecat's Smart Turn model",
    "category": "speech-to-text",
    "description": "An open source, community-driven and native audio turn detection model by Pipecat AI.\n\n",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/smart-turn",
    "documentationUrl": "https://fal.ai/models/fal-ai/smart-turn/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio file to be processed.",
        "required": true,
        "examples": [
          "https://fal.media/files/panda/5-QaAOC32rB_hqWaVdqEH.mpga"
        ]
      }
    },
    "outputParameters": {
      "prediction": {
        "type": "integer",
        "description": "The predicted turn type. 1 for Complete, 0 for Incomplete."
      },
      "probability": {
        "type": "number",
        "description": "The probability of the predicted turn type."
      },
      "metrics": {
        "type": "object",
        "description": "The metrics of the inference."
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux-lora/inpainting",
    "title": "Juggernaut Flux Lora",
    "category": "image-to-image",
    "description": "Juggernaut Base Flux LoRA Inpainting by RunDiffusion is a drop-in replacement for Flux [Dev] inpainting that delivers sharper details, richer colors, and enhanced realism to all your LoRAs and LyCORIS with full compatibility.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-lora.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux-lora/inpainting",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux-lora/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "mask_url": {
        "type": "string",
        "description": "\n            The mask to area to Inpaint in.\n        ",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fashn/tryon/v1.5",
    "title": "FASHN Virtual Try-On V1.5",
    "category": "image-to-image",
    "description": "FASHN v1.5 delivers precise virtual try-on capabilities, accurately rendering garment details like text and patterns at 576x864 resolution from both on-model and flat-lay photo references.",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fashn_wide.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fashn/tryon/v1.5",
    "documentationUrl": "https://fal.ai/models/fal-ai/fashn/tryon/v1.5/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model_image": {
        "type": "string",
        "description": "URL or base64 of the model image",
        "required": true,
        "examples": [
          "https://utfs.io/f/wXFHUNfTHmLj4prvqbRMQ6JXFyUr3IT0avK2HSOmZWiAsxg9"
        ]
      },
      "moderation_level": {
        "type": "string",
        "description": "Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.",
        "required": false,
        "enum": [
          "none",
          "permissive",
          "conservative"
        ],
        "default": "permissive"
      },
      "garment_photo_type": {
        "type": "string",
        "description": "Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.",
        "required": false,
        "enum": [
          "auto",
          "model",
          "flat-lay"
        ],
        "default": "auto"
      },
      "garment_image": {
        "type": "string",
        "description": "URL or base64 of the garment image",
        "required": true,
        "examples": [
          "https://utfs.io/f/wXFHUNfTHmLjtkhepmqOUnkr8XxZbNIFmRWldShDLu320TeC"
        ]
      },
      "category": {
        "type": "string",
        "description": "Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.",
        "required": false,
        "enum": [
          "tops",
          "bottoms",
          "one-pieces",
          "auto"
        ],
        "default": "auto"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "segmentation_free": {
        "type": "boolean",
        "description": "Disables human parsing on the model image.",
        "required": false,
        "default": true
      },
      "num_samples": {
        "type": "integer",
        "description": "Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "mode": {
        "type": "string",
        "description": "Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.",
        "required": false,
        "enum": [
          "performance",
          "balanced",
          "quality"
        ],
        "default": "balanced"
      },
      "seed": {
        "type": "integer",
        "description": "Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "png"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/plushify",
    "title": "Plushify",
    "category": "image-to-image",
    "description": "Turn any image into a cute plushie!",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/plushie_thumbnail.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/plushify",
    "documentationUrl": "https://fal.ai/models/fal-ai/plushify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt for the generation. Default is empty which is usually best, but sometimes it can help to add a description of the subject.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "use_cfg_zero": {
        "type": "boolean",
        "description": "Whether to use CFG zero",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to apply cartoon style to",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/c8VSfX5XtJ3DCzV-4Bxg8_kid_image.png"
        ]
      },
      "scale": {
        "type": "number",
        "description": "Scale factor for the Cartoon effect",
        "required": false,
        "minimum": 0.1,
        "maximum": 2,
        "default": 1
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed for image generation. Same seed with same parameters will generate same image.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/instant-character",
    "title": "Instant Character",
    "category": "image-to-image",
    "description": "InstantCharacter creates high-quality, consistent characters from text prompts, supporting diverse poses, styles, and appearances with strong identity control.",
    "tags": [
      "personalization",
      "customization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-3.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/instant-character",
    "documentationUrl": "https://fal.ai/models/fal-ai/instant-character/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A girl is playing a guitar in street"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/girl.jpg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any only 1 lora at a time.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "scale": {
        "type": "number",
        "description": "The scale of the subject image. Higher values will make the subject image more prominent in the generated image.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/wan-flf2v",
    "title": "Wan-2.1 First-Last-Frame-to-Video",
    "category": "image-to-video",
    "description": "Wan-2.1 flf2v generates dynamic videos by intelligently bridging a given first frame to a desired end frame through smooth, coherent motion sequences.",
    "tags": [
      "image to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-flf2v",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-flf2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A tabby cat is confidely strolling toward the camera, when it spins and with a flash of magic reveals itself to be a cat-dragon hybrid with glistening amber scales."
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "acceleration": {
        "type": "string",
        "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
        "required": false,
        "enum": [
          "none",
          "regular"
        ],
        "default": "regular",
        "examples": [
          "regular"
        ]
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "start_image_url": {
        "type": "string",
        "description": "URL of the starting image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan_flf/first_frame.png"
        ]
      },
      "end_image_url": {
        "type": "string",
        "description": "URL of the ending image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/wan_flf/last_frame.png"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 81,
        "maximum": 100,
        "default": 81
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "auto"
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "guide_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/turbo-flux-trainer",
    "title": "Turbo Flux Trainer",
    "category": "training",
    "description": "A blazing fast FLUX dev LoRA trainer for subjects and styles.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/turbo-flux-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/turbo-flux-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "images_data_url": {
        "type": "string",
        "description": "\n        URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n        ",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "Trigger phrase to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_work will be used instead of captions. If captions are provided, the trigger word will replace the `[trigger]` string in the captions.\n        ",
        "required": false,
        "default": "ohwx"
      },
      "steps": {
        "type": "integer",
        "description": "Number of steps to train the LoRA on.",
        "required": false,
        "minimum": 1,
        "maximum": 10000,
        "default": 1000,
        "examples": [
          1000
        ]
      },
      "learning_rate": {
        "type": "number",
        "description": "Learning rate for the training.",
        "required": false,
        "minimum": 1e-07,
        "maximum": 0.01,
        "default": 0.00115
      },
      "training_style": {
        "type": "string",
        "description": "Training style to use.",
        "required": false,
        "enum": [
          "subject",
          "style"
        ],
        "default": "subject"
      },
      "face_crop": {
        "type": "boolean",
        "description": "Whether to try to detect the face and crop the images to the face.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "config_file": {
        "type": null,
        "description": "URL to the trained diffusers config file."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "URL to the trained diffusers lora weights."
      }
    }
  },
  {
    "id": "fal-ai/framepack",
    "title": "Framepack",
    "category": "image-to-video",
    "description": "Framepack is an efficient Image-to-video model that autoregressively generates videos.",
    "tags": [
      "image to video",
      "motion"
    ],
    "thumbnailUrl": "https://v3.fal.media/files/koala/dUfFd9Z7aSX06gL2_qXn0_image.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/framepack",
    "documentationUrl": "https://fal.ai/models/fal-ai/framepack/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation (max 500 characters).",
        "required": true,
        "examples": [
          "A mesmerising video of a deep sea jellyfish moving through an inky-black ocean. The jellyfish glows softly with an amber bioluminescence. The overall scene is lifelike."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
        "required": false,
        "enum": [
          "720p",
          "480p"
        ],
        "default": "480p"
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate.",
        "required": false,
        "minimum": 30,
        "maximum": 900,
        "default": 180
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/framepack/framepack.jpg"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 32,
        "default": 10
      },
      "seed": {
        "type": null,
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "",
        "examples": [
          "Ugly, blurry distorted, bad quality"
        ]
      },
      "cfg_scale": {
        "type": "number",
        "description": "Classifier-Free Guidance scale for the generation.",
        "required": false,
        "minimum": 0,
        "maximum": 7,
        "default": 1
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/cartoonify",
    "title": "Cartoonify",
    "category": "image-to-image",
    "description": "Transform images into 3D cartoon artwork using an AI model that applies cartoon stylization while preserving the original image's composition and details.",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/cartoonify",
    "documentationUrl": "https://fal.ai/models/fal-ai/cartoonify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "use_cfg_zero": {
        "type": "boolean",
        "description": "Whether to use CFG zero",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to apply Pixar style to",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/c8VSfX5XtJ3DCzV-4Bxg8_kid_image.png"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the generation",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "scale": {
        "type": "number",
        "description": "Scale factor for the Pixar effect",
        "required": false,
        "minimum": 0.1,
        "maximum": 2,
        "default": 1
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed for image generation. Same seed with same parameters will generate same image.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/wan-vace",
    "title": "Vace",
    "category": "video-to-video",
    "description": "Vace a video generation model that uses a source image, mask, and video to create prompted videos with controllable sources.",
    "tags": [
      "video-to-video",
      "image-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-vace",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-vace/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "video_url": {
        "type": "string",
        "description": "URL to the source video file. If provided, the model will use this video as a reference.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_video.mp4"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse."
        ]
      },
      "ref_image_urls": {
        "type": "array",
        "description": "Urls to source reference image. If provided, the model will use this image as reference.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/vace/src_ref_image_1.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "task": {
        "type": "string",
        "description": "Task type for the model.",
        "required": false,
        "enum": [
          "depth",
          "inpainting"
        ],
        "default": "depth"
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "mask_image_url": {
        "type": "string",
        "description": "URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video. If provided mask video url will be ignored.",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames",
        "required": false,
        "minimum": 81,
        "maximum": 240,
        "default": 81
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "auto",
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p,580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "mask_video_url": {
        "type": "string",
        "description": "URL to the source mask file. If provided, the model will use this mask as a reference.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/vace/src_mask.mp4"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      },
      "preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the input video.",
        "required": false,
        "default": false
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/finegrain-eraser/mask",
    "title": "finegrain eraser",
    "category": "image-to-image",
    "description": "Finegrain Eraser removes any object selected with a mask—along with its shadows, reflections, and lighting artifacts—seamlessly reconstructing the scene with contextually accurate content.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/finegrain-eraser/mask",
    "documentationUrl": "https://fal.ai/models/fal-ai/finegrain-eraser/mask/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "mode": {
        "type": "string",
        "description": "Erase quality mode",
        "required": false,
        "enum": [
          "express",
          "standard",
          "premium"
        ],
        "default": "standard"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation",
        "required": false,
        "minimum": 0,
        "maximum": 999
      },
      "mask_url": {
        "type": "string",
        "description": "URL of the mask image. Should be a binary mask where white (255) indicates areas to erase",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/panda/-31cZrsoy-8BrLqOEFmST_indir%20(18).png"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to edit",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/IKqKIxDfRDK8fzeETCveO_erase_example01.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The edited image with content erased"
      },
      "used_seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/finegrain-eraser/bbox",
    "title": "finegrain eraser",
    "category": "image-to-image",
    "description": "Finegrain Eraser removes any object selected with a bounding box—along with its shadows, reflections, and lighting artifacts—seamlessly reconstructing the scene with contextually accurate content.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/finegrain-eraser/bbox",
    "documentationUrl": "https://fal.ai/models/fal-ai/finegrain-eraser/bbox/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "mode": {
        "type": "string",
        "description": "Erase quality mode",
        "required": false,
        "enum": [
          "express",
          "standard",
          "premium"
        ],
        "default": "standard"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation",
        "required": false,
        "minimum": 0,
        "maximum": 999
      },
      "box_prompts": {
        "type": "array",
        "description": "List of bounding box coordinates to erase (only one box prompt is supported)",
        "required": true,
        "items": {
          "$ref": "#/components/schemas/BoxPromptBase"
        }
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to edit",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/IKqKIxDfRDK8fzeETCveO_erase_example01.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The edited image with content erased"
      },
      "used_seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/finegrain-eraser",
    "title": "finegrain eraser",
    "category": "image-to-image",
    "description": "Finegrain Eraser removes objects—along with their shadows, reflections, and lighting artifacts—using only natural language, seamlessly filling the scene with contextually accurate content.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/finegrain-eraser",
    "documentationUrl": "https://fal.ai/models/fal-ai/finegrain-eraser/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text description of what to erase",
        "required": true,
        "examples": [
          "person on the right and snowboard"
        ]
      },
      "mode": {
        "type": "string",
        "description": "Erase quality mode",
        "required": false,
        "enum": [
          "express",
          "standard",
          "premium"
        ],
        "default": "standard"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation",
        "required": false,
        "minimum": 0,
        "maximum": 999
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to edit",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/IKqKIxDfRDK8fzeETCveO_erase_example01.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The edited image with content erased"
      },
      "used_seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "cassetteai/video-sound-effects-generator",
    "title": "Video Sound Effects Generator",
    "category": "video-to-video",
    "description": "Add sound effects to your videos",
    "tags": [
      "sound-effects",
      "sfx",
      "cassetteai"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/cassetteai-video-sound-effects-generator.webp",
    "playgroundUrl": "https://fal.ai/models/cassetteai/video-sound-effects-generator",
    "documentationUrl": "https://fal.ai/models/cassetteai/video-sound-effects-generator/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": null,
        "description": "A video file to analyze & re-sound with generated SFX.",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/3NOa3BqrJfr3jJBMqGexs_final_with_sfx.mp4",
          "https://v3.fal.media/files/rabbit/vkNtbcJ3x7KmzjJZeVWQe_final_with_sfx.mp4"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The final video with the newly generated SFX track."
      }
    }
  },
  {
    "id": "fal-ai/speech-to-text/turbo",
    "title": "Speech-to-Text",
    "category": "speech-to-text",
    "description": "Leverage the rapid processing capabilities of AI models to enable accurate and efficient real-time speech-to-text transcription.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/canary.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/speech-to-text/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/speech-to-text/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "Local filesystem path (or remote URL) to a long audio file",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/canary/18e15559-ab3e-4f96-9583-be5ddde91e43.mp3"
        ]
      },
      "use_pnc": {
        "type": "boolean",
        "description": "Whether to use Canary's built-in punctuation & capitalization",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "partial": {
        "type": "boolean",
        "description": "Indicates if this is a partial (in-progress) transcript"
      },
      "output": {
        "type": "string",
        "description": "The partial or final transcription output from Canary"
      }
    }
  },
  {
    "id": "fal-ai/speech-to-text/turbo/stream",
    "title": "Speech-to-Text",
    "category": "speech-to-text",
    "description": "Leverage the rapid processing capabilities of AI models to enable accurate and efficient real-time speech-to-text transcription.",
    "tags": [
      "streaming"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/canary.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/speech-to-text/turbo/stream",
    "documentationUrl": "https://fal.ai/models/fal-ai/speech-to-text/turbo/stream/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "Local filesystem path (or remote URL) to a long audio file",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/canary/18e15559-ab3e-4f96-9583-be5ddde91e43.mp3"
        ]
      },
      "use_pnc": {
        "type": "boolean",
        "description": "Whether to use Canary's built-in punctuation & capitalization",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {}
  },
  {
    "id": "fal-ai/speech-to-text/stream",
    "title": "Speech-To-text",
    "category": "speech-to-text",
    "description": "Leverage the rapid processing capabilities of AI models to enable accurate and efficient real-time speech-to-text transcription.",
    "tags": [
      "streaming"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/canary.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/speech-to-text/stream",
    "documentationUrl": "https://fal.ai/models/fal-ai/speech-to-text/stream/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "Local filesystem path (or remote URL) to a long audio file",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/canary/18e15559-ab3e-4f96-9583-be5ddde91e43.mp3"
        ]
      },
      "use_pnc": {
        "type": "boolean",
        "description": "Whether to use Canary's built-in punctuation & capitalization",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {}
  },
  {
    "id": "fal-ai/speech-to-text",
    "title": "Speech-to-Text",
    "category": "speech-to-text",
    "description": "Leverage the rapid processing capabilities of AI models to enable accurate and efficient real-time speech-to-text transcription.",
    "tags": [
      ""
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/canary.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/speech-to-text",
    "documentationUrl": "https://fal.ai/models/fal-ai/speech-to-text/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "Local filesystem path (or remote URL) to a long audio file",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/canary/18e15559-ab3e-4f96-9583-be5ddde91e43.mp3"
        ]
      },
      "use_pnc": {
        "type": "boolean",
        "description": "Whether to use Canary's built-in punctuation & capitalization",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "partial": {
        "type": "boolean",
        "description": "Indicates if this is a partial (in-progress) transcript"
      },
      "output": {
        "type": "string",
        "description": "The partial or final transcription output from Canary"
      }
    }
  },
  {
    "id": "cassetteai/sound-effects-generator",
    "title": "Sound Effects Generator",
    "category": "text-to-audio",
    "description": "Create stunningly realistic sound effects in seconds - CassetteAI's Sound Effects Model generates high-quality SFX up to 30 seconds long in just 1 second of processing time",
    "tags": [
      "sound",
      "sfx",
      "sound-effects",
      "cassetteai"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/cassetteai-sound-effects-generator.webp",
    "playgroundUrl": "https://fal.ai/models/cassetteai/sound-effects-generator",
    "documentationUrl": "https://fal.ai/models/cassetteai/sound-effects-generator/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate SFX.",
        "required": true,
        "examples": [
          "dog barking in the rain"
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated SFX in seconds.",
        "required": true,
        "minimum": 1,
        "maximum": 30,
        "examples": [
          30
        ]
      }
    },
    "outputParameters": {
      "audio_file": {
        "type": null,
        "description": "The generated SFX"
      }
    }
  },
  {
    "id": "fal-ai/sync-lipsync/v2",
    "title": "Sync Lipsync 2.0",
    "category": "video-to-video",
    "description": "Generate realistic lipsync animations from audio using advanced algorithms for high-quality synchronization with Sync Lipsync 2.0 model",
    "tags": [
      "animation",
      "lip sync"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/LXWSAzq0Snzf2xmt-qPQL_62439375ce7745769a977f3989d035d7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sync-lipsync/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/sync-lipsync/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "The model to use for lipsyncing. `lipsync-2-pro` will cost roughly 1.67 times as much as `lipsync-2` for the same duration.",
        "required": false,
        "enum": [
          "lipsync-2",
          "lipsync-2-pro"
        ],
        "default": "lipsync-2"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/tiger/IugLCDJRIoGqvqTa-EJTr_3wg74vCqyNuQ-IiBd77MM_output.mp4"
        ]
      },
      "sync_mode": {
        "type": "string",
        "description": "Lipsync mode when audio and video durations are out of sync.",
        "required": false,
        "enum": [
          "cut_off",
          "loop",
          "bounce",
          "silence",
          "remap"
        ],
        "default": "cut_off"
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the input audio",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/vyFWygmZsIZlUO4s0nr2n.wav"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/star-vector",
    "title": "StarVector",
    "category": "image-to-image",
    "description": "AI vectorization model that transforms raster images into scalable SVG graphics, preserving visual details while enabling infinite scaling and easy editing capabilities.\n\n",
    "tags": [
      "image-to-image"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/starvector.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/star-vector",
    "documentationUrl": "https://fal.ai/models/fal-ai/star-vector/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "seed to be used for generation",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/star-vector/sample-18.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4/image-to-video/fast",
    "title": "PixVerse v4: Image to Video Fast",
    "category": "image-to-video",
    "description": "Generate fast high quality video clips from text and image prompts using PixVerse v4",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4/image-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4/image-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A woman warrior with her hammer walking with his glacier wolf."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "camera_movement": {
        "type": "string",
        "description": "The type of camera movement to apply to the video",
        "required": false,
        "enum": [
          "horizontal_left",
          "horizontal_right",
          "vertical_up",
          "vertical_down",
          "zoom_in",
          "zoom_out",
          "crane_up",
          "quickly_zoom_in",
          "quickly_zoom_out",
          "smooth_zoom_in",
          "camera_rotation",
          "robo_arm",
          "super_dolly_out",
          "whip_pan",
          "hitchcock",
          "left_follow",
          "right_follow",
          "pan_left",
          "pan_right",
          "fix_bg"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4/image-to-video",
    "title": "PixVerse v4: Image to Video",
    "category": "image-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A woman warrior with her hammer walking with his glacier wolf."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "camera_movement": {
        "type": "string",
        "description": "The type of camera movement to apply to the video",
        "required": false,
        "enum": [
          "horizontal_left",
          "horizontal_right",
          "vertical_up",
          "vertical_down",
          "zoom_in",
          "zoom_out",
          "crane_up",
          "quickly_zoom_in",
          "quickly_zoom_out",
          "smooth_zoom_in",
          "camera_rotation",
          "robo_arm",
          "super_dolly_out",
          "whip_pan",
          "hitchcock",
          "left_follow",
          "right_follow",
          "pan_left",
          "pan_right",
          "fix_bg"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/effects",
    "title": "PixVerse v3.5: Effects",
    "category": "image-to-video",
    "description": "Generate high quality video clips with different effects using PixVerse v3.5",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": ""
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video.",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "effect": {
        "type": "string",
        "description": "The effect to apply to the video",
        "required": true,
        "enum": [
          "Kiss Me AI",
          "Kiss",
          "Muscle Surge",
          "Warmth of Jesus",
          "Anything, Robot",
          "The Tiger Touch",
          "Hug",
          "Holy Wings",
          "Microwave",
          "Zombie Mode",
          "Squid Game",
          "Baby Face",
          "Black Myth: Wukong",
          "Long Hair Magic",
          "Leggy Run",
          "Fin-tastic Mermaid",
          "Punch Face",
          "Creepy Devil Smile",
          "Thunder God",
          "Eye Zoom Challenge",
          "Who's Arrested?",
          "Baby Arrived",
          "Werewolf Rage",
          "Bald Swipe",
          "BOOM DROP",
          "Huge Cutie",
          "Liquid Metal",
          "Sharksnap!",
          "Dust Me Away",
          "3D Figurine Factor",
          "Bikini Up",
          "My Girlfriends",
          "My Boyfriends",
          "Subject 3 Fever",
          "Earth Zoom",
          "Pole Dance",
          "Vroom Dance",
          "GhostFace Terror",
          "Dragon Evoker",
          "Skeletal Bae",
          "Summoning succubus",
          "Halloween Voodoo Doll",
          "3D Naked-Eye AD",
          "Package Explosion",
          "Dishes Served",
          "Ocean ad",
          "Supermarket AD"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
        "required": false,
        "examples": [
          "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4/text-to-video",
    "title": "PixVerse v4: Text to Video",
    "category": "text-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/transition",
    "title": "PixVerse v3.5: Transition",
    "category": "image-to-video",
    "description": "Create seamless transition between images using PixVerse v3.5",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/transition",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/transition/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "first_image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/owQh2DAzk8UU7J02nr5RY_Co2P4boLv6meIZ5t9gKvL_8685da151df343ab8bf82165c928e2a5.jpg"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The prompt for the transition",
        "required": true,
        "examples": [
          "Scene slowly transition into cat swimming under water"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      },
      "last_image_url": {
        "type": "string",
        "description": "URL of the image to use as the last frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/RgedFs_WSnq5BgER7qDx1_ONrbTJ1YAGXz-9JnSsBoB_bdc8750387734bfe940319f469f7b0b2.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v4/text-to-video/fast",
    "title": "PixVerse v4: Text to Video Fast",
    "category": "text-to-video",
    "description": "Generate high quality and fast video clips from text and image prompts using PixVerse v4 fast",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v4/text-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v4/text-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ghiblify",
    "title": "Ghiblify Images",
    "category": "image-to-image",
    "description": "Reimagine and transform your ordinary photos into enchanting Studio Ghibli style artwork",
    "tags": [
      "stylized",
      "transform"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/ghibli/ghibli_example.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ghiblify",
    "documentationUrl": "https://fal.ai/models/fal-ai/ghiblify/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": null,
        "description": "The seed to use for the upscale. If not provided, a random seed will be used.",
        "required": false,
        "examples": [
          null
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to upscale.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/QMPFC_avr-fEywDjp2ujy_60f6e32332384cada30c7016599d93e8.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The URL of the generated image."
      }
    }
  },
  {
    "id": "fal-ai/orpheus-tts",
    "title": "Orpheus TTS",
    "category": "text-to-speech",
    "description": "Orpheus TTS is a state-of-the-art, Llama-based Speech-LLM designed for high-quality, empathetic text-to-speech generation. This model has been finetuned to deliver human-level speech synthesis, achieving exceptional clarity, expressiveness, and real-time performances.",
    "tags": [
      "text to speech",
      "voice synthesis",
      "high-fidelity"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/orpheus-tts",
    "documentationUrl": "https://fal.ai/models/fal-ai/orpheus-tts/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>",
        "required": true,
        "examples": [
          "I just found a hidden treasure in the backyard! <gasp> Check it out!"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": false,
        "enum": [
          "tara",
          "leah",
          "jess",
          "leo",
          "dan",
          "mia",
          "zac",
          "zoe"
        ],
        "default": "tara",
        "examples": [
          "tara"
        ]
      },
      "repetition_penalty": {
        "type": "number",
        "description": "Repetition penalty (>= 1.1 required for stable generations).",
        "required": false,
        "minimum": 1.1,
        "maximum": 2,
        "default": 1.2
      },
      "temperature": {
        "type": "number",
        "description": "Temperature for generation (higher = more creative).",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 0.7
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated speech audio"
      }
    }
  },
  {
    "id": "fal-ai/sana/v1.5/1.6b",
    "title": "Sana v1.5 1.6B",
    "category": "text-to-image",
    "description": "Sana v1.5 1.6B is a lightweight text-to-image model that delivers 4K image generation with impressive efficiency.",
    "tags": [
      "text to image",
      "4k",
      "lightweight"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sana.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sana/v1.5/1.6b",
    "documentationUrl": "https://fal.ai/models/fal-ai/sana/v1.5/1.6b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 2160,
          "width": 3840
        }
      },
      "style_name": {
        "type": "string",
        "description": "The style to generate the image in.",
        "required": false,
        "enum": [
          "(No style)",
          "Cinematic",
          "Photographic",
          "Anime",
          "Manga",
          "Digital Art",
          "Pixel art",
          "Fantasy art",
          "Neonpunk",
          "3D Model"
        ],
        "default": "(No style)"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 18
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sana/v1.5/4.8b",
    "title": "Sana v1.5 4.8B",
    "category": "text-to-image",
    "description": "Sana v1.5 4.8B is a powerful text-to-image model that generates ultra-high quality 4K images with remarkable detail.",
    "tags": [
      "text to image",
      "4k",
      "high-quality"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sana.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sana/v1.5/4.8b",
    "documentationUrl": "https://fal.ai/models/fal-ai/sana/v1.5/4.8b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 2160,
          "width": 3840
        }
      },
      "style_name": {
        "type": "string",
        "description": "The style to generate the image in.",
        "required": false,
        "enum": [
          "(No style)",
          "Cinematic",
          "Photographic",
          "Anime",
          "Manga",
          "Digital Art",
          "Pixel art",
          "Fantasy art",
          "Neonpunk",
          "3D Model"
        ],
        "default": "(No style)"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 18
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sana/sprint",
    "title": "Sana Sprint",
    "category": "text-to-image",
    "description": "Sana Sprint is a text-to-image model capable of generating 4K images with exceptional speed.",
    "tags": [
      "text to image",
      "4k",
      "high-speed"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Upscale-6.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sana/sprint",
    "documentationUrl": "https://fal.ai/models/fal-ai/sana/sprint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 2160,
          "width": 3840
        }
      },
      "style_name": {
        "type": "string",
        "description": "The style to generate the image in.",
        "required": false,
        "enum": [
          "(No style)",
          "Cinematic",
          "Photographic",
          "Anime",
          "Manga",
          "Digital Art",
          "Pixel art",
          "Fantasy art",
          "Neonpunk",
          "3D Model"
        ],
        "default": "(No style)"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 2
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "cassetteai/music-generator",
    "title": "music generator",
    "category": "text-to-audio",
    "description": "CassetteAI’s model generates a 30-second sample in under 2 seconds and a full 3-minute track in under 10 seconds. At 44.1 kHz stereo audio, expect a level of professional consistency with no breaks, no squeaks, and no random interruptions in your creations.\n\n",
    "tags": [
      "music",
      "cassetteai"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/sMvFmn2J_7gVG77CCgseb_728490598d0242a2abf19f7fae6a93a6.jpg",
    "playgroundUrl": "https://fal.ai/models/cassetteai/music-generator",
    "documentationUrl": "https://fal.ai/models/cassetteai/music-generator/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate music from.",
        "required": true,
        "examples": [
          "Smooth chill hip-hop beat with mellow piano melodies, deep bass, and soft drums, perfect for a night drive. Key: D Minor, Tempo: 90 BPM."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated music in seconds.",
        "required": true,
        "minimum": 10,
        "maximum": 180,
        "examples": [
          50
        ]
      }
    },
    "outputParameters": {
      "audio_file": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/lipsync/text-to-video",
    "title": "Kling LipSync Text-to-Video",
    "category": "text-to-video",
    "description": "Kling LipSync is a text-to-video model that generates realistic lip movements from text input.",
    "tags": [
      "text to video",
      "lipsync"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/lipsync/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/lipsync/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "Text content for lip-sync video generation. Max 120 characters.",
        "required": true,
        "maxLength": 120,
        "examples": [
          "Mental health is as important as physical health, shaping our emotions, thoughts, and daily interactions."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2-60s, 720p/1080p only, width/height 720–1920px. If validation fails, an error is returned.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/8teUPbRRMtAUTORDvqy0l.mp4"
        ]
      },
      "voice_id": {
        "type": "string",
        "description": "Voice ID to use for speech synthesis",
        "required": true,
        "enum": [
          "genshin_vindi2",
          "zhinen_xuesheng",
          "AOT",
          "ai_shatang",
          "genshin_klee2",
          "genshin_kirara",
          "ai_kaiya",
          "oversea_male1",
          "ai_chenjiahao_712",
          "girlfriend_4_speech02",
          "chat1_female_new-3",
          "chat_0407_5-1",
          "cartoon-boy-07",
          "uk_boy1",
          "cartoon-girl-01",
          "PeppaPig_platform",
          "ai_huangzhong_712",
          "ai_huangyaoshi_712",
          "ai_laoguowang_712",
          "chengshu_jiejie",
          "you_pingjing",
          "calm_story1",
          "uk_man2",
          "laopopo_speech02",
          "heainainai_speech02",
          "reader_en_m-v1",
          "commercial_lady_en_f-v1",
          "tiyuxi_xuedi",
          "tiexin_nanyou",
          "girlfriend_1_speech02",
          "girlfriend_2_speech02",
          "zhuxi_speech02",
          "uk_oldman3",
          "dongbeilaotie_speech02",
          "chongqingxiaohuo_speech02",
          "chuanmeizi_speech02",
          "chaoshandashu_speech02",
          "ai_taiwan_man2_speech02",
          "xianzhanggui_speech02",
          "tianjinjiejie_speech02",
          "diyinnansang_DB_CN_M_04-v2",
          "yizhipiannan-v1",
          "guanxiaofang-v2",
          "tianmeixuemei-v1",
          "daopianyansang-v1",
          "mengwa-v1"
        ],
        "examples": [
          "genshin_klee2"
        ]
      },
      "voice_language": {
        "type": "string",
        "description": "The voice language corresponding to the Voice ID",
        "required": false,
        "enum": [
          "zh",
          "en"
        ],
        "default": "en"
      },
      "voice_speed": {
        "type": "number",
        "description": "Speech rate for Text to Video generation",
        "required": false,
        "minimum": 0.8,
        "maximum": 2,
        "default": 1
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/lipsync/audio-to-video",
    "title": "Kling LipSync Audio-to-Video",
    "category": "text-to-video",
    "description": "Kling LipSync is an audio-to-video model that generates realistic lip movements from audio input.",
    "tags": [
      "audio to video",
      "lipsync"
    ],
    "thumbnailUrl": "https://v3b.fal.media/files/b/elephant/njNipNC0TkA9fJguiS1NB_c75b090e2ebb4d9581d21d66cfc4a0d3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/lipsync/audio-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/lipsync/audio-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2–10s, 720p/1080p only, width/height 720–1920px.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/8teUPbRRMtAUTORDvqy0l.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/kling/kling-audio.mp3"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/latentsync",
    "title": "LatentSync",
    "category": "video-to-video",
    "description": "LatentSync is a video-to-video model that generates lip sync animations from audio using advanced algorithms for high-quality synchronization.",
    "tags": [
      "animation",
      "lip sync"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/latentsync/latentsync-3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/latentsync",
    "documentationUrl": "https://fal.ai/models/fal-ai/latentsync/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the video to generate the lip sync for.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/8teUPbRRMtAUTORDvqy0l.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "The URL of the audio to generate the lip sync for.",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/vyFWygmZsIZlUO4s0nr2n.wav"
        ]
      },
      "seed": {
        "type": null,
        "description": "Random seed for generation. If None, a random seed will be used.",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model inference",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "loop_mode": {
        "type": null,
        "description": "Video loop mode when audio is longer than video. Options: pingpong, loop",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with the lip sync."
      }
    }
  },
  {
    "id": "fal-ai/wan-t2v-lora",
    "title": "Wan-2.1 Text-to-Video with LoRAs",
    "category": "text-to-video",
    "description": "Add custom LoRAs to Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from images",
    "tags": [
      "\"text to video\"",
      "\"motion\"",
      "\"lora\""
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/wan-i2v-lora.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-t2v-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-t2v-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p,580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "480p"
      },
      "reverse_video": {
        "type": "boolean",
        "description": "If true, the video will be reversed.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to be used in the inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "turbo_mode": {
        "type": "boolean",
        "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
        "required": false,
        "default": true
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive).",
        "required": false,
        "minimum": 81,
        "maximum": 100,
        "default": 81
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/wan-trainer",
    "title": "Wan-2.1 LoRA Trainer",
    "category": "training",
    "description": "Train custom LoRAs for Wan-2.1 I2V 480P",
    "tags": [
      "lora",
      "training"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/wan-trainer.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "number_of_steps": {
        "type": "integer",
        "description": "The number of steps to train for.",
        "required": false,
        "minimum": 1,
        "maximum": 20000,
        "default": 400
      },
      "training_data_url": {
        "type": "string",
        "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.",
        "required": true
      },
      "trigger_phrase": {
        "type": "string",
        "description": "The phrase that will trigger the model to generate an image.",
        "required": false,
        "default": ""
      },
      "learning_rate": {
        "type": "number",
        "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
        "required": false,
        "minimum": 1e-06,
        "maximum": 1,
        "default": 0.0002
      },
      "auto_scale_input": {
        "type": "boolean",
        "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      }
    },
    "outputParameters": {
      "lora_file": {
        "type": null,
        "description": "URL to the trained LoRA weights."
      },
      "config_file": {
        "type": null,
        "description": "Configuration used for setting up the inference endpoints."
      }
    }
  },
  {
    "id": "fal-ai/thera",
    "title": "Thera",
    "category": "image-to-image",
    "description": "Fix low resolution images with fast speed and quality of thera.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/thera.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/thera",
    "documentationUrl": "https://fal.ai/models/fal-ai/thera/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": null,
        "description": "Random seed for reproducible generation.",
        "required": false
      },
      "backbone": {
        "type": "string",
        "description": "Backbone to use for upscaling",
        "required": true,
        "enum": [
          "edsr",
          "rdn"
        ],
        "examples": [
          "edsr"
        ]
      },
      "upscaling": {
        "type": "number",
        "description": "",
        "required": false,
        "minimum": 1,
        "maximum": 6,
        "default": 2
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for upscaling",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/docres_ckpt/NoN6cImXI9DCeEYzX7-a7_1224f6da06354948ab477fa450e8c4f6.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/mix-dehaze-net",
    "title": "MixDehazer",
    "category": "image-to-image",
    "description": "An advanced dehaze model to remove atmospheric haze, restoring clarity and detail in images through intelligent neural network processing.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/mix-dehaze.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/mix-dehaze-net",
    "documentationUrl": "https://fal.ai/models/fal-ai/mix-dehaze-net/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "Model to be used for dehazing",
        "required": false,
        "enum": [
          "indoor",
          "outdoor"
        ],
        "default": "indoor"
      },
      "seed": {
        "type": "integer",
        "description": "seed to be used for generation",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for image enhancement",
        "required": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d/v2/multi-view/turbo",
    "title": "Hunyuan3D",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Hunyuan 3D. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/video_models/Hunyuan3D.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/multi-view/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/multi-view/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "front_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/front.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "back_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/back.png"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "left_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/left.png"
        ]
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/gemini-flash-edit",
    "title": "Gemini Flash Edit Multi Image",
    "category": "image-to-image",
    "description": "Gemini Flash Edit is a model that can edit single image using a text prompt and a reference image.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/gemini-edit/gemini_flash.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gemini-flash-edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/gemini-flash-edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image generation or editing",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "Make the car black"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Optional URL of an input image for editing. If not provided, generates a new image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/gemini-edit/input.png"
        ]
      }
    },
    "outputParameters": {
      "description": {
        "type": "string",
        "description": "Text description or response from Gemini"
      },
      "image": {
        "type": null,
        "description": "The generated or edited image"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d/v2",
    "title": "Hunyuan3D",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Hunyuan 3D. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/video_models/Hunyuan3D.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "input_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/robot.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d/v2/mini",
    "title": "Hunyuan3D",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Hunyuan 3D. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/video_models/Hunyuan3D.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/mini",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/mini/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "input_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/robot.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d/v2/multi-view",
    "title": "Hunyuan3D",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Hunyuan 3D. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/video_models/Hunyuan3D.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/multi-view",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/multi-view/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "front_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/front.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "back_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/back.png"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "left_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/left.png"
        ]
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d/v2/turbo",
    "title": "Hunyuan3D",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Hunyuan 3D. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/video_models/Hunyuan3D.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "input_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/robot.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/hunyuan3d/v2/mini/turbo",
    "title": "Hunyuan3D",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Hunyuan 3D. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/video_models/Hunyuan3D.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/mini/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan3d/v2/mini/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "input_image_url": {
        "type": "string",
        "description": "URL of image to use while generating the 3D model.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/robot.png"
        ]
      },
      "octree_resolution": {
        "type": "integer",
        "description": "Octree resolution for the model.",
        "required": false,
        "minimum": 1,
        "maximum": 1024,
        "default": 256
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "textured_mesh": {
        "type": "boolean",
        "description": "If set true, textured mesh will be generated and the price charged would be 3 times that of white mesh.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/gemini-flash-edit/multi",
    "title": "Gemini Flash Edit Multi Image",
    "category": "image-to-image",
    "description": "Gemini Flash Edit Multi Image is a model that can edit multiple images using a text prompt and a reference image.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/gemini-edit/gemini_flash.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/gemini-flash-edit/multi",
    "documentationUrl": "https://fal.ai/models/fal-ai/gemini-flash-edit/multi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for image generation or editing",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "Make the car black"
        ]
      },
      "input_image_urls": {
        "type": "array",
        "description": "List of URLs of input images for editing",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/web-examples/gemini-edit/input.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "description": {
        "type": "string",
        "description": "Text description or response from Gemini"
      },
      "image": {
        "type": null,
        "description": "The generated or edited image"
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2-flash",
    "title": "Luma Ray 2 Flash",
    "category": "text-to-video",
    "description": "Ray2 Flash is a fast video generative model capable of creating realistic visuals with natural, coherent motion.",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
        "required": false,
        "enum": [
          "540p",
          "720p",
          "1080p"
        ],
        "default": "540p"
      },
      "loop": {
        "type": "boolean",
        "description": "Whether the video should loop (end of video is blended with the beginning)",
        "required": false,
        "default": false
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video (9s costs 2x more)",
        "required": false,
        "enum": [
          "5s",
          "9s"
        ],
        "default": "5s"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2-flash/image-to-video",
    "title": "Luma Ray 2 Flash (Image to Video)",
    "category": "image-to-video",
    "description": "Ray2 Flash is a fast video generative model capable of creating realistic visuals with natural, coherent motion.",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2-flash/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
        "required": false,
        "enum": [
          "540p",
          "720p",
          "1080p"
        ],
        "default": "540p"
      },
      "loop": {
        "type": "boolean",
        "description": "Whether the video should loop (end of video is blended with the beginning)",
        "required": false,
        "default": false
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video",
        "required": false,
        "enum": [
          "5s",
          "9s"
        ],
        "default": "5s"
      },
      "image_url": {
        "type": "string",
        "description": "Initial image to start the video from. Can be used together with end_image_url.",
        "required": false,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      },
      "end_image_url": {
        "type": "string",
        "description": "Final image to end the video with. Can be used together with image_url.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the generated video"
      }
    }
  },
  {
    "id": "fal-ai/pika/v1.5/pikaffects",
    "title": "Pika Effects (v1.5)",
    "category": "image-to-video",
    "description": "Pika Effects are AI-powered video effects designed to modify objects, characters, and environments in a fun, engaging, and visually compelling manner.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v1.5/pikaffects",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v1.5/pikaffects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "pikaffect": {
        "type": "string",
        "description": "The Pikaffect to apply",
        "required": true,
        "enum": [
          "Cake-ify",
          "Crumble",
          "Crush",
          "Decapitate",
          "Deflate",
          "Dissolve",
          "Explode",
          "Eye-pop",
          "Inflate",
          "Levitate",
          "Melt",
          "Peel",
          "Poke",
          "Squish",
          "Ta-da",
          "Tear"
        ],
        "examples": [
          "Crush"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide the effect",
        "required": false,
        "examples": [
          "A duck getting crushed"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to guide the model",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image",
        "required": true,
        "examples": [
          "https://fal.media/files/zebra/2Ro7MtV3BGarwQXPtdK6B_148325d4459c4e34917e8eb5c25877d4.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with applied effect"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2/turbo/image-to-video",
    "title": "Pika Image to Video Turbo (v2)",
    "category": "image-to-video",
    "description": "Pika v2 Turbo creates videos from images with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2/turbo/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2/turbo/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A pink heart exploding."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/dJjBQXNHRbGJn4aUv4-g9_hearth.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2/turbo/text-to-video",
    "title": "Pika Text to Video Turbo (v2)",
    "category": "text-to-video",
    "description": "Pika v2 Turbo creates videos from a text prompt with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2/turbo/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2/turbo/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A young woman in a pale blue corset and denim, her vibrant blue bob framed against a dusky desert landscape, walks slowly, her gaze unwavering and enigmatic as the camera remains fixed on her deliberate pace.  The warm glow of a stucco house contrasts with the cool desert air, hinting at both refuge and isolation, while a blurred figure retreating inside adds a layer of unspoken narrative to her solitary journey."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1",
          "4:5",
          "5:4",
          "3:2",
          "2:3"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/invisible-watermark",
    "title": "Invisible Watermark",
    "category": "image-to-image",
    "description": "Invisible Watermark is a model that can add an invisible watermark to an image.",
    "tags": [
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/watermark/watermark.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/invisible-watermark",
    "documentationUrl": "https://fal.ai/models/fal-ai/invisible-watermark/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "decode": {
        "type": "boolean",
        "description": "Whether to decode a watermark from the image instead of encoding",
        "required": false,
        "default": false
      },
      "watermark": {
        "type": "string",
        "description": "Text to use as watermark (for encoding only)",
        "required": false,
        "default": "watermark",
        "examples": [
          "watermark"
        ]
      },
      "length": {
        "type": "integer",
        "description": "Length of watermark bits to decode (required when decode=True)",
        "required": false,
        "default": 0
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be watermarked or decoded",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/watermark/watermark_ex.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The watermarked image file info (when encoding)"
      },
      "extracted_watermark": {
        "type": "string",
        "description": "The extracted watermark text (when decoding)"
      },
      "length": {
        "type": "integer",
        "description": "Length of the watermark bits used (helpful for future decoding)"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2.2/image-to-video",
    "title": "Pika Image to Video (v2.2)",
    "category": "image-to-video",
    "description": "Pika v2.2 creates videos from images with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2.2/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2.2/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "a woman looking into camera slowly smiling"
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/pika/pika%202.2/pika_input.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2.2/text-to-video",
    "title": "Pika Text to Video (v2.2)",
    "category": "text-to-video",
    "description": "Pika v2.2 creates videos from a text prompt with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2.2/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2.2/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Sunlight streams down on a woman with flowing auburn hair as she runs effortlessly along a tree-lined street, her joyous expression reflecting the freedom of the moment; the simple, steady camerawork emphasizes her grace and the beauty of the everyday."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1",
          "4:5",
          "5:4",
          "3:2",
          "2:3"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2.1/text-to-video",
    "title": "Pika Text to Video (v2.1)",
    "category": "text-to-video",
    "description": "Pika v2.1 creates videos from a text prompt with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2.1/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2.1/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A young woman in a pale blue corset and denim, her vibrant blue bob framed against a dusky desert landscape, walks slowly, her gaze unwavering and enigmatic as the camera remains fixed on her deliberate pace.  The warm glow of a stucco house contrasts with the cool desert air, hinting at both refuge and isolation, while a blurred figure retreating inside adds a layer of unspoken narrative to her solitary journey."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1",
          "4:5",
          "5:4",
          "3:2",
          "2:3"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2.1/image-to-video",
    "title": "Pika Image to Video (v2.1)",
    "category": "image-to-video",
    "description": "Pika v2.1 creates videos from images with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2.1/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2.1/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A pink heart exploding."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/elephant/dJjBQXNHRbGJn4aUv4-g9_hearth.jpg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pika/v2.2/pikascenes",
    "title": "Pika Scenes (v2.2)",
    "category": "image-to-video",
    "description": "Pika Scenes v2.2 creates videos from a images with high quality output.",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/1wavesunset.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pika/v2.2/pikascenes",
    "documentationUrl": "https://fal.ai/models/fal-ai/pika/v2.2/pikascenes/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "An old man and his duck swimming in the pool."
        ]
      },
      "duration": {
        "type": "integer",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "default": 5
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1",
          "4:5",
          "5:4",
          "3:2",
          "2:3"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "ingredients_mode": {
        "type": "string",
        "description": "Mode for integrating multiple images",
        "required": false,
        "enum": [
          "creative",
          "precise"
        ],
        "default": "creative"
      },
      "images": {
        "type": "array",
        "description": "List of images to use for video generation",
        "required": true,
        "examples": [
          [
            {
              "image_url": "https://fal.media/files/panda/dfbC7oH6IASN3LFOfZ9VV.jpeg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/PikaImage"
        }
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the model",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/csm-1b",
    "title": "CSM-1B",
    "category": "text-to-audio",
    "description": "CSM (Conversational Speech Model) is a speech generation model from Sesame that generates RVQ audio codes from text and audio inputs.",
    "tags": [
      "conversational",
      "text to speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/csm.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/csm-1b",
    "documentationUrl": "https://fal.ai/models/fal-ai/csm-1b/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "scene": {
        "type": "array",
        "description": "The text to generate an audio from.",
        "required": true,
        "examples": [
          [
            {
              "text": "Hey how are you doing.",
              "speaker_id": 0
            },
            {
              "text": "Pretty good, pretty good.",
              "speaker_id": 1
            },
            {
              "text": "I'm great, so happy to be speaking to you.",
              "speaker_id": 0
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/Turn"
        }
      },
      "context": {
        "type": "array",
        "description": "The context to generate an audio from.",
        "required": false,
        "examples": [
          [
            {
              "prompt": "like revising for an exam I'd have to try and like keep up the momentum because I'd start really early I'd be like okay I'm gonna start revising now and then like you're revising for ages and then I just like start losing steam I didn't do that for the exam we had recently to be fair that was a more of a last minute scenario but like yeah I'm trying to like yeah I noticed this yesterday that like Mondays I sort of start the day with this not like a panic but like a",
              "audio_url": "https://huggingface.co/spaces/sesame/csm-1b/resolve/main/prompts/conversational_a.wav",
              "speaker_id": 0
            },
            {
              "prompt": "like a super Mario level. Like it's very like high detail. And like, once you get into the park, it just like, everything looks like a computer game and they have all these, like, you know, if, if there's like a, you know, like in a Mario game, they will have like a question block. And if you like, you know, punch it, a coin will come out. So like everyone, when they come into the park, they get like this little bracelet and then you can go punching question blocks around.",
              "audio_url": "https://huggingface.co/spaces/sesame/csm-1b/resolve/main/prompts/conversational_b.wav",
              "speaker_id": 1
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/Speaker"
        }
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio."
      }
    }
  },
  {
    "id": "fal-ai/vidu/image-to-video",
    "title": "Vidu Image to Video",
    "category": "image-to-video",
    "description": "Vidu Image to Video generates high-quality videos with exceptional visual quality and motion diversity from a single image",
    "tags": [
      "motion",
      "image to video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/vidu/start-end-to-video",
    "title": "Vidu Start-End to Video",
    "category": "image-to-video",
    "description": "Vidu Start-End to Video generates smooth transition videos between specified start and end images.",
    "tags": [
      "motion",
      "transition"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/start-end-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/start-end-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "Transform the car frame into a complete vehicle."
        ]
      },
      "start_image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/vidu/2-carchasis.png"
        ]
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "end_image_url": {
        "type": "string",
        "description": "URL of the image to use as the last frame",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/vidu/2-carbody.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated transition video between start and end frames"
      }
    }
  },
  {
    "id": "fal-ai/vidu/reference-to-video",
    "title": "Vidu Reference to Video",
    "category": "image-to-video",
    "description": "Vidu Reference to Video creates videos by using a reference images and combining them with a prompt.",
    "tags": [
      "motion",
      "reference"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/reference-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/reference-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation, max 1500 characters",
        "required": true,
        "maxLength": 1500,
        "examples": [
          "The little devil is looking at the apple on the beach and walking around it."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "reference_image_urls": {
        "type": "array",
        "description": "URLs of the reference images to use for consistent subject appearance",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference1.png",
            "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference2.png",
            "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference3.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "movement_amplitude": {
        "type": "string",
        "description": "The movement amplitude of objects in the frame",
        "required": false,
        "enum": [
          "auto",
          "small",
          "medium",
          "large"
        ],
        "default": "auto"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with consistent subjects from reference images"
      }
    }
  },
  {
    "id": "fal-ai/vidu/template-to-video",
    "title": "Vidu Template to Video",
    "category": "image-to-video",
    "description": "Vidu Template to Video lets you create different effects by applying motion templates to your images.",
    "tags": [
      "motion",
      "template"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/vidu/template-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/vidu/template-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "template": {
        "type": "string",
        "description": "AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).",
        "required": false,
        "enum": [
          "dreamy_wedding",
          "romantic_lift",
          "sweet_proposal",
          "couple_arrival",
          "cupid_arrow",
          "pet_lovers",
          "lunar_newyear",
          "hug",
          "kiss",
          "dynasty_dress",
          "wish_sender",
          "love_pose",
          "hair_swap",
          "youth_rewind",
          "morphlab",
          "live_photo",
          "emotionlab",
          "live_memory",
          "interaction",
          "christmas",
          "pet_finger",
          "eat_mushrooms",
          "beast_chase_library",
          "beast_chase_supermarket",
          "petal_scattered",
          "emoji_figure",
          "hair_color_change",
          "multiple_people_kissing",
          "beast_chase_amazon",
          "beast_chase_mountain",
          "balloonman_explodes_pro",
          "get_thinner",
          "jump2pool",
          "bodyshake",
          "jiggle_up",
          "shake_it_dance",
          "subject_3",
          "pubg_winner_hit",
          "shake_it_down",
          "blueprint_supreme",
          "hip_twist",
          "motor_dance",
          "rat_dance",
          "kwok_dance",
          "leg_sweep_dance",
          "heeseung_march",
          "shake_to_max",
          "dame_un_grrr",
          "i_know",
          "lit_bounce",
          "wave_dance",
          "chill_dance",
          "hip_flicking",
          "sakura_season",
          "zongzi_wrap",
          "zongzi_drop",
          "dragonboat_shot",
          "rain_kiss",
          "child_memory",
          "couple_drop",
          "couple_walk",
          "flower_receive",
          "love_drop",
          "cheek_kiss",
          "carry_me",
          "blow_kiss",
          "love_fall",
          "french_kiss_8s",
          "workday_feels",
          "love_story",
          "bloom_magic",
          "ghibli",
          "minecraft",
          "box_me",
          "claw_me",
          "clayshot",
          "manga_meme",
          "quad_meme",
          "pixel_me",
          "clayshot_duo",
          "irasutoya",
          "american_comic",
          "simpsons_comic",
          "yayoi_kusama_style",
          "pop_art",
          "jojo_style",
          "slice_therapy",
          "balloon_flyaway",
          "flying",
          "paperman",
          "pinch",
          "bloom_doorobear",
          "gender_swap",
          "nap_me",
          "sexy_me",
          "spin360",
          "smooth_shift",
          "paper_fall",
          "jump_to_cloud",
          "pilot",
          "sweet_dreams",
          "soul_depart",
          "punch_hit",
          "watermelon_hit",
          "split_stance_pet",
          "make_face",
          "break_glass",
          "split_stance_human",
          "covered_liquid_metal",
          "fluffy_plunge",
          "pet_belly_dance",
          "water_float",
          "relax_cut",
          "head_to_balloon",
          "cloning",
          "across_the_universe_jungle",
          "clothes_spinning_remnant",
          "across_the_universe_jurassic",
          "across_the_universe_moon",
          "fisheye_pet",
          "hitchcock_zoom",
          "cute_bangs",
          "earth_zoom_out",
          "fisheye_human",
          "drive_yacht",
          "virtual_singer",
          "earth_zoom_in",
          "aliens_coming",
          "drive_ferrari",
          "bjd_style",
          "virtual_fitting",
          "orbit",
          "zoom_in",
          "ai_outfit",
          "spin180",
          "orbit_dolly",
          "orbit_dolly_fast",
          "auto_spin",
          "walk_forward",
          "outfit_show",
          "zoom_in_fast",
          "zoom_out_image",
          "zoom_out_startend",
          "muscling",
          "captain_america",
          "hulk",
          "cap_walk",
          "hulk_dive",
          "exotic_princess",
          "beast_companion",
          "cartoon_doll",
          "golden_epoch",
          "oscar_gala",
          "fashion_stride",
          "star_carpet",
          "flame_carpet",
          "frost_carpet",
          "mecha_x",
          "style_me",
          "tap_me",
          "saber_warrior",
          "pet2human",
          "graduation",
          "fishermen",
          "happy_birthday",
          "fairy_me",
          "ladudu_me",
          "ladudu_me_random",
          "squid_game",
          "superman",
          "grow_wings",
          "clevage",
          "fly_with_doraemon",
          "creatice_product_down",
          "pole_dance",
          "hug_from_behind",
          "creatice_product_up_cybercity",
          "creatice_product_up_bluecircuit",
          "creatice_product_up",
          "run_fast",
          "background_explosion"
        ],
        "default": "hug"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "input_image_urls": {
        "type": "array",
        "description": "URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.",
        "required": true,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/hug.PNG"
          ]
        ],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video using a predefined template"
      }
    }
  },
  {
    "id": "fal-ai/wan-pro/text-to-video",
    "title": "Wan-2.1 Pro Text-to-Video",
    "category": "text-to-video",
    "description": "Wan-2.1 Pro is a premium text-to-video model that generates high-quality 1080p videos at 30fps with up to 6 seconds duration, delivering exceptional visual quality and motion diversity from text prompts",
    "tags": [
      "text to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video",
        "required": true,
        "examples": [
          "A lone astronaut in a detailed NASA spacesuit performs an exuberant dance on the lunar surface, arms outstretched in joyful abandon against the stark moonscape. The Earth hangs dramatically in the black sky, appearing to streak past due to the motion of the dance, creating a sense of dynamic movement. The scene captures extreme contrasts between the brilliant white of the spacesuit reflecting harsh sunlight and the deep shadows of the lunar craters. Every detail is rendered with photorealistic precision: the texture of the regolith disturbed by the astronaut's boots, the reflections on the helmet visor."
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Whether to enable the safety checker",
        "required": false,
        "default": true
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "easel-ai/advanced-face-swap",
    "title": "Easel AI Advanced Face Swap",
    "category": "image-to-image",
    "description": "Swap faces of one or two people at once, while preserving user and scene details!",
    "tags": [
      "face swap",
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/easel-face-swap.webp",
    "playgroundUrl": "https://fal.ai/models/easel-ai/advanced-face-swap",
    "documentationUrl": "https://fal.ai/models/easel-ai/advanced-face-swap/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "detailer": {
        "type": "boolean",
        "description": "(Beta) Apply detailer to the image. Detailer will improve certain image details, but slightly increase generation time.",
        "required": false,
        "default": false
      },
      "face_image_1": {
        "type": null,
        "description": "(Optional) The Second face image to face swap FROM",
        "required": false,
        "examples": [
          "https://images.easelai.com/mirror_fal/faces/female.png",
          "https://images.easelai.com/mirror_fal/faces/male.png"
        ]
      },
      "target_image": {
        "type": null,
        "description": "The target image to face swap TO",
        "required": false,
        "examples": [
          "https://images.easelai.com/mirror_fal/men_single_player/rip.jpg",
          "https://images.easelai.com/mirror_fal/men_single_player/saturday.png",
          "https://images.easelai.com/mirror_fal/multiplayer/bf.jpg",
          "https://images.easelai.com/mirror_fal/multiplayer/couple.png",
          "https://images.easelai.com/mirror_fal/multiplayer/forever.png"
        ]
      },
      "workflow_type": {
        "type": "string",
        "description": "The type of face swap workflow. target_hair = preserve target's hair. user_hair = preserve user's hair.",
        "required": true,
        "enum": [
          "user_hair",
          "target_hair"
        ]
      },
      "face_image_0": {
        "type": null,
        "description": "User's face image to face swap FROM",
        "required": true,
        "examples": [
          "https://images.easelai.com/mirror_fal/faces/male.png",
          "https://images.easelai.com/mirror_fal/faces/female.png"
        ]
      },
      "upscale": {
        "type": "boolean",
        "description": "Apply 2x upscale and boost quality. Upscaling will refine the image and make the subjects brighter.",
        "required": false,
        "default": true
      },
      "gender_1": {
        "type": "string",
        "description": "The gender of the person in the second face image.",
        "required": false,
        "enum": [
          "male",
          "female",
          "non-binary"
        ]
      },
      "gender_0": {
        "type": "string",
        "description": "The gender of the person in the face image.",
        "required": true,
        "enum": [
          "male",
          "female",
          "non-binary"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The mirrored image."
      }
    }
  },
  {
    "id": "fal-ai/wan-i2v-lora",
    "title": "Wan-2.1 Image-to-Video with LoRAs",
    "category": "image-to-video",
    "description": "Add custom LoRAs to Wan-2.1 is a image-to-video model that generates high-quality videos with high visual quality and motion diversity from images",
    "tags": [
      "image to video",
      "motion",
      "lora"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-i2v-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-i2v-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "Cars race in slow motion."
        ]
      },
      "shift": {
        "type": "number",
        "description": "Shift parameter for video generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "reverse_video": {
        "type": "boolean",
        "description": "If true, the video will be reversed.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "LoRA weights to be used in the inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "turbo_mode": {
        "type": "boolean",
        "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
        "required": false,
        "default": true
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
        "required": false,
        "minimum": 81,
        "maximum": 100,
        "default": 81
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the output video.",
        "required": false,
        "enum": [
          "auto",
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "guide_scale": {
        "type": "number",
        "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.5/pro/effects",
    "title": "Kling 1.5",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.5 (pro)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.5/pro/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.5/pro/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to be used for hug, kiss or heart_gesture video.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
            "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "effect_scene": {
        "type": "string",
        "description": "The effect scene to use for the video generation",
        "required": true,
        "enum": [
          "hug",
          "kiss",
          "heart_gesture",
          "squish",
          "expansion",
          "fuzzyfuzzy",
          "bloombloom",
          "dizzydizzy",
          "jelly_press",
          "jelly_slice",
          "jelly_squish",
          "jelly_jiggle",
          "pixelpixel",
          "yearbook",
          "instant_film",
          "anime_figure",
          "rocketrocket"
        ],
        "examples": [
          "hug"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/effects",
    "title": "Kling 1.6",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.6 (pro)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to be used for hug, kiss or heart_gesture video.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
            "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "effect_scene": {
        "type": "string",
        "description": "The effect scene to use for the video generation",
        "required": true,
        "enum": [
          "hug",
          "kiss",
          "heart_gesture",
          "squish",
          "expansion",
          "fuzzyfuzzy",
          "bloombloom",
          "dizzydizzy",
          "jelly_press",
          "jelly_slice",
          "jelly_squish",
          "jelly_jiggle",
          "pixelpixel",
          "yearbook",
          "instant_film",
          "anime_figure",
          "rocketrocket"
        ],
        "examples": [
          "hug"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/effects",
    "title": "Kling 1.0",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.0",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to be used for hug, kiss or heart_gesture video.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
            "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "effect_scene": {
        "type": "string",
        "description": "The effect scene to use for the video generation",
        "required": true,
        "enum": [
          "hug",
          "kiss",
          "heart_gesture",
          "squish",
          "expansion",
          "fuzzyfuzzy",
          "bloombloom",
          "dizzydizzy",
          "jelly_press",
          "jelly_slice",
          "jelly_squish",
          "jelly_jiggle",
          "pixelpixel",
          "yearbook",
          "instant_film",
          "anime_figure",
          "rocketrocket"
        ],
        "examples": [
          "hug"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/effects",
    "title": "Kling 1.6",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.6 (std)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/effects",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/effects/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to be used for hug, kiss or heart_gesture video.",
        "required": false,
        "examples": [
          [
            "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
            "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "effect_scene": {
        "type": "string",
        "description": "The effect scene to use for the video generation",
        "required": true,
        "enum": [
          "hug",
          "kiss",
          "heart_gesture",
          "squish",
          "expansion",
          "fuzzyfuzzy",
          "bloombloom",
          "dizzydizzy",
          "jelly_press",
          "jelly_slice",
          "jelly_squish",
          "jelly_jiggle",
          "pixelpixel",
          "yearbook",
          "instant_film",
          "anime_figure",
          "rocketrocket"
        ],
        "examples": [
          "hug"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video-image-to-video",
    "title": "Hunyuan Video Image-to-Video Inference",
    "category": "image-to-video",
    "description": "Image to Video for the high-quality Hunyuan Video I2V model.",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video-image-to-video.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "maxLength": 1000,
        "examples": [
          "Two muscular cats boxing in a boxing ring."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate.",
        "required": false,
        "enum": [
          "720p"
        ],
        "default": "720p"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/hunyuan_i2v.jpg"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "num_frames": {
        "type": "string",
        "description": "The number of frames to generate.",
        "required": false,
        "enum": [
          "129"
        ],
        "default": 129
      },
      "i2v_stability": {
        "type": "boolean",
        "description": "Turning on I2V Stability reduces hallucination but also reduces motion.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/pro/image-to-image",
    "title": "Juggernaut Flux Pro",
    "category": "image-to-image",
    "description": "Juggernaut Pro Flux by RunDiffusion is the flagship Juggernaut model rivaling some of the most advanced image models available, often surpassing them in realism. It combines Juggernaut Base with RunDiffusion Photo and features enhancements like reduced background blurriness.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-pro.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/pro/image-to-image",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/pro/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "a cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/lightning",
    "title": "Juggernaut Flux Lightning",
    "category": "text-to-image",
    "description": "Juggernaut Lightning Flux by RunDiffusion provides blazing-fast, high-quality images rendered at five times the speed of Flux. Perfect for mood boards and mass ideation, this model excels in both realism and prompt adherence.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-lightning.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/lightning",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/lightning/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "rundiffusion-fal/rundiffusion-photo-flux",
    "title": "Rundiffusion Photo Flux",
    "category": "text-to-image",
    "description": "RunDiffusion Photo Flux provides insane realism. With this enhancer, textures and skin details burst to life, turning your favorite prompts into vivid, lifelike creations. Recommended to keep it at 0.65 to 0.80 weight. Supports resolutions up to 1536x1536.",
    "tags": [
      "image generation",
      "lora"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/rundiffusion-photo-flux.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/rundiffusion-photo-flux",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/rundiffusion-photo-flux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "photo_lora_scale": {
        "type": "number",
        "description": "LoRA Scale of the photo lora model",
        "required": false,
        "default": 0.75
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux-lora",
    "title": "Juggernaut Flux Base LoRA",
    "category": "text-to-image",
    "description": "Juggernaut Base Flux LoRA by RunDiffusion is a drop-in replacement for Flux [Dev] that delivers sharper details, richer colors, and enhanced realism to all your LoRAs and LyCORIS with full compatibility.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-lora.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux-lora",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/base/image-to-image",
    "title": "Juggernaut Flux Base",
    "category": "image-to-image",
    "description": "Juggernaut Base Flux by RunDiffusion is a drop-in replacement for Flux [Dev] that delivers sharper details, richer colors, and enhanced realism, while instantly boosting LoRAs and LyCORIS with full compatibility.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-base.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/base/image-to-image",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/base/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "a cat dressed as a wizard with a background of a mystic forest."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the initial image. Higher strength values are better for this model.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 10,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-v095/multiconditioning",
    "title": "LTX Video-0.9.5",
    "category": "video-to-video",
    "description": "Generate videos from prompts,images, and videos using LTX Video-0.9.5",
    "tags": [
      "video",
      "image-to-video",
      "text-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ltx-0.9.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-v095/multiconditioning",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-v095/multiconditioning/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "\n            A vibrant, abstract composition featuring a person with outstretched arms, rendered in a kaleidoscope of colors against a deep, dark background. The figure is composed of intricate, swirling patterns reminiscent of a mosaic, with hues of orange, yellow, blue, and green that evoke the style of artists such as Wassily Kandinsky or Bridget Riley. \n\nThe camera zooms into the face striking portrait of a man, reimagined through the lens of old-school video-game graphics. The subject's face is rendered in a kaleidoscope of colors, with bold blues and reds set against a vibrant yellow backdrop. His dark hair is pulled back, framing his profile in a dramatic pose\n        "
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using the model's own capabilities.",
        "required": false,
        "default": true
      },
      "images": {
        "type": "array",
        "description": "URL of images to use as conditioning",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "start_frame_num": 0,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/NswO1P8sCLzrh1WefqQFK_9a6bdbfa54b944c9a770338159a113fd.jpg"
            },
            {
              "start_frame_num": 120,
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/ltx/YAPOGvmS2tM_Krdp7q6-d_267c97e017c34f679844a4477dfcec38.jpg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/ImageConditioningInput"
        }
      },
      "videos": {
        "type": "array",
        "description": "Videos to use as conditioning",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/VideoConditioningInput"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-v095",
    "title": "LTX Video-0.9.5",
    "category": "text-to-video",
    "description": "Generate videos from prompts using LTX Video-0.9.5",
    "tags": [
      "video",
      "text-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ltx-0.9.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-v095",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-v095/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "A cute cat walking on a sidewalk"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using the model's own capabilities.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/ltx-video-v095/extend",
    "title": "LTX Video-0.9.5",
    "category": "video-to-video",
    "description": "Generate videos from prompts and videos using LTX Video-0.9.5",
    "tags": [
      "video",
      "video-to-video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ltx-0.9.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-v095/extend",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-v095/extend/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt to guide generation",
        "required": true,
        "examples": [
          "Woman walking on a street in Tokyo"
        ]
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p or 720p).",
        "required": false,
        "enum": [
          "480p",
          "720p"
        ],
        "default": "720p"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt using the model's own capabilities.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 40
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for generation",
        "required": false,
        "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
      },
      "video": {
        "type": null,
        "description": "Video to be extended.",
        "required": true,
        "examples": [
          {
            "video_url": "https://storage.googleapis.com/falserverless/web-examples/wan/t2v.mp4",
            "start_frame_num": 24
          }
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/pro",
    "title": "Juggernaut Flux Pro",
    "category": "text-to-image",
    "description": "Juggernaut Pro Flux by RunDiffusion is the flagship Juggernaut model rivaling some of the most advanced image models available, often surpassing them in realism. It combines Juggernaut Base with RunDiffusion Photo and features enhancements like reduced background blurriness.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-pro.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/pro",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/pro/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/base",
    "title": "Juggernaut Flux Base",
    "category": "text-to-image",
    "description": "Juggernaut Base Flux by RunDiffusion is a drop-in replacement for Flux [Dev] that delivers sharper details, richer colors, and enhanced realism, while instantly boosting LoRAs and LyCORIS with full compatibility.",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-base.webp",
    "playgroundUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/base",
    "documentationUrl": "https://fal.ai/models/rundiffusion-fal/juggernaut-flux/base/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/diffrhythm",
    "title": "DiffRhythm: Lyrics to Song",
    "category": "text-to-audio",
    "description": "DiffRhythm is a blazing fast model for transforming lyrics into full songs. It boasts the capability to generate full songs in less than 30 seconds.",
    "tags": [
      "music"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/Bb-9UKANlvJDh-TwrH9sB_f38e20cbf40c42f485428c775e76543b.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/diffrhythm",
    "documentationUrl": "https://fal.ai/models/fal-ai/diffrhythm/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lyrics": {
        "type": "string",
        "description": "The prompt to generate the song from. Must have two sections. Sections start with either [chorus] or a [verse].",
        "required": true,
        "examples": [
          "[00:10.00]Moonlight spills through broken blinds\n[00:13.20]Your shadow dances on the dashboard shrine\n[00:16.85]Neon ghosts in gasoline rain\n[00:20.40]I hear your laughter down the midnight train\n[00:24.15]Static whispers through frayed wires\n[00:27.65]Guitar strings hum our cathedral choirs\n[00:31.30]Flicker screens show reruns of June\n[00:34.90]I'm drowning in this mercury lagoon\n[00:38.55]Electric veins pulse through concrete skies\n[00:42.10]Your name echoes in the hollow where my heartbeat lies\n[00:45.75]We're satellites trapped in parallel light\n[00:49.25]Burning through the atmosphere of endless night\n[01:00.00]Dusty vinyl spins reverse\n[01:03.45]Our polaroid timeline bleeds through the verse\n[01:07.10]Telescope aimed at dead stars\n[01:10.65]Still tracing constellations through prison bars\n[01:14.30]Electric veins pulse through concrete skies\n[01:17.85]Your name echoes in the hollow where my heartbeat lies\n[01:21.50]We're satellites trapped in parallel light\n[01:25.05]Burning through the atmosphere of endless night\n[02:10.00]Clockwork gears grind moonbeams to rust\n[02:13.50]Our fingerprint smudged by interstellar dust\n[02:17.15]Velvet thunder rolls through my veins\n[02:20.70]Chasing phantom trains through solar plane\n[02:24.35]Electric veins pulse through concrete skies\n[02:27.90]Your name echoes in the hollow where my heartbeat lies\n"
        ]
      },
      "cfg_strength": {
        "type": "number",
        "description": "The CFG strength to use for the music generation.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4
      },
      "reference_audio_url": {
        "type": "string",
        "description": "The URL of the reference audio to use for the music generation.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/diffrythm/rock_en.wav"
        ]
      },
      "music_duration": {
        "type": "string",
        "description": "The duration of the music to generate.",
        "required": false,
        "enum": [
          "95s",
          "285s"
        ],
        "default": "95s"
      },
      "scheduler": {
        "type": "string",
        "description": "The scheduler to use for the music generation.",
        "required": false,
        "enum": [
          "euler",
          "midpoint",
          "rk4",
          "implicit_adams"
        ],
        "default": "euler"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to use for the music generation.",
        "required": false,
        "minimum": 10,
        "maximum": 100,
        "default": 32
      },
      "style_prompt": {
        "type": "string",
        "description": "The style prompt to use for the music generation.",
        "required": false,
        "examples": [
          "pop"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "Generated music file."
      }
    }
  },
  {
    "id": "fal-ai/cogview4",
    "title": "CogView",
    "category": "text-to-image",
    "description": "Generate high quality images from text prompts using CogView4. Longer text prompts will result in better quality images.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/CogView4/CogView4.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/cogview4",
    "documentationUrl": "https://fal.ai/models/fal-ai/cogview4/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A vibrant and artistic digital composition featuring colorful splashes of paint in the background, creating an energetic and dynamic effect. The text 'CogView4 on Fal' is elegantly integrated into the scene, standing out with a modern, bold, and slightly futuristic font. The colors are bright and varied, including neon blues, purples, pinks, and oranges, blending seamlessly in a fluid, abstract style. The text appears slightly illuminated, complementing the vivid splashes around it."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/topaz/upscale/video",
    "title": "Topaz Video Upscale",
    "category": "video-to-video",
    "description": "Professional-grade video upscaling using Topaz technology. Enhance your videos with high-quality upscaling.",
    "tags": [
      "upscaling",
      "high-res"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/topaz-video-upscale.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/topaz/upscale/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/topaz/upscale/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "H264_output": {
        "type": "boolean",
        "description": "Whether to use H264 codec for output video. Default is H265.",
        "required": false,
        "default": false
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to upscale",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/kangaroo/y5-1YTGpun17eSeggZMzX_video-1733468228.mp4"
        ]
      },
      "upscale_factor": {
        "type": "number",
        "description": "Factor to upscale the video by (e.g. 2.0 doubles width and height)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 2
      },
      "target_fps": {
        "type": "integer",
        "description": "Target FPS for frame interpolation. If set, frame interpolation will be enabled.",
        "required": false,
        "minimum": 16,
        "maximum": 60
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The upscaled video file"
      }
    }
  },
  {
    "id": "fal-ai/docres/dewarp",
    "title": "DocRes-dewarp",
    "category": "image-to-image",
    "description": "Enhance wraped, folded documents with the superior quality of docres for sharper, clearer results.",
    "tags": [
      "image-enhancement"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/docres.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/docres/dewarp",
    "documentationUrl": "https://fal.ai/models/fal-ai/docres/dewarp/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/docres_ckpt/218_in.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/docres",
    "title": "DocRes",
    "category": "image-to-image",
    "description": "Enhance low-resolution, blur, shadowed documents with the superior quality of docres for sharper, clearer results.",
    "tags": [
      "image-enhancement"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/docres.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/docres",
    "documentationUrl": "https://fal.ai/models/fal-ai/docres/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "task": {
        "type": "string",
        "description": "Task to perform",
        "required": true,
        "enum": [
          "deshadowing",
          "appearance",
          "deblurring",
          "binarization"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/docres_ckpt/218_in.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/swin2sr",
    "title": "SWIN2SR",
    "category": "image-to-image",
    "description": "Enhance low-resolution images with the superior quality of Swin2SR for sharper, clearer results.",
    "tags": [
      "image-enhancement"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/swin2sr.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/swin2sr",
    "documentationUrl": "https://fal.ai/models/fal-ai/swin2sr/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "task": {
        "type": "string",
        "description": "Task to perform",
        "required": false,
        "enum": [
          "classical_sr",
          "compressed_sr",
          "real_sr"
        ],
        "default": "classical_sr"
      },
      "seed": {
        "type": "integer",
        "description": "seed to be used for generation",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for image enhancement",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/seoul.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2a/remix",
    "title": "Ideogram V2A Remix",
    "category": "image-to-image",
    "description": "Create variations of existing images with Ideogram V2A Remix while maintaining creative control through prompt guidance.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to remix the image with",
        "required": true,
        "examples": [
          "An ice field in north atlantic"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to remix",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/FHOx4y4a0ef7Sgmo-sOUR_image.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Strength of the input image in the remix",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/text-to-video",
    "title": "Kling 1.6",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.6 (pro)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2a/turbo/remix",
    "title": "Ideogram V2A Turbo Remix",
    "category": "image-to-image",
    "description": "Rapidly create image variations with Ideogram V2A Turbo Remix. Fast and efficient reimagining of existing images while maintaining creative control through prompt guidance.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/turbo/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/turbo/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to remix the image with",
        "required": true,
        "examples": [
          "An ice field in north atlantic"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to remix",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/FHOx4y4a0ef7Sgmo-sOUR_image.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Strength of the input image in the remix",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/tts/multilingual-v2",
    "title": "ElevenLabs TTS Multilingual v2",
    "category": "text-to-audio",
    "description": "Generate multilingual text-to-speech audio using ElevenLabs TTS Multilingual v2.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/twZsKdCTiF8JXv-rRcPZu_8414166d52a548859a8df01bf720fe46.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/tts/multilingual-v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/tts/multilingual-v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to convert to speech",
        "required": true,
        "examples": [
          "Hello! This is a test of the text to speech system, powered by ElevenLabs. How does it sound?"
        ]
      },
      "next_text": {
        "type": null,
        "description": "The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.",
        "required": false
      },
      "speed": {
        "type": "number",
        "description": "Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.",
        "required": false,
        "minimum": 0.7,
        "maximum": 1.2,
        "default": 1
      },
      "style": {
        "type": "number",
        "description": "Style exaggeration (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "stability": {
        "type": "number",
        "description": "Voice stability (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "timestamps": {
        "type": "boolean",
        "description": "Whether to return timestamps for each word in the generated speech",
        "required": false,
        "default": false
      },
      "similarity_boost": {
        "type": "number",
        "description": "Similarity boost (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "voice": {
        "type": "string",
        "description": "The voice to use for speech generation",
        "required": false,
        "default": "Rachel",
        "examples": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ]
      },
      "language_code": {
        "type": null,
        "description": "Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.",
        "required": false
      },
      "previous_text": {
        "type": null,
        "description": "The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.",
        "required": false
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file"
      },
      "timestamps": {
        "type": null,
        "description": "Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request."
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2a/turbo",
    "title": "Ideogram V2A Turbo",
    "category": "text-to-image",
    "description": "Accelerated image generation with Ideogram V2A Turbo. Create high-quality visuals, posters, and logos with enhanced speed while maintaining Ideogram's signature quality.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://fal.media/files/zebra/G9QL1XoVt8ZMvbYwA3Zrw_15ff55eb74a0429eaeb9a288e71763ef.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/tts/turbo-v2.5",
    "title": "ElevenLabs TTS Turbo v2.5",
    "category": "text-to-speech",
    "description": "Generate high-speed text-to-speech audio using ElevenLabs TTS Turbo v2.5.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/elevenlabs/elevenlabs_thumbnail.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/tts/turbo-v2.5",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/tts/turbo-v2.5/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text": {
        "type": "string",
        "description": "The text to convert to speech",
        "required": true,
        "examples": [
          "Hello! This is a test of the text to speech system, powered by ElevenLabs. How does it sound?"
        ]
      },
      "next_text": {
        "type": null,
        "description": "The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.",
        "required": false
      },
      "speed": {
        "type": "number",
        "description": "Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.",
        "required": false,
        "minimum": 0.7,
        "maximum": 1.2,
        "default": 1
      },
      "style": {
        "type": "number",
        "description": "Style exaggeration (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "stability": {
        "type": "number",
        "description": "Voice stability (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "timestamps": {
        "type": "boolean",
        "description": "Whether to return timestamps for each word in the generated speech",
        "required": false,
        "default": false
      },
      "similarity_boost": {
        "type": "number",
        "description": "Similarity boost (0-1)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "voice": {
        "type": "string",
        "description": "The voice to use for speech generation",
        "required": false,
        "default": "Rachel",
        "examples": [
          "Aria",
          "Roger",
          "Sarah",
          "Laura",
          "Charlie",
          "George",
          "Callum",
          "River",
          "Liam",
          "Charlotte",
          "Alice",
          "Matilda",
          "Will",
          "Jessica",
          "Eric",
          "Chris",
          "Brian",
          "Daniel",
          "Lily",
          "Bill"
        ]
      },
      "language_code": {
        "type": null,
        "description": "Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 and Flash v2.5 support language enforcement. For other models, an error will be returned if language code is provided.",
        "required": false
      },
      "previous_text": {
        "type": null,
        "description": "The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.",
        "required": false
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file"
      },
      "timestamps": {
        "type": null,
        "description": "Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request."
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/audio-isolation",
    "title": "ElevenLabs Audio Isolation",
    "category": "audio-to-audio",
    "description": "Isolate audio tracks using ElevenLabs advanced audio isolation technology.",
    "tags": [
      "audio"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/elevenlabs/elevenlabs_thumbnail.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/audio-isolation",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/audio-isolation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to isolate voice from",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/zJL_oRY8h5RWwjoK1w7tx_output.mp3"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file"
      },
      "timestamps": {
        "type": null,
        "description": "Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request."
      }
    }
  },
  {
    "id": "fal-ai/elevenlabs/speech-to-text",
    "title": "ElevenLabs Speech to Text",
    "category": "speech-to-text",
    "description": "Generate text from speech using ElevenLabs advanced speech-to-text model.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/elevenlabs/elevenlabs_thumbnail.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/elevenlabs/speech-to-text",
    "documentationUrl": "https://fal.ai/models/fal-ai/elevenlabs/speech-to-text/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "language_code": {
        "type": null,
        "description": "Language code of the audio",
        "required": false,
        "examples": [
          "eng",
          "spa",
          "fra",
          "deu",
          "jpn"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to transcribe",
        "required": true,
        "examples": [
          "https://v3.fal.media/files/zebra/zJL_oRY8h5RWwjoK1w7tx_output.mp3"
        ]
      },
      "diarize": {
        "type": "boolean",
        "description": "Whether to annotate who is speaking",
        "required": false,
        "default": true
      },
      "tag_audio_events": {
        "type": "boolean",
        "description": "Tag audio events like laughter, applause, etc.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "text": {
        "type": "string",
        "description": "The full transcribed text"
      },
      "language_probability": {
        "type": "number",
        "description": "Confidence in language detection"
      },
      "language_code": {
        "type": "string",
        "description": "Detected or specified language code"
      },
      "words": {
        "type": "array",
        "description": "Word-level transcription details",
        "items": {
          "$ref": "#/components/schemas/TranscriptionWord"
        }
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2a",
    "title": "Ideogram V2A",
    "category": "text-to-image",
    "description": "Generate high-quality images, posters, and logos with Ideogram V2A. Features exceptional typography handling and realistic outputs optimized for commercial and creative use.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/mYGi5w1eEI_yIOrXfqMPk_e233dd6442da4904b2bc2fd83f8915f8.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2a",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2a/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/evf-sam",
    "title": "EVF-SAM2 Segmentation",
    "category": "image-to-image",
    "description": "EVF-SAM2 combines natural language understanding with advanced segmentation capabilities, allowing you to precisely mask image regions using intuitive positive and negative text prompts.",
    "tags": [
      "segmentation",
      "mask"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/evf-sam2/evf-sam2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/evf-sam",
    "documentationUrl": "https://fal.ai/models/fal-ai/evf-sam/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate segmentation from.",
        "required": true,
        "examples": [
          "Cat in the middle of the image"
        ]
      },
      "use_grounding_dino": {
        "type": "boolean",
        "description": "Use GroundingDINO instead of SAM for segmentation",
        "required": false,
        "default": false
      },
      "semantic_type": {
        "type": "boolean",
        "description": "Enable semantic level segmentation for body parts, background or multi objects",
        "required": false,
        "default": false
      },
      "fill_holes": {
        "type": "boolean",
        "description": "Fill holes in the mask using morphological operations",
        "required": false,
        "default": false
      },
      "expand_mask": {
        "type": "integer",
        "description": "Expand/dilate the mask by specified pixels",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 0
      },
      "mask_only": {
        "type": "boolean",
        "description": "Output only the binary mask instead of masked image",
        "required": false,
        "default": true
      },
      "revert_mask": {
        "type": "boolean",
        "description": "Invert the mask (background becomes foreground and vice versa)",
        "required": false,
        "default": false
      },
      "blur_mask": {
        "type": "integer",
        "description": "Apply Gaussian blur to the mask. Value determines kernel size (must be odd number)",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 0
      },
      "negative_prompt": {
        "type": "string",
        "description": "Areas to exclude from segmentation (will be subtracted from prompt results)",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/evf-sam2/evfsam2-cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The segmented output image"
      }
    }
  },
  {
    "id": "fal-ai/ddcolor",
    "title": "DDColor",
    "category": "image-to-image",
    "description": "Bring colors into old or new black and white photos with DDColor.",
    "tags": [
      "image-recolorization",
      "faces",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ddcolor.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ddcolor",
    "documentationUrl": "https://fal.ai/models/fal-ai/ddcolor/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "seed to be used for generation",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/Screenshot%202025-02-26%20154226.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/wan-t2v",
    "title": "Wan-2.1 Text-to-Video",
    "category": "text-to-video",
    "description": "Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from text prompts",
    "tags": [
      "text to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wan-t2v",
    "documentationUrl": "https://fal.ai/models/fal-ai/wan-t2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt to guide video generation.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the generated video (16:9 or 9:16).",
        "required": false,
        "enum": [
          "9:16",
          "16:9"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "Resolution of the generated video (480p, 580p, or 720p).",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility. If None, a random seed is chosen.",
        "required": false
      },
      "turbo_mode": {
        "type": "boolean",
        "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
        "required": false,
        "default": false
      },
      "frames_per_second": {
        "type": "integer",
        "description": "Frames per second of the generated video. Must be between 5 to 24.",
        "required": false,
        "minimum": 5,
        "maximum": 24,
        "default": 16
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_frames": {
        "type": "integer",
        "description": "Number of frames to generate. Must be between 81 to 100 (inclusive).",
        "required": false,
        "minimum": 81,
        "maximum": 100,
        "default": 81
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
        "required": false,
        "minimum": 2,
        "maximum": 40,
        "default": 30
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt for video generation.",
        "required": false,
        "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
        "examples": [
          "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": false,
        "examples": [
          false
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation."
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/video-prompt-generator",
    "title": "Video Prompt Generator",
    "category": "llm",
    "description": "Generate video prompts using a variety of techniques including camera direction, style, pacing, special effects and more.",
    "tags": [
      "motion",
      "transformation",
      "chat",
      "claude",
      "gpt"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/video-prompt/vprompt.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/video-prompt-generator",
    "documentationUrl": "https://fal.ai/models/fal-ai/video-prompt-generator/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "custom_elements": {
        "type": "string",
        "description": "Custom technical elements (optional)",
        "required": false,
        "default": ""
      },
      "style": {
        "type": "string",
        "description": "Style of the video prompt",
        "required": false,
        "enum": [
          "Minimalist",
          "Simple",
          "Detailed",
          "Descriptive",
          "Dynamic",
          "Cinematic",
          "Documentary",
          "Animation",
          "Action",
          "Experimental"
        ],
        "default": "Simple"
      },
      "camera_direction": {
        "type": "string",
        "description": "Camera direction",
        "required": false,
        "enum": [
          "None",
          "Zoom in",
          "Zoom out",
          "Pan left",
          "Pan right",
          "Tilt up",
          "Tilt down",
          "Orbital rotation",
          "Push in",
          "Pull out",
          "Track forward",
          "Track backward",
          "Spiral in",
          "Spiral out",
          "Arc movement",
          "Diagonal traverse",
          "Vertical rise",
          "Vertical descent"
        ],
        "default": "None"
      },
      "pacing": {
        "type": "string",
        "description": "Pacing rhythm",
        "required": false,
        "enum": [
          "None",
          "Slow burn",
          "Rhythmic pulse",
          "Frantic energy",
          "Ebb and flow",
          "Hypnotic drift",
          "Time-lapse rush",
          "Stop-motion staccato",
          "Gradual build",
          "Quick cut rhythm",
          "Long take meditation",
          "Jump cut energy",
          "Match cut flow",
          "Cross-dissolve dreamscape",
          "Parallel action",
          "Slow motion impact",
          "Ramping dynamics",
          "Montage tempo",
          "Continuous flow",
          "Episodic breaks"
        ],
        "default": "None"
      },
      "special_effects": {
        "type": "string",
        "description": "Special effects approach",
        "required": false,
        "enum": [
          "None",
          "Practical effects",
          "CGI enhancement",
          "Analog glitches",
          "Light painting",
          "Projection mapping",
          "Nanosecond exposures",
          "Double exposure",
          "Smoke diffusion",
          "Lens flare artistry",
          "Particle systems",
          "Holographic overlay",
          "Chromatic aberration",
          "Digital distortion",
          "Wire removal",
          "Motion capture",
          "Miniature integration",
          "Weather simulation",
          "Color grading",
          "Mixed media composite",
          "Neural style transfer"
        ],
        "default": "None"
      },
      "image_url": {
        "type": "string",
        "description": "URL of an image to analyze and incorporate into the video prompt (optional)",
        "required": false
      },
      "model": {
        "type": "string",
        "description": "Model to use",
        "required": false,
        "enum": [
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-3-5-haiku",
          "anthropic/claude-3-haiku",
          "google/gemini-pro-1.5",
          "google/gemini-flash-1.5",
          "google/gemini-flash-1.5-8b",
          "google/gemini-2.0-flash-001",
          "meta-llama/llama-3.2-1b-instruct",
          "meta-llama/llama-3.2-3b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "openai/gpt-4o-mini",
          "openai/gpt-4o",
          "deepseek/deepseek-r1"
        ],
        "default": "google/gemini-2.0-flash-001"
      },
      "camera_style": {
        "type": "string",
        "description": "Camera movement style",
        "required": false,
        "enum": [
          "None",
          "Steadicam flow",
          "Drone aerials",
          "Handheld urgency",
          "Crane elegance",
          "Dolly precision",
          "VR 360",
          "Multi-angle rig",
          "Static tripod",
          "Gimbal smoothness",
          "Slider motion",
          "Jib sweep",
          "POV immersion",
          "Time-slice array",
          "Macro extreme",
          "Tilt-shift miniature",
          "Snorricam character",
          "Whip pan dynamics",
          "Dutch angle tension",
          "Underwater housing",
          "Periscope lens"
        ],
        "default": "None"
      },
      "input_concept": {
        "type": "string",
        "description": "Core concept or thematic input for the video prompt",
        "required": true,
        "examples": [
          "A futuristic city at dusk"
        ]
      },
      "prompt_length": {
        "type": "string",
        "description": "Length of the prompt",
        "required": false,
        "enum": [
          "Short",
          "Medium",
          "Long"
        ],
        "default": "Medium"
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "Generated video prompt"
      }
    }
  },
  {
    "id": "fal-ai/sam2/auto-segment",
    "title": "Segment Anything Model 2",
    "category": "image-to-image",
    "description": "SAM 2 is a model for segmenting images automatically. It can return individual masks or a single mask for the entire image.",
    "tags": [
      "segmentation",
      "mask"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sam2.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sam2/auto-segment",
    "documentationUrl": "https://fal.ai/models/fal-ai/sam2/auto-segment/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "points_per_side": {
        "type": "integer",
        "description": "Number of points to sample along each side of the image.",
        "required": false,
        "default": 32
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "min_mask_region_area": {
        "type": "integer",
        "description": "Minimum area of a mask region.",
        "required": false,
        "default": 100
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be automatically segmented",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/truck.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "pred_iou_thresh": {
        "type": "number",
        "description": "Threshold for predicted IOU score.",
        "required": false,
        "default": 0.88
      },
      "stability_score_thresh": {
        "type": "number",
        "description": "Threshold for stability score.",
        "required": false,
        "default": 0.95
      }
    },
    "outputParameters": {
      "combined_mask": {
        "type": null,
        "description": "Combined segmentation mask."
      },
      "individual_masks": {
        "type": "array",
        "description": "Individual segmentation masks.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01-director/image-to-video",
    "title": "MiniMax (Hailuo AI) Video 01 Director - Image to Video",
    "category": "image-to-video",
    "description": "Generate video clips more accurately with respect to initial image, natural language descriptions, and using camera movement instructions for shot control.",
    "tags": [
      "motion",
      "transformation",
      "camera-controls"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/red_clouds.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01-director/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01-director/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "[Push in, Follow]A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse.[Pan left] The street opens into a small plaza where street vendors sell steaming food under colorful awnings."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/drct-super-resolution",
    "title": "DRCT-Super-Resolution",
    "category": "image-to-image",
    "description": "Upscale your images with DRCT-Super-Resolution.",
    "tags": [
      "upscaling",
      "high-res"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/drct.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/drct-super-resolution",
    "documentationUrl": "https://fal.ai/models/fal-ai/drct-super-resolution/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "upscaling_factor": {
        "type": "integer",
        "description": "Upscaling factor.",
        "required": false,
        "enum": [
          4
        ],
        "default": 4,
        "examples": [
          4
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to upscale.",
        "required": true,
        "examples": [
          "https://fal.media/files/rabbit/JlBgYUyQRS3zxiBu_B4fM.png",
          "https://fal.media/files/monkey/e6RtJf_ue0vyWzeiEmTby.png",
          "https://fal.media/files/monkey/A6HGsigx4mmvs-hJVoOZX.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Upscaled image"
      }
    }
  },
  {
    "id": "fal-ai/veo2",
    "title": "Veo 2",
    "category": "text-to-video",
    "description": "Veo 2 creates videos with realistic motion and high quality output. Explore different styles and find your own with extensive camera controls.",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/veo2/veo2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/veo2",
    "documentationUrl": "https://fal.ai/models/fal-ai/veo2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing the video you want to generate",
        "required": true,
        "minLength": 1,
        "examples": [
          "The camera floats gently through rows of pastel-painted wooden beehives, buzzing honeybees gliding in and out of frame. The motion settles on the refined farmer standing at the center, his pristine white beekeeping suit gleaming in the golden afternoon light. He lifts a jar of honey, tilting it slightly to catch the light. Behind him, tall sunflowers sway rhythmically in the breeze, their petals glowing in the warm sunlight. The camera tilts upward to reveal a retro farmhouse with mint-green shutters, its walls dappled with shadows from swaying trees. Shot with a 35mm lens on Kodak Portra 400 film, the golden light creates rich textures on the farmer's gloves, marmalade jar, and weathered wood of the beehives."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5s",
          "6s",
          "7s",
          "8s"
        ],
        "default": "5s"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "seed": {
        "type": "integer",
        "description": "A seed to use for the video generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to guide the video generation",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the video generation",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/nafnet/denoise",
    "title": "NAFNet-denoise",
    "category": "image-to-image",
    "description": "Use NAFNet to fix issues like blurriness and noise in your images. This model specializes in image restoration and can help enhance the overall quality of your photography.",
    "tags": [
      "image-restoration",
      "deblur",
      "denoise"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/HyeESWwRpMtc-Q0fVsDdt_2de9ad23b7894d18abc770358c32eee7.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/nafnet/denoise",
    "documentationUrl": "https://fal.ai/models/fal-ai/nafnet/denoise/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "seed to be used for generation",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/nafnet/noisy.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/nafnet/deblur",
    "title": "NAFNet-deblur",
    "category": "image-to-image",
    "description": "Use NAFNet to fix issues like blurriness and noise in your images. This model specializes in image restoration and can help enhance the overall quality of your photography.",
    "tags": [
      "image-restoration",
      "deblur",
      "denoise"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/HyeESWwRpMtc-Q0fVsDdt_2de9ad23b7894d18abc770358c32eee7.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/nafnet/deblur",
    "documentationUrl": "https://fal.ai/models/fal-ai/nafnet/deblur/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "seed to be used for generation",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/nafnet/blurry.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/post-processing",
    "title": "Post Processing",
    "category": "image-to-image",
    "description": "Post Processing is an endpoint that can enhance images using a variety of techniques including grain, blur, sharpen, and more.",
    "tags": [
      "stylized",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/post-process/post-processing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/post-processing",
    "documentationUrl": "https://fal.ai/models/fal-ai/post-processing/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "blue_shift": {
        "type": "integer",
        "description": "Blue channel shift amount",
        "required": false,
        "minimum": -20,
        "maximum": 20,
        "default": 0
      },
      "enable_chromatic": {
        "type": "boolean",
        "description": "Enable chromatic aberration",
        "required": false,
        "default": false
      },
      "glow_intensity": {
        "type": "number",
        "description": "Glow intensity",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 1
      },
      "enable_glow": {
        "type": "boolean",
        "description": "Enable glow effect",
        "required": false,
        "default": false
      },
      "dodge_burn_mode": {
        "type": "string",
        "description": "Dodge and burn mode",
        "required": false,
        "enum": [
          "dodge",
          "burn",
          "dodge_and_burn",
          "burn_and_dodge",
          "color_dodge",
          "color_burn",
          "linear_dodge",
          "linear_burn"
        ],
        "default": "dodge"
      },
      "preserve_edges": {
        "type": "number",
        "description": "Edge preservation factor",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.75
      },
      "blur_sigma": {
        "type": "number",
        "description": "Sigma for Gaussian blur",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 1
      },
      "desaturate_method": {
        "type": "string",
        "description": "Desaturation method",
        "required": false,
        "enum": [
          "luminance (Rec.709)",
          "luminance (Rec.601)",
          "average",
          "lightness"
        ],
        "default": "luminance (Rec.709)"
      },
      "enable_blur": {
        "type": "boolean",
        "description": "Enable blur effect",
        "required": false,
        "default": false
      },
      "blur_radius": {
        "type": "integer",
        "description": "Blur radius",
        "required": false,
        "minimum": 0,
        "maximum": 31,
        "default": 3
      },
      "cas_amount": {
        "type": "number",
        "description": "CAS sharpening amount",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "grain_style": {
        "type": "string",
        "description": "Style of film grain to apply",
        "required": false,
        "enum": [
          "modern",
          "analog",
          "kodak",
          "fuji",
          "cinematic",
          "newspaper"
        ],
        "default": "modern"
      },
      "gamma": {
        "type": "number",
        "description": "Gamma adjustment",
        "required": false,
        "minimum": 0.2,
        "maximum": 2.2,
        "default": 1
      },
      "dodge_burn_intensity": {
        "type": "number",
        "description": "Dodge and burn intensity",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "enable_vignette": {
        "type": "boolean",
        "description": "Enable vignette effect",
        "required": false,
        "default": false
      },
      "blur_type": {
        "type": "string",
        "description": "Type of blur to apply",
        "required": false,
        "enum": [
          "gaussian",
          "kuwahara"
        ],
        "default": "gaussian"
      },
      "dissolve_image_url": {
        "type": "string",
        "description": "URL of second image for dissolve",
        "required": false,
        "default": ""
      },
      "red_shift": {
        "type": "integer",
        "description": "Red channel shift amount",
        "required": false,
        "minimum": -20,
        "maximum": 20,
        "default": 0
      },
      "enable_desaturate": {
        "type": "boolean",
        "description": "Enable desaturation effect",
        "required": false,
        "default": false
      },
      "grain_intensity": {
        "type": "number",
        "description": "Film grain intensity (when enabled)",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.4
      },
      "tint_mode": {
        "type": "string",
        "description": "Tint color mode",
        "required": false,
        "enum": [
          "sepia",
          "red",
          "green",
          "blue",
          "cyan",
          "magenta",
          "yellow",
          "purple",
          "orange",
          "warm",
          "cool",
          "lime",
          "navy",
          "vintage",
          "rose",
          "teal",
          "maroon",
          "peach",
          "lavender",
          "olive"
        ],
        "default": "sepia"
      },
      "green_direction": {
        "type": "string",
        "description": "Green channel shift direction",
        "required": false,
        "enum": [
          "horizontal",
          "vertical"
        ],
        "default": "horizontal"
      },
      "red_direction": {
        "type": "string",
        "description": "Red channel shift direction",
        "required": false,
        "enum": [
          "horizontal",
          "vertical"
        ],
        "default": "horizontal"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
        ]
      },
      "vertex_x": {
        "type": "number",
        "description": "Vertex X position",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "tint_strength": {
        "type": "number",
        "description": "Tint strength",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 1
      },
      "enable_dissolve": {
        "type": "boolean",
        "description": "Enable dissolve effect",
        "required": false,
        "default": false
      },
      "smart_sharpen_strength": {
        "type": "number",
        "description": "Smart sharpen strength",
        "required": false,
        "minimum": 0,
        "maximum": 25,
        "default": 5
      },
      "enable_grain": {
        "type": "boolean",
        "description": "Enable film grain effect",
        "required": false,
        "default": false
      },
      "solarize_threshold": {
        "type": "number",
        "description": "Solarize threshold",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "enable_sharpen": {
        "type": "boolean",
        "description": "Enable sharpen effect",
        "required": false,
        "default": false
      },
      "enable_dodge_burn": {
        "type": "boolean",
        "description": "Enable dodge and burn effect",
        "required": false,
        "default": false
      },
      "glow_radius": {
        "type": "integer",
        "description": "Glow blur radius",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 5
      },
      "sharpen_alpha": {
        "type": "number",
        "description": "Sharpen strength (for basic mode)",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      },
      "enable_color_correction": {
        "type": "boolean",
        "description": "Enable color correction",
        "required": false,
        "default": false
      },
      "enable_solarize": {
        "type": "boolean",
        "description": "Enable solarize effect",
        "required": false,
        "default": false
      },
      "contrast": {
        "type": "number",
        "description": "Contrast adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "noise_radius": {
        "type": "integer",
        "description": "Noise radius for smart sharpen",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 7
      },
      "grain_scale": {
        "type": "number",
        "description": "Film grain scale (when enabled)",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 10
      },
      "brightness": {
        "type": "number",
        "description": "Brightness adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "temperature": {
        "type": "number",
        "description": "Color temperature adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "sharpen_mode": {
        "type": "string",
        "description": "Type of sharpening to apply",
        "required": false,
        "enum": [
          "basic",
          "smart",
          "cas"
        ],
        "default": "basic"
      },
      "blue_direction": {
        "type": "string",
        "description": "Blue channel shift direction",
        "required": false,
        "enum": [
          "horizontal",
          "vertical"
        ],
        "default": "horizontal"
      },
      "dissolve_factor": {
        "type": "number",
        "description": "Dissolve blend factor",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "vignette_strength": {
        "type": "number",
        "description": "Vignette strength (when enabled)",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 0.5
      },
      "sharpen_radius": {
        "type": "integer",
        "description": "Sharpen radius (for basic mode)",
        "required": false,
        "minimum": 1,
        "maximum": 15,
        "default": 1
      },
      "parabolize_coeff": {
        "type": "number",
        "description": "Parabolize coefficient",
        "required": false,
        "minimum": -10,
        "maximum": 10,
        "default": 1
      },
      "saturation": {
        "type": "number",
        "description": "Saturation adjustment",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "enable_tint": {
        "type": "boolean",
        "description": "Enable color tint effect",
        "required": false,
        "default": false
      },
      "green_shift": {
        "type": "integer",
        "description": "Green channel shift amount",
        "required": false,
        "minimum": -20,
        "maximum": 20,
        "default": 0
      },
      "enable_parabolize": {
        "type": "boolean",
        "description": "Enable parabolize effect",
        "required": false,
        "default": false
      },
      "desaturate_factor": {
        "type": "number",
        "description": "Desaturation factor",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "smart_sharpen_ratio": {
        "type": "number",
        "description": "Smart sharpen blend ratio",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "vertex_y": {
        "type": "number",
        "description": "Vertex Y position",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The processed images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/skyreels-i2v",
    "title": "Skyreels V1 (Image-to-Video)",
    "category": "image-to-video",
    "description": "SkyReels V1 is the first and most advanced open-source human-centric video foundation model. By fine-tuning HunyuanVideo on O(10M) high-quality film and television clips",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/skyreels-i2v.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/skyreels-i2v",
    "documentationUrl": "https://fal.ai/models/fal-ai/skyreels-i2v/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "Aspect ratio of the output video",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image input.",
        "required": true,
        "examples": [
          "https://fal.media/files/panda/TuXlMwArpQcdYNCLAEM8K.webp"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for generation (between 1.0 and 20.0)",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 6
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for generation. If not provided, a random seed will be used.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to guide generation away from certain attributes.",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generation"
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flowedit",
    "title": "Flow-Edit",
    "category": "image-to-image",
    "description": "The model provides you high quality image editing capabilities.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/bAGbLA85i32P9R6-lEeEI_d0d975dbda3846fb89034ab9067ecee3.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flowedit",
    "documentationUrl": "https://fal.ai/models/fal-ai/flowedit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "src_guidance_scale": {
        "type": "integer",
        "description": "Guidance scale for the source.",
        "required": false,
        "minimum": 0,
        "maximum": 30,
        "default": 1.5
      },
      "n_min": {
        "type": "integer",
        "description": "Minimum step for improved style edits",
        "required": false,
        "default": 0
      },
      "n_max": {
        "type": "integer",
        "description": "Control the strength of the edit",
        "required": false,
        "default": 23
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/FlowEdit/lighthouse.png"
        ]
      },
      "source_prompt": {
        "type": "string",
        "description": "Prompt of the image to be used.",
        "required": true,
        "examples": [
          "The image features a tall white lighthouse standing prominently\n      on a hill, with a beautiful blue sky in the background. The lighthouse is illuminated\n      by a bright light, making it a prominent landmark in the scene."
        ]
      },
      "tar_guidance_scale": {
        "type": "integer",
        "description": "Guidance scale for target.",
        "required": false,
        "minimum": 0,
        "maximum": 30,
        "default": 5.5
      },
      "target_prompt": {
        "type": "string",
        "description": "Prompt of the image to be made.",
        "required": true,
        "examples": [
          "The image features Big ben clock tower standing prominently\n      on a hill, with a beautiful blue sky in the background. The Big ben clock tower is illuminated\n      by a bright light, making it a prominent landmark in the scene."
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation. If set none, a random seed will be used.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Steps for which the model should run.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "n_avg": {
        "type": "integer",
        "description": "Average step count",
        "required": false,
        "default": 1
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/kokoro/hindi",
    "title": "Kokoro TTS (Hindi)",
    "category": "text-to-audio",
    "description": "A fast and expressive Hindi text-to-speech model with clear pronunciation and accurate intonation.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/hindi",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/hindi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "सपने वो नहीं जो हम सोते समय देखते हैं, सपने वो हैं जो हमें सोने नहीं देते।"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "hf_alpha",
          "hf_beta",
          "hm_omega",
          "hm_psi"
        ],
        "examples": [
          "hf_alpha"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/mandarin-chinese",
    "title": "Kokoro TTS (Mandarin Chinese)",
    "category": "text-to-audio",
    "description": "A highly efficient Mandarin Chinese text-to-speech model that captures natural tones and prosody.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/mandarin-chinese",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/mandarin-chinese/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "每一个伟大的旅程，都始于勇敢迈出的第一步。加油，你可以做到！"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "zf_xiaobei",
          "zf_xiaoni",
          "zf_xiaoxiao",
          "zf_xiaoyi",
          "zm_yunjian",
          "zm_yunxi",
          "zm_yunxia",
          "zm_yunyang"
        ],
        "examples": [
          "zf_xiaobei"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/brazilian-portuguese",
    "title": "Kokoro TTS (Brazilian Portuguese)",
    "category": "text-to-audio",
    "description": "A natural and expressive Brazilian Portuguese text-to-speech model optimized for clarity and fluency.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/brazilian-portuguese",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/brazilian-portuguese/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "O segredo do sucesso é a persistência. Nunca desista dos seus sonhos!"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "pf_dora",
          "pm_alex",
          "pm_santa"
        ],
        "examples": [
          "pf_dora"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/french",
    "title": "Kokoro TTS (French)",
    "category": "text-to-audio",
    "description": "An expressive and natural French text-to-speech model for both European and Canadian French.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/french",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/french/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "La seule limite à nos réalisations de demain, ce sont nos doutes d’aujourd’hui."
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "ff_siwis"
        ],
        "examples": [
          "ff_siwis"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/japanese",
    "title": "Kokoro TTS (Japanese)",
    "category": "text-to-audio",
    "description": "A fast and natural-sounding Japanese text-to-speech model optimized for smooth pronunciation.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/japanese",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/japanese/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "夢を追いかけることを恐れないでください。努力すれば、必ず道は開けます！"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "jf_alpha",
          "jf_gongitsune",
          "jf_nezumi",
          "jf_tebukuro",
          "jm_kumo"
        ],
        "examples": [
          "jf_alpha"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/american-english",
    "title": "Kokoro TTS",
    "category": "text-to-audio",
    "description": "Kokoro is a lightweight text-to-speech model that delivers comparable quality to larger models while being significantly faster and more cost-efficient.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/american-english",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/american-english/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "default": "",
        "examples": [
          "The future belongs to those who believe in the beauty of their dreams. So, dream big, work hard, and make it happen!"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": false,
        "enum": [
          "af_heart",
          "af_alloy",
          "af_aoede",
          "af_bella",
          "af_jessica",
          "af_kore",
          "af_nicole",
          "af_nova",
          "af_river",
          "af_sarah",
          "af_sky",
          "am_adam",
          "am_echo",
          "am_eric",
          "am_fenrir",
          "am_liam",
          "am_michael",
          "am_onyx",
          "am_puck",
          "am_santa"
        ],
        "default": "af_heart",
        "examples": [
          "af_heart"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/british-english",
    "title": "Kokoro TTS (British English)",
    "category": "text-to-audio",
    "description": "A high-quality British English text-to-speech model offering natural and expressive voice synthesis.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/british-english",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/british-english/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Ladies and gentlemen, welcome aboard. Please ensure your seatbelt is fastened and your tray table is stowed as we prepare for takeoff."
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "bf_alice",
          "bf_emma",
          "bf_isabella",
          "bf_lily",
          "bm_daniel",
          "bm_fable",
          "bm_george",
          "bm_lewis"
        ],
        "examples": [
          "bf_alice"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/spanish",
    "title": "Kokoro TTS (Spanish)",
    "category": "text-to-audio",
    "description": "A natural-sounding Spanish text-to-speech model optimized for Latin American and European Spanish.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/spanish",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/spanish/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "La vida es un viaje, no un destino. Disfruta cada momento y sigue adelante con pasión."
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "ef_dora",
          "em_alex",
          "em_santa"
        ],
        "examples": [
          "ef_dora"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/zonos",
    "title": "Zonos-Audio-Clone",
    "category": "text-to-audio",
    "description": "Clone voice of any person and speak anything in their voice using zonos' voice cloning.",
    "tags": [
      "voice cloning"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/Ben2/2VVmzf2y5GyRdFoof8BLu.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/zonos",
    "documentationUrl": "https://fal.ai/models/fal-ai/zonos/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The content generated using cloned voice.",
        "required": true,
        "examples": [
          "Fal is the fastest solution for your image generation."
        ]
      },
      "reference_audio_url": {
        "type": "string",
        "description": "The reference audio.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/zonos/demo_voice_zonos.wav"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio"
      }
    }
  },
  {
    "id": "fal-ai/kokoro/italian",
    "title": "Kokoro TTS (Italian)",
    "category": "text-to-audio",
    "description": "A high-quality Italian text-to-speech model delivering smooth and expressive speech synthesis.",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kokoro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kokoro/italian",
    "documentationUrl": "https://fal.ai/models/fal-ai/kokoro/italian/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Ogni giorno è una nuova opportunità per scrivere la tua storia. Rendila straordinaria!"
        ]
      },
      "voice": {
        "type": "string",
        "description": "Voice ID for the desired voice.",
        "required": true,
        "enum": [
          "if_sara",
          "im_nicola"
        ],
        "examples": [
          "if_sara"
        ]
      },
      "speed": {
        "type": "number",
        "description": "Speed of the generated audio. Default is 1.0.",
        "required": false,
        "minimum": 0.1,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2/image-to-video",
    "title": "Luma Ray 2 (Image to Video)",
    "category": "image-to-video",
    "description": "Ray2 is a large-scale video generative model capable of creating realistic visuals with natural, coherent motion.",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
        "required": false,
        "enum": [
          "540p",
          "720p",
          "1080p"
        ],
        "default": "540p"
      },
      "loop": {
        "type": "boolean",
        "description": "Whether the video should loop (end of video is blended with the beginning)",
        "required": false,
        "default": false
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video",
        "required": false,
        "enum": [
          "5s",
          "9s"
        ],
        "default": "5s"
      },
      "image_url": {
        "type": "string",
        "description": "Initial image to start the video from. Can be used together with end_image_url.",
        "required": false,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      },
      "end_image_url": {
        "type": "string",
        "description": "Final image to end the video with. Can be used together with image_url.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the generated video"
      }
    }
  },
  {
    "id": "fal-ai/got-ocr/v2",
    "title": "GOT OCR 2.0",
    "category": "vision",
    "description": "GOT-OCR2 works on a wide range of tasks, including plain document OCR, scene text OCR, formatted document OCR, and even OCR for tables, charts, mathematical formulas, geometric shapes, molecular formulas and sheet music.",
    "tags": [
      "optical character recognition",
      "high-res",
      "utility"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/roeSKm7MGJpsQpuFfpd5S_05ed784bd82b4519bd3b0dbd41c0e946.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/got-ocr/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/got-ocr/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "do_format": {
        "type": "boolean",
        "description": "Generate the output in formatted mode.",
        "required": false,
        "default": false
      },
      "multi_page": {
        "type": "boolean",
        "description": "Use provided images to generate a single output.",
        "required": false,
        "default": false
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images.",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "outputs": {
        "type": "array",
        "description": "Generated output",
        "items": {
          "type": "string"
        }
      }
    }
  },
  {
    "id": "fal-ai/flux-control-lora-canny",
    "title": "FLUX.1 [dev] Control LoRA Canny",
    "category": "text-to-image",
    "description": "FLUX Control LoRA Canny is a high-performance endpoint that uses a control image to transfer structure to the generated image, using a Canny edge map.",
    "tags": [
      "lora",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/control-lora-canny.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-control-lora-canny",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-control-lora-canny/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "control_lora_strength": {
        "type": "number",
        "description": "The strength of the control lora.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "control_lora_image_url": {
        "type": "string",
        "description": "\n            The image to use for control lora. This is used to control the style of the generated image.\n        ",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-control-lora-canny/image-to-image",
    "title": "FLUX.1 [dev] Control LoRA Canny",
    "category": "image-to-image",
    "description": "FLUX Control LoRA Canny is a high-performance endpoint that uses a control image using a Canny edge map to transfer structure to the generated image and another initial image to guide color.",
    "tags": [
      "lora",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/control-lora-canny.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-control-lora-canny/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-control-lora-canny/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "control_lora_strength": {
        "type": "number",
        "description": "The strength of the control lora.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "control_lora_image_url": {
        "type": "string",
        "description": "\n            The image to use for control lora. This is used to control the style of the generated image.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-control-lora-depth/image-to-image",
    "title": "FLUX.1 [dev] Control LoRA Depth",
    "category": "image-to-image",
    "description": "FLUX Control LoRA Depth is a high-performance endpoint that uses a control image using a depth map to transfer structure to the generated image and another initial image to guide color.",
    "tags": [
      "lora",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/control-lora-depth.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-control-lora-depth/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-control-lora-depth/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "control_lora_strength": {
        "type": "number",
        "description": "The strength of the control lora.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "control_lora_image_url": {
        "type": "string",
        "description": "\n            The image to use for control lora. This is used to control the style of the generated image.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ben/v2/image",
    "title": "ben-v2-image",
    "category": "image-to-image",
    "description": "A fast and high quality model for image background removal.",
    "tags": [
      "background removal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/Ben2/FepDP7G4K2nxlX0sq6AMB_945a221d079e447c9bcfea77f931cdc1.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ben/v2/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/ben/v2/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for background removal",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/Ben2/arduino-uno-board-electronics-hand-600nw-1869855883.webp"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The output image after background removal."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-control-lora-depth",
    "title": "FLUX.1 [dev] Control LoRA Depth",
    "category": "text-to-image",
    "description": "FLUX Control LoRA Depth is a high-performance endpoint that uses a control image to transfer structure to the generated image, using a depth map.",
    "tags": [
      "lora",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/control-lora-depth.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-control-lora-depth",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-control-lora-depth/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "control_lora_strength": {
        "type": "number",
        "description": "The strength of the control lora.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "preprocess_depth": {
        "type": "boolean",
        "description": "\n            If set to true, the input image will be preprocessed to extract depth information.\n            This is useful for generating depth maps from images.\n        ",
        "required": false,
        "default": true
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "control_lora_image_url": {
        "type": "string",
        "description": "\n            The image to use for control lora. This is used to control the style of the generated image.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01-director",
    "title": "MiniMax (Hailuo AI) Video 01 Director",
    "category": "text-to-video",
    "description": "Generate video clips more accurately with respect to natural language descriptions and using camera movement instructions for shot control.",
    "tags": [
      "motion",
      "transformation",
      "camera-controls"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/red_clouds.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01-director",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01-director/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "[Push in]Close up of a tense woman looks to the left, startled by a sound, in a darkened kitchen, Pots and pans hang ominously, the window in the kitchen is open and the wind softly blows the pans and creates an ominous mood. [Shake]the woman's shock turns to fear. Black-and-white film noir shot dimly lit, 1950s-style, with dramatic, high-contrast shadows. The overall atmosphere is reminiscent of Alfred Hitchcock's suspenseful storytelling, evoking a looming sense of dread with stark chiaroscuro lighting and a slight film-grain texture."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ben/v2/video",
    "title": "Ben-Video-Bg-Rm",
    "category": "video-to-video",
    "description": "A model for high quality and smooth background removal for videos.",
    "tags": [
      "segmentation",
      "background removal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/Ben2/Vi9PBzFF8BfuKGsLCvoH-_773fe2c0efc744af900eaac2047b9b5f.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ben/v2/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ben/v2/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL of video to be used for background removal.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/Ben2/100063-video-2160.mp4"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation.",
        "required": false
      },
      "background_color": {
        "type": "array",
        "description": "Optional RGB values (0-255) for the background color. If not provided, the background will be transparent. For ex: [0, 0, 0]",
        "required": false,
        "items": {
          "0": {
            "type": "integer"
          },
          "1": {
            "type": "integer"
          },
          "2": {
            "type": "integer"
          }
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/imagen3",
    "title": "Imagen3",
    "category": "text-to-image",
    "description": "Imagen3 is a high-quality text-to-image model that generates realistic images from text prompts.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/imagen3/imagen.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imagen3",
    "documentationUrl": "https://fal.ai/models/fal-ai/imagen3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing what you want to see",
        "required": true,
        "examples": [
          "A serene landscape with mountains reflected in a crystal clear lake at sunset"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "3:4",
          "4:3"
        ],
        "default": "1:1"
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-4)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A description of what to discourage in the generated images",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/imagen3/fast",
    "title": "Imagen3 Fast",
    "category": "text-to-image",
    "description": "Imagen3 Fast is a high-quality text-to-image model that generates realistic images from text prompts.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/imagen3/imagen.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imagen3/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/imagen3/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The text prompt describing what you want to see",
        "required": true,
        "examples": [
          "A serene landscape with mountains reflected in a crystal clear lake at sunset"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "1:1",
          "16:9",
          "9:16",
          "3:4",
          "4:3"
        ],
        "default": "1:1"
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate (1-4)",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A description of what to discourage in the generated images",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for generation"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/upscale",
    "title": "Ideogram Upscale",
    "category": "image-to-image",
    "description": "Ideogram Upscale enhances the resolution of the reference image by up to 2X and might enhance the reference image too. Optionally refine outputs with a prompt for guided improvements.",
    "tags": [
      "upscaling",
      "high-res"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/upscale",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/upscale/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": null,
        "description": "The prompt to upscale the image with",
        "required": false,
        "default": ""
      },
      "detail": {
        "type": "integer",
        "description": "The detail of the upscaled image",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 50
      },
      "resemblance": {
        "type": "integer",
        "description": "The resemblance of the upscaled image to the original image",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 50
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to upscale",
        "required": true,
        "examples": [
          "https://fal.media/files/monkey/e6RtJf_ue0vyWzeiEmTby.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video-img2vid-lora",
    "title": "Hunyuan Video Image-to-Video LoRA Inference",
    "category": "image-to-video",
    "description": "Image to Video for the Hunyuan Video model using a custom trained LoRA.",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-img2vid-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-img2vid-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A low angle shot of a man walking down a street, illuminated by the neon signs of the bars around him"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL to the image to generate the video from. The image must be 960x544 or it will get cropped and resized to that size.",
        "required": true,
        "examples": [
          "https://d3phaj0sisr2ct.cloudfront.net/research/eugene.jpg"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/codeformer",
    "title": "CodeFormer",
    "category": "image-to-image",
    "description": "Fix distorted or blurred photos of people with CodeFormer.",
    "tags": [
      "image-restoration",
      "faces",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/code_thumbnail.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/codeformer",
    "documentationUrl": "https://fal.ai/models/fal-ai/codeformer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "aligned": {
        "type": "boolean",
        "description": "Should faces etc should be aligned.",
        "required": false,
        "default": false
      },
      "upscaling": {
        "type": "number",
        "description": "Upscaling factor",
        "required": false,
        "default": 2
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/codeformer/codeformer_poor_1.jpeg"
        ]
      },
      "only_center_face": {
        "type": "boolean",
        "description": "Should only center face be restored",
        "required": false,
        "default": false
      },
      "face_upscale": {
        "type": "boolean",
        "description": "Should faces be upscaled",
        "required": false,
        "default": true
      },
      "fidelity": {
        "type": "number",
        "description": "Weight of the fidelity factor.",
        "required": false,
        "default": 0.5
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducible generation.",
        "required": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/lumina-image/v2",
    "title": "Lumina Image 2",
    "category": "text-to-image",
    "description": "Lumina-Image-2.0 is a 2 billion parameter flow-based diffusion transforer which features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "tags": [
      "diffusion",
      "typography",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/lumina-image-v2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lumina-image/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/lumina-image/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A vibrant and artistic digital composition featuring colorful splashes of paint in the background, creating an energetic and dynamic effect. The text 'Lumina on Fal' is elegantly integrated into the scene, standing out with a modern, bold, and slightly futuristic font. The colors are bright and varied, including neon blues, purples, pinks, and oranges, blending seamlessly in a fluid, abstract style. The text appears slightly illuminated, complementing the vivid splashes around it."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "cfg_trunc_ratio": {
        "type": "number",
        "description": "The ratio of the timestep interval to apply normalization-based guidance scale.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "system_prompt": {
        "type": "string",
        "description": "The system prompt to use.",
        "required": false,
        "default": "You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts."
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "cfg_normalization": {
        "type": "boolean",
        "description": "Whether to apply normalization-based guidance scale.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video/video-to-video",
    "title": "Hunyuan Video (Video-to-Video)",
    "category": "video-to-video",
    "description": "Hunyuan Video is an Open video generation model with high visual quality, motion diversity, text-video alignment, and generation stability. Use this endpoint to generate videos from videos.",
    "tags": [
      "video to video",
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a dark blue leather jacket, a long pink dress, and bright yellow boots, and carries a black purse."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate.",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video input.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/hunyuan_video/hunyuan_v2v_input.mp4"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Strength for Video-to-Video",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to run. Lower gets faster results, higher gets better results.",
        "required": false,
        "minimum": 2,
        "maximum": 30,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "num_frames": {
        "type": "string",
        "description": "The number of frames to generate.",
        "required": false,
        "enum": [
          "129",
          "85"
        ],
        "default": 129
      },
      "pro_mode": {
        "type": "boolean",
        "description": "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video-lora/video-to-video",
    "title": "Hunyuan Video LoRA Inference (Video-to-Video)",
    "category": "video-to-video",
    "description": "Hunyuan Video is an Open video generation model with high visual quality, motion diversity, text-video alignment, and generation stability. Use this endpoint to generate videos from videos.",
    "tags": [
      "video to video",
      "motion",
      "lora"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a dark blue leather jacket, a long pink dress, and bright yellow boots, and carries a black purse."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate.",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/hunyuan_video/hunyuan_v2v_input.mp4"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "strength": {
        "type": "number",
        "description": "Strength of video-to-video",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.75
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "num_frames": {
        "type": "string",
        "description": "The number of frames to generate.",
        "required": false,
        "enum": [
          "129",
          "85"
        ],
        "default": 129
      },
      "pro_mode": {
        "type": "boolean",
        "description": "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/text-to-video",
    "title": "PixVerse v3.5",
    "category": "text-to-video",
    "description": "Generate high quality video clips from text prompts using PixVerse v3.5",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/image-to-video/fast",
    "title": "PixVerse v3.5: Image to Video Fast",
    "category": "image-to-video",
    "description": "Generate high quality video clips from text and image prompts quickly using PixVerse v3.5 Fast",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/image-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/image-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/text-to-video/fast",
    "title": "PixVerse v3.5 Fast",
    "category": "text-to-video",
    "description": "Generate high quality video clips quickly from text prompts using PixVerse v3.5 Fast",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/text-to-video/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/text-to-video/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/image-to-video",
    "title": "PixVerse v3.5: Image to Video",
    "category": "image-to-video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v3.5",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixverse/v3.5/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "4:3",
          "1:1",
          "3:4",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video",
        "required": false,
        "enum": [
          "360p",
          "540p",
          "720p",
          "1080p"
        ],
        "default": "720p"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated video",
        "required": false,
        "enum": [
          "anime",
          "3d_animation",
          "clay",
          "comic",
          "cyberpunk"
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
        "required": false,
        "enum": [
          "5",
          "8"
        ],
        "default": "5"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to be used for the generation",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/janus",
    "title": "DeepSeek Janus-Pro",
    "category": "text-to-image",
    "description": "DeepSeek Janus-Pro is a novel text-to-image model that unifies multimodal understanding and generation through an autoregressive framework",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/janus/januspro.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/janus",
    "documentationUrl": "https://fal.ai/models/fal-ai/janus/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "beautiful girl, inside a house"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate in parallel.",
        "required": false,
        "minimum": 1,
        "maximum": 16,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square"
      },
      "cfg_weight": {
        "type": "number",
        "description": "Classifier Free Guidance scale - how closely to follow the prompt.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "temperature": {
        "type": "number",
        "description": "Controls randomness in the generation. Higher values make output more random.",
        "required": false,
        "minimum": 0.1,
        "maximum": 2,
        "default": 1
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducible generation.",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/yue",
    "title": "YuE: Lyrics to Song",
    "category": "text-to-audio",
    "description": "YuE is a groundbreaking series of open-source foundation models designed for music generation, specifically for transforming lyrics into full songs.",
    "tags": [
      "music"
    ],
    "thumbnailUrl": "https://fal.media/files/lion/JAvN_VTh4kcTwtLBuS-A-_152d79bde246442ea7d8a0e2422d90d1.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/yue",
    "documentationUrl": "https://fal.ai/models/fal-ai/yue/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "lyrics": {
        "type": "string",
        "description": "The prompt to generate an image from. Must have two sections. Sections start with either [chorus] or a [verse].",
        "required": true,
        "examples": [
          "[verse]\nStaring at the sunset, colors paint the sky\nThoughts of you keep swirling, can't deny\nI know I let you down, I made mistakes\nBut I'm here to mend the heart I didn't break\n\n[chorus]\nEvery road you take, I'll be one step behind\nEvery dream you chase, I'm reaching for the light\nYou can't fight this feeling now\nI won't back down\nYou know you can't deny it now\nI won't back down\n"
        ]
      },
      "genres": {
        "type": "string",
        "description": "The genres (separated by a space ' ') to guide the music generation.",
        "required": true,
        "examples": [
          "inspiring female uplifting pop airy vocal electronic bright vocal vocal",
          "R&B male hiphop pop 80s vocal electronic dark vocal vocal"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "Generated music file."
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2",
    "title": "Luma Ray 2",
    "category": "text-to-video",
    "description": "Ray2 is a large-scale video generative model capable of creating realistic visuals with natural, coherent motion.",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/ray-2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
        "required": false,
        "enum": [
          "540p",
          "720p",
          "1080p"
        ],
        "default": "540p"
      },
      "loop": {
        "type": "boolean",
        "description": "Whether the video should loop (end of video is blended with the beginning)",
        "required": false,
        "default": false
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video (9s costs 2x more)",
        "required": false,
        "enum": [
          "5s",
          "9s"
        ],
        "default": "5s"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling/v1-5/kolors-virtual-try-on",
    "title": "Kling Kolors Virtual TryOn v1.5",
    "category": "image-to-image",
    "description": "Kling Kolors Virtual TryOn v1.5 is a high quality image based Try-On endpoint which can be used for commercial try on.",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/kling-tryon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling/v1-5/kolors-virtual-try-on",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling/v1-5/kolors-virtual-try-on/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If true, the function will return the image in the response.",
        "required": false,
        "default": false
      },
      "garment_image_url": {
        "type": "string",
        "description": "Url to the garment image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/leffa/tshirt_image.jpg"
        ]
      },
      "human_image_url": {
        "type": "string",
        "description": "Url for the human image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/leffa/person_image.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The output image."
      }
    }
  },
  {
    "id": "fal-ai/ffmpeg-api/waveform",
    "title": "FFmpeg API Waveform",
    "category": "json",
    "description": "Get waveform data from audio files using FFmpeg API.",
    "tags": [
      "ffmpeg"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ffmpeg-api-waveform.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/waveform",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/waveform/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "points_per_second": {
        "type": "number",
        "description": "Controls how many points are sampled per second of audio. Lower values (e.g. 1-2) create a coarser waveform, higher values (e.g. 4-10) create a more detailed one.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4
      },
      "smoothing_window": {
        "type": "integer",
        "description": "Size of the smoothing window. Higher values create a smoother waveform. Must be an odd number.",
        "required": false,
        "minimum": 1,
        "maximum": 21,
        "default": 3
      },
      "media_url": {
        "type": "string",
        "description": "URL of the audio file to analyze",
        "required": true
      },
      "precision": {
        "type": "integer",
        "description": "Number of decimal places for the waveform values. Higher values provide more precision but increase payload size.",
        "required": false,
        "minimum": 1,
        "maximum": 6,
        "default": 2
      }
    },
    "outputParameters": {
      "precision": {
        "type": "integer",
        "description": "Number of decimal places used in the waveform values"
      },
      "points": {
        "type": "integer",
        "description": "Number of points in the waveform data"
      },
      "duration": {
        "type": "number",
        "description": "Duration of the audio in seconds"
      },
      "waveform": {
        "type": "array",
        "description": "Normalized waveform data as an array of values between -1 and 1. The number of points is determined by audio duration × points_per_second.",
        "items": {
          "type": "number"
        }
      }
    }
  },
  {
    "id": "fal-ai/ffmpeg-api/metadata",
    "title": "FFmpeg API Metadata",
    "category": "json",
    "description": "Get encoding metadata from video and audio files using FFmpeg API.",
    "tags": [
      "ffmpeg"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ffmpeg-api-metadata.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/metadata",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/metadata/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "extract_frames": {
        "type": "boolean",
        "description": "Whether to extract the start and end frames for videos. Note that when true the request will be slower.",
        "required": false,
        "default": false
      },
      "media_url": {
        "type": "string",
        "description": "URL of the media file (video or audio) to analyze",
        "required": true
      }
    },
    "outputParameters": {
      "media": {
        "type": null,
        "description": "Metadata for the analyzed media file (either Video or Audio)"
      }
    }
  },
  {
    "id": "fal-ai/ffmpeg-api/compose",
    "title": "FFmpeg API Compose",
    "category": "video-to-video",
    "description": "Compose videos from multiple media sources using FFmpeg API.",
    "tags": [
      "ffmpeg"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ffmpeg-api-compose.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/compose",
    "documentationUrl": "https://fal.ai/models/fal-ai/ffmpeg-api/compose/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "tracks": {
        "type": "array",
        "description": "List of tracks to be combined into the final media",
        "required": true,
        "items": {
          "$ref": "#/components/schemas/Track"
        }
      }
    },
    "outputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL of the processed video file"
      },
      "thumbnail_url": {
        "type": "string",
        "description": "URL of the video's thumbnail image"
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01-subject-reference",
    "title": "MiniMax (Hailuo AI) Video 01 Subject Reference",
    "category": "image-to-video",
    "description": "Generate video clips maintaining consistent, realistic facial features and identity across dynamic video content",
    "tags": [
      "subject",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/minimax-video-01-subject-reference.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01-subject-reference",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01-subject-reference/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "subject_reference_image_url": {
        "type": "string",
        "description": "URL of the subject reference image to use for consistent subject appearance",
        "required": true,
        "examples": [
          "https://fal.media/files/tiger/s2xnjhLpjM6L8ISxlDCAw.png"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/moondream-next/batch",
    "title": "MoonDreamNext Batch",
    "category": "vision",
    "description": "MoonDreamNext Batch is a multimodal vision-language model for batch captioning.",
    "tags": [
      "multimodal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/moondreamnext/moondream-next.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream-next/batch",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream-next/batch/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Single prompt to apply to all images",
        "required": true,
        "examples": [
          "Describe this image in detail."
        ]
      },
      "images_data_url": {
        "type": "string",
        "description": "List of image URLs to be processed (maximum 32 images)",
        "required": true
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum number of tokens to generate",
        "required": false,
        "minimum": 1,
        "maximum": 512,
        "default": 64
      }
    },
    "outputParameters": {
      "outputs": {
        "type": "array",
        "description": "List of generated captions",
        "items": {
          "type": "string"
        }
      },
      "captions_file": {
        "type": null,
        "description": "URL to the generated captions JSON file containing filename-caption pairs."
      }
    }
  },
  {
    "id": "fal-ai/flux-lora-canny",
    "title": "FLUX.1 [dev] Canny with LoRAs",
    "category": "image-to-image",
    "description": "Utilize Flux.1 [dev] Controlnet to generate high-quality images with precise control over composition, style, and structure through advanced edge detection and guidance mechanisms.",
    "tags": [
      "controlnet",
      "detection",
      "lora",
      "editing",
      "composition"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux_lora.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-canny",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-canny/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A blue owl."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for canny input",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/eNSkRdVFzNvDkrrMjxFA3.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 20,
        "maximum": 40,
        "default": 30
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1.1",
    "title": "FLUX1.1 [pro]",
    "category": "text-to-image",
    "description": "FLUX1.1 [pro] is an enhanced version of FLUX.1 [pro], improved image generation capabilities, delivering superior composition, detail, and artistic fidelity compared to its predecessor.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/turbo_thumbnail.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1.1-ultra-finetuned",
    "title": "FLUX1.1 [pro] ultra Fine-tuned",
    "category": "text-to-image",
    "description": "FLUX1.1 [pro] ultra fine-tuned is the newest version of FLUX1.1 [pro] with a fine-tuned LoRA, maintaining professional-grade image quality while delivering up to 2K resolution with improved photo realism.",
    "tags": [
      "high-res",
      "realism"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-pro-11-ultra.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1-ultra-finetuned",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1-ultra-finetuned/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "finetune_id": {
        "type": "string",
        "description": "References your specific model",
        "required": true
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "image_prompt_strength": {
        "type": "number",
        "description": "The strength of the image prompt, between 0 and 1.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "raw": {
        "type": "boolean",
        "description": "Generate less processed, more natural-looking images.",
        "required": false,
        "default": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": null,
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "default": "16:9"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from.",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "finetune_strength": {
        "type": "number",
        "description": "\n        Controls finetune influence.\n        Increase this value if your target concept isn't showing up strongly enough.\n        The optimal setting depends on your finetune and prompt\n        ",
        "required": true,
        "minimum": 0,
        "maximum": 2
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1/fill-finetuned",
    "title": "FLUX.1 [pro] Fill Fine-tuned",
    "category": "image-to-image",
    "description": "FLUX.1 [pro] Fill Fine-tuned is a high-performance endpoint for the FLUX.1 [pro] model with a fine-tuned LoRA that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fluxpro.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1/fill-finetuned",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1/fill-finetuned/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "A knight in shining armour holding a greatshield with \"FAL\" on it"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "finetune_strength": {
        "type": "number",
        "description": "\n        Controls finetune influence.\n        Increase this value if your target concept isn't showing up strongly enough.\n        The optimal setting depends on your finetune and prompt\n        ",
        "required": true,
        "minimum": 0,
        "maximum": 2
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "finetune_id": {
        "type": "string",
        "description": "References your specific model",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/knight.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The mask URL to inpaint the image. Needs to match the dimensions of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/mask_knight.jpeg"
        ]
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video-lora",
    "title": "Hunyuan Video LoRA Inference",
    "category": "text-to-video",
    "description": "Hunyuan Video is an Open video generation model with high visual quality, motion diversity, text-video alignment, and generation stability",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate.",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "num_frames": {
        "type": "string",
        "description": "The number of frames to generate.",
        "required": false,
        "enum": [
          "129",
          "85"
        ],
        "default": 129
      },
      "pro_mode": {
        "type": "boolean",
        "description": "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/transpixar",
    "title": "TransPixar V1",
    "category": "text-to-video",
    "description": "Transform text into stunning videos with TransPixar - an AI model that generates both RGB footage and alpha channels, enabling seamless compositing and creative video effects.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/transpixar.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/transpixar",
    "documentationUrl": "https://fal.ai/models/fal-ai/transpixar/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A cloud of dust erupting and dispersing like an explosion."
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 24
      },
      "export_fps": {
        "type": "integer",
        "description": "The target FPS of the video",
        "required": false,
        "minimum": 4,
        "maximum": 32,
        "default": 8
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate video from",
        "required": false,
        "default": "",
        "examples": [
          "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
        ]
      },
      "seed": {
        "type": null,
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the video."
      },
      "videos": {
        "type": "array",
        "description": "The URL to the generated video",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video-lora-training",
    "title": "Train Hunyuan LoRA",
    "category": "training",
    "description": "Train Hunyuan Video lora on people, objects, characters and more!",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_014.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora-training",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora-training/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "trigger_word": {
        "type": "string",
        "description": "The trigger word to use.",
        "required": false,
        "default": ""
      },
      "images_data_url": {
        "type": "string",
        "description": "\n        URL to zip archive with images. Try to use at least 4 images in general the more the better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n    ",
        "required": true
      },
      "steps": {
        "type": "integer",
        "description": "Number of steps to train the LoRA on.",
        "required": true,
        "minimum": 1,
        "maximum": 5000,
        "examples": [
          1000
        ]
      },
      "data_archive_format": {
        "type": null,
        "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
        "required": false
      },
      "learning_rate": {
        "type": "number",
        "description": "Learning rate to use for training.",
        "required": false,
        "default": 0.0001
      },
      "do_caption": {
        "type": "boolean",
        "description": "Whether to generate captions for the images.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "config_file": {
        "type": null,
        "description": "URL to the lora configuration file."
      },
      "diffusers_lora_file": {
        "type": null,
        "description": "URL to the trained diffusers lora weights."
      }
    }
  },
  {
    "id": "fal-ai/cogvideox-5b",
    "title": "CogVideoX-5B",
    "category": "text-to-video",
    "description": "Generate videos from prompts using CogVideoX-5B",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/cogvideox-5b",
    "documentationUrl": "https://fal.ai/models/fal-ai/cogvideox-5b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A garden comes to life as a kaleidoscope of butterflies flutters amidst the blossoms, their delicate wings casting shadows on the petals below. In the background, a grand fountain cascades water with a gentle splendor, its rhythmic sound providing a soothing backdrop. Beneath the cool shade of a mature tree, a solitary wooden chair invites solitude and reflection, its smooth surface worn by the touch of countless visitors seeking a moment of tranquility in nature's embrace."
        ]
      },
      "use_rife": {
        "type": "boolean",
        "description": "Use RIFE for video interpolation",
        "required": false,
        "default": true
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "video_size": {
        "type": null,
        "description": "The size of the generated video.",
        "required": false,
        "default": {
          "height": 480,
          "width": 720
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "export_fps": {
        "type": "integer",
        "description": "The target FPS of the video",
        "required": false,
        "minimum": 4,
        "maximum": 32,
        "default": 16
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate video from",
        "required": false,
        "default": "",
        "examples": [
          "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the video."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "video": {
        "type": null,
        "description": "The URL to the generated video"
      }
    }
  },
  {
    "id": "fal-ai/sync-lipsync",
    "title": "sync.so -- lipsync 1.9.0-beta",
    "category": "video-to-video",
    "description": "Generate realistic lipsync animations from audio using advanced algorithms for high-quality synchronization.",
    "tags": [
      "animation",
      "lip sync"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/0FiW23RmTuPYSqUv6RSCc.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sync-lipsync",
    "documentationUrl": "https://fal.ai/models/fal-ai/sync-lipsync/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "The model to use for lipsyncing",
        "required": false,
        "enum": [
          "lipsync-1.8.0",
          "lipsync-1.7.1",
          "lipsync-1.9.0-beta"
        ],
        "default": "lipsync-1.9.0-beta"
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/8teUPbRRMtAUTORDvqy0l.mp4"
        ]
      },
      "sync_mode": {
        "type": "string",
        "description": "Lipsync mode when audio and video durations are out of sync.",
        "required": false,
        "enum": [
          "cut_off",
          "loop",
          "bounce",
          "silence",
          "remap"
        ],
        "default": "cut_off"
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the input audio",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/vyFWygmZsIZlUO4s0nr2n.wav"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/sa2va/8b/video",
    "title": "Sa2VA 8B Video",
    "category": "vision",
    "description": "Sa2VA is an MLLM capable of question answering, visual prompt understanding, and dense object segmentation at both image and video levels",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sa2va.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sa2va/8b/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/sa2va/8b/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the chat completion",
        "required": true,
        "examples": [
          "Could you please give me a brief description of the video? Please respond with interleaved segmentation masks for the corresponding parts of the answer."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the input video.",
        "required": true,
        "examples": [
          "https://drive.google.com/uc?id=1iOFYbNITYwrebBBp9kaEGhBndFSRLz8k"
        ]
      },
      "num_frames_to_sample": {
        "type": "integer",
        "description": "Number of frames to sample from the video. If not provided, all frames are sampled.",
        "required": false,
        "minimum": 1,
        "maximum": 100
      }
    },
    "outputParameters": {
      "masks": {
        "type": "array",
        "description": "Dictionary of label: mask image",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      }
    }
  },
  {
    "id": "fal-ai/sa2va/4b/video",
    "title": "Sa2VA 4B Video",
    "category": "vision",
    "description": "Sa2VA is an MLLM capable of question answering, visual prompt understanding, and dense object segmentation at both image and video levels",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sa2va.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sa2va/4b/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/sa2va/4b/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the chat completion",
        "required": true,
        "examples": [
          "Could you please give me a brief description of the video? Please respond with interleaved segmentation masks for the corresponding parts of the answer."
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The URL of the input video.",
        "required": true,
        "examples": [
          "https://drive.google.com/uc?id=1iOFYbNITYwrebBBp9kaEGhBndFSRLz8k"
        ]
      },
      "num_frames_to_sample": {
        "type": "integer",
        "description": "Number of frames to sample from the video. If not provided, all frames are sampled.",
        "required": false,
        "minimum": 1,
        "maximum": 100
      }
    },
    "outputParameters": {
      "masks": {
        "type": "array",
        "description": "Dictionary of label: mask image",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      }
    }
  },
  {
    "id": "fal-ai/sa2va/4b/image",
    "title": "Sa2VA 4B Image",
    "category": "vision",
    "description": "Sa2VA is an MLLM capable of question answering, visual prompt understanding, and dense object segmentation at both image and video levels",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sa2va.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sa2va/4b/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/sa2va/4b/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the chat completion",
        "required": true,
        "examples": [
          "Could you please give me a brief description of the image? Please respond with interleaved segmentation masks for the corresponding parts of the answer."
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Url for the Input image.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/truck.jpg"
        ]
      }
    },
    "outputParameters": {
      "masks": {
        "type": "array",
        "description": "Dictionary of label: mask image",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      }
    }
  },
  {
    "id": "fal-ai/sa2va/8b/image",
    "title": "Sa2VA 8B Image",
    "category": "vision",
    "description": "Sa2VA is an MLLM capable of question answering, visual prompt understanding, and dense object segmentation at both image and video levels",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sa2va.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sa2va/8b/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/sa2va/8b/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the chat completion",
        "required": true,
        "examples": [
          "Could you please give me a brief description of the image? Please respond with interleaved segmentation masks for the corresponding parts of the answer."
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Url for the Input image.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/truck.jpg"
        ]
      }
    },
    "outputParameters": {
      "masks": {
        "type": "array",
        "description": "Dictionary of label: mask image",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      }
    }
  },
  {
    "id": "fal-ai/moondream-next",
    "title": "MoonDreamNext",
    "category": "vision",
    "description": "MoonDreamNext is a multimodal vision-language model for captioning, gaze detection, bbox detection, point detection, and more.",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/moondreamnext/moondream-next.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream-next",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream-next/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt for query task",
        "required": true,
        "examples": [
          "Describe this image in detail."
        ]
      },
      "task_type": {
        "type": "string",
        "description": "Type of task to perform",
        "required": false,
        "enum": [
          "caption",
          "query"
        ],
        "default": "caption"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum number of tokens to generate",
        "required": false,
        "minimum": 1,
        "maximum": 512,
        "default": 64
      },
      "image_url": {
        "type": "string",
        "description": "Image URL to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "output": {
        "type": "string",
        "description": "Response from the model"
      }
    }
  },
  {
    "id": "fal-ai/moondream-next/detection",
    "title": "MoonDreamNext Detection",
    "category": "image-to-image",
    "description": "MoonDreamNext Detection is a multimodal vision-language model for gaze detection, bbox detection, point detection, and more.",
    "tags": [
      "multimodal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/moondreamnext/moondream-next.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream-next/detection",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream-next/detection/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "detection_prompt": {
        "type": "string",
        "description": "Text description of what to detect",
        "required": true,
        "examples": [
          "Person"
        ]
      },
      "use_ensemble": {
        "type": "boolean",
        "description": "Whether to use ensemble for gaze detection",
        "required": false,
        "default": false
      },
      "task_type": {
        "type": "string",
        "description": "Type of detection to perform",
        "required": true,
        "enum": [
          "bbox_detection",
          "point_detection",
          "gaze_detection"
        ]
      },
      "show_visualization": {
        "type": "boolean",
        "description": "Whether to show visualization for detection",
        "required": false,
        "default": true
      },
      "combine_points": {
        "type": "boolean",
        "description": "Whether to combine points into a single point for point detection. This has no effect for bbox detection or gaze detection.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "Image URL to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Output image with detection visualization"
      },
      "text_output": {
        "type": "string",
        "description": "Detection results as text"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/image-to-video",
    "title": "Kling 1.6",
    "category": "image-to-video",
    "description": "Generate video clips from your images using Kling 1.6 (std)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Snowflakes fall as a car moves forward along the road."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/text-to-video",
    "title": "Kling 1.6",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.6 (std)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.6/standard/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/auto-caption",
    "title": "Auto-Captioner",
    "category": "video-to-video",
    "description": "Automatically generates text captions for your videos from the audio as per text colour/font specifications",
    "tags": [
      "captioning",
      "video"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/caption_thumbnail.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/auto-caption",
    "documentationUrl": "https://fal.ai/models/fal-ai/auto-caption/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "txt_font": {
        "type": "string",
        "description": "Font for generated captions. Choose one in 'Arial','Standard','Garamond', 'Times New Roman','Georgia', or pass a url to a .ttf file",
        "required": false,
        "default": "Standard"
      },
      "video_url": {
        "type": "string",
        "description": "URL to the .mp4 video with audio. Only videos of size <100MB are allowed.",
        "required": true
      },
      "top_align": {
        "type": null,
        "description": "Top-to-bottom alignment of the text. Can be a string ('top', 'center', 'bottom') or a float (0.0-1.0)",
        "required": false,
        "default": "center"
      },
      "txt_color": {
        "type": "string",
        "description": "Colour of the text. Can be a RGB tuple, a color name, or an hexadecimal notation.",
        "required": false,
        "default": "white"
      },
      "stroke_width": {
        "type": "integer",
        "description": "Width of the text strokes in pixels",
        "required": false,
        "default": 1
      },
      "refresh_interval": {
        "type": "number",
        "description": "Number of seconds the captions should stay on screen. A higher number will also result in more text being displayed at once.",
        "required": false,
        "minimum": 0.5,
        "maximum": 3,
        "default": 1.5
      },
      "font_size": {
        "type": "integer",
        "description": "Size of text in generated captions.",
        "required": false,
        "default": 24
      },
      "left_align": {
        "type": null,
        "description": "Left-to-right alignment of the text. Can be a string ('left', 'center', 'right') or a float (0.0-1.0)",
        "required": false,
        "default": "center"
      }
    },
    "outputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL to the caption .mp4 video."
      }
    }
  },
  {
    "id": "fal-ai/switti",
    "title": "Switti 1024",
    "category": "text-to-image",
    "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/switti.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/switti",
    "documentationUrl": "https://fal.ai/models/fal-ai/switti/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat wearing a hoodie with 'FAL' written on it."
        ]
      },
      "sampling_top_k": {
        "type": "integer",
        "description": "The number of top-k tokens to sample from.",
        "required": false,
        "minimum": 10,
        "maximum": 1000,
        "default": 400
      },
      "turn_off_cfg_start_si": {
        "type": "integer",
        "description": "Disable CFG starting scale",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 8
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 6
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "smooth_start_si": {
        "type": "integer",
        "description": "Smoothing starting scale",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 2
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "last_scale_temp": {
        "type": "number",
        "description": "Temperature after disabling CFG",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 0.1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "more_diverse": {
        "type": "boolean",
        "description": "More diverse sampling",
        "required": false,
        "default": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "more_smooth": {
        "type": "boolean",
        "description": "Smoothing with Gumbel softmax sampling",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "sampling_top_p": {
        "type": "number",
        "description": "The top-p probability to sample from.",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 0.95
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/switti/512",
    "title": "Switti 512",
    "category": "text-to-image",
    "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/switti.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/switti/512",
    "documentationUrl": "https://fal.ai/models/fal-ai/switti/512/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A cat wearing a hoodie with 'FAL' written on it."
        ]
      },
      "sampling_top_k": {
        "type": "integer",
        "description": "The number of top-k tokens to sample from.",
        "required": false,
        "minimum": 10,
        "maximum": 1000,
        "default": 400
      },
      "turn_off_cfg_start_si": {
        "type": "integer",
        "description": "Disable CFG starting scale",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 8
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 6
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "smooth_start_si": {
        "type": "integer",
        "description": "Smoothing starting scale",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 2
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "last_scale_temp": {
        "type": "number",
        "description": "Temperature after disabling CFG",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 0.1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "more_diverse": {
        "type": "boolean",
        "description": "More diverse sampling",
        "required": false,
        "default": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "more_smooth": {
        "type": "boolean",
        "description": "Smoothing with Gumbel softmax sampling",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "sampling_top_p": {
        "type": "number",
        "description": "The top-p probability to sample from.",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 0.95
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/mmaudio-v2/text-to-audio",
    "title": "MMAudio V2 Text to Audio",
    "category": "text-to-audio",
    "description": "MMAudio generates synchronized audio given text inputs. It can generate sounds described by a prompt.",
    "tags": [
      "audio",
      "fast"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/mmaudio-v2.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/mmaudio-v2/text-to-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/mmaudio-v2/text-to-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the audio for.",
        "required": true,
        "examples": [
          "Indian holy music"
        ]
      },
      "num_steps": {
        "type": "integer",
        "description": "The number of steps to generate the audio for.",
        "required": false,
        "minimum": 4,
        "maximum": 50,
        "default": 25
      },
      "duration": {
        "type": "number",
        "description": "The duration of the audio to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 8
      },
      "cfg_strength": {
        "type": "number",
        "description": "The strength of Classifier Free Guidance.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4.5
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the random number generator",
        "required": false,
        "minimum": 0,
        "maximum": 65535
      },
      "mask_away_clip": {
        "type": "boolean",
        "description": "Whether to mask away the clip.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate the audio for.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio."
      }
    }
  },
  {
    "id": "fal-ai/sadtalker/reference",
    "title": "Sad Talker",
    "category": "image-to-video",
    "description": "Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation",
    "tags": [
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sadtalker.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sadtalker/reference",
    "documentationUrl": "https://fal.ai/models/fal-ai/sadtalker/reference/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "pose_style": {
        "type": "integer",
        "description": "The style of the pose",
        "required": false,
        "minimum": 0,
        "maximum": 45,
        "default": 0
      },
      "source_image_url": {
        "type": "string",
        "description": "URL of the source image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/sadtalker/anime_girl.png"
        ]
      },
      "driven_audio_url": {
        "type": "string",
        "description": "URL of the driven audio",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/sadtalker/deyu.wav"
        ]
      },
      "reference_pose_video_url": {
        "type": "string",
        "description": "URL of the reference video",
        "required": true,
        "examples": [
          "https://github.com/OpenTalker/SadTalker/raw/main/examples/ref_video/WDA_AlexandriaOcasioCortez_000.mp4"
        ]
      },
      "face_enhancer": {
        "type": "string",
        "description": "The type of face enhancer to use",
        "required": false,
        "enum": [
          "gfpgan"
        ],
        "examples": [
          null
        ]
      },
      "face_model_resolution": {
        "type": "string",
        "description": "The resolution of the face model",
        "required": false,
        "enum": [
          "256",
          "512"
        ],
        "default": "256"
      },
      "expression_scale": {
        "type": "number",
        "description": "The scale of the expression",
        "required": false,
        "minimum": 0,
        "maximum": 3,
        "default": 1
      },
      "still_mode": {
        "type": "boolean",
        "description": "Whether to use still mode. Fewer head motion, works with preprocess `full`.",
        "required": false,
        "default": false
      },
      "preprocess": {
        "type": "string",
        "description": "The type of preprocessing to use",
        "required": false,
        "enum": [
          "crop",
          "extcrop",
          "resize",
          "full",
          "extfull"
        ],
        "default": "crop"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the generated video"
      }
    }
  },
  {
    "id": "fal-ai/dubbing",
    "title": "Dubbing",
    "category": "video-to-video",
    "description": "This endpoint delivers seamlessly localized videos by generating lip-synced dubs in multiple languages, ensuring natural and immersive multilingual experiences",
    "tags": [
      "animation",
      "lip sync",
      "dubbing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/dubbing.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dubbing",
    "documentationUrl": "https://fal.ai/models/fal-ai/dubbing/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "do_lipsync": {
        "type": "boolean",
        "description": "Whether to lip sync the audio to the video",
        "required": false,
        "default": true
      },
      "video_url": {
        "type": "string",
        "description": "Input video URL to be dubbed.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/dubbing/swapjokes_clip_cropped.mp4"
        ]
      },
      "target_language": {
        "type": "string",
        "description": "Target language to dub the video to",
        "required": false,
        "enum": [
          "hindi",
          "turkish",
          "english"
        ],
        "default": "hindi"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video with the lip sync."
      }
    }
  },
  {
    "id": "fal-ai/playai/tts/v3",
    "title": "PlayAI Text-to-Speech v3",
    "category": "text-to-speech",
    "description": "Blazing-fast text-to-speech. Generate audio with improved emotional tones and extensive multilingual support. Ideal for high-volume processing and efficient workflows.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/playht-tts-v3.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/playai/tts/v3",
    "documentationUrl": "https://fal.ai/models/fal-ai/playai/tts/v3/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "response_format": {
        "type": "string",
        "description": "The format of the response.",
        "required": false,
        "enum": [
          "url",
          "bytes"
        ],
        "default": "url"
      },
      "input": {
        "type": "string",
        "description": "The text to be converted to speech.",
        "required": true,
        "minLength": 1,
        "examples": [
          "The quick brown fox jumped over the lazy dog."
        ]
      },
      "voice": {
        "type": "string",
        "description": "The unique ID of a PlayHT or Cloned Voice, or a name from the available presets.",
        "required": true,
        "examples": [
          "Jennifer (English (US)/American)",
          "Dexter (English (US)/American)",
          "Ava (English (AU)/Australian)",
          "Tilly (English (AU)/Australian)",
          "Charlotte (Advertising) (English (CA)/Canadian)",
          "Charlotte (Meditation) (English (CA)/Canadian)",
          "Cecil (English (GB)/British)",
          "Sterling (English (GB)/British)",
          "Cillian (English (IE)/Irish)",
          "Madison (English (IE)/Irish)",
          "Ada (English (ZA)/South african)",
          "Furio (English (IT)/Italian)",
          "Alessandro (English (IT)/Italian)",
          "Carmen (English (MX)/Mexican)",
          "Sumita (English (IN)/Indian)",
          "Navya (English (IN)/Indian)",
          "Baptiste (English (FR)/French)",
          "Lumi (English (FI)/Finnish)",
          "Ronel Conversational (Afrikaans/South african)",
          "Ronel Narrative (Afrikaans/South african)",
          "Abdo Conversational (Arabic/Arabic)",
          "Abdo Narrative (Arabic/Arabic)",
          "Mousmi Conversational (Bengali/Bengali)",
          "Mousmi Narrative (Bengali/Bengali)",
          "Caroline Conversational (Portuguese (BR)/Brazilian)",
          "Caroline Narrative (Portuguese (BR)/Brazilian)",
          "Ange Conversational (French/French)",
          "Ange Narrative (French/French)",
          "Anke Conversational (German/German)",
          "Anke Narrative (German/German)",
          "Bora Conversational (Greek/Greek)",
          "Bora Narrative (Greek/Greek)",
          "Anuj Conversational (Hindi/Indian)",
          "Anuj Narrative (Hindi/Indian)",
          "Alessandro Conversational (Italian/Italian)",
          "Alessandro Narrative (Italian/Italian)",
          "Kiriko Conversational (Japanese/Japanese)",
          "Kiriko Narrative (Japanese/Japanese)",
          "Dohee Conversational (Korean/Korean)",
          "Dohee Narrative (Korean/Korean)",
          "Ignatius Conversational (Malay/Malay)",
          "Ignatius Narrative (Malay/Malay)",
          "Adam Conversational (Polish/Polish)",
          "Adam Narrative (Polish/Polish)",
          "Andrei Conversational (Russian/Russian)",
          "Andrei Narrative (Russian/Russian)",
          "Aleksa Conversational (Serbian/Serbian)",
          "Aleksa Narrative (Serbian/Serbian)",
          "Carmen Conversational (Spanish/Spanish)",
          "Patricia Conversational (Spanish/Spanish)",
          "Aiken Conversational (Tagalog/Filipino)",
          "Aiken Narrative (Tagalog/Filipino)",
          "Katbundit Conversational (Thai/Thai)",
          "Katbundit Narrative (Thai/Thai)",
          "Ali Conversational (Turkish/Turkish)",
          "Ali Narrative (Turkish/Turkish)",
          "Sahil Conversational (Urdu/Pakistani)",
          "Sahil Narrative (Urdu/Pakistani)",
          "Mary Conversational (Hebrew/Israeli)",
          "Mary Narrative (Hebrew/Israeli)"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "An integer number greater than or equal to 0. If equal to null or not provided, a random seed will be used. Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file.",
        "required": false,
        "minimum": 0,
        "examples": [
          null
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated audio file."
      }
    }
  },
  {
    "id": "fal-ai/bria/expand",
    "title": "Bria Expand Image",
    "category": "image-to-image",
    "description": "Bria Expand expands images beyond their borders in high quality. Trained exclusively on licensed data for safe and risk-free commercial use. Access the model's source code and weights: https://bria.ai/contact-us",
    "tags": [
      "outpainting"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/expand",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/expand/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Text on which you wish to base the image expansion. This parameter is optional. Bria currently supports prompts in English only, excluding special characters.",
        "required": false,
        "default": ""
      },
      "original_image_location": {
        "type": "array",
        "description": "The desired location of the original image, inside the full canvas. Provide the location of the upper left corner of the original image. The location can also be outside the canvas (the original image will be cropped).",
        "required": true,
        "examples": [
          [
            301,
            -66
          ]
        ],
        "items": {
          "type": "integer"
        }
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/orange.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "canvas_size": {
        "type": "array",
        "description": "The desired size of the final image, after the expansion. should have an area of less than 5000x5000 pixels.",
        "required": true,
        "examples": [
          [
            1200,
            674
          ]
        ],
        "items": {
          "type": "integer"
        }
      },
      "original_image_size": {
        "type": "array",
        "description": "The desired size of the original image, inside the full canvas. Ensure that the ratio of input image foreground or main subject to the canvas area is greater than 15% to achieve optimal results.",
        "required": true,
        "examples": [
          [
            610,
            855
          ]
        ],
        "items": {
          "type": "integer"
        }
      },
      "seed": {
        "type": "integer",
        "description": "You can choose whether you want your generated expension to be random or predictable. You can recreate the same result in the future by using the seed value of a result from the response. You can exclude this parameter if you are not interested in recreating your results. This parameter is optional.",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt you would like to use to generate images.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image"
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/bria/text-to-image/fast",
    "title": "Bria Text-to-Image Fast",
    "category": "text-to-image",
    "description": "Bria's Text-to-Image model with perfect harmony of latency and quality. Trained exclusively on licensed data for safe and risk-free commercial use. Available also as source code and weights. For access to weights: https://bria.ai/contact-us",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/text-to-image/fast",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/text-to-image/fast/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt you would like to use to generate images.",
        "required": true,
        "minLength": 1,
        "examples": [
          "A lone figure stands on the edge of a serene cliff at sunset, gazing out over a vast, mystical valley. The figure is clad in flowing robes that ripple in the gentle breeze, silhouetted against the golden and lavender hues of the sky. Below, a cascading waterfall pours into a sparkling river winding through a forest of bioluminescent trees. The scene blends the awe of nature with a touch of otherworldly wonder, inviting reflection and imagination."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.",
        "required": false,
        "enum": [
          "1:1",
          "2:3",
          "3:2",
          "3:4",
          "4:3",
          "4:5",
          "5:4",
          "9:16",
          "16:9"
        ],
        "default": "1:1"
      },
      "prompt_enhancement": {
        "type": "boolean",
        "description": "When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.",
        "required": false,
        "default": false
      },
      "guidance": {
        "type": "array",
        "description": "Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/GuidanceInput"
        }
      },
      "num_images": {
        "type": "integer",
        "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 4
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
        "required": false,
        "minimum": 4,
        "maximum": 10,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt you would like to use to generate images.",
        "required": false,
        "default": ""
      },
      "medium": {
        "type": "string",
        "description": "Which medium should be included in your generated images. This parameter is optional.",
        "required": false,
        "enum": [
          "photography",
          "art"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/bria/text-to-image/base",
    "title": "Bria Text-to-Image Base",
    "category": "text-to-image",
    "description": "Bria's Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use. Available also as source code and weights. For access to weights: https://bria.ai/contact-us",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/text-to-image/base",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/text-to-image/base/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt you would like to use to generate images.",
        "required": true,
        "minLength": 1,
        "examples": [
          "A lone figure stands on the edge of a serene cliff at sunset, gazing out over a vast, mystical valley. The figure is clad in flowing robes that ripple in the gentle breeze, silhouetted against the golden and lavender hues of the sky. Below, a cascading waterfall pours into a sparkling river winding through a forest of bioluminescent trees. The scene blends the awe of nature with a touch of otherworldly wonder, inviting reflection and imagination."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.",
        "required": false,
        "enum": [
          "1:1",
          "2:3",
          "3:2",
          "3:4",
          "4:3",
          "4:5",
          "5:4",
          "9:16",
          "16:9"
        ],
        "default": "1:1"
      },
      "prompt_enhancement": {
        "type": "boolean",
        "description": "When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.",
        "required": false,
        "default": false
      },
      "guidance": {
        "type": "array",
        "description": "Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/GuidanceInput"
        }
      },
      "num_images": {
        "type": "integer",
        "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 4
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt you would like to use to generate images.",
        "required": false,
        "default": ""
      },
      "medium": {
        "type": "string",
        "description": "Which medium should be included in your generated images. This parameter is optional.",
        "required": false,
        "enum": [
          "photography",
          "art"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/bria/genfill",
    "title": "Bria GenFill",
    "category": "image-to-image",
    "description": "Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use. Access the model's source code and weights: https://bria.ai/contact-us",
    "tags": [
      "image editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/genfill",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/genfill/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt you would like to use to generate images.",
        "required": true,
        "examples": [
          "A red delicious cherry"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of Images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "Input Image to erase from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_genfill_img.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the binary mask image that represents the area that will be cleaned.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_genfill_mask.png"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt you would like to use to generate images.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Generated Images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/bria/eraser",
    "title": "Bria Eraser",
    "category": "image-to-image",
    "description": "Bria Eraser enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use. Access the model's source code and weights: https://bria.ai/contact-us",
    "tags": [
      "image editing",
      "object removal"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/eraser",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/eraser/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "preserve_alpha": {
        "type": "boolean",
        "description": "\n            If set to true, attempts to preserve the alpha channel of the input image.\n        ",
        "required": false,
        "default": false
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the binary mask image that represents the area that will be cleaned.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_eraser_mask.png"
        ]
      },
      "mask_type": {
        "type": "string",
        "description": "You can use this parameter to specify the type of the input mask from the list. 'manual' opttion should be used in cases in which the mask had been generated by a user (e.g. with a brush tool), and 'automatic' mask type should be used when mask had been generated by an algorithm like 'SAM'.",
        "required": false,
        "enum": [
          "manual",
          "automatic"
        ],
        "default": "manual"
      },
      "image_url": {
        "type": "string",
        "description": "Input Image to erase from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_eraser_img.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image"
      }
    }
  },
  {
    "id": "fal-ai/bria/background/replace",
    "title": "Bria Background Replace",
    "category": "image-to-image",
    "description": "Bria Background Replace allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use ",
    "tags": [
      "image editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/background/replace",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/background/replace/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt you would like to use to generate images.",
        "required": false,
        "examples": [
          "Man leaning against a wall"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of Images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "ref_image_url": {
        "type": "string",
        "description": "The URL of the reference image to be used for generating the new background. Use \"\" to leave empty. Either ref_image_url or bg_prompt has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.",
        "required": false,
        "default": "",
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_bg_replace_bg.jpg"
        ]
      },
      "refine_prompt": {
        "type": "boolean",
        "description": "Whether to refine prompt",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "Input Image to erase from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_bg_replace_fg.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "fast": {
        "type": "boolean",
        "description": "Whether to use the fast model",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt you would like to use to generate images.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/flux-lora-fill",
    "title": "FLUX.1 [dev] Fill with LoRAs",
    "category": "image-to-image",
    "description": "FLUX.1 [dev] Fill is a high-performance endpoint for the FLUX.1 [pro] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "editing",
      "lora"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux_lora.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-fill",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-fill/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": false,
        "default": "",
        "examples": [
          "A knight in shining armour holding a greatshield with 'FAL' on it"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "paste_back": {
        "type": "boolean",
        "description": "Specifies whether to paste-back the original image onto to the non-inpainted areas of the output",
        "required": false,
        "default": true
      },
      "resize_to_original": {
        "type": "boolean",
        "description": "Resizes the image back to the original size. Use when you wish to preserve the exact image size as the originally provided image.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 28,
        "maximum": 35,
        "default": 30
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for fill operation",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/knight.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "fill_image": {
        "type": null,
        "description": "Use an image fill input to fill in particular images into the masked area.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "mask_url": {
        "type": "string",
        "description": "\n            The mask to area to Inpaint in.\n        ",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/mask_knight.jpeg"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/bria/product-shot",
    "title": "Bria Product Shot",
    "category": "image-to-image",
    "description": "Place any product in any scenery with just a prompt or reference image while maintaining high integrity of the product. Trained exclusively on licensed data for safe and risk-free commercial use and optimized for eCommerce.",
    "tags": [
      "product photography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/product-shot",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/product-shot/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "ref_image_url": {
        "type": "string",
        "description": "The URL of the reference image to be used for generating the new scene or background for the product shot. Use \"\" to leave empty.Either ref_image_url or scene_description has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.",
        "required": false,
        "default": "",
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_product_bg.jpg"
        ]
      },
      "manual_placement_selection": {
        "type": "string",
        "description": "If you've selected placement_type=manual_placement, you should use this parameter to specify which placements/positions you would like to use from the list. You can select more than one placement in one request.",
        "required": false,
        "enum": [
          "upper_left",
          "upper_right",
          "bottom_left",
          "bottom_right",
          "right_center",
          "left_center",
          "upper_center",
          "bottom_center",
          "center_vertical",
          "center_horizontal"
        ],
        "default": "bottom_center"
      },
      "num_results": {
        "type": "integer",
        "description": "The number of lifestyle product shots you would like to generate. You will get num_results x 10 results when placement_type=automatic and according to the number of required placements x num_results if placement_type=manual_placement.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "padding_values": {
        "type": "array",
        "description": "The desired padding in pixels around the product, when using placement_type=manual_padding. The order of the values is [left, right, top, bottom]. For optimal results, the total number of pixels, including padding, should be around 1,000,000. It is recommended to first use the product cutout API, get the cutout and understand the size of the result, and then define the required padding and use the cutout as an input for this API.",
        "required": false,
        "items": {
          "type": "integer"
        }
      },
      "shot_size": {
        "type": "array",
        "description": "The desired size of the final product shot. For optimal results, the total number of pixels should be around 1,000,000. This parameter is only relevant when placement_type=automatic or placement_type=manual_placement.",
        "required": false,
        "default": [
          1000,
          1000
        ],
        "items": {
          "type": "integer"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "placement_type": {
        "type": "string",
        "description": "This parameter allows you to control the positioning of the product in the image. Choosing 'original' will preserve the original position of the product in the image. Choosing 'automatic' will generate results with the 10 recommended positions for the product. Choosing 'manual_placement' will allow you to select predefined positions (using the parameter 'manual_placement_selection'). Selecting 'manual_padding' will allow you to control the position and size of the image by defining the desired padding in pixels around the product.",
        "required": false,
        "enum": [
          "original",
          "automatic",
          "manual_placement",
          "manual_padding"
        ],
        "default": "manual_placement"
      },
      "original_quality": {
        "type": "boolean",
        "description": "This flag is only relevant when placement_type=original. If true, the output image retains the original input image's size; otherwise, the image is scaled to 1 megapixel (1MP) while preserving its aspect ratio.",
        "required": false,
        "default": false
      },
      "optimize_description": {
        "type": "boolean",
        "description": "Whether to optimize the scene description",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the product shot to be placed in a lifestyle shot. If both image_url and image_file are provided, image_url will be used. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/bria/bria_product_fg.jpg"
        ]
      },
      "scene_description": {
        "type": "string",
        "description": "Text description of the new scene or background for the provided product shot. Bria currently supports prompts in English only, excluding special characters.",
        "required": false,
        "examples": [
          "on a rock, next to the ocean, dark theme"
        ]
      },
      "fast": {
        "type": "boolean",
        "description": "Whether to use the fast model",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/bria/text-to-image/hd",
    "title": "Bria Text-to-Image HD",
    "category": "text-to-image",
    "description": "Bria's Text-to-Image model for HD images. Trained exclusively on licensed data for safe and risk-free commercial use. Available also as source code and weights. For access to weights: https://bria.ai/contact-us",
    "tags": [
      "image generation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/text-to-image/hd",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/text-to-image/hd/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt you would like to use to generate images.",
        "required": true,
        "minLength": 1,
        "examples": [
          "A lone figure stands on the edge of a serene cliff at sunset, gazing out over a vast, mystical valley. The figure is clad in flowing robes that ripple in the gentle breeze, silhouetted against the golden and lavender hues of the sky. Below, a cascading waterfall pours into a sparkling river winding through a forest of bioluminescent trees. The scene blends the awe of nature with a touch of otherworldly wonder, inviting reflection and imagination."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.",
        "required": false,
        "enum": [
          "1:1",
          "2:3",
          "3:2",
          "3:4",
          "4:3",
          "4:5",
          "5:4",
          "9:16",
          "16:9"
        ],
        "default": "1:1"
      },
      "prompt_enhancement": {
        "type": "boolean",
        "description": "When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.",
        "required": false,
        "default": false
      },
      "guidance": {
        "type": "array",
        "description": "Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/GuidanceInput"
        }
      },
      "num_images": {
        "type": "integer",
        "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 4
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2147483647
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt you would like to use to generate images.",
        "required": false,
        "default": ""
      },
      "medium": {
        "type": "string",
        "description": "Which medium should be included in your generated images. This parameter is optional.",
        "required": false,
        "enum": [
          "photography",
          "art"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      }
    }
  },
  {
    "id": "fal-ai/bria/background/remove",
    "title": "Bria RMBG 2.0",
    "category": "image-to-image",
    "description": "Bria RMBG 2.0 enables seamless removal of backgrounds from images, ideal for professional editing tasks. Trained exclusively on licensed data for safe and risk-free commercial use. Model weights for commercial use are available here: https://share-eu1.hsforms.com/2GLpEVQqJTI2Lj7AMYwgfIwf4e04",
    "tags": [
      "background removal",
      "image segmentation",
      "high resolution",
      "utility",
      "rembg"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/dfGL-2avwhhBgJB2FbHKB_fb529162dbcf4556a66e86079e22f856.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/bria/background/remove",
    "documentationUrl": "https://fal.ai/models/fal-ai/bria/background/remove/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "Input Image to erase from",
        "required": true,
        "examples": [
          "https://fal.media/files/panda/K5Rndvzmn1j-OI1VZXDVd.jpeg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image"
      }
    }
  },
  {
    "id": "fal-ai/cat-vton",
    "title": "try-on",
    "category": "image-to-image",
    "description": "Image based high quality Virtual Try-On",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/idm-vton.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/cat-vton",
    "documentationUrl": "https://fal.ai/models/fal-ai/cat-vton/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "garment_image_url": {
        "type": "string",
        "description": "Url to the garment image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/catvton/tshirt.jpg"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "portrait_4_3"
      },
      "human_image_url": {
        "type": "string",
        "description": "Url for the human image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/catvton/man5.jpg"
        ]
      },
      "cloth_type": {
        "type": "string",
        "description": "\n        Type of the Cloth to be tried on.\n\n        Options:\n        upper: Upper body cloth\n        lower: Lower body cloth\n        overall: Full body cloth\n        inner: Inner cloth, like T-shirt inside a jacket\n        outer: Outer cloth, like a jacket over a T-shirt\n        ",
        "required": true,
        "enum": [
          "upper",
          "lower",
          "overall",
          "inner",
          "outer"
        ],
        "examples": [
          "upper",
          "lower",
          "overall",
          "inner",
          "outer"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same input given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The output image."
      }
    }
  },
  {
    "id": "fal-ai/leffa/pose-transfer",
    "title": "Leffa Pose Transfer",
    "category": "image-to-image",
    "description": "Leffa Pose Transfer is an endpoint for changing pose of an image with a reference image.",
    "tags": [
      "pose",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/leffa-pose-transfer.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/leffa/pose-transfer",
    "documentationUrl": "https://fal.ai/models/fal-ai/leffa/pose-transfer/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "pose_image_url": {
        "type": "string",
        "description": "Url for the human image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/leffa/person_image.jpg"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your input when generating the image.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same input given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "person_image_url": {
        "type": "string",
        "description": "Url to the garment image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/leffa/pose_image.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The output image."
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the inference."
      },
      "has_nsfw_concepts": {
        "type": "boolean",
        "description": "Whether the image contains NSFW concepts."
      }
    }
  },
  {
    "id": "fal-ai/minimax-music",
    "title": "MiniMax (Hailuo AI) Music",
    "category": "text-to-audio",
    "description": "Generate music from text prompts using the MiniMax model, which leverages advanced AI techniques to create high-quality, diverse musical compositions.",
    "tags": [
      "music"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/lEWIZDHHfLPEO6tVIK9wz_be57b257c9de4924ba34a22d4814eaf7.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax-music",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax-music/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment. Maximum 600 characters.",
        "required": true,
        "minLength": 1,
        "maxLength": 600,
        "examples": [
          "## Fast and Limitless   \n In the heart of the code, where dreams collide,   \n\nFAL's the name, taking tech for a ride.    \nGenerative media, blazing the trail,   \n\nFast inference power, we'll never fail.\n##"
        ]
      },
      "reference_audio_url": {
        "type": "string",
        "description": "Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/OOTBTSlxKMH_E8H6hoSlb.mpga"
        ]
      }
    },
    "outputParameters": {
      "audio": {
        "type": null,
        "description": "The generated music"
      }
    }
  },
  {
    "id": "fal-ai/leffa/virtual-tryon",
    "title": "Leffa Virtual TryOn",
    "category": "image-to-image",
    "description": "Leffa Virtual TryOn is a high quality image based Try-On endpoint which can be used for commercial try on.",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/leffa-vitrual-tryon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/leffa/virtual-tryon",
    "documentationUrl": "https://fal.ai/models/fal-ai/leffa/virtual-tryon/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "garment_image_url": {
        "type": "string",
        "description": "Url to the garment image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/leffa/tshirt_image.jpg"
        ]
      },
      "human_image_url": {
        "type": "string",
        "description": "Url for the human image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/leffa/person_image.jpg"
        ]
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "garment_type": {
        "type": "string",
        "description": "The type of the garment used for virtual try-on.",
        "required": true,
        "enum": [
          "upper_body",
          "lower_body",
          "dresses"
        ],
        "examples": [
          "upper_body",
          "lower_body",
          "dresses"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your input when generating the image.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same input given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The output image."
      },
      "seed": {
        "type": "integer",
        "description": "The seed for the inference."
      },
      "has_nsfw_concepts": {
        "type": "boolean",
        "description": "Whether the image contains NSFW concepts."
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01-live/image-to-video",
    "title": "MiniMax (Hailuo AI) Video 01 Live",
    "category": "image-to-video",
    "description": "Generate video clips from your images using MiniMax Video model",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_016.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01-live/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01-live/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to use as the first frame",
        "required": true,
        "examples": [
          "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/recraft-20b",
    "title": "Recraft 20b",
    "category": "text-to-image",
    "description": "Recraft 20b is a new and affordable text-to-image model.",
    "tags": [
      "image generation",
      "vector art",
      "typograph",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_011.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/recraft-20b",
    "documentationUrl": "https://fal.ai/models/fal-ai/recraft-20b/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 1,
        "maxLength": 1000,
        "examples": [
          "a red panda in Kyoto"
        ]
      },
      "image_size": {
        "type": null,
        "description": "",
        "required": false,
        "default": "square_hd"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "colors": {
        "type": "array",
        "description": "An array of preferable colors",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/RGBColor"
        }
      },
      "style": {
        "type": "string",
        "description": "The style of the generated images. Vector images cost 2X as much.",
        "required": false,
        "enum": [
          "any",
          "realistic_image",
          "digital_illustration",
          "vector_illustration",
          "realistic_image/b_and_w",
          "realistic_image/enterprise",
          "realistic_image/hard_flash",
          "realistic_image/hdr",
          "realistic_image/motion_blur",
          "realistic_image/natural_light",
          "realistic_image/studio_portrait",
          "digital_illustration/2d_art_poster",
          "digital_illustration/2d_art_poster_2",
          "digital_illustration/3d",
          "digital_illustration/80s",
          "digital_illustration/engraving_color",
          "digital_illustration/glow",
          "digital_illustration/grain",
          "digital_illustration/hand_drawn",
          "digital_illustration/hand_drawn_outline",
          "digital_illustration/handmade_3d",
          "digital_illustration/infantile_sketch",
          "digital_illustration/kawaii",
          "digital_illustration/pixel_art",
          "digital_illustration/psychedelic",
          "digital_illustration/seamless",
          "digital_illustration/voxel",
          "digital_illustration/watercolor",
          "vector_illustration/cartoon",
          "vector_illustration/doodle_line_art",
          "vector_illustration/engraving",
          "vector_illustration/flat_2",
          "vector_illustration/kawaii",
          "vector_illustration/line_art",
          "vector_illustration/line_circuit",
          "vector_illustration/linocut",
          "vector_illustration/seamless",
          "icon/broken_line",
          "icon/colored_outline",
          "icon/colored_shapes",
          "icon/colored_shapes_gradient",
          "icon/doodle_fill",
          "icon/doodle_offset_fill",
          "icon/offset_fill",
          "icon/outline",
          "icon/outline_gradient",
          "icon/uneven_fill"
        ],
        "default": "realistic_image"
      },
      "style_id": {
        "type": "string",
        "description": "The ID of the custom style reference (optional)",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/hyper3d/rodin",
    "title": "Hyper3D Rodin",
    "category": "image-to-3d",
    "description": "Rodin by Hyper3D generates realistic and production ready 3D models from text or images.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hyper3d-rodin.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hyper3d/rodin",
    "documentationUrl": "https://fal.ai/models/fal-ai/hyper3d/rodin/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "tier": {
        "type": "string",
        "description": "Tier of generation. For Rodin Sketch, set to Sketch. For Rodin Regular, set to Regular.",
        "required": false,
        "enum": [
          "Regular",
          "Sketch"
        ],
        "default": "Regular"
      },
      "condition_mode": {
        "type": "string",
        "description": "For fuse mode, One or more images are required.It will generate a model by extracting and fusing features of objects from multiple images.For concat mode, need to upload multiple multi-view images of the same object and generate the model. (You can upload multi-view images in any order, regardless of the order of view.)",
        "required": false,
        "enum": [
          "fuse",
          "concat"
        ],
        "default": "concat"
      },
      "prompt": {
        "type": "string",
        "description": "A textual prompt to guide model generation. Required for Text-to-3D mode. Optional for Image-to-3D mode.",
        "required": false,
        "default": "",
        "examples": [
          "A futuristic robot with sleek metallic design."
        ]
      },
      "bbox_condition": {
        "type": "array",
        "description": "An array that specifies the dimensions and scaling factor of the bounding box. Typically, this array contains 3 elements, Length(X-axis), Width(Y-axis) and Height(Z-axis).",
        "required": false,
        "items": {
          "type": "integer"
        }
      },
      "quality": {
        "type": "string",
        "description": "Generation quality. Possible values: high, medium, low, extra-low. Default is medium.",
        "required": false,
        "enum": [
          "high",
          "medium",
          "low",
          "extra-low"
        ],
        "default": "medium"
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to use while generating the 3D model. Required for Image-to-3D mode. Optional for Text-to-3D mode.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/video_models/robot.png"
        ],
        "items": {
          "type": "string"
        }
      },
      "TAPose": {
        "type": "boolean",
        "description": "When generating the human-like model, this parameter control the generation result to T/A Pose.",
        "required": false,
        "default": false
      },
      "use_hyper": {
        "type": "boolean",
        "description": "Whether to export the model using hyper mode. Default is false.",
        "required": false,
        "default": false
      },
      "geometry_file_format": {
        "type": "string",
        "description": "Format of the geometry file. Possible values: glb, usdz, fbx, obj, stl. Default is glb.",
        "required": false,
        "enum": [
          "glb",
          "usdz",
          "fbx",
          "obj",
          "stl"
        ],
        "default": "glb"
      },
      "addons": {
        "type": "string",
        "description": "Generation add-on features. Default is []. Possible values are HighPack. The HighPack option will provide 4K resolution textures instead of the default 1K, as well as models with high-poly. It will cost triple the billable units.",
        "required": false,
        "enum": [
          "HighPack"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Seed value for randomization, ranging from 0 to 65535. Optional.",
        "required": false,
        "minimum": 0,
        "maximum": 65535
      },
      "material": {
        "type": "string",
        "description": "Material type. Possible values: PBR, Shaded. Default is PBR.",
        "required": false,
        "enum": [
          "PBR",
          "Shaded"
        ],
        "default": "PBR",
        "examples": [
          "Shaded"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed value used for generation."
      },
      "textures": {
        "type": "array",
        "description": "Generated textures for the 3D object.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01-live",
    "title": "MiniMax (Hailuo AI) Video 01 Live",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using MiniMax model",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_016.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01-live",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01-live/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "A rugged middle-aged man with wheat-colored skin and a full beard streaked with gray stands in the harsh sunlight of a desert outpost. His curly hair is windswept, and sweat drips down the bridge of his slightly crooked nose. His faded utility jacket and weathered boots are caked in dust, while his sharp, watchful eyes scan the horizon."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2/edit",
    "title": "Ideogram V2 Edit",
    "category": "image-to-image",
    "description": "Transform existing images with Ideogram V2's editing capabilities. Modify, adjust, and refine images while maintaining high fidelity and realistic outputs with precise prompt control.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "A knight in shining armour holding a greatshield with \"FAL\" on it"
        ]
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/knight.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The mask URL to inpaint the image. Needs to match the dimensions of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/mask_knight.jpeg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/trellis",
    "title": "Trellis",
    "category": "image-to-3d",
    "description": "Generate 3D models from your images using Trellis. A native 3D generative model enabling versatile and high-quality 3D asset creation.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/trellis/trellis-photo.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/trellis",
    "documentationUrl": "https://fal.ai/models/fal-ai/trellis/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "slat_sampling_steps": {
        "type": "integer",
        "description": "Sampling steps for structured latent generation",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 12
      },
      "ss_sampling_steps": {
        "type": "integer",
        "description": "Sampling steps for sparse structure generation",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 12
      },
      "image_url": {
        "type": "string",
        "description": "URL of the input image to convert to 3D",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/web-examples/rodin3d/warriorwoman.png"
        ]
      },
      "slat_guidance_strength": {
        "type": "number",
        "description": "Guidance strength for structured latent generation",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 3
      },
      "mesh_simplify": {
        "type": "number",
        "description": "Mesh simplification factor",
        "required": false,
        "minimum": 0.9,
        "maximum": 0.98,
        "default": 0.95
      },
      "ss_guidance_strength": {
        "type": "number",
        "description": "Guidance strength for sparse structure generation",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 7.5
      },
      "seed": {
        "type": null,
        "description": "Random seed for reproducibility",
        "required": false
      },
      "texture_size": {
        "type": "integer",
        "description": "Texture resolution",
        "required": false,
        "enum": [
          512,
          1024,
          2048
        ],
        "default": 1024
      }
    },
    "outputParameters": {
      "model_mesh": {
        "type": null,
        "description": "Generated 3D mesh file"
      },
      "timings": {
        "type": "object",
        "description": "Processing timings"
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine",
    "title": "Luma Dream Machine",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Luma Dream Machine v1.5",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/JtiRw34MZ1GkgxRnH52Cs.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A teddy bear in sunglasses playing electric guitar and dancing"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "16:9"
      },
      "loop": {
        "type": "boolean",
        "description": "Whether the video should loop (end of video is blended with the beginning)",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2/turbo/remix",
    "title": "Ideogram V2 Turbo Remix",
    "category": "image-to-image",
    "description": "Rapidly create image variations with Ideogram V2 Turbo Remix. Fast and efficient reimagining of existing images while maintaining creative control through prompt guidance.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2/turbo/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2/turbo/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to remix the image with",
        "required": true,
        "examples": [
          "An ice field in north atlantic"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to remix",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/FHOx4y4a0ef7Sgmo-sOUR_image.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Strength of the input image in the remix",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2/turbo/edit",
    "title": "Ideogram V2 Turbo Edit",
    "category": "image-to-image",
    "description": "Edit images faster with Ideogram V2 Turbo. Quick modifications and adjustments while preserving the high-quality standards and realistic outputs of Ideogram.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2/turbo/edit",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2/turbo/edit/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "A knight in shining armour holding a greatshield with \"FAL\" on it"
        ]
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/knight.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The mask URL to inpaint the image. Needs to match the dimensions of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/mask_knight.jpeg"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/video-upscaler",
    "title": "Video Upscaler",
    "category": "video-to-video",
    "description": "The video upscaler endpoint uses RealESRGAN on each frame of the input video to upscale the video to a higher resolution.",
    "tags": [
      "video generation",
      "video to video",
      "ai video",
      "high fidelity motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/video-upscaler-thumbnail.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/video-upscaler",
    "documentationUrl": "https://fal.ai/models/fal-ai/video-upscaler/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the video to upscale",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/videos/_o3VmzjOytBwRjCVPFX6i_output.mp4"
        ]
      },
      "scale": {
        "type": "number",
        "description": "The scale factor",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 2
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The stitched video"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2/turbo",
    "title": "Ideogram V2 Turbo",
    "category": "text-to-image",
    "description": "Accelerated image generation with Ideogram V2 Turbo. Create high-quality visuals, posters, and logos with enhanced speed while maintaining Ideogram's signature quality.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2/turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2/turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "A negative prompt to avoid in the generated image",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/ideogram/v2/remix",
    "title": "Ideogram V2 Remix",
    "category": "image-to-image",
    "description": "Reimagine existing images with Ideogram V2's remix feature. Create variations and adaptations while preserving core elements and adding new creative directions through prompt guidance.",
    "tags": [
      "realism",
      "typography"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ideogram/v2/remix",
    "documentationUrl": "https://fal.ai/models/fal-ai/ideogram/v2/remix/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to remix the image with",
        "required": true,
        "examples": [
          "An ice field in north atlantic"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated image",
        "required": false,
        "enum": [
          "10:16",
          "16:10",
          "9:16",
          "16:9",
          "4:3",
          "3:4",
          "1:1",
          "1:3",
          "3:1",
          "3:2",
          "2:3"
        ],
        "default": "1:1"
      },
      "style": {
        "type": "string",
        "description": "The style of the generated image",
        "required": false,
        "enum": [
          "auto",
          "general",
          "realistic",
          "design",
          "render_3D",
          "anime"
        ],
        "default": "auto"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to remix",
        "required": true,
        "examples": [
          "https://fal.media/files/lion/FHOx4y4a0ef7Sgmo-sOUR_image.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "Strength of the input image in the remix",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "seed": {
        "type": null,
        "description": "Seed for the random number generator",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for the random number generator"
      }
    }
  },
  {
    "id": "fal-ai/luma-photon/flash",
    "title": "Luma Photon Flash",
    "category": "text-to-image",
    "description": "Generate images from your prompts using Luma Photon Flash. Photon Flash is the most creative, personalizable, and intelligent visual models for creatives, bringing a step-function change in the cost of high-quality image generation.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-photon/flash",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-photon/flash/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A teddy bear in sunglasses playing electric guitar and dancing"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "1:1"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/text-to-video",
    "title": "Kling 1.0",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.0",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "advanced_camera_control": {
        "type": null,
        "description": "Advanced Camera control parameters",
        "required": false
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "camera_control": {
        "type": "string",
        "description": "Camera control parameters",
        "required": false,
        "enum": [
          "down_back",
          "forward_up",
          "right_turn_forward",
          "left_turn_forward"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/aura-flow",
    "title": "AuraFlow",
    "category": "text-to-image",
    "description": "AuraFlow v0.3 is an open-source flow-based text-to-image generation model that achieves state-of-the-art results on GenEval. The model is currently in beta.",
    "tags": [
      "typography",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/aura-flow.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/aura-flow",
    "documentationUrl": "https://fal.ai/models/fal-ai/aura-flow/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate images from",
        "required": true,
        "examples": [
          "Close-up portrait of a majestic iguana with vibrant blue-green scales, piercing amber eyes, and orange spiky crest. Intricate textures and details visible on scaly skin. Wrapped in dark hood, giving regal appearance. Dramatic lighting against black background. Hyper-realistic, high-resolution image showcasing the reptile's expressive features and coloration."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "Whether to perform prompt expansion (recommended)",
        "required": false,
        "default": true
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Classifier free guidance scale",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to take",
        "required": false,
        "minimum": 20,
        "maximum": 50,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating images",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The expanded prompt"
      },
      "images": {
        "type": "array",
        "description": "The generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "The seed used to generate the images"
      }
    }
  },
  {
    "id": "fal-ai/omnigen-v1",
    "title": "OmniGen v1",
    "category": "text-to-image",
    "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts. It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On, Multi Person Generation and more!",
    "tags": [
      "multimodal",
      "editing",
      "try-on"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/omnigen-v1.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/omnigen-v1",
    "documentationUrl": "https://fal.ai/models/fal-ai/omnigen-v1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Neon words \"Omni Gen\" are flashing in the prosperous future city, the sense of science and technology, quality details, hyper realistic, high definition, 8K, photo, best quality, high quality."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "img_guidance_scale": {
        "type": "number",
        "description": "\n            The Image Guidance scale is a measure of how close you want\n            the model to stick to your input image when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1.6
      },
      "input_image_urls": {
        "type": "array",
        "description": "URL of images to use while generating the image, Use <img><|image_1|></img> for the first image and so on.",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "type": "string"
        }
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux/schnell/redux",
    "title": "FLUX.1 [schnell] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 [schnell] Redux is a high-performance endpoint for the FLUX.1 [schnell] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-schnell-thumb.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/schnell/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/schnell/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux/schnell",
    "title": "FLUX.1 [schnell]",
    "category": "text-to-image",
    "description": "FLUX.1 [schnell] is a 12 billion parameter flow transformer that generates high-quality images from text in 1 to 4 steps, suitable for personal and commercial use.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-schnell-thumb.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/schnell",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/schnell/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.5/pro/text-to-video",
    "title": "Kling 1.5",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using Kling 1.5 (pro)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.5/pro/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.5/pro/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1.1/redux",
    "title": "FLUX1.1 [pro] Redux",
    "category": "image-to-image",
    "description": "FLUX1.1 [pro] Redux is a high-performance endpoint for the FLUX1.1 [pro] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/turbo_thumbnail.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux/dev/redux",
    "title": "FLUX.1 [dev] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 [dev] Redux is a high-performance endpoint for the FLUX.1 [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      ""
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-dev-thumb.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux/dev/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux/dev/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "acceleration": {
        "type": "string",
        "description": "The speed of the generation. The higher the speed, the faster the generation.",
        "required": false,
        "enum": [
          "none",
          "regular",
          "high"
        ],
        "default": "none"
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n        If set to true, the function will wait for the image to be generated and uploaded\n        before returning the response. This will increase the latency of the function but\n        it allows you to get the image directly in the response without going through the CDN.\n    ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": null,
        "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/flux-lora-depth",
    "title": "FLUX.1 [dev] Depth with LoRAs",
    "category": "image-to-image",
    "description": "Generate high-quality images from depth maps using Flux.1 [dev] depth estimation model. The model produces accurate depth representations for scene understanding and 3D visualization.",
    "tags": [
      "depth",
      "lora",
      "utility",
      "composition"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux_lora.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-depth",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-depth/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Black hole in space, orange accretion disc"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for depth input",
        "required": true,
        "examples": [
          "https://fal.media/files/penguin/vt-SeIOweN7_oYBsvGO6t.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ltx-video/image-to-video",
    "title": "LTX Video (preview)",
    "category": "image-to-video",
    "description": "Generate videos from images using LTX Video",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video/image-to-video/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A lone astronaut in a white spacesuit with gold-tinted visor drifts weightlessly through a sleek, cylindrical corridor of a spaceship. Their movements are slow and graceful as they gently push off the metallic walls with their gloved hands, rotating slightly as they float from right to left across the frame. The corridor features brushed aluminum panels with blue LED strips running along the ceiling, casting a cool glow on the astronaut's suit. Various cables, pipes, and control panels line the walls. The camera follows the astronaut's movement in a handheld style, slightly swaying and adjusting focus, maintaining a medium shot that captures both the astronaut and the corridor's depth. Small particles of dust catch the light as they float in the zero-gravity environment. The scene appears cinematic, with lens flares occasionally reflecting off the metallic surfaces and the astronaut's visor."
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale to use.",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "seed": {
        "type": null,
        "description": "The seed to use for random number generation.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to take.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate the video from.",
        "required": false,
        "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to generate the video from.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/4OePu2ifG7SKxTM__TQrQ_72929fec9fb74790bb8c8b760450c9b9.jpg"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for random number generation."
      },
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1.1-ultra/redux",
    "title": "FLUX1.1 [pro] ultra Redux",
    "category": "image-to-image",
    "description": "FLUX1.1 [pro] ultra Redux is a high-performance endpoint for the FLUX1.1 [pro] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "style transfer",
      "high-res"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-pro-11-ultra.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1-ultra/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1.1-ultra/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": null,
        "description": "The aspect ratio of the generated image.",
        "required": false,
        "default": "16:9"
      },
      "raw": {
        "type": "boolean",
        "description": "Generate less processed, more natural-looking images.",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_prompt_strength": {
        "type": "number",
        "description": "The strength of the image prompt, between 0 and 1.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.1
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1/fill",
    "title": "FLUX.1 [pro] Fill",
    "category": "image-to-image",
    "description": "FLUX.1 [pro] Fill is a high-performance endpoint for the FLUX.1 [pro] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fluxpro.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1/fill",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1/fill/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to fill the masked part of the image.",
        "required": true,
        "examples": [
          "A knight in shining armour holding a greatshield with \"FAL\" on it"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/knight.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The mask URL to inpaint the image. Needs to match the dimensions of the input image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-lora/example-images/mask_knight.jpeg"
        ]
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/v1/redux",
    "title": "FLUX.1 [pro] Redux",
    "category": "image-to-image",
    "description": "FLUX.1 [pro] Redux is a high-performance endpoint for the FLUX.1 [pro] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "tags": [
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fluxpro.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/v1/redux",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/v1/redux/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from. Needs to match the dimensions of the mask.",
        "required": true,
        "examples": [
          "https://fal.media/files/kangaroo/acQvq-Kmo2lajkgvcEHdv.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1.5,
        "maximum": 5,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/kolors/image-to-image",
    "title": "Kolors Image to Image",
    "category": "image-to-image",
    "description": "Photorealistic Image-to-Image",
    "tags": [
      "realism",
      "editing",
      "diffusion"
    ],
    "thumbnailUrl": "https://v2.fal.media/files/bdcf6a7a3f4146c39555e0c195715e65_73e054513f15488f93248ae10d67ece5.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kolors/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/kolors/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "high quality image of a capybara wearing sunglasses. In the background of the image there are trees, poles, grass and other objects. At the bottom of the object there is the road., 8k, highly detailed."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for image to image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_models/bunny_source.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and\n            uploaded before returning the response. This will increase the latency of\n            the function but it allows you to get the image directly in the response\n            without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "scheduler": {
        "type": "string",
        "description": "The scheduler to use for the model.",
        "required": false,
        "enum": [
          "EulerDiscreteScheduler",
          "EulerAncestralDiscreteScheduler",
          "DPMSolverMultistepScheduler",
          "DPMSolverMultistepScheduler_SDE_karras",
          "UniPCMultistepScheduler",
          "DEISMultistepScheduler"
        ],
        "default": "EulerDiscreteScheduler"
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show\n            you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 150,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "Seed",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small\n            details (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "ugly, deformed, blurry"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Enable safety checker.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/iclight-v2",
    "title": "IC-Light-v2 for Image Relighting",
    "category": "image-to-image",
    "description": "An endpoint for re-lighting photos and changing their backgrounds per a given description",
    "tags": [
      "relighting",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/web-examples/iclight-v2/iclightv2-default-output.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/iclight-v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/iclight-v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "initial_latent": {
        "type": "string",
        "description": "\n            Provide lighting conditions for the model\n        ",
        "required": false,
        "enum": [
          "None",
          "Left",
          "Right",
          "Top",
          "Bottom"
        ],
        "default": "None"
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "perfume bottle in a volcano surrounded by lava."
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "background_threshold": {
        "type": "number",
        "description": "Threshold for the background removal algorithm. A high threshold will produce sharper masks. Note: This parameter is currently deprecated and has no effect on the output.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.67
      },
      "mask_image_url": {
        "type": "string",
        "description": "URL of mask to be used for ic-light conditioning image",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "lowres_denoise": {
        "type": "number",
        "description": "Strength for low-resolution pass.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.98
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative Prompt for the image",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "hr_downscale": {
        "type": "number",
        "description": "",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be used for relighting",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/iclight-v2/bottle.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "highres_denoise": {
        "type": "number",
        "description": "Strength for high-resolution pass. Only used if enable_hr_fix is True.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_hr_fix": {
        "type": "boolean",
        "description": "Use HR fix",
        "required": false,
        "default": false
      },
      "cfg": {
        "type": "number",
        "description": "The real classifier-free-guidance scale for the generation.",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 1
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/mochi-v1",
    "title": "Mochi 1",
    "category": "text-to-video",
    "description": "Mochi 1 preview is an open state-of-the-art video generation model with high-fidelity motion and strong prompt adherence in preliminary evaluation.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/mochi-v1.webp?v=1",
    "playgroundUrl": "https://fal.ai/models/fal-ai/mochi-v1",
    "documentationUrl": "https://fal.ai/models/fal-ai/mochi-v1/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate a video from.",
        "required": true,
        "examples": [
          "A dog running in a field."
        ]
      },
      "enable_prompt_expansion": {
        "type": "boolean",
        "description": "Whether to enable prompt expansion.",
        "required": false,
        "default": true
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt for the video.",
        "required": false,
        "default": "",
        "examples": [
          "Blurry, shaky footage"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/flux-differential-diffusion",
    "title": "FLUX.1 [dev] Differential Diffusion",
    "category": "image-to-image",
    "description": "FLUX.1 Differential Diffusion is a rapid endpoint that enables swift, granular control over image transformations through change maps, delivering fast and precise region-specific modifications while maintaining FLUX.1 [dev]'s high-quality output.",
    "tags": [
      "transformation"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/e-8Q3gR-WkrPM9-p4aicX.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-differential-diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-differential-diffusion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Tree of life under the sea, ethereal, glittering, lens flares, cinematic lighting, artwork by Anna Dittmann & Carne Griffiths, 8k, unreal engine 5, hightly detailed, intricate detailed."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use as initial image.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/h6a7KK2Ie_inuGbdartoX.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "change_map_image_url": {
        "type": "string",
        "description": "URL of change map.",
        "required": true,
        "examples": [
          "https://fal.media/files/zebra/Wh4IYAiAAcVbuZ8M9ZMSn.jpeg"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-pulid",
    "title": "PuLID Flux",
    "category": "image-to-image",
    "description": "An endpoint for personalized image generation using Flux as per given description.",
    "tags": [
      "personalization",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-pulid.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pulid",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pulid/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "a woman holding sign with glowing green text 'PuLID for FLUX'"
        ]
      },
      "id_weight": {
        "type": "number",
        "description": "The weight of the ID loss.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "start_step": {
        "type": "integer",
        "description": "The number of steps to start the CFG from.",
        "required": false,
        "minimum": 0,
        "maximum": 50,
        "default": 0
      },
      "reference_image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/example_inputs_liuyifei.png"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "max_sequence_length": {
        "type": "string",
        "description": "The maximum sequence length for the model.",
        "required": false,
        "enum": [
          "128",
          "256",
          "512"
        ],
        "default": "128"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 20
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": false,
        "default": "",
        "examples": [
          "bad quality, worst quality, text, signature, watermark, extra limbs"
        ]
      },
      "true_cfg": {
        "type": "number",
        "description": "The weight of the CFG loss.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/birefnet/v2",
    "title": "Birefnet Background Removal",
    "category": "image-to-image",
    "description": "bilateral reference framework (BiRefNet) for high-resolution dichotomous image segmentation (DIS)",
    "tags": [
      "background removal",
      "segmentation",
      "high-res",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/birefnet.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/birefnet/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/birefnet/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "operating_resolution": {
        "type": "string",
        "description": "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images.",
        "required": false,
        "enum": [
          "1024x1024",
          "2048x2048"
        ],
        "default": "1024x1024"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the output image",
        "required": false,
        "enum": [
          "webp",
          "png",
          "gif"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to remove background from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/birefnet-input.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "model": {
        "type": "string",
        "description": "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository but trained with 2K images.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Matting' model is a model trained specifically for matting images.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet-DIS_ep580.pth\n            - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth\n            - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth\n        ",
        "required": false,
        "enum": [
          "General Use (Light)",
          "General Use (Light 2K)",
          "General Use (Heavy)",
          "Matting",
          "Portrait"
        ],
        "default": "General Use (Light)"
      },
      "output_mask": {
        "type": "boolean",
        "description": "Whether to output the mask used to remove the background",
        "required": false,
        "default": false
      },
      "refine_foreground": {
        "type": "boolean",
        "description": "Whether to refine the foreground using the estimated mask",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with background removed"
      },
      "mask_image": {
        "type": null,
        "description": "Mask used to remove the background"
      }
    }
  },
  {
    "id": "fal-ai/stable-diffusion-v35-medium",
    "title": "Stable Diffusion 3.5 Medium",
    "category": "text-to-image",
    "description": "Stable Diffusion 3.5 Medium is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "tags": [
      "diffusion",
      "typography",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/stable-diffusion-v35-medium.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v35-medium",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v35-medium/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A dreamlike Japanese garden in perpetual twilight, bathed in bioluminescent cherry blossoms that emit a soft pink-purple glow. Floating paper lanterns drift lazily through the scene, their warm light creating dancing reflections in a mirror-like koi pond. Ethereal mist weaves between ancient stone pathways lined with glowing mushrooms in pastel blues and purples. A traditional wooden bridge arches gracefully over the water, dusted with fallen petals that sparkle like stardust. The scene is captured through a cinematic lens with perfect bokeh, creating an otherworldly atmosphere. In the background, a crescent moon hangs impossibly large in the sky, surrounded by a sea of stars and auroral wisps in teal and violet. Crystal formations emerge from the ground, refracting the ambient light into rainbow prisms. The entire composition follows the golden ratio, with moody film-like color grading reminiscent of Studio Ghibli, enhanced by volumetric god rays filtering through the luminous foliage. 8K resolution, masterful photography, hyperdetailed, magical realism."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 40
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hunyuan-video",
    "title": "Hunyuan Video",
    "category": "text-to-video",
    "description": "Hunyuan Video is an Open video generation model with high visual quality, motion diversity, text-video alignment, and generation stability. This endpoint generates videos from text descriptions.",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the video to generate.",
        "required": false,
        "enum": [
          "16:9",
          "9:16"
        ],
        "default": "16:9"
      },
      "resolution": {
        "type": "string",
        "description": "The resolution of the video to generate.",
        "required": false,
        "enum": [
          "480p",
          "580p",
          "720p"
        ],
        "default": "720p"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to run. Lower gets faster results, higher gets better results.",
        "required": false,
        "minimum": 2,
        "maximum": 30,
        "default": 30
      },
      "seed": {
        "type": "integer",
        "description": "The seed to use for generating the video.",
        "required": false
      },
      "num_frames": {
        "type": "string",
        "description": "The number of frames to generate.",
        "required": false,
        "enum": [
          "129",
          "85"
        ],
        "default": 129
      },
      "pro_mode": {
        "type": "boolean",
        "description": "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/cogvideox-5b/image-to-video",
    "title": "CogVideoX-5B",
    "category": "image-to-video",
    "description": "Generate videos from images and prompts using CogVideoX-5B",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/cogvideox-5b/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/cogvideox-5b/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A low angle shot of a man walking down a street, illuminated by the neon signs of the bars around him"
        ]
      },
      "use_rife": {
        "type": "boolean",
        "description": "Use RIFE for video interpolation",
        "required": false,
        "default": true
      },
      "image_url": {
        "type": "string",
        "description": "The URL to the image to generate the video from.",
        "required": true,
        "examples": [
          "https://d3phaj0sisr2ct.cloudfront.net/research/eugene.jpg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "video_size": {
        "type": null,
        "description": "The size of the generated video.",
        "required": false,
        "default": {
          "height": 480,
          "width": 720
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "export_fps": {
        "type": "integer",
        "description": "The target FPS of the video",
        "required": false,
        "minimum": 4,
        "maximum": 32,
        "default": 16
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate video from",
        "required": false,
        "default": "",
        "examples": [
          "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the video."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "video": {
        "type": null,
        "description": "The URL to the generated video"
      }
    }
  },
  {
    "id": "fal-ai/f5-tts",
    "title": "F5 TTS",
    "category": "text-to-audio",
    "description": "F5 TTS",
    "tags": [
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/f5-tts.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/f5-tts",
    "documentationUrl": "https://fal.ai/models/fal-ai/f5-tts/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "ref_text": {
        "type": "string",
        "description": "The reference text to be used for TTS. If not provided, an ASR (Automatic Speech Recognition) model will be used to generate the reference text.",
        "required": false,
        "default": "",
        "examples": [
          "Some call me nature, others call me mother nature."
        ]
      },
      "remove_silence": {
        "type": "boolean",
        "description": "Whether to remove the silence from the audio file.",
        "required": false,
        "default": true
      },
      "gen_text": {
        "type": "string",
        "description": "The text to be converted to speech.",
        "required": true,
        "examples": [
          "I don't really care what you call me. I've been a silent spectator, watching species evolve, empires rise and fall. But always remember, I am mighty and enduring. Respect me and I'll nurture you; ignore me and you shall face the consequences."
        ]
      },
      "model_type": {
        "type": "string",
        "description": "The name of the model to be used for TTS.",
        "required": true,
        "enum": [
          "F5-TTS",
          "E2-TTS"
        ]
      },
      "ref_audio_url": {
        "type": "string",
        "description": "The URL of the reference audio file.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/reference_audio.wav"
        ]
      }
    },
    "outputParameters": {
      "audio_url": {
        "type": null,
        "description": "The audio file containing the generated speech."
      }
    }
  },
  {
    "id": "fal-ai/cogvideox-5b/video-to-video",
    "title": "CogVideoX-5B",
    "category": "video-to-video",
    "description": "Generate videos from videos and prompts using CogVideoX-5B",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/cogvideox-5b/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/cogvideox-5b/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "An astronaut stands triumphantly at the peak of a towering mountain. Panorama of rugged peaks and valleys. Very futuristic vibe and animated aesthetic. Highlights of purple and golden colors in the scene. The sky is looks like an animated/cartoonish dream of galaxies, nebulae, stars, planets, moons, but the remainder of the scene is mostly realistic. "
        ]
      },
      "video_url": {
        "type": "string",
        "description": "The video to generate the video from.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/hiker.mp4"
        ]
      },
      "use_rife": {
        "type": "boolean",
        "description": "Use RIFE for video interpolation",
        "required": false,
        "default": true
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for Video to Video.  1.0 completely remakes the video while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.8
      },
      "video_size": {
        "type": null,
        "description": "The size of the generated video.",
        "required": false,
        "default": {
          "height": 480,
          "width": 720
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
        "required": false
      },
      "export_fps": {
        "type": "integer",
        "description": "The target FPS of the video",
        "required": false,
        "minimum": 4,
        "maximum": 32,
        "default": 16
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate video from",
        "required": false,
        "default": "",
        "examples": [
          "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 50
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the video."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "video": {
        "type": null,
        "description": "The URL to the generated video"
      }
    }
  },
  {
    "id": "fal-ai/any-llm/vision",
    "title": "Any VLM",
    "category": "vision",
    "description": "Use any vision language model from our selected catalogue (powered by OpenRouter)",
    "tags": [
      "multimodal",
      "vision",
      "streaming"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/-wKtDrmGZzHnnV1KCBz2x_f3fbc1daea3548c5bca0aae44cf15f5f.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/any-llm/vision",
    "documentationUrl": "https://fal.ai/models/fal-ai/any-llm/vision/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the image",
        "required": true,
        "examples": [
          "Caption this image for a text-to-image model with as much detail as possible."
        ]
      },
      "system_prompt": {
        "type": "string",
        "description": "System prompt to provide context or instructions to the model",
        "required": false,
        "examples": [
          "Only answer the question, do not provide any additional information or add any prefix/suffix other than the answer of the original question. Don't use markdown."
        ]
      },
      "reasoning": {
        "type": "boolean",
        "description": "Should reasoning be the part of the final answer.",
        "required": false,
        "default": false
      },
      "model": {
        "type": "string",
        "description": "Name of the model to use. Premium models are charged at 3x the rate of standard models, they include: google/gemini-pro-1.5, openai/gpt-5-chat, openai/gpt-4o, anthropic/claude-sonnet-4.5, google/gemini-2.5-pro, anthropic/claude-3.7-sonnet, anthropic/claude-3.5-sonnet, meta-llama/llama-3.2-90b-vision-instruct, openai/gpt-4.1.",
        "required": false,
        "enum": [
          "anthropic/claude-sonnet-4.5",
          "anthropic/claude-3.7-sonnet",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-3-haiku",
          "google/gemini-pro-1.5",
          "google/gemini-flash-1.5",
          "google/gemini-flash-1.5-8b",
          "google/gemini-2.0-flash-001",
          "google/gemini-2.5-flash",
          "google/gemini-2.5-flash-lite",
          "google/gemini-2.5-pro",
          "openai/gpt-4o",
          "openai/gpt-4.1",
          "openai/gpt-5-chat",
          "meta-llama/llama-3.2-90b-vision-instruct",
          "meta-llama/llama-4-maverick",
          "meta-llama/llama-4-scout"
        ],
        "default": "google/gemini-2.5-flash-lite"
      },
      "max_tokens": {
        "type": "integer",
        "description": "This sets the upper limit for the number of tokens the model can generate in response. It won’t produce more than this limit. The maximum value is the context length minus the prompt length.",
        "required": false,
        "minimum": 1
      },
      "temperature": {
        "type": "number",
        "description": "This setting influences the variety in the model’s responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.",
        "required": false,
        "minimum": 0,
        "maximum": 2
      },
      "image_urls": {
        "type": "array",
        "description": "List of image URLs to be processed",
        "required": false,
        "examples": [
          [
            "https://fal.media/files/tiger/4Ew1xYW6oZCs6STQVC7V8_86440216d0fe42e4b826d03a2121468e.jpg"
          ]
        ],
        "items": {
          "type": "string"
        }
      },
      "priority": {
        "type": "string",
        "description": "Throughput is the default and is recommended for most use cases. Latency is recommended for use cases where low latency is important.",
        "required": false,
        "enum": [
          "throughput",
          "latency"
        ],
        "default": "latency"
      }
    },
    "outputParameters": {
      "error": {
        "type": "string",
        "description": "Error message if an error occurred"
      },
      "partial": {
        "type": "boolean",
        "description": "Whether the output is partial"
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      },
      "reasoning": {
        "type": "string",
        "description": "Generated reasoning for the final answer"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1.5/pro/image-to-video",
    "title": "Kling 1.5",
    "category": "image-to-video",
    "description": "Generate video clips from your images using Kling 1.5 (pro)",
    "tags": [],
    "thumbnailUrl": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1.5/pro/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1.5/pro/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Snowflakes fall as a car moves along the road."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video frame",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1"
        ],
        "default": "16:9"
      },
      "tail_image_url": {
        "type": "string",
        "description": "URL of the image to be used for the end of the video",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/image-to-video",
    "title": "Kling 1.0",
    "category": "image-to-video",
    "description": "Generate video clips from your images using Kling 1.0",
    "tags": [
      "motion"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/kling-video/v1/standard/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt for the video",
        "required": true,
        "maxLength": 2500,
        "examples": [
          "Snowflakes fall as a car moves forward along the road."
        ]
      },
      "duration": {
        "type": "string",
        "description": "The duration of the generated video in seconds",
        "required": false,
        "enum": [
          "5",
          "10"
        ],
        "default": "5"
      },
      "negative_prompt": {
        "type": "string",
        "description": "",
        "required": false,
        "maxLength": 2500,
        "default": "blur, distort, and low quality"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be used for the video",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
        ]
      },
      "static_mask_url": {
        "type": "string",
        "description": "URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/kling/new_static_mask.png"
        ]
      },
      "dynamic_masks": {
        "type": "array",
        "description": "List of dynamic masks",
        "required": false,
        "items": {
          "$ref": "#/components/schemas/DynamicMask"
        }
      },
      "tail_image_url": {
        "type": "string",
        "description": "URL of the image to be used for the end of the video",
        "required": false
      },
      "cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/ltx-video",
    "title": "LTX Video (preview)",
    "category": "text-to-video",
    "description": "Generate videos from prompts using LTX Video",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate the video from.",
        "required": true,
        "examples": [
          "A man stands waist-deep in a crystal-clear mountain pool, his back turned to a massive, thundering waterfall that cascades down jagged cliffs behind him. He wears a dark blue swimming shorts and his muscular back glistens with water droplets. The camera moves in a dynamic circular motion around him, starting from his right side and sweeping left, maintaining a slightly low angle that emphasizes the towering height of the waterfall. As the camera moves, the man slowly turns his head to follow its movement, his expression one of awe as he gazes up at the natural wonder. The waterfall creates a misty atmosphere, with sunlight filtering through the spray to create rainbow refractions. The water churns and ripples around him, reflecting the dramatic landscape. The handheld camera movement adds a subtle shake that enhances the raw, untamed energy of the scene. The lighting is natural and bright, with the sun positioned behind the waterfall, creating a backlit effect that silhouettes the falling water and illuminates the mist."
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale to use.",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "seed": {
        "type": null,
        "description": "The seed to use for random number generation.",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to take.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 30
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate the video from.",
        "required": false,
        "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly"
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used for random number generation."
      },
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/flux-pro/new",
    "title": "FLUX.1 [pro]",
    "category": "text-to-image",
    "description": "FLUX.1 [pro] new is an accelerated version of FLUX.1 [pro], maintaining professional-grade image quality while delivering significantly faster generation speeds.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-pro-thumb.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-pro/new",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-pro/new/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "landscape_4_3"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "safety_tolerance": {
        "type": "string",
        "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
        "required": false,
        "enum": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "default": "2"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enhance_prompt": {
        "type": "boolean",
        "description": "Whether to enhance the prompt for better results.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/registry__image__fast_sdxl__models__Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/live-portrait/image",
    "title": "Live Portrait",
    "category": "image-to-image",
    "description": "Transfer expression from a video to a portrait.",
    "tags": [
      "expression",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/live-portrait/XKEmk3mAzGHUjK3qqH-UL.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/live-portrait/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/live-portrait/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "smile": {
        "type": "number",
        "description": "Amount to smile",
        "required": false,
        "minimum": -2,
        "maximum": 2,
        "default": 0
      },
      "eyebrow": {
        "type": "number",
        "description": "Amount to raise or lower eyebrows",
        "required": false,
        "minimum": -30,
        "maximum": 30,
        "default": 0
      },
      "rotate_roll": {
        "type": "number",
        "description": "Amount to rotate the face in roll",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "blink": {
        "type": "number",
        "description": "Amount to blink the eyes",
        "required": false,
        "minimum": -30,
        "maximum": 30,
        "default": 0
      },
      "rotate_pitch": {
        "type": "number",
        "description": "Amount to rotate the face in pitch",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "wink": {
        "type": "number",
        "description": "Amount to wink",
        "required": false,
        "minimum": 0,
        "maximum": 25,
        "default": 0
      },
      "pupil_x": {
        "type": "number",
        "description": "Amount to move pupils horizontally",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "eee": {
        "type": "number",
        "description": "Amount to shape mouth in 'eee' position",
        "required": false,
        "minimum": -40,
        "maximum": 40,
        "default": 0
      },
      "vy_ratio": {
        "type": "number",
        "description": "Vertical offset ratio for face crop. Positive values move up, negative values move down.",
        "required": false,
        "default": -0.125
      },
      "scale": {
        "type": "number",
        "description": "Scaling factor for the face crop.",
        "required": false,
        "default": 2.3
      },
      "flag_pasteback": {
        "type": "boolean",
        "description": "Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.",
        "required": false,
        "default": true
      },
      "dsize": {
        "type": "integer",
        "description": "Size of the output image.",
        "required": false,
        "default": 512
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ",
        "required": false,
        "default": false
      },
      "vx_ratio": {
        "type": "number",
        "description": "Horizontal offset ratio for face crop.",
        "required": false,
        "default": 0
      },
      "pupil_y": {
        "type": "number",
        "description": "Amount to move pupils vertically",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "rotate_yaw": {
        "type": "number",
        "description": "Amount to rotate the face in yaw",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "output_format": {
        "type": "string",
        "description": "Output format",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be animated",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/live-portrait/XKEmk3mAzGHUjK3qqH-UL.jpeg"
        ]
      },
      "woo": {
        "type": "number",
        "description": "Amount to shape mouth in 'woo' position",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "aaa": {
        "type": "number",
        "description": "Amount to open mouth in 'aaa' shape",
        "required": false,
        "minimum": -200,
        "maximum": 200,
        "default": 0
      },
      "flag_do_rot": {
        "type": "boolean",
        "description": "Whether to conduct the rotation when flag_do_crop is True.",
        "required": false,
        "default": true
      },
      "flag_do_crop": {
        "type": "boolean",
        "description": "Whether to crop the source portrait to the face-cropping space.",
        "required": false,
        "default": true
      },
      "flag_lip_zero": {
        "type": "boolean",
        "description": "Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file."
      }
    }
  },
  {
    "id": "fal-ai/flux-lora/inpainting",
    "title": "FLUX.1 [dev] Inpainting with LoRAs",
    "category": "text-to-image",
    "description": "Super fast endpoint for the FLUX.1 [dev] inpainting model with LoRA support, enabling rapid and high-quality image inpaingting using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "lora",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux_lora.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "mask_url": {
        "type": "string",
        "description": "\n            The mask to area to Inpaint in.\n        ",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/dog_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-general/rf-inversion",
    "title": "FLUX.1 [dev] with Controlnets and Loras",
    "category": "image-to-image",
    "description": "A general purpose endpoint for the FLUX.1 [dev] model, implementing the RF-Inversion pipeline. This can be used to edit a reference image based on a prompt.",
    "tags": [
      "rf-inversion",
      "editing",
      "lora"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/flux-lora/flux_general.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-general/rf-inversion",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-general/rf-inversion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to edit the image with",
        "required": true,
        "examples": [
          "Wearing glasses"
        ]
      },
      "nag_end": {
        "type": "number",
        "description": "\n            The proportion of steps to apply NAG. After the specified proportion\n            of steps has been iterated, the remaining steps will use original\n            attention processors in FLUX.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "control_loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/ControlLoraWeight"
        }
      },
      "controller_guidance_reverse": {
        "type": "number",
        "description": "The controller guidance (eta) used in the denoising process.Using values closer to 1 will result in an image closer to input.",
        "required": false,
        "minimum": 0.01,
        "maximum": 3,
        "default": 0.75
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "reverse_guidance_start": {
        "type": "integer",
        "description": "Timestep to start guidance during reverse process.",
        "required": false,
        "default": 0
      },
      "easycontrols": {
        "type": "array",
        "description": "\n        EasyControl Inputs to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/EasyControlWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler for the denoising process.",
        "required": false,
        "enum": [
          "euler",
          "dpmpp_2m"
        ],
        "default": "euler"
      },
      "use_cfg_zero": {
        "type": "boolean",
        "description": "\n            Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.\n        ",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "reference_strength": {
        "type": "number",
        "description": "Strength of reference_only generation. Only used if a reference image is provided.",
        "required": false,
        "minimum": -3,
        "maximum": 3,
        "default": 0.65
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "sigma_schedule": {
        "type": "string",
        "description": "Sigmas schedule for the denoising process.",
        "required": false,
        "enum": [
          "sgm_uniform"
        ]
      },
      "reference_end": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to be ended.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "controller_guidance_forward": {
        "type": "number",
        "description": "The controller guidance (gamma) used in the creation of structured noise.",
        "required": false,
        "minimum": 0.01,
        "maximum": 3,
        "default": 0.6
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "fill_image": {
        "type": null,
        "description": "Use an image input to influence the generation. Can be used to fill images in masked areas.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to be edited",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/flux-general-tests/anime_style.png"
        ]
      },
      "nag_scale": {
        "type": "number",
        "description": "\n            The scale for NAG. Higher values will result in a image that is more distant\n            to the negative prompt.\n        ",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "reverse_guidance_schedule": {
        "type": "string",
        "description": "Scheduler for applying reverse guidance.",
        "required": false,
        "enum": [
          "constant",
          "linear_increase",
          "linear_decrease"
        ],
        "default": "constant"
      },
      "reference_image_url": {
        "type": "string",
        "description": "URL of Image for Reference-Only",
        "required": false
      },
      "reverse_guidance_end": {
        "type": "integer",
        "description": "Timestep to stop guidance during reverse process.",
        "required": false,
        "default": 8
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "controlnet_unions": {
        "type": "array",
        "description": "\n            The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNetUnion"
        }
      },
      "nag_tau": {
        "type": "number",
        "description": "\n            The tau for NAG. Controls the normalization of the hidden state.\n            Higher values will result in a less aggressive normalization,\n            but may also lead to unexpected changes with respect to the original image.\n            Not recommended to change this value.\n        ",
        "required": false,
        "default": 2.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            Negative prompt to steer the image generation away from unwanted features.\n            By default, we will be using NAG for processing the negative prompt.\n        ",
        "required": false,
        "default": ""
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      },
      "use_beta_schedule": {
        "type": "boolean",
        "description": "Specifies whether beta sigmas ought to be used.",
        "required": false,
        "default": false
      },
      "nag_alpha": {
        "type": "number",
        "description": "\n            The alpha value for NAG. This value is used as a final weighting\n            factor for steering the normalized guidance (positive and negative prompts)\n            in the direction of the positive prompt. Higher values will result in less\n            steering on the normalized guidance where lower values will result in\n            considering the positive prompt guidance more.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "base_shift": {
        "type": "number",
        "description": "Base shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 0.5
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The controlnets to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "reference_start": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to bestarted.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "max_shift": {
        "type": "number",
        "description": "Max shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 1.15
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/stable-video",
    "title": "High Quality Stable Video Diffusion",
    "category": "image-to-video",
    "description": "Generate short video clips from your images using SVD v1.1",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-svd.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "motion_bucket_id": {
        "type": "integer",
        "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 255,
        "default": 127
      },
      "fps": {
        "type": "integer",
        "description": "The frames per second of the generated video.",
        "required": false,
        "minimum": 10,
        "maximum": 100,
        "default": 25
      },
      "cond_aug": {
        "type": "number",
        "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 0.02
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "minLength": 1,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/svd/rocket.png",
          "https://storage.googleapis.com/falserverless/model_tests/svd/mustang.png",
          "https://storage.googleapis.com/falserverless/model_tests/svd/ship.png",
          "https://storage.googleapis.com/falserverless/model_tests/svd/rocket2.png"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed for random number generator"
      },
      "video": {
        "type": null,
        "description": "Generated video"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/hed",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "Holistically-Nested Edge Detection (HED) preprocessor.",
    "tags": [
      "preprocess",
      "detection",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/hed",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/hed/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "safe": {
        "type": "boolean",
        "description": "Whether to use the safe version of the HED detector",
        "required": false,
        "default": false
      },
      "scribble": {
        "type": "boolean",
        "description": "Whether to use the scribble version of the HED detector",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with lines detected using the HED detector"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/scribble",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "Scribble preprocessor.",
    "tags": [
      "preprocess",
      "utility",
      "editing",
      "controlnet",
      "sketch"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/scribble",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/scribble/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "The model to use for the Scribble detector",
        "required": false,
        "enum": [
          "HED",
          "PiDi"
        ],
        "default": "HED"
      },
      "safe": {
        "type": "boolean",
        "description": "Whether to use the safe version of the Scribble detector",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with lines detected using the Scribble detector"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/depth-anything/v2",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "Depth Anything v2 preprocessor.",
    "tags": [
      "depth",
      "preprocess",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/depth-anything/v2",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/depth-anything/v2/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with depth map"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/zoe",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "ZoeDepth preprocessor.",
    "tags": [
      "depth",
      "preprocess",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/zoe",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/zoe/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with depth map"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/teed",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "TEED (Temporal Edge Enhancement Detection) preprocessor.",
    "tags": [
      "preprocess",
      "detection",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/teed",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/teed/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with TeeD lines detected"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/mlsd",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "M-LSD line segment detection preprocessor.",
    "tags": [
      "preprocess",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/mlsd",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/mlsd/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "distance_threshold": {
        "type": "number",
        "description": "Distance threshold for the MLSD detector",
        "required": false,
        "default": 0.1
      },
      "score_threshold": {
        "type": "number",
        "description": "Score threshold for the MLSD detector",
        "required": false,
        "default": 0.1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with lines detected using the MLSD detector"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/lineart",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "Line art preprocessor.",
    "tags": [
      "preprocess",
      "utility",
      "sketch",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/lineart",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/lineart/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "coarse": {
        "type": "boolean",
        "description": "Whether to use the coarse model",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with edges detected using the Canny algorithm"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/sam",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "Segment Anything Model (SAM) preprocessor.",
    "tags": [
      "segmentation",
      "preprocess",
      "utility",
      "mask",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/sam",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/sam/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with SAM segmentation map"
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/midas",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "MiDaS depth estimation preprocessor.",
    "tags": [
      "depth",
      "preprocess",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/midas",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/midas/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "a": {
        "type": "number",
        "description": "A parameter for the MiDaS detector",
        "required": false,
        "default": 6.283185307179586
      },
      "background_threshold": {
        "type": "number",
        "description": "Background threshold for the MiDaS detector",
        "required": false,
        "default": 0.1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "normal_map": {
        "type": null,
        "description": "Image with MiDaS normal map"
      },
      "depth_map": {
        "type": null,
        "description": "Image with MiDaS depth map"
      }
    }
  },
  {
    "id": "fal-ai/fast-svd/text-to-video",
    "title": "Stable Video Diffusion",
    "category": "text-to-video",
    "description": "Generate short video clips from your prompts using SVD v1.1",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/svd_rocket.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-svd/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-svd/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "A rocket flying that is about to take off"
        ]
      },
      "cond_aug": {
        "type": "number",
        "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 0.02
      },
      "deep_cache": {
        "type": "string",
        "description": "\n            Enabling [DeepCache](https://github.com/horseee/DeepCache) will make the execution\n            faster, but might sometimes degrade overall quality. The higher the setting, the\n            faster the execution will be, but the more quality might be lost.\n        ",
        "required": false,
        "enum": [
          "none",
          "minimum",
          "medium",
          "high"
        ],
        "default": "none"
      },
      "fps": {
        "type": "integer",
        "description": "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 10
      },
      "motion_bucket_id": {
        "type": "integer",
        "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 255,
        "default": 127
      },
      "video_size": {
        "type": null,
        "description": "The size of the generated video.",
        "required": false,
        "default": "landscape_16_9"
      },
      "steps": {
        "type": "integer",
        "description": "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 20
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use as a starting point for the generation.",
        "required": false,
        "default": "unrealistic, saturated, high contrast, big nose, painting, drawing, sketch, cartoon, anime, manga, render, CG, 3d, watermark, signature, label"
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        "
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/image-preprocessors/pidi",
    "title": "Image Preprocessors",
    "category": "image-to-image",
    "description": "PIDI (Pidinet) preprocessor.",
    "tags": [
      "detection",
      "preprocess",
      "utility",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/image-preprocessors.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/image-preprocessors/pidi",
    "documentationUrl": "https://fal.ai/models/fal-ai/image-preprocessors/pidi/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "safe": {
        "type": "boolean",
        "description": "Whether to use the safe version of the Pidi detector",
        "required": false,
        "default": false
      },
      "apply_filter": {
        "type": "boolean",
        "description": "Whether to apply the filter to the image.",
        "required": false,
        "default": false
      },
      "scribble": {
        "type": "boolean",
        "description": "Whether to use the scribble version of the Pidi detector",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to process",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/image_preprocessors/cat.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with Pidi lines detected"
      }
    }
  },
  {
    "id": "fal-ai/controlnext",
    "title": "ControlNeXt SVD",
    "category": "video-to-video",
    "description": "Animate a reference image with a driving video using ControlNeXt.",
    "tags": [
      "animation",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/controlnext.JPG",
    "playgroundUrl": "https://fal.ai/models/fal-ai/controlnext",
    "documentationUrl": "https://fal.ai/models/fal-ai/controlnext/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "controlnext_cond_scale": {
        "type": "number",
        "description": "Condition scale for ControlNeXt.",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 1
      },
      "video_url": {
        "type": "string",
        "description": "URL of the input video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/musepose/dance.mp4"
        ]
      },
      "fps": {
        "type": "integer",
        "description": "Frames per second for the output video.",
        "required": false,
        "minimum": 1,
        "maximum": 60,
        "default": 7
      },
      "max_frame_num": {
        "type": "integer",
        "description": "Maximum number of frames to process.",
        "required": false,
        "minimum": 1,
        "maximum": 1000,
        "default": 240
      },
      "width": {
        "type": "integer",
        "description": "Width of the output video.",
        "required": false,
        "minimum": 64,
        "maximum": 1024,
        "default": 576
      },
      "overlap": {
        "type": "integer",
        "description": "Number of overlapping frames between batches.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 6
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale for the diffusion process.",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 3
      },
      "batch_frames": {
        "type": "integer",
        "description": "Number of frames to process in each batch.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 24
      },
      "height": {
        "type": "integer",
        "description": "Height of the output video.",
        "required": false,
        "minimum": 64,
        "maximum": 1024,
        "default": 1024
      },
      "sample_stride": {
        "type": "integer",
        "description": "Stride for sampling frames from the input video.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2
      },
      "image_url": {
        "type": "string",
        "description": "URL of the reference image.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/musepose/ref.png"
        ]
      },
      "decode_chunk_size": {
        "type": "integer",
        "description": "Chunk size for decoding frames.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 2
      },
      "motion_bucket_id": {
        "type": "number",
        "description": "Motion bucket ID for the pipeline.",
        "required": false,
        "minimum": 0,
        "maximum": 255,
        "default": 127
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of inference steps.",
        "required": false,
        "minimum": 1,
        "maximum": 100,
        "default": 25
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video."
      }
    }
  },
  {
    "id": "fal-ai/stable-diffusion-v3-medium",
    "title": "Stable Diffusion V3",
    "category": "text-to-image",
    "description": "Stable Diffusion 3 Medium (Text to Image) is a Multimodal Diffusion Transformer (MMDiT) model that improves image quality, typography, prompt understanding, and efficiency.",
    "tags": [
      "diffusion",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/landing/sd3-sample-03.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v3-medium",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v3-medium/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt_expansion": {
        "type": "boolean",
        "description": "If set to true, prompt will be upsampled with more details.",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Digital art, portrait of an anthropomorphic roaring Tiger warrior with full armor, close up in the middle of a battle, behind him there is a banner with the text \"Open Source\""
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate an image from.",
        "required": false,
        "default": ""
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images generated."
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sam2/image",
    "title": "Segment Anything Model 2",
    "category": "image-to-image",
    "description": "SAM 2 is a model for segmenting images and videos in real-time.",
    "tags": [
      "segmentation",
      "mask",
      "real-time"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sam2.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sam2/image",
    "documentationUrl": "https://fal.ai/models/fal-ai/sam2/image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "prompts": {
        "type": "array",
        "description": "List of prompts to segment the image",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "y": 375,
              "label": 1,
              "x": 500
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/PointPrompt"
        }
      },
      "box_prompts": {
        "type": "array",
        "description": "Coordinates for boxes",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "y_min": 600,
              "x_max": 700,
              "x_min": 425,
              "y_max": 875
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/BoxPrompt"
        }
      },
      "apply_mask": {
        "type": "boolean",
        "description": "Apply the mask on the image.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be segmented",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/truck.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Segmented image."
      }
    }
  },
  {
    "id": "fal-ai/sam2/video",
    "title": "Segment Anything Model 2",
    "category": "video-to-video",
    "description": "SAM 2 is a model for segmenting images and videos in real-time.",
    "tags": [
      "segmentation",
      "mask",
      "real-time"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sam2.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sam2/video",
    "documentationUrl": "https://fal.ai/models/fal-ai/sam2/video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "The URL of the video to be segmented.",
        "required": true,
        "examples": [
          "https://drive.google.com/uc?id=1iOFYbNITYwrebBBp9kaEGhBndFSRLz8k"
        ]
      },
      "prompts": {
        "type": "array",
        "description": "List of prompts to segment the video",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "y": 350,
              "label": 1,
              "frame_index": 0,
              "x": 210
            },
            {
              "y": 220,
              "label": 1,
              "frame_index": 0,
              "x": 250
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/PointPrompt"
        }
      },
      "box_prompts": {
        "type": "array",
        "description": "Coordinates for boxes",
        "required": false,
        "default": [],
        "examples": [
          [
            {
              "y_min": 0,
              "frame_index": 0,
              "x_max": 500,
              "x_min": 300,
              "y_max": 400
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/BoxPrompt"
        }
      },
      "apply_mask": {
        "type": "boolean",
        "description": "Apply the mask on the video.",
        "required": false,
        "default": false
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to be applied initially.",
        "required": false
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The segmented video."
      }
    }
  },
  {
    "id": "fal-ai/flux-general/image-to-image",
    "title": "FLUX.1 [dev] with Controlnets and Loras",
    "category": "image-to-image",
    "description": "FLUX General Image-to-Image is a versatile endpoint that transforms existing images with support for LoRA, ControlNet, and IP-Adapter extensions, enabling precise control over style transfer, modifications, and artistic variations through multiple guidance methods.",
    "tags": [
      "lora",
      "controlnet",
      "ip-adapter"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/flux-lora/flux_general.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-general/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-general/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "nag_end": {
        "type": "number",
        "description": "\n            The proportion of steps to apply NAG. After the specified proportion\n            of steps has been iterated, the remaining steps will use original\n            attention processors in FLUX.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "control_loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/ControlLoraWeight"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler for the denoising process.",
        "required": false,
        "enum": [
          "euler",
          "dpmpp_2m"
        ],
        "default": "euler"
      },
      "easycontrols": {
        "type": "array",
        "description": "\n        EasyControl Inputs to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/EasyControlWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "real_cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 3.5
      },
      "use_cfg_zero": {
        "type": "boolean",
        "description": "\n            Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.\n        ",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "fill_image": {
        "type": null,
        "description": "Use an image input to influence the generation. Can be used to fill images in masked areas.",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "sigma_schedule": {
        "type": "string",
        "description": "Sigmas schedule for the denoising process.",
        "required": false,
        "enum": [
          "sgm_uniform"
        ]
      },
      "reference_end": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to be ended.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "reference_strength": {
        "type": "number",
        "description": "Strength of reference_only generation. Only used if a reference image is provided.",
        "required": false,
        "minimum": -3,
        "maximum": 3,
        "default": 0.65
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "nag_scale": {
        "type": "number",
        "description": "\n            The scale for NAG. Higher values will result in a image that is more distant\n            to the negative prompt.\n        ",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "reference_image_url": {
        "type": "string",
        "description": "URL of Image for Reference-Only",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "controlnet_unions": {
        "type": "array",
        "description": "\n            The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNetUnion"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            Negative prompt to steer the image generation away from unwanted features.\n            By default, we will be using NAG for processing the negative prompt.\n        ",
        "required": false,
        "default": ""
      },
      "nag_tau": {
        "type": "number",
        "description": "\n            The tau for NAG. Controls the normalization of the hidden state.\n            Higher values will result in a less aggressive normalization,\n            but may also lead to unexpected changes with respect to the original image.\n            Not recommended to change this value.\n        ",
        "required": false,
        "default": 2.5
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      },
      "use_beta_schedule": {
        "type": "boolean",
        "description": "Specifies whether beta sigmas ought to be used.",
        "required": false,
        "default": false
      },
      "nag_alpha": {
        "type": "number",
        "description": "\n            The alpha value for NAG. This value is used as a final weighting\n            factor for steering the normalized guidance (positive and negative prompts)\n            in the direction of the positive prompt. Higher values will result in less\n            steering on the normalized guidance where lower values will result in\n            considering the positive prompt guidance more.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "base_shift": {
        "type": "number",
        "description": "Base shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 0.5
      },
      "ip_adapters": {
        "type": "array",
        "description": "\n        IP-Adapter to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "use_real_cfg": {
        "type": "boolean",
        "description": "\n            Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.\n            If using XLabs IP-Adapter v1, this will be turned on!.\n        ",
        "required": false,
        "default": false
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The controlnets to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "reference_start": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to bestarted.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "max_shift": {
        "type": "number",
        "description": "Max shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 1.15
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-general/inpainting",
    "title": "FLUX.1 [dev] with Controlnets and Loras",
    "category": "image-to-image",
    "description": "FLUX General Inpainting is a versatile endpoint that enables precise image editing and completion, supporting multiple AI extensions including LoRA, ControlNet, and IP-Adapter for enhanced control over inpainting results and sophisticated image modifications.",
    "tags": [
      "lora",
      "controlnet",
      "ip-adapter"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/flux-lora/flux_general.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-general/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-general/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "nag_end": {
        "type": "number",
        "description": "\n            The proportion of steps to apply NAG. After the specified proportion\n            of steps has been iterated, the remaining steps will use original\n            attention processors in FLUX.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "control_loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/ControlLoraWeight"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler for the denoising process.",
        "required": false,
        "enum": [
          "euler",
          "dpmpp_2m"
        ],
        "default": "euler"
      },
      "easycontrols": {
        "type": "array",
        "description": "\n        EasyControl Inputs to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/EasyControlWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "real_cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 3.5
      },
      "use_cfg_zero": {
        "type": "boolean",
        "description": "\n            Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.\n        ",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "fill_image": {
        "type": null,
        "description": "Use an image input to influence the generation. Can be used to fill images in masked areas.",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "sigma_schedule": {
        "type": "string",
        "description": "Sigmas schedule for the denoising process.",
        "required": false,
        "enum": [
          "sgm_uniform"
        ]
      },
      "reference_end": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to be ended.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "reference_strength": {
        "type": "number",
        "description": "Strength of reference_only generation. Only used if a reference image is provided.",
        "required": false,
        "minimum": -3,
        "maximum": 3,
        "default": 0.65
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "\n            The mask to area to Inpaint in.\n        ",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "nag_scale": {
        "type": "number",
        "description": "\n            The scale for NAG. Higher values will result in a image that is more distant\n            to the negative prompt.\n        ",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "reference_image_url": {
        "type": "string",
        "description": "URL of Image for Reference-Only",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "controlnet_unions": {
        "type": "array",
        "description": "\n            The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNetUnion"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            Negative prompt to steer the image generation away from unwanted features.\n            By default, we will be using NAG for processing the negative prompt.\n        ",
        "required": false,
        "default": ""
      },
      "nag_tau": {
        "type": "number",
        "description": "\n            The tau for NAG. Controls the normalization of the hidden state.\n            Higher values will result in a less aggressive normalization,\n            but may also lead to unexpected changes with respect to the original image.\n            Not recommended to change this value.\n        ",
        "required": false,
        "default": 2.5
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      },
      "use_real_cfg": {
        "type": "boolean",
        "description": "\n            Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.\n            If using XLabs IP-Adapter v1, this will be turned on!.\n        ",
        "required": false,
        "default": false
      },
      "nag_alpha": {
        "type": "number",
        "description": "\n            The alpha value for NAG. This value is used as a final weighting\n            factor for steering the normalized guidance (positive and negative prompts)\n            in the direction of the positive prompt. Higher values will result in less\n            steering on the normalized guidance where lower values will result in\n            considering the positive prompt guidance more.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "base_shift": {
        "type": "number",
        "description": "Base shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 0.5
      },
      "use_beta_schedule": {
        "type": "boolean",
        "description": "Specifies whether beta sigmas ought to be used.",
        "required": false,
        "default": false
      },
      "ip_adapters": {
        "type": "array",
        "description": "\n        IP-Adapter to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "max_shift": {
        "type": "number",
        "description": "Max shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 1.15
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "reference_start": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to bestarted.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The controlnets to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-general/differential-diffusion",
    "title": "FLUX.1 [dev] with Controlnets and Loras",
    "category": "image-to-image",
    "description": "A specialized FLUX endpoint combining differential diffusion control with LoRA, ControlNet, and IP-Adapter support, enabling precise, region-specific image transformations through customizable change maps.",
    "tags": [
      "lora",
      "controlnet",
      "ip-adapter"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/flux-lora/flux_general.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-general/differential-diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-general/differential-diffusion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Tree of life under the sea, ethereal, glittering, lens flares, cinematic lighting, artwork by Anna Dittmann & Carne Griffiths, 8k, unreal engine 5, hightly detailed, intricate detailed."
        ]
      },
      "nag_end": {
        "type": "number",
        "description": "\n            The proportion of steps to apply NAG. After the specified proportion\n            of steps has been iterated, the remaining steps will use original\n            attention processors in FLUX.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "control_loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/ControlLoraWeight"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler for the denoising process.",
        "required": false,
        "enum": [
          "euler",
          "dpmpp_2m"
        ],
        "default": "euler"
      },
      "easycontrols": {
        "type": "array",
        "description": "\n        EasyControl Inputs to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/EasyControlWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "real_cfg_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 3.5
      },
      "use_cfg_zero": {
        "type": "boolean",
        "description": "\n            Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.\n        ",
        "required": false,
        "default": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "fill_image": {
        "type": null,
        "description": "Use an image input to influence the generation. Can be used to fill images in masked areas.",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "sigma_schedule": {
        "type": "string",
        "description": "Sigmas schedule for the denoising process.",
        "required": false,
        "enum": [
          "sgm_uniform"
        ]
      },
      "reference_end": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to be ended.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "reference_strength": {
        "type": "number",
        "description": "Strength of reference_only generation. Only used if a reference image is provided.",
        "required": false,
        "minimum": -3,
        "maximum": 3,
        "default": 0.65
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use as initial image.",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/h6a7KK2Ie_inuGbdartoX.jpeg"
        ]
      },
      "nag_scale": {
        "type": "number",
        "description": "\n            The scale for NAG. Higher values will result in a image that is more distant\n            to the negative prompt.\n        ",
        "required": false,
        "maximum": 10,
        "default": 3
      },
      "reference_image_url": {
        "type": "string",
        "description": "URL of Image for Reference-Only",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "controlnet_unions": {
        "type": "array",
        "description": "\n            The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNetUnion"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            Negative prompt to steer the image generation away from unwanted features.\n            By default, we will be using NAG for processing the negative prompt.\n        ",
        "required": false,
        "default": ""
      },
      "change_map_image_url": {
        "type": "string",
        "description": "URL of change map.",
        "required": true,
        "examples": [
          "https://fal.media/files/zebra/Wh4IYAiAAcVbuZ8M9ZMSn.jpeg"
        ]
      },
      "nag_tau": {
        "type": "number",
        "description": "\n            The tau for NAG. Controls the normalization of the hidden state.\n            Higher values will result in a less aggressive normalization,\n            but may also lead to unexpected changes with respect to the original image.\n            Not recommended to change this value.\n        ",
        "required": false,
        "default": 2.5
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 1
      },
      "use_beta_schedule": {
        "type": "boolean",
        "description": "Specifies whether beta sigmas ought to be used.",
        "required": false,
        "default": false
      },
      "nag_alpha": {
        "type": "number",
        "description": "\n            The alpha value for NAG. This value is used as a final weighting\n            factor for steering the normalized guidance (positive and negative prompts)\n            in the direction of the positive prompt. Higher values will result in less\n            steering on the normalized guidance where lower values will result in\n            considering the positive prompt guidance more.\n        ",
        "required": false,
        "maximum": 1,
        "default": 0.25
      },
      "base_shift": {
        "type": "number",
        "description": "Base shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 0.5
      },
      "ip_adapters": {
        "type": "array",
        "description": "\n        IP-Adapter to use for image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "use_real_cfg": {
        "type": "boolean",
        "description": "\n            Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.\n            If using XLabs IP-Adapter v1, this will be turned on!.\n        ",
        "required": false,
        "default": false
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The controlnets to use for the image generation. Only one controlnet is supported at the moment.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "reference_start": {
        "type": "number",
        "description": "\n            The percentage of the total timesteps when the reference guidance is to bestarted.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "max_shift": {
        "type": "number",
        "description": "Max shift for the scheduled timesteps",
        "required": false,
        "minimum": 0.01,
        "maximum": 5,
        "default": 1.15
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for differential diffusion. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/flux-lora/image-to-image",
    "title": "FLUX.1 [dev] with LoRAs",
    "category": "image-to-image",
    "description": "FLUX LoRA Image-to-Image is a high-performance endpoint that transforms existing images using FLUX models, leveraging LoRA adaptations to enable rapid and precise image style transfer, modifications, and artistic variations.",
    "tags": [
      "lora",
      "style transfer"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/h2glDvCl5RvtgjNx_-5qY.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "A photo of a lion sitting on a stone bench"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate. This is always set to 1 for streaming output.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for inpainting. or img2img",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "examples": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "strength": {
        "type": "number",
        "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.85
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 35,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fooocus/upscale-or-vary",
    "title": "Fooocus Upscale or Vary",
    "category": "text-to-image",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "tags": [
      "upscaling",
      "vary",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fooocus/upscale-or-vary",
    "documentationUrl": "https://fal.ai/models/fal-ai/fooocus/upscale-or-vary/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "styles": {
        "type": "array",
        "description": "\n            The style to use.\n        ",
        "required": false,
        "default": [
          "Fooocus Enhance",
          "Fooocus V2",
          "Fooocus Sharp"
        ],
        "items": {
          "enum": [
            "Fooocus V2",
            "Fooocus Enhance",
            "Fooocus Sharp",
            "Fooocus Semi Realistic",
            "Fooocus Masterpiece",
            "Fooocus Photograph",
            "Fooocus Negative",
            "Fooocus Cinematic",
            "SAI 3D Model",
            "SAI Analog Film",
            "SAI Anime",
            "SAI Cinematic",
            "SAI Comic Book",
            "SAI Craft Clay",
            "SAI Digital Art",
            "SAI Enhance",
            "SAI Fantasy Art",
            "SAI Isometric",
            "SAI Line Art",
            "SAI Lowpoly",
            "SAI Neonpunk",
            "SAI Origami",
            "SAI Photographic",
            "SAI Pixel Art",
            "SAI Texture",
            "MRE Cinematic Dynamic",
            "MRE Spontaneous Picture",
            "MRE Artistic Vision",
            "MRE Dark Dream",
            "MRE Gloomy Art",
            "MRE Bad Dream",
            "MRE Underground",
            "MRE Surreal Painting",
            "MRE Dynamic Illustration",
            "MRE Undead Art",
            "MRE Elemental Art",
            "MRE Space Art",
            "MRE Ancient Illustration",
            "MRE Brave Art",
            "MRE Heroic Fantasy",
            "MRE Dark Cyberpunk",
            "MRE Lyrical Geometry",
            "MRE Sumi E Symbolic",
            "MRE Sumi E Detailed",
            "MRE Manga",
            "MRE Anime",
            "MRE Comic",
            "Ads Advertising",
            "Ads Automotive",
            "Ads Corporate",
            "Ads Fashion Editorial",
            "Ads Food Photography",
            "Ads Gourmet Food Photography",
            "Ads Luxury",
            "Ads Real Estate",
            "Ads Retail",
            "Artstyle Abstract",
            "Artstyle Abstract Expressionism",
            "Artstyle Art Deco",
            "Artstyle Art Nouveau",
            "Artstyle Constructivist",
            "Artstyle Cubist",
            "Artstyle Expressionist",
            "Artstyle Graffiti",
            "Artstyle Hyperrealism",
            "Artstyle Impressionist",
            "Artstyle Pointillism",
            "Artstyle Pop Art",
            "Artstyle Psychedelic",
            "Artstyle Renaissance",
            "Artstyle Steampunk",
            "Artstyle Surrealist",
            "Artstyle Typography",
            "Artstyle Watercolor",
            "Futuristic Biomechanical",
            "Futuristic Biomechanical Cyberpunk",
            "Futuristic Cybernetic",
            "Futuristic Cybernetic Robot",
            "Futuristic Cyberpunk Cityscape",
            "Futuristic Futuristic",
            "Futuristic Retro Cyberpunk",
            "Futuristic Retro Futurism",
            "Futuristic Sci Fi",
            "Futuristic Vaporwave",
            "Game Bubble Bobble",
            "Game Cyberpunk Game",
            "Game Fighting Game",
            "Game Gta",
            "Game Mario",
            "Game Minecraft",
            "Game Pokemon",
            "Game Retro Arcade",
            "Game Retro Game",
            "Game Rpg Fantasy Game",
            "Game Strategy Game",
            "Game Streetfighter",
            "Game Zelda",
            "Misc Architectural",
            "Misc Disco",
            "Misc Dreamscape",
            "Misc Dystopian",
            "Misc Fairy Tale",
            "Misc Gothic",
            "Misc Grunge",
            "Misc Horror",
            "Misc Kawaii",
            "Misc Lovecraftian",
            "Misc Macabre",
            "Misc Manga",
            "Misc Metropolis",
            "Misc Minimalist",
            "Misc Monochrome",
            "Misc Nautical",
            "Misc Space",
            "Misc Stained Glass",
            "Misc Techwear Fashion",
            "Misc Tribal",
            "Misc Zentangle",
            "Papercraft Collage",
            "Papercraft Flat Papercut",
            "Papercraft Kirigami",
            "Papercraft Paper Mache",
            "Papercraft Paper Quilling",
            "Papercraft Papercut Collage",
            "Papercraft Papercut Shadow Box",
            "Papercraft Stacked Papercut",
            "Papercraft Thick Layered Papercut",
            "Photo Alien",
            "Photo Film Noir",
            "Photo Glamour",
            "Photo Hdr",
            "Photo Iphone Photographic",
            "Photo Long Exposure",
            "Photo Neon Noir",
            "Photo Silhouette",
            "Photo Tilt Shift",
            "Cinematic Diva",
            "Abstract Expressionism",
            "Academia",
            "Action Figure",
            "Adorable 3D Character",
            "Adorable Kawaii",
            "Art Deco",
            "Art Nouveau",
            "Astral Aura",
            "Avant Garde",
            "Baroque",
            "Bauhaus Style Poster",
            "Blueprint Schematic Drawing",
            "Caricature",
            "Cel Shaded Art",
            "Character Design Sheet",
            "Classicism Art",
            "Color Field Painting",
            "Colored Pencil Art",
            "Conceptual Art",
            "Constructivism",
            "Cubism",
            "Dadaism",
            "Dark Fantasy",
            "Dark Moody Atmosphere",
            "Dmt Art Style",
            "Doodle Art",
            "Double Exposure",
            "Dripping Paint Splatter Art",
            "Expressionism",
            "Faded Polaroid Photo",
            "Fauvism",
            "Flat 2d Art",
            "Fortnite Art Style",
            "Futurism",
            "Glitchcore",
            "Glo Fi",
            "Googie Art Style",
            "Graffiti Art",
            "Harlem Renaissance Art",
            "High Fashion",
            "Idyllic",
            "Impressionism",
            "Infographic Drawing",
            "Ink Dripping Drawing",
            "Japanese Ink Drawing",
            "Knolling Photography",
            "Light Cheery Atmosphere",
            "Logo Design",
            "Luxurious Elegance",
            "Macro Photography",
            "Mandola Art",
            "Marker Drawing",
            "Medievalism",
            "Minimalism",
            "Neo Baroque",
            "Neo Byzantine",
            "Neo Futurism",
            "Neo Impressionism",
            "Neo Rococo",
            "Neoclassicism",
            "Op Art",
            "Ornate And Intricate",
            "Pencil Sketch Drawing",
            "Pop Art 2",
            "Rococo",
            "Silhouette Art",
            "Simple Vector Art",
            "Sketchup",
            "Steampunk 2",
            "Surrealism",
            "Suprematism",
            "Terragen",
            "Tranquil Relaxing Atmosphere",
            "Sticker Designs",
            "Vibrant Rim Light",
            "Volumetric Lighting",
            "Watercolor 2",
            "Whimsical And Playful",
            "Mk Chromolithography",
            "Mk Cross Processing Print",
            "Mk Dufaycolor Photograph",
            "Mk Herbarium",
            "Mk Punk Collage",
            "Mk Mosaic",
            "Mk Van Gogh",
            "Mk Coloring Book",
            "Mk Singer Sargent",
            "Mk Pollock",
            "Mk Basquiat",
            "Mk Andy Warhol",
            "Mk Halftone Print",
            "Mk Gond Painting",
            "Mk Albumen Print",
            "Mk Aquatint Print",
            "Mk Anthotype Print",
            "Mk Inuit Carving",
            "Mk Bromoil Print",
            "Mk Calotype Print",
            "Mk Color Sketchnote",
            "Mk Cibulak Porcelain",
            "Mk Alcohol Ink Art",
            "Mk One Line Art",
            "Mk Blacklight Paint",
            "Mk Carnival Glass",
            "Mk Cyanotype Print",
            "Mk Cross Stitching",
            "Mk Encaustic Paint",
            "Mk Embroidery",
            "Mk Gyotaku",
            "Mk Luminogram",
            "Mk Lite Brite Art",
            "Mk Mokume Gane",
            "Pebble Art",
            "Mk Palekh",
            "Mk Suminagashi",
            "Mk Scrimshaw",
            "Mk Shibori",
            "Mk Vitreous Enamel",
            "Mk Ukiyo E",
            "Mk Vintage Airline Poster",
            "Mk Vintage Travel Poster",
            "Mk Bauhaus Style",
            "Mk Afrofuturism",
            "Mk Atompunk",
            "Mk Constructivism",
            "Mk Chicano Art",
            "Mk De Stijl",
            "Mk Dayak Art",
            "Mk Fayum Portrait",
            "Mk Illuminated Manuscript",
            "Mk Kalighat Painting",
            "Mk Madhubani Painting",
            "Mk Pictorialism",
            "Mk Pichwai Painting",
            "Mk Patachitra Painting",
            "Mk Samoan Art Inspired",
            "Mk Tlingit Art",
            "Mk Adnate Style",
            "Mk Ron English Style",
            "Mk Shepard Fairey Style"
          ],
          "type": "string"
        }
      },
      "uov_image_url": {
        "type": "string",
        "description": "The image to upscale or vary.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/fooocus/fruit_basket.jpeg"
        ]
      },
      "performance": {
        "type": "string",
        "description": "\n            You can choose Speed or Quality\n        ",
        "required": false,
        "enum": [
          "Speed",
          "Quality",
          "Extreme Speed",
          "Lightning"
        ],
        "default": "Extreme Speed"
      },
      "mixing_image_prompt_and_vary_upscale": {
        "type": "boolean",
        "description": "Mixing Image Prompt and Vary/Upscale",
        "required": false,
        "default": false
      },
      "image_prompt_3": {
        "type": null,
        "description": "",
        "required": false
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "",
        "examples": [
          "a basket of various fruits, bokeh, realistic, masterpiece"
        ]
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [
          {
            "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
            "scale": 0.1
          }
        ],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "image_prompt_4": {
        "type": null,
        "description": "",
        "required": false
      },
      "image_prompt_1": {
        "type": null,
        "description": "",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "sharpness": {
        "type": "number",
        "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 30,
        "default": 2
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 4
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "1024x1024"
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "jpeg"
      },
      "refiner_model": {
        "type": "string",
        "description": "Refiner (SDXL or SD 1.5)",
        "required": false,
        "enum": [
          "None",
          "realisticVisionV60B1_v51VAE.safetensors"
        ],
        "default": "None"
      },
      "image_prompt_2": {
        "type": null,
        "description": "",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "uov_method": {
        "type": "string",
        "description": "The method to use for upscaling or varying.",
        "required": false,
        "enum": [
          "Disabled",
          "Vary (Subtle)",
          "Vary (Strong)",
          "Upscale (1.5x)",
          "Upscale (2x)",
          "Upscale (Fast 2x)"
        ],
        "default": "Vary (Strong)"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          176400
        ]
      },
      "refiner_switch": {
        "type": "number",
        "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image file info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "The time taken for the generation process."
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/flux-subject",
    "title": "FLUX.1 Subject",
    "category": "text-to-image",
    "description": "Super fast endpoint for the FLUX.1 [schnell] model with subject input capabilities, enabling rapid and high-quality image generation for personalization, specific styles, brand identities, and product-specific outputs.",
    "tags": [
      "personalization",
      "customization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/flux-subject.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/flux-subject",
    "documentationUrl": "https://fal.ai/models/fal-ai/flux-subject/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "On the beach, a lady sits under a beach umbrella with 'Omini' written on it. She's wearing this shirt and has a big smile on her face, with her surfboard hehind her. The sun is setting in the background. The sky is a beautiful shade of orange and purple."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "URL of image of the subject",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/ominicontrol/ominishirt.jpg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sana",
    "title": "Sana",
    "category": "text-to-image",
    "description": "Sana can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed, with the ability to generate 4K images in less than a second.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sana.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sana",
    "documentationUrl": "https://fal.ai/models/fal-ai/sana/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 2160,
          "width": 3840
        }
      },
      "style_name": {
        "type": "string",
        "description": "The style to generate the image in.",
        "required": false,
        "enum": [
          "(No style)",
          "Cinematic",
          "Photographic",
          "Anime",
          "Manga",
          "Digital Art",
          "Pixel art",
          "Fantasy art",
          "Neonpunk",
          "3D Model"
        ],
        "default": "(No style)"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 18
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/pixart-sigma",
    "title": "PixArt-Σ",
    "category": "text-to-image",
    "description": "Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation",
    "tags": [
      "diffusion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/pixart-sigma.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pixart-sigma",
    "documentationUrl": "https://fal.ai/models/fal-ai/pixart-sigma/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee.",
          "an astronaut sitting in a diner, eating fries, cinematic, analog film",
          "Pirate ship trapped in a cosmic maelstrom nebula, rendered in cosmic beach whirlpool engine, volumetric lighting, spectacular, ambient lights, light pollution, cinematic atmosphere, art nouveau style, illustration art artwork by SenseiJaye, intricate detail.",
          "stars, water, brilliantly, gorgeous large scale scene, a little girl, in the style of dreamy realism, light gold and amber, blue and pink, brilliantly illuminated in the background.",
          "professional portrait photo of an anthropomorphic cat wearing fancy gentleman hat and jacket walking in autumn forest.",
          "beautiful lady, freckles, big smile, blue eyes, short ginger hair, dark makeup, wearing a floral blue vest top, soft light, dark grey background",
          "Spectacular Tiny World in the Transparent Jar On the Table, interior of the Great Hall, Elaborate, Carved Architecture, Anatomy, Symmetrical, Geometric and Parameteric Details, Precision Flat line Details, Pattern, Dark fantasy, Dark errie mood and ineffably mysterious mood, Technical design, Intricate Ultra Detail, Ornate Detail, Stylized and Futuristic and Biomorphic Details, Architectural Concept, Low contrast Details, Cinematic Lighting, 8k, by moebius, Fullshot, Epic, Fullshot, Octane render, Unreal ,Photorealistic, Hyperrealism",
          "anthropomorphic profile of the white snow owl Crystal priestess , art deco painting, pretty and expressive eyes, ornate costume, mythical, ethereal, intricate, elaborate, hyperrealism, hyper detailed, 3D, 8K, Ultra Realistic, high octane, ultra resolution, amazing detail, perfection, In frame, photorealistic, cinematic lighting, visual clarity, shading , Lumen Reflections, Super-Resolution, gigapixel, color grading, retouch, enhanced, PBR, Blender, V-ray, Procreate, zBrush, Unreal Engine 5, cinematic, volumetric, dramatic, neon lighting, wide angle lens ,no digital painting blur",
          "The parametric hotel lobby is a sleek and modern space with plenty of natural light. The lobby is spacious and open with a variety of seating options. The front desk is a sleek white counter with a parametric design. The walls are a light blue color with parametric patterns. The floor is a light wood color with a parametric design. There are plenty of plants and flowers throughout the space. The overall effect is a calm and relaxing space. occlusion, moody, sunset, concept art, octane rendering, 8k, highly detailed, concept art, highly detailed, beautiful scenery, cinematic, beautiful light, hyperreal, octane render, hdr, long exposure, 8K, realistic, fog, moody, fire and explosions, smoke, 50mm f2.8"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "style": {
        "type": "string",
        "description": "The style to apply to the image.",
        "required": false,
        "enum": [
          "(No style)",
          "Cinematic",
          "Photographic",
          "Anime",
          "Manga",
          "Digital Art",
          "Pixel art",
          "Fantasy art",
          "Neonpunk",
          "3D Model"
        ],
        "default": "(No style)"
      },
      "scheduler": {
        "type": "string",
        "description": "The scheduler to use for the model.",
        "required": false,
        "enum": [
          "DPM-SOLVER",
          "SA-SOLVER"
        ],
        "default": "DPM-SOLVER"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 5,
        "maximum": 50,
        "default": 35
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "The timings of the different steps of the generation process."
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sdxl-controlnet-union",
    "title": "SDXL ControlNet Union",
    "category": "text-to-image",
    "description": "An efficent SDXL multi-controlnet text-to-image model.",
    "tags": [
      "diffusion",
      "controlnet",
      "composition"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/controlnet-union/000004_openpose_scribble_concat.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sdxl-controlnet-union",
    "documentationUrl": "https://fal.ai/models/fal-ai/sdxl-controlnet-union/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "depth_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the depth image.",
        "required": false,
        "default": true
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false,
        "examples": [
          null
        ]
      },
      "normal_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "teed_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "canny_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "segmentation_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the segmentation image.",
        "required": false,
        "default": true
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "segmentation_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "openpose_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "canny_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the canny image.",
        "required": false,
        "default": true
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "depth_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "normal_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the normal image.",
        "required": false,
        "default": true
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "teed_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the teed image.",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "openpose_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the openpose image.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 70,
        "default": 35
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sdxl-controlnet-union/inpainting",
    "title": "SDXL ControlNet Union",
    "category": "image-to-image",
    "description": "An efficent SDXL multi-controlnet inpainting model.",
    "tags": [
      "diffusion",
      "controlnet",
      "composition"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/controlnet-union/000004_openpose_scribble_concat.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sdxl-controlnet-union/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/sdxl-controlnet-union/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "depth_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the depth image.",
        "required": false,
        "default": true
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false,
        "examples": [
          null
        ]
      },
      "normal_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "teed_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "canny_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "segmentation_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the segmentation image.",
        "required": false,
        "default": true
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "segmentation_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "openpose_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "canny_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the canny image.",
        "required": false,
        "default": true
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "depth_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "normal_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the normal image.",
        "required": false,
        "default": true
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "teed_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the teed image.",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "openpose_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the openpose image.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 70,
        "default": 35
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sdxl-controlnet-union/image-to-image",
    "title": "SDXL ControlNet Union",
    "category": "image-to-image",
    "description": "An efficent SDXL multi-controlnet image-to-image model.",
    "tags": [
      "diffusion",
      "controlnet",
      "composition"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/controlnet-union/000004_openpose_scribble_concat.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sdxl-controlnet-union/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/sdxl-controlnet-union/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "depth_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the depth image.",
        "required": false,
        "default": true
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false,
        "examples": [
          null
        ]
      },
      "normal_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "teed_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "canny_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "segmentation_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the segmentation image.",
        "required": false,
        "default": true
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "segmentation_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "openpose_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "canny_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the canny image.",
        "required": false,
        "default": true
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "depth_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": false,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "normal_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the normal image.",
        "required": false,
        "default": true
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "teed_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the teed image.",
        "required": false,
        "default": true
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "openpose_preprocess": {
        "type": "boolean",
        "description": "Whether to preprocess the openpose image.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 70,
        "default": 35
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/kolors",
    "title": "Kolors",
    "category": "text-to-image",
    "description": "Photorealistic Text-to-Image",
    "tags": [
      "realism",
      "diffusion"
    ],
    "thumbnailUrl": "https://v2.fal.media/files/bdcf6a7a3f4146c39555e0c195715e65_73e054513f15488f93248ae10d67ece5.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/kolors",
    "documentationUrl": "https://fal.ai/models/fal-ai/kolors/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "\n            The prompt to use for generating the image. Be as descriptive as possible\n            for best results.\n        ",
        "required": true,
        "examples": [
          "A young Chinese couple with fair skin, dressed in stylish sportswear, with the modern Beijing city skyline in the background. Facial details, clear pores, captured using the latest camera model, close-up shot, ultra-high quality, 8K, visual feast.",
          "The image features four mythical beasts: Vermilion Bird, Black Tortoise, Azure Dragon, and White Tiger. The Vermilion Bird is at the top of the image, with feathers as red as fire and a tail as magnificent as a phoenix, its wings spreading like burning flames. The Black Tortoise is at the bottom, depicted as a giant turtle intertwined with a snake. Ancient runes adorn the turtle's shell, and the snake's eyes are cold and sharp. The Azure Dragon is on the right, its long body coiling in the sky, with jade-green scales, flowing whiskers, deer-like horns, and exhaling clouds and mist. The White Tiger is on the left, with a majestic posture, white fur with black stripes, piercing eyes, sharp teeth and claws, surrounded by vast mountains and grasslands."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and\n            uploaded before returning the response. This will increase the latency of\n            the function but it allows you to get the image directly in the response\n            without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "scheduler": {
        "type": "string",
        "description": "The scheduler to use for the model.",
        "required": false,
        "enum": [
          "EulerDiscreteScheduler",
          "EulerAncestralDiscreteScheduler",
          "DPMSolverMultistepScheduler",
          "DPMSolverMultistepScheduler_SDE_karras",
          "UniPCMultistepScheduler",
          "DEISMultistepScheduler"
        ],
        "default": "EulerDiscreteScheduler"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show\n            you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 10,
        "default": 5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 150,
        "default": 50
      },
      "seed": {
        "type": "integer",
        "description": "Seed",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small\n            details (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "ugly, deformed, blurry"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "Enable safety checker.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/amt-interpolation/frame-interpolation",
    "title": "AMT Frame Interpolation",
    "category": "image-to-video",
    "description": "Interpolate between image frames",
    "tags": [
      "interpolation",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/amt-interpolation.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/amt-interpolation/frame-interpolation",
    "documentationUrl": "https://fal.ai/models/fal-ai/amt-interpolation/frame-interpolation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "frames": {
        "type": "array",
        "description": "Frames to interpolate",
        "required": true,
        "examples": [
          [
            {
              "url": "https://storage.googleapis.com/falserverless/model_tests/amt-interpolation/start.png"
            },
            {
              "url": "https://storage.googleapis.com/falserverless/model_tests/amt-interpolation/end.png"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/Frame"
        }
      },
      "recursive_interpolation_passes": {
        "type": "integer",
        "description": "Number of recursive interpolation passes",
        "required": false,
        "default": 4
      },
      "output_fps": {
        "type": "integer",
        "description": "Output frames per second",
        "required": false,
        "default": 24
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "Generated video"
      }
    }
  },
  {
    "id": "fal-ai/live-portrait",
    "title": "Live Portrait",
    "category": "image-to-video",
    "description": "Transfer expression from a video to a portrait.",
    "tags": [
      "expression",
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/live-portrait/XKEmk3mAzGHUjK3qqH-UL.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/live-portrait",
    "documentationUrl": "https://fal.ai/models/fal-ai/live-portrait/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "smile": {
        "type": "number",
        "description": "Amount to smile",
        "required": false,
        "minimum": -2,
        "maximum": 2,
        "default": 0
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video to drive the lip syncing.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/live-portrait/liveportrait-example.mp4"
        ]
      },
      "eyebrow": {
        "type": "number",
        "description": "Amount to raise or lower eyebrows",
        "required": false,
        "minimum": -30,
        "maximum": 30,
        "default": 0
      },
      "flag_stitching": {
        "type": "boolean",
        "description": "Whether to enable stitching. Recommended to set to True.",
        "required": false,
        "default": true
      },
      "blink": {
        "type": "number",
        "description": "Amount to blink the eyes",
        "required": false,
        "minimum": -30,
        "maximum": 30,
        "default": 0
      },
      "rotate_pitch": {
        "type": "number",
        "description": "Amount to rotate the face in pitch",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "wink": {
        "type": "number",
        "description": "Amount to wink",
        "required": false,
        "minimum": 0,
        "maximum": 25,
        "default": 0
      },
      "scale": {
        "type": "number",
        "description": "Scaling factor for the face crop.",
        "required": false,
        "default": 2.3
      },
      "eee": {
        "type": "number",
        "description": "Amount to shape mouth in 'eee' position",
        "required": false,
        "minimum": -40,
        "maximum": 40,
        "default": 0
      },
      "flag_pasteback": {
        "type": "boolean",
        "description": "Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.",
        "required": false,
        "default": true
      },
      "pupil_y": {
        "type": "number",
        "description": "Amount to move pupils vertically",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "rotate_yaw": {
        "type": "number",
        "description": "Amount to rotate the face in yaw",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be animated",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/live-portrait/XKEmk3mAzGHUjK3qqH-UL.jpeg"
        ]
      },
      "woo": {
        "type": "number",
        "description": "Amount to shape mouth in 'woo' position",
        "required": false,
        "minimum": -100,
        "maximum": 100,
        "default": 0
      },
      "aaa": {
        "type": "number",
        "description": "Amount to open mouth in 'aaa' shape",
        "required": false,
        "minimum": -200,
        "maximum": 200,
        "default": 0
      },
      "flag_do_rot": {
        "type": "boolean",
        "description": "Whether to conduct the rotation when flag_do_crop is True.",
        "required": false,
        "default": true
      },
      "flag_relative": {
        "type": "boolean",
        "description": "Whether to use relative motion.",
        "required": false,
        "default": true
      },
      "flag_eye_retargeting": {
        "type": "boolean",
        "description": "Whether to enable eye retargeting.",
        "required": false,
        "default": false
      },
      "flag_lip_zero": {
        "type": "boolean",
        "description": "Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.",
        "required": false,
        "default": true
      },
      "batch_size": {
        "type": "integer",
        "description": "Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.",
        "required": false,
        "default": 32
      },
      "rotate_roll": {
        "type": "number",
        "description": "Amount to rotate the face in roll",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "pupil_x": {
        "type": "number",
        "description": "Amount to move pupils horizontally",
        "required": false,
        "minimum": -45,
        "maximum": 45,
        "default": 0
      },
      "vy_ratio": {
        "type": "number",
        "description": "Vertical offset ratio for face crop. Positive values move up, negative values move down.",
        "required": false,
        "default": -0.125
      },
      "dsize": {
        "type": "integer",
        "description": "Size of the output image.",
        "required": false,
        "default": 512
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ",
        "required": false,
        "default": false
      },
      "vx_ratio": {
        "type": "number",
        "description": "Horizontal offset ratio for face crop.",
        "required": false,
        "default": 0
      },
      "flag_lip_retargeting": {
        "type": "boolean",
        "description": "Whether to enable lip retargeting.",
        "required": false,
        "default": false
      },
      "flag_do_crop": {
        "type": "boolean",
        "description": "Whether to crop the source portrait to the face-cropping space.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/era-3d",
    "title": "Era 3D",
    "category": "image-to-image",
    "description": "A powerful image to novel multiview model with normals.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/era3d/pignormals.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/era-3d",
    "documentationUrl": "https://fal.ai/models/fal-ai/era-3d/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "cfg": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "background_removal": {
        "type": "boolean",
        "description": "Background removal",
        "required": false,
        "default": true
      },
      "steps": {
        "type": "integer",
        "description": "Number of steps to run the model for",
        "required": false,
        "minimum": 1,
        "maximum": 200,
        "default": 40
      },
      "crop_size": {
        "type": "integer",
        "description": "Size of the image to crop to",
        "required": false,
        "minimum": 256,
        "maximum": 512,
        "default": 400
      },
      "seed": {
        "type": "integer",
        "description": "Seed for random number generation",
        "required": false,
        "default": -1
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to remove background from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/era3d/DnvGjd9CCS-ESmLgTYgOn.png"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "Images with background removed",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Seed used for random number generation"
      },
      "normal_images": {
        "type": "array",
        "description": "Normal images with background removed",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      }
    }
  },
  {
    "id": "fal-ai/stable-cascade",
    "title": "Stable Cascade",
    "category": "text-to-image",
    "description": "Stable Cascade: Image generation on a smaller & cheaper latent space.",
    "tags": [
      "diffusion",
      "lcm"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/stable-cascade.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-cascade",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-cascade/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "An image of a shiba inu, donning a spacesuit and helmet"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "second_stage_guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 0
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the image will be returned as base64 encoded string.\n        ",
        "required": false,
        "default": false
      },
      "first_stage_steps": {
        "type": "integer",
        "description": "Number of steps to run the first stage for.",
        "required": false,
        "minimum": 4,
        "maximum": 40,
        "default": 20
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Cascade\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "ugly, deformed"
        ]
      },
      "second_stage_steps": {
        "type": "integer",
        "description": "Number of steps to run the second stage for.",
        "required": false,
        "minimum": 4,
        "maximum": 24,
        "default": 10
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/referring-expression-segmentation",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision",
      "segmentation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/referring-expression-segmentation",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/referring-expression-segmentation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text_input": {
        "type": "string",
        "description": "Text input for the task",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/dense-region-caption",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/dense-region-caption",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/dense-region-caption/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/object-detection",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "detection",
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/object-detection",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/object-detection/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/open-vocabulary-detection",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision",
      "detection"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/open-vocabulary-detection",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/open-vocabulary-detection/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text_input": {
        "type": "string",
        "description": "Text input for the task",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/region-to-description",
    "title": "Florence-2 Large",
    "category": "vision",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-to-description",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-to-description/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "region": {
        "type": null,
        "description": "The user input coordinates",
        "required": true,
        "examples": [
          {
            "y2": 200,
            "x2": 200,
            "y1": 100,
            "x1": 100
          }
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "results": {
        "type": "string",
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/caption-to-phrase-grounding",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/caption-to-phrase-grounding",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/caption-to-phrase-grounding/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "text_input": {
        "type": "string",
        "description": "Text input for the task",
        "required": true
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/ocr-with-region",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "ocr",
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/ocr-with-region",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/ocr-with-region/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/ocr",
    "title": "Florence-2 Large",
    "category": "vision",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "ocr",
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/ocr",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/ocr/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "results": {
        "type": "string",
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/more-detailed-caption",
    "title": "Florence-2 Large",
    "category": "vision",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "captioning",
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/more-detailed-caption",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/more-detailed-caption/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "results": {
        "type": "string",
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/region-proposal",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-proposal",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-proposal/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/region-to-category",
    "title": "Florence-2 Large",
    "category": "vision",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-to-category",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-to-category/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "region": {
        "type": null,
        "description": "The user input coordinates",
        "required": true,
        "examples": [
          {
            "y2": 200,
            "x2": 200,
            "y1": 100,
            "x1": 100
          }
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "results": {
        "type": "string",
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/caption",
    "title": "Florence-2 Large",
    "category": "vision",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "captioning",
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/caption",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/caption/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "results": {
        "type": "string",
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/detailed-caption",
    "title": "Florence-2 Large",
    "category": "vision",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "captioning",
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/detailed-caption",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/detailed-caption/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "results": {
        "type": "string",
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/florence-2-large/region-to-segmentation",
    "title": "Florence-2 Large",
    "category": "image-to-image",
    "description": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks",
    "tags": [
      "multimodal",
      "vision",
      "segmentation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-to-segmentation",
    "documentationUrl": "https://fal.ai/models/fal-ai/florence-2-large/region-to-segmentation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "region": {
        "type": null,
        "description": "The user input coordinates",
        "required": true,
        "examples": [
          {
            "y2": 200,
            "x2": 200,
            "y1": 100,
            "x1": 100
          }
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be processed.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg",
          "http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Processed image"
      },
      "results": {
        "type": null,
        "description": "Results from the model"
      }
    }
  },
  {
    "id": "fal-ai/fast-sdxl",
    "title": "Stable Diffusion XL",
    "category": "text-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "diffusion",
      "lora",
      "embeddings",
      "high-res",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-sdxl.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-sdxl",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-sdxl/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "photo of a rhino dressed suit and tie sitting at a table in a bar with a bar stools, award winning photography, Elke vogelsang",
          "Photo of a classic red mustang car parked in las vegas strip at night"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/stable-diffusion-v3-medium/image-to-image",
    "title": "Stable Diffusion V3",
    "category": "image-to-image",
    "description": "Stable Diffusion 3 Medium (Image to Image) is a Multimodal Diffusion Transformer (MMDiT) model that improves image quality, typography, prompt understanding, and efficiency.",
    "tags": [
      "diffusion",
      "editing",
      "style"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/florence-2-large.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v3-medium/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v3-medium/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt_expansion": {
        "type": "boolean",
        "description": "If set to true, prompt will be upsampled with more details.",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Defaults to the conditioning image's size.",
        "required": false,
        "examples": [
          null
        ]
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to generate an image from.",
        "required": true,
        "examples": [
          "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "The image URL to generate an image from.",
        "required": true,
        "examples": [
          "https://fal.media/files/zebra/b52cVi3BhLDJcBrk6x0DL.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the image-to-image transformation.",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.9
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 28
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to generate an image from.",
        "required": false,
        "default": ""
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images generated."
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/stable-cascade/sote-diffusion",
    "title": "SoteDiffusion",
    "category": "text-to-image",
    "description": "Anime finetune of Würstchen V3.",
    "tags": [
      "lcm",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sotediffusion.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-cascade/sote-diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-cascade/sote-diffusion/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "newest, extremely aesthetic, best quality, 1girl, solo, pink hair, blue eyes, long hair, looking at viewer, smile, black background, holding a sign, the text on the sign says \"Hello\""
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": {
          "height": 1536,
          "width": 1024
        }
      },
      "second_stage_guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the image will be returned as base64 encoded string.\n        ",
        "required": false,
        "default": false
      },
      "first_stage_steps": {
        "type": "integer",
        "description": "Number of steps to run the first stage for.",
        "required": false,
        "minimum": 4,
        "maximum": 50,
        "default": 25
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Cascade\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "very displeasing, worst quality, monochrome, realistic, oldest"
        ]
      },
      "second_stage_steps": {
        "type": "integer",
        "description": "Number of steps to run the second stage for.",
        "required": false,
        "minimum": 4,
        "maximum": 24,
        "default": 10
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/luma-photon",
    "title": "Luma Photon",
    "category": "text-to-image",
    "description": "Generate images from your prompts using Luma Photon. Photon is the most creative, personalizable, and intelligent visual models for creatives, bringing a step-function change in the cost of high-quality image generation.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-photon",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-photon/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "A teddy bear in sunglasses playing electric guitar and dancing"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "1:1",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "1:1"
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image",
        "items": {
          "$ref": "#/components/schemas/File"
        }
      }
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/image-to-video",
    "title": "Luma Dream Machine",
    "category": "image-to-video",
    "description": "Generate video clips from your images using Luma Dream Machine v1.5",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/JtiRw34MZ1GkgxRnH52Cs.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/image-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/luma-dream-machine/image-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "minLength": 3,
        "maxLength": 5000,
        "examples": [
          "Low-angle shot of a majestic tiger prowling through a snowy landscape, leaving paw prints on the white blanket"
        ]
      },
      "aspect_ratio": {
        "type": "string",
        "description": "The aspect ratio of the generated video",
        "required": false,
        "enum": [
          "16:9",
          "9:16",
          "4:3",
          "3:4",
          "21:9",
          "9:21"
        ],
        "default": "16:9"
      },
      "loop": {
        "type": "boolean",
        "description": "Whether the video should loop (end of video is blended with the beginning)",
        "required": false,
        "default": false
      },
      "end_image_url": {
        "type": "string",
        "description": "An image to blend the end of the video with",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "https://fal.media/files/koala/1oLY4Bjp4XdGBBTSsrGlE.jpeg"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/fast-svd-lcm/text-to-video",
    "title": "Stable Video Diffusion Turbo",
    "category": "text-to-video",
    "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed",
    "tags": [
      "lcm",
      "diffusion",
      "turbo"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-svd-turbo.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-svd-lcm/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-svd-lcm/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "A rocket flying that is about to take off"
        ]
      },
      "cond_aug": {
        "type": "number",
        "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 0.02
      },
      "fps": {
        "type": "integer",
        "description": "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 10
      },
      "motion_bucket_id": {
        "type": "integer",
        "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 255,
        "default": 127
      },
      "video_size": {
        "type": null,
        "description": "The size of the generated video.",
        "required": false,
        "default": "landscape_16_9"
      },
      "steps": {
        "type": "integer",
        "description": "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        "
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/dwpose",
    "title": "DWPose Pose Prediction",
    "category": "image-to-image",
    "description": "Predict poses from images.",
    "tags": [
      "pose",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/dwpose.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dwpose",
    "documentationUrl": "https://fal.ai/models/fal-ai/dwpose/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "draw_mode": {
        "type": "string",
        "description": "Mode of drawing the pose on the image. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.",
        "required": false,
        "enum": [
          "full-pose",
          "body-pose",
          "face-pose",
          "hand-pose",
          "face-hand-mask",
          "face-mask",
          "hand-mask"
        ],
        "default": "body-pose",
        "examples": [
          "body-pose"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed",
        "required": true,
        "examples": [
          "https://github.com/badayvedat/sane-controlnet-aux/blob/main/tests/data/pose_sample.jpg?raw=true"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The predicted pose image"
      }
    }
  },
  {
    "id": "fal-ai/sd15-depth-controlnet",
    "title": "SD 1.5 Depth ControlNet",
    "category": "image-to-image",
    "description": "SD 1.5 ControlNet",
    "tags": [
      "diffusion",
      "editing",
      "manipulation",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/tree.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sd15-depth-controlnet",
    "documentationUrl": "https://fal.ai/models/fal-ai/sd15-depth-controlnet/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false,
        "examples": [
          null
        ]
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "control_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 70,
        "default": 35
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_deep_cache": {
        "type": "boolean",
        "description": "\n            If set to true, DeepCache will be enabled. TBD\n        ",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ccsr",
    "title": "CCSR Upscaler",
    "category": "image-to-image",
    "description": "SOTA Image Upscaler",
    "tags": [
      "upscaling"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ccsr.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ccsr",
    "documentationUrl": "https://fal.ai/models/fal-ai/ccsr/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "t_max": {
        "type": "number",
        "description": "The ending point of uniform sampling strategy.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.6667
      },
      "scale": {
        "type": "number",
        "description": "The scale of the output image. The higher the scale, the bigger the output image will be.",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 2
      },
      "tile_vae_decoder_size": {
        "type": "integer",
        "description": "Size of VAE patch.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 226
      },
      "t_min": {
        "type": "number",
        "description": "The starting point of uniform sampling strategy.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.3333
      },
      "tile_vae_encoder_size": {
        "type": "integer",
        "description": "Size of latent image",
        "required": false,
        "minimum": 128,
        "maximum": 2048,
        "default": 1024
      },
      "image_url": {
        "type": "string",
        "description": "The URL or data URI of the image to upscale.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/gallery/blue-bird.jpeg"
        ]
      },
      "tile_diffusion_stride": {
        "type": "integer",
        "description": "Stride of sliding patch.",
        "required": false,
        "minimum": 128,
        "maximum": 1024,
        "default": 512
      },
      "steps": {
        "type": "integer",
        "description": "The number of steps to run the model for. The higher the number the better the quality and longer it will take to generate.",
        "required": false,
        "minimum": 10,
        "maximum": 100,
        "default": 50
      },
      "tile_diffusion_size": {
        "type": "integer",
        "description": "Size of patch.",
        "required": false,
        "minimum": 256,
        "maximum": 2048,
        "default": 1024
      },
      "seed": {
        "type": "integer",
        "description": "Seed for reproducibility. Different seeds will make slightly different results.",
        "required": false
      },
      "color_fix_type": {
        "type": "string",
        "description": "Type of color correction for samples.",
        "required": false,
        "enum": [
          "none",
          "wavelet",
          "adain"
        ],
        "default": "adain",
        "examples": [
          "adain",
          "wavelet",
          "none"
        ]
      },
      "tile_vae": {
        "type": "boolean",
        "description": "If specified, a patch-based sampling strategy will be used for VAE decoding.",
        "required": false,
        "default": false
      },
      "tile_diffusion": {
        "type": "string",
        "description": "If specified, a patch-based sampling strategy will be used for sampling.",
        "required": false,
        "enum": [
          "none",
          "mix",
          "gaussian"
        ],
        "default": "none",
        "examples": [
          "none",
          "mix",
          "gaussian"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for the generation."
      }
    }
  },
  {
    "id": "fal-ai/omni-zero",
    "title": "Omni Zero",
    "category": "image-to-image",
    "description": "Any pose, any style, any identity",
    "tags": [
      "style transfer"
    ],
    "thumbnailUrl": "https://pbs.twimg.com/media/GMBtTg8W0AEg_-I?format=jpg&name=medium",
    "playgroundUrl": "https://fal.ai/models/fal-ai/omni-zero",
    "documentationUrl": "https://fal.ai/models/fal-ai/omni-zero/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to guide the image generation.",
        "required": true,
        "examples": [
          "A woman"
        ]
      },
      "identity_image_url": {
        "type": "string",
        "description": "Identity image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/omni_zero/identity.jpg"
        ]
      },
      "identity_strength": {
        "type": "number",
        "description": "Identity strength.",
        "required": false,
        "default": 1,
        "examples": [
          1
        ]
      },
      "number_of_images": {
        "type": "integer",
        "description": "Number of images.",
        "required": false,
        "default": 1,
        "examples": [
          1
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale.",
        "required": false,
        "default": 5,
        "examples": [
          5
        ]
      },
      "image_strength": {
        "type": "number",
        "description": "Image strength.",
        "required": false,
        "default": 0.75,
        "examples": [
          0.75
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to guide the image generation.",
        "required": false,
        "default": "",
        "examples": [
          ""
        ]
      },
      "composition_image_url": {
        "type": "string",
        "description": "Composition image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/omni_zero/structure.jpg"
        ]
      },
      "depth_strength": {
        "type": "number",
        "description": "Depth strength.",
        "required": false,
        "default": 0.5,
        "examples": [
          0.5
        ]
      },
      "composition_strength": {
        "type": "number",
        "description": "Composition strength.",
        "required": false,
        "default": 1,
        "examples": [
          1
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Input image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/omni_zero/structure.jpg"
        ]
      },
      "style_image_url": {
        "type": "string",
        "description": "Style image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/omni_zero/style.jpg"
        ]
      },
      "face_strength": {
        "type": "number",
        "description": "Face strength.",
        "required": false,
        "default": 1,
        "examples": [
          1
        ]
      },
      "style_strength": {
        "type": "number",
        "description": "Style strength.",
        "required": false,
        "default": 1,
        "examples": [
          1
        ]
      },
      "seed": {
        "type": "integer",
        "description": "Seed.",
        "required": false,
        "default": 42,
        "examples": [
          42
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image."
      }
    }
  },
  {
    "id": "fal-ai/lightning-models",
    "title": "Lightning Models",
    "category": "text-to-image",
    "description": "Collection of SDXL Lightning models.",
    "tags": [
      "diffusion",
      "lightning"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/lightning-models.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lightning-models",
    "documentationUrl": "https://fal.ai/models/fal-ai/lightning-models/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "A hyperdetailed photograph of a Cat dressed as a mafia boss holding a fish walking down a Japanese fish market with an angry face, 8k resolution, best quality, beautiful photograph, dynamic lighting,"
        ]
      },
      "image_size": {
        "type": null,
        "description": "",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler / sampler to use for the image denoising process.",
        "required": false,
        "enum": [
          "DPM++ 2M",
          "DPM++ 2M Karras",
          "DPM++ 2M SDE",
          "DPM++ 2M SDE Karras",
          "DPM++ SDE",
          "DPM++ SDE Karras",
          "KDPM 2A",
          "Euler",
          "Euler (trailing timesteps)",
          "Euler A",
          "LCM",
          "EDMDPMSolverMultistepScheduler",
          "TCDScheduler"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 2
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
        "required": false,
        "default": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "model_name": {
        "type": "string",
        "description": "The Lightning model to use.",
        "required": false,
        "examples": [
          "Lykon/dreamshaper-xl-lightning",
          "SG161222/RealVisXL_V4.0_Lightning"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/playground-v25",
    "title": "Playground v2.5",
    "category": "text-to-image",
    "description": "State-of-the-art open-source model in aesthetic quality",
    "tags": [
      "artistic",
      "style"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/monkey/8WXjrk5HEam79CPlQlo5T.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/playground-v25",
    "documentationUrl": "https://fal.ai/models/fal-ai/playground-v25/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Masterpiece (wide angle shot) , Easterbunny crafting an incantation, (creating a little colorful magic egg in a nest:1.6), standing on an old carved table in a colorful factory laboratory. fantastic view"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hyper-sdxl/image-to-image",
    "title": "Hyper SDXL",
    "category": "image-to-image",
    "description": "Hyper-charge SDXL's performance and creativity.",
    "tags": [
      "diffusion",
      "editing"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/LM0fy_9qT_8FlKrWhR7Zt.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hyper-sdxl/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/hyper-sdxl/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "preserve_aspect_ratio": {
        "type": "boolean",
        "description": "\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ",
        "required": false,
        "default": false
      },
      "crop_output": {
        "type": "boolean",
        "description": "\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ",
        "required": false,
        "default": false
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "string",
        "description": "The number of inference steps to perform.",
        "required": false,
        "enum": [
          "1",
          "2",
          "4"
        ],
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/realistic-vision",
    "title": "Realistic Vision",
    "category": "text-to-image",
    "description": "Generate realistic images.",
    "tags": [
      "realism",
      "diffusion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/realistic-vision.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/realistic-vision",
    "documentationUrl": "https://fal.ai/models/fal-ai/realistic-vision/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "A hyperdetailed photograph of a Cat dressed as a mafia boss holding a fish walking down a Japanese fish market with an angry face, 8k resolution, best quality, beautiful photograph, dynamic lighting,"
        ]
      },
      "image_size": {
        "type": null,
        "description": "",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
        "required": false,
        "default": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "model_name": {
        "type": "string",
        "description": "The Realistic Vision model to use.",
        "required": false,
        "examples": [
          "SG161222/Realistic_Vision_V6.0_B1_noVAE",
          "SG161222/RealVisXL_V4.0"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 70,
        "default": 35
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/dreamshaper",
    "title": "Dreamshaper",
    "category": "text-to-image",
    "description": "Dreamshaper model.",
    "tags": [
      "stylized",
      "diffusion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/dreamshaper.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/dreamshaper",
    "documentationUrl": "https://fal.ai/models/fal-ai/dreamshaper/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "A hyperdetailed photograph of a Cat dressed as a mafia boss holding a fish walking down a Japanese fish market with an angry face, 8k resolution, best quality, beautiful photograph, dynamic lighting,"
        ]
      },
      "image_size": {
        "type": null,
        "description": "",
        "required": false,
        "default": {
          "height": 1024,
          "width": 1024
        }
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
        "required": false,
        "default": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "model_name": {
        "type": "string",
        "description": "The Dreamshaper model to use.",
        "required": false,
        "enum": [
          "Lykon/dreamshaper-xl-1-0",
          "Lykon/dreamshaper-xl-v2-turbo",
          "Lykon/dreamshaper-8"
        ],
        "examples": [
          "Lykon/dreamshaper-8",
          "Lykon/dreamshaper-xl-1-0",
          "Lykon/dreamshaper-xl-v2-turbo"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 70,
        "default": 35
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/hyper-sdxl/inpainting",
    "title": "Hyper SDXL",
    "category": "image-to-image",
    "description": "Hyper-charge SDXL's performance and creativity.",
    "tags": [
      "diffusion"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/LM0fy_9qT_8FlKrWhR7Zt.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hyper-sdxl/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/hyper-sdxl/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a tiger sitting on a park bench"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "string",
        "description": "The number of inference steps to perform.",
        "required": false,
        "enum": [
          "1",
          "2",
          "4"
        ],
        "default": 1
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/ip-adapter-face-id",
    "title": "IP Adapter Face ID",
    "category": "image-to-image",
    "description": "High quality zero-shot personalization",
    "tags": [
      "ip-adapter",
      "personalization",
      "customization",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ip-adapter-face-id.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/ip-adapter-face-id",
    "documentationUrl": "https://fal.ai/models/fal-ai/ip-adapter-face-id/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Man cyberpunk, synthwave night city, futuristic, high quality, highly detailed, high resolution, sharp, hyper realistic, extremely detailed"
        ]
      },
      "face_image_url": {
        "type": "string",
        "description": "An image of a face to match. If an image with a size of 640x640 is not provided, it will be scaled and cropped to that size.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/upscale/image%20(8).png"
        ]
      },
      "width": {
        "type": "integer",
        "description": "\n            The width of the generated image.\n        ",
        "required": false,
        "minimum": 512,
        "maximum": 1024,
        "default": 512
      },
      "face_id_det_size": {
        "type": "integer",
        "description": "\n            The size of the face detection model. The higher the number the more accurate\n            the detection will be but it will also take longer to run. The higher the number the more\n            likely it will fail to find a face as well. Lower it if you are having trouble\n            finding a face in the image.\n        ",
        "required": false,
        "minimum": 64,
        "maximum": 640,
        "default": 640
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 16,
        "default": 7.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy",
        "examples": [
          "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy"
        ]
      },
      "height": {
        "type": "integer",
        "description": "\n            The height of the generated image.\n        ",
        "required": false,
        "minimum": 512,
        "maximum": 1024,
        "default": 512
      },
      "num_samples": {
        "type": "integer",
        "description": "\n            The number of samples for face id. The more samples the better the image will\n            be but it will also take longer to generate. Default is 4.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 4
      },
      "base_sdxl_model_repo": {
        "type": "string",
        "description": "The URL to the base SDXL model. Default is SG161222/RealVisXL_V3.0",
        "required": false,
        "default": "SG161222/RealVisXL_V3.0"
      },
      "base_1_5_model_repo": {
        "type": "string",
        "description": "The URL to the base 1.5 model. Default is SG161222/Realistic_Vision_V4.0_noVAE",
        "required": false,
        "default": "SG161222/Realistic_Vision_V4.0_noVAE"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 200,
        "default": 50
      },
      "model_type": {
        "type": "string",
        "description": "The model type to use. 1_5 is the default and is recommended for most use cases.",
        "required": false,
        "enum": [
          "1_5-v1",
          "1_5-v1-plus",
          "1_5-v2-plus",
          "SDXL-v1",
          "SDXL-v2-plus",
          "1_5-auraface-v1"
        ],
        "default": "1_5-v1",
        "examples": [
          "1_5-v1",
          "1_5-v1-plus",
          "1_5-v2-plus",
          "SDXL-v1",
          "SDXL-v2-plus",
          "1_5-auraface-v1"
        ]
      },
      "face_images_data_url": {
        "type": "string",
        "description": "\n            URL to zip archive with images of faces. The images embedding will be averaged to\n            create a more accurate face id.\n        ",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          42
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/lora/inpaint",
    "title": "Stable Diffusion with LoRAs",
    "category": "image-to-image",
    "description": "Run Any Stable Diffusion model with customizable LoRA weights.",
    "tags": [
      "diffusion",
      "lora",
      "customization",
      "fine-tuning"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sd-loras.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lora/inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/lora/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Photo of a european medieval 40 year old queen, silver hair, highly detailed face, detailed eyes, head shot, intricate crown, age spots, wrinkles",
          "Photo of a classic red mustang car parked in las vegas strip at night"
        ]
      },
      "noise_strength": {
        "type": "number",
        "description": "The amount of noise to add to noise image for image. Only used if the image_url is provided. 1.0 is complete noise and 0 is no noise.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "tile_height": {
        "type": "integer",
        "description": "The size of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 128,
        "maximum": 4096,
        "default": 4096
      },
      "embeddings": {
        "type": "array",
        "description": "\n            The embeddings to use for the image generation. Only a single embedding is supported at the moment.\n            The embeddings will be used to map the tokens in the prompt to the embedding weights.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "ic_light_model_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model to use for the image generation.\n        ",
        "required": false
      },
      "image_encoder_weight_name": {
        "type": "string",
        "description": "\n            The weight name of the image encoder model to use for the image generation.\n        ",
        "required": false,
        "default": "pytorch_model.bin",
        "examples": [
          "pytorch_model.bin"
        ]
      },
      "ip_adapter": {
        "type": "array",
        "description": "\n            The IP adapter to use for the image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler / sampler to use for the image denoising process.",
        "required": false,
        "enum": [
          "DPM++ 2M",
          "DPM++ 2M Karras",
          "DPM++ 2M SDE",
          "DPM++ 2M SDE Karras",
          "Euler",
          "Euler A",
          "Euler (trailing timesteps)",
          "LCM",
          "LCM (trailing timesteps)",
          "DDIM",
          "TCD"
        ]
      },
      "sigmas": {
        "type": null,
        "description": "\n            Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.\n            If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.\n        ",
        "required": false,
        "default": {
          "method": "default",
          "array": []
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "tile_stride_width": {
        "type": "integer",
        "description": "The stride of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 2048
      },
      "debug_per_pass_latents": {
        "type": "boolean",
        "description": "If set to true, the latents will be saved for debugging per pass.",
        "required": false,
        "default": false
      },
      "timesteps": {
        "type": null,
        "description": "\n            Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.\n            If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.\n        ",
        "required": false,
        "default": {
          "method": "default",
          "array": []
        }
      },
      "model_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the base model to generate the image.",
        "required": true,
        "examples": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5",
          "SG161222/Realistic_Vision_V2.0"
        ]
      },
      "prompt_weighting": {
        "type": "boolean",
        "description": "\n            If set to true, the prompt weighting syntax will be used.\n            Additionally, this will lift the 77 token limit by averaging embeddings.\n        ",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "variant": {
        "type": "string",
        "description": "The variant of the model to use for huggingface models, e.g. 'fp16'.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for image to image/inpainting.",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "URL of black-and-white image to use as mask during inpainting.",
        "required": false
      },
      "image_encoder_subfolder": {
        "type": "string",
        "description": "\n            The subfolder of the image encoder model to use for the image generation.\n        ",
        "required": false,
        "examples": []
      },
      "ic_light_model_background_image_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model background image to use for the image generation.\n            Make sure to use a background compatible with the model.\n        ",
        "required": false
      },
      "rescale_betas_snr_zero": {
        "type": "boolean",
        "description": "\n            Whether to set the rescale_betas_snr_zero option or not for the sampler\n        ",
        "required": false,
        "default": false
      },
      "tile_width": {
        "type": "integer",
        "description": "The size of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 128,
        "maximum": 4096,
        "default": 4096
      },
      "controlnet_guess_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the controlnet will be applied to only the conditional predictions.\n        ",
        "required": false,
        "default": false
      },
      "prediction_type": {
        "type": "string",
        "description": "\n            The type of prediction to use for the image generation.\n            The `epsilon` is the default.\n        ",
        "required": false,
        "enum": [
          "v_prediction",
          "epsilon"
        ],
        "default": "epsilon"
      },
      "eta": {
        "type": "number",
        "description": "The eta value to be used for the image generation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "image_encoder_path": {
        "type": "string",
        "description": "\n            The path to the image encoder model to use for the image generation.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, painting, illustration, worst quality, low quality, normal quality"
        ]
      },
      "image_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png",
        "examples": [
          "jpeg"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request. Note that the higher the batch size,\n            the longer it will take to generate the images.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "debug_latents": {
        "type": "boolean",
        "description": "If set to true, the latents will be saved for debugging.",
        "required": false,
        "default": false
      },
      "ic_light_image_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model image to use for the image generation.\n        ",
        "required": false
      },
      "unet_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the custom U-Net model to use for the image generation.",
        "required": false
      },
      "clip_skip": {
        "type": "integer",
        "description": "\n            Skips part of the image generation process, leading to slightly different results.\n            This means the image renders faster, too.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 0
      },
      "tile_stride_height": {
        "type": "integer",
        "description": "The stride of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 2048
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The control nets to use for the image generation. You can use any number of control nets\n            and they will be applied to the image at the specified timesteps.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 150,
        "default": 30
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "debug_latents": {
        "type": null,
        "description": "The latents saved for debugging."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "debug_per_pass_latents": {
        "type": null,
        "description": "The latents saved for debugging per pass."
      }
    }
  },
  {
    "id": "fal-ai/lora/image-to-image",
    "title": "Stable Diffusion with LoRAs",
    "category": "image-to-image",
    "description": "Run Any Stable Diffusion model with customizable LoRA weights.",
    "tags": [
      "diffusion",
      "lora",
      "customization",
      "fine-tuning"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sd-loras.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lora/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/lora/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Photo of a european medieval 40 year old queen, silver hair, highly detailed face, detailed eyes, head shot, intricate crown, age spots, wrinkles",
          "Photo of a classic red mustang car parked in las vegas strip at night"
        ]
      },
      "noise_strength": {
        "type": "number",
        "description": "The amount of noise to add to noise image for image. Only used if the image_url is provided. 1.0 is complete noise and 0 is no noise.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "tile_height": {
        "type": "integer",
        "description": "The size of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 128,
        "maximum": 4096,
        "default": 4096
      },
      "embeddings": {
        "type": "array",
        "description": "\n            The embeddings to use for the image generation. Only a single embedding is supported at the moment.\n            The embeddings will be used to map the tokens in the prompt to the embedding weights.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "ic_light_model_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model to use for the image generation.\n        ",
        "required": false
      },
      "image_encoder_weight_name": {
        "type": "string",
        "description": "\n            The weight name of the image encoder model to use for the image generation.\n        ",
        "required": false,
        "default": "pytorch_model.bin",
        "examples": [
          "pytorch_model.bin"
        ]
      },
      "ip_adapter": {
        "type": "array",
        "description": "\n            The IP adapter to use for the image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler / sampler to use for the image denoising process.",
        "required": false,
        "enum": [
          "DPM++ 2M",
          "DPM++ 2M Karras",
          "DPM++ 2M SDE",
          "DPM++ 2M SDE Karras",
          "Euler",
          "Euler A",
          "Euler (trailing timesteps)",
          "LCM",
          "LCM (trailing timesteps)",
          "DDIM",
          "TCD"
        ]
      },
      "sigmas": {
        "type": null,
        "description": "\n            Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.\n            If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.\n        ",
        "required": false,
        "default": {
          "method": "default",
          "array": []
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "tile_stride_width": {
        "type": "integer",
        "description": "The stride of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 2048
      },
      "debug_per_pass_latents": {
        "type": "boolean",
        "description": "If set to true, the latents will be saved for debugging per pass.",
        "required": false,
        "default": false
      },
      "timesteps": {
        "type": null,
        "description": "\n            Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.\n            If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.\n        ",
        "required": false,
        "default": {
          "method": "default",
          "array": []
        }
      },
      "model_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the base model to generate the image.",
        "required": true,
        "examples": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5",
          "SG161222/Realistic_Vision_V2.0"
        ]
      },
      "prompt_weighting": {
        "type": "boolean",
        "description": "\n            If set to true, the prompt weighting syntax will be used.\n            Additionally, this will lift the 77 token limit by averaging embeddings.\n        ",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "variant": {
        "type": "string",
        "description": "The variant of the model to use for huggingface models, e.g. 'fp16'.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "URL of image to use for image to image/inpainting.",
        "required": false
      },
      "controlnet_guess_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the controlnet will be applied to only the conditional predictions.\n        ",
        "required": false,
        "default": false
      },
      "image_encoder_subfolder": {
        "type": "string",
        "description": "\n            The subfolder of the image encoder model to use for the image generation.\n        ",
        "required": false,
        "examples": []
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "ic_light_model_background_image_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model background image to use for the image generation.\n            Make sure to use a background compatible with the model.\n        ",
        "required": false
      },
      "rescale_betas_snr_zero": {
        "type": "boolean",
        "description": "\n            Whether to set the rescale_betas_snr_zero option or not for the sampler\n        ",
        "required": false,
        "default": false
      },
      "tile_width": {
        "type": "integer",
        "description": "The size of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 128,
        "maximum": 4096,
        "default": 4096
      },
      "prediction_type": {
        "type": "string",
        "description": "\n            The type of prediction to use for the image generation.\n            The `epsilon` is the default.\n        ",
        "required": false,
        "enum": [
          "v_prediction",
          "epsilon"
        ],
        "default": "epsilon"
      },
      "eta": {
        "type": "number",
        "description": "The eta value to be used for the image generation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "image_encoder_path": {
        "type": "string",
        "description": "\n            The path to the image encoder model to use for the image generation.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, painting, illustration, worst quality, low quality, normal quality"
        ]
      },
      "image_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png",
        "examples": [
          "jpeg"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request. Note that the higher the batch size,\n            the longer it will take to generate the images.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "debug_latents": {
        "type": "boolean",
        "description": "If set to true, the latents will be saved for debugging.",
        "required": false,
        "default": false
      },
      "ic_light_image_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model image to use for the image generation.\n        ",
        "required": false
      },
      "unet_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the custom U-Net model to use for the image generation.",
        "required": false
      },
      "clip_skip": {
        "type": "integer",
        "description": "\n            Skips part of the image generation process, leading to slightly different results.\n            This means the image renders faster, too.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 0
      },
      "tile_stride_height": {
        "type": "integer",
        "description": "The stride of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 2048
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The control nets to use for the image generation. You can use any number of control nets\n            and they will be applied to the image at the specified timesteps.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 150,
        "default": 30
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "debug_latents": {
        "type": null,
        "description": "The latents saved for debugging."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "debug_per_pass_latents": {
        "type": null,
        "description": "The latents saved for debugging per pass."
      }
    }
  },
  {
    "id": "fal-ai/fast-sdxl/image-to-image",
    "title": "Stable Diffusion XL",
    "category": "image-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "diffusion",
      "high-res",
      "lora",
      "ip-adapter",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-sdxl.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-sdxl/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-sdxl/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "preserve_aspect_ratio": {
        "type": "boolean",
        "description": "\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "crop_output": {
        "type": "boolean",
        "description": "\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ",
        "required": false,
        "default": false
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 65,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-sdxl/inpainting",
    "title": "Stable Diffusion XL",
    "category": "image-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "diffusion",
      "high-res",
      "lora",
      "ip-adapter",
      "controlnet"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-sdxl.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-sdxl/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-sdxl/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a tiger sitting on a park bench"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 65,
        "default": 25
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/stable-diffusion-v15",
    "title": "Stable Diffusion v1.5",
    "category": "text-to-image",
    "description": "Stable Diffusion v1.5",
    "tags": [
      "diffusion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sd-loras.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v15",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-diffusion-v15/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "photo of a rhino dressed suit and tie sitting at a table in a bar with a bar stools, award winning photography, Elke vogelsang",
          "Photo of a classic red mustang car parked in las vegas strip at night"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/layer-diffusion",
    "title": "Layer Diffusion XL",
    "category": "text-to-image",
    "description": "SDXL with an alpha channel.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/layer_diffusion/309211077-38ace070-6530-43c9-9ca1-c98aa5b7a0ed.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/layer-diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/layer-diffusion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "",
        "examples": [
          "a male army soldier holding a gun"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale for the model.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 8
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps for the model.",
        "required": false,
        "minimum": 10,
        "maximum": 40,
        "default": 20
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "The prompt to use for generating the negative image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "text, watermark"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The URL of the generated image."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used to generate the image."
      }
    }
  },
  {
    "id": "fal-ai/musetalk",
    "title": "MuseTalk",
    "category": "image-to-video",
    "description": "MuseTalk is a real-time high quality audio-driven lip-syncing model. Use MuseTalk to animate a face with your own audio.",
    "tags": [
      "animation",
      "lip sync",
      "real-time"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/wgGNp3M_u50xIisUZ_Wm8.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/musetalk",
    "documentationUrl": "https://fal.ai/models/fal-ai/musetalk/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "source_video_url": {
        "type": "string",
        "description": "URL of the source video",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/TMElyralab/MuseTalk/main/data/video/sun.mp4"
        ]
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/TMElyralab/MuseTalk/main/data/audio/sun.wav"
        ]
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/fast-lightning-sdxl",
    "title": "Stable Diffusion XL Lightning",
    "category": "text-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "diffusion",
      "lightning",
      "real-time"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/stable-diffusion-xl-lightning.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-lightning-sdxl",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-lightning-sdxl/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "photo of a girl smiling during a sunset, with lightnings in the background"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "string",
        "description": "The number of inference steps to perform.",
        "required": false,
        "enum": [
          "1",
          "2",
          "4",
          "8"
        ],
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/sadtalker",
    "title": "Sad Talker",
    "category": "image-to-video",
    "description": "Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation",
    "tags": [
      "animation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sadtalker.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/sadtalker",
    "documentationUrl": "https://fal.ai/models/fal-ai/sadtalker/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "pose_style": {
        "type": "integer",
        "description": "The style of the pose",
        "required": false,
        "minimum": 0,
        "maximum": 45,
        "default": 0
      },
      "source_image_url": {
        "type": "string",
        "description": "URL of the source image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/sadtalker/anime_girl.png"
        ]
      },
      "driven_audio_url": {
        "type": "string",
        "description": "URL of the driven audio",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/sadtalker/deyu.wav"
        ]
      },
      "face_enhancer": {
        "type": "string",
        "description": "The type of face enhancer to use",
        "required": false,
        "enum": [
          "gfpgan"
        ],
        "examples": [
          null
        ]
      },
      "face_model_resolution": {
        "type": "string",
        "description": "The resolution of the face model",
        "required": false,
        "enum": [
          "256",
          "512"
        ],
        "default": "256"
      },
      "expression_scale": {
        "type": "number",
        "description": "The scale of the expression",
        "required": false,
        "minimum": 0,
        "maximum": 3,
        "default": 1
      },
      "still_mode": {
        "type": "boolean",
        "description": "Whether to use still mode. Fewer head motion, works with preprocess `full`.",
        "required": false,
        "default": false
      },
      "preprocess": {
        "type": "string",
        "description": "The type of preprocessing to use",
        "required": false,
        "enum": [
          "crop",
          "extcrop",
          "resize",
          "full",
          "extfull"
        ],
        "default": "crop"
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "URL of the generated video"
      }
    }
  },
  {
    "id": "fal-ai/wizper",
    "title": "Wizper (Whisper v3 -- fal.ai edition)",
    "category": "speech-to-text",
    "description": "[Experimental] Whisper v3 Large -- but optimized by our inference wizards. Same WER, double the performance!",
    "tags": [
      "transcription",
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/wizper.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/wizper",
    "documentationUrl": "https://fal.ai/models/fal-ai/wizper/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "language": {
        "type": "string",
        "description": "\n        Language of the audio file.\n        If translate is selected as the task, the audio will be translated to\n        English, regardless of the language selected.\n        ",
        "required": false,
        "enum": [
          "af",
          "am",
          "ar",
          "as",
          "az",
          "ba",
          "be",
          "bg",
          "bn",
          "bo",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fo",
          "fr",
          "gl",
          "gu",
          "ha",
          "haw",
          "he",
          "hi",
          "hr",
          "ht",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jw",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "la",
          "lb",
          "ln",
          "lo",
          "lt",
          "lv",
          "mg",
          "mi",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "mt",
          "my",
          "ne",
          "nl",
          "nn",
          "no",
          "oc",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "sn",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "tg",
          "th",
          "tk",
          "tl",
          "tr",
          "tt",
          "uk",
          "ur",
          "uz",
          "vi",
          "yi",
          "yo",
          "zh"
        ],
        "default": "en"
      },
      "chunk_level": {
        "type": "string",
        "description": "Level of the chunks to return.",
        "required": false,
        "default": "segment"
      },
      "version": {
        "type": "string",
        "description": "Version of the model to use. All of the models are the Whisper large variant.",
        "required": false,
        "default": "3"
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, wav or webm.",
        "required": true,
        "examples": [
          "https://ihlhivqvotguuqycfcvj.supabase.co/storage/v1/object/public/public-text-to-speech/scratch-testing/earth-history-19mins.mp3"
        ]
      },
      "task": {
        "type": "string",
        "description": "Task to perform on the audio file. Either transcribe or translate.",
        "required": false,
        "enum": [
          "transcribe",
          "translate"
        ],
        "default": "transcribe"
      }
    },
    "outputParameters": {
      "text": {
        "type": "string",
        "description": "Transcription of the audio file"
      },
      "chunks": {
        "type": "array",
        "description": "Timestamp chunks of the audio file",
        "items": {
          "$ref": "#/components/schemas/WhisperChunk"
        }
      }
    }
  },
  {
    "id": "fal-ai/imageutils/nsfw",
    "title": "NSFW Filter",
    "category": "vision",
    "description": "Predict the probability of an image being NSFW.",
    "tags": [
      "filter",
      "safety",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/nsfw-filter.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imageutils/nsfw",
    "documentationUrl": "https://fal.ai/models/fal-ai/imageutils/nsfw/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "Input image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/remove_background/elephant.jpg"
        ]
      }
    },
    "outputParameters": {
      "nsfw_probability": {
        "type": "number",
        "description": "The probability of the image being NSFW."
      }
    }
  },
  {
    "id": "fal-ai/moondream/batched",
    "title": "Moondream",
    "category": "vision",
    "description": "Answer questions from the images.",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/moondream.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/moondream/batched",
    "documentationUrl": "https://fal.ai/models/fal-ai/moondream/batched/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model_id": {
        "type": "string",
        "description": "Model ID to use for inference",
        "required": false,
        "enum": [
          "vikhyatk/moondream2",
          "fal-ai/moondream2-docci"
        ],
        "default": "vikhyatk/moondream2"
      },
      "repetition_penalty": {
        "type": "number",
        "description": "Repetition penalty for sampling",
        "required": false,
        "minimum": 1,
        "maximum": 2,
        "default": 1
      },
      "inputs": {
        "type": "array",
        "description": "List of input prompts and image URLs",
        "required": true,
        "examples": [
          [
            {
              "prompt": "What is the girl doing?",
              "image_url": "https://github.com/vikhyat/moondream/raw/main/assets/demo-1.jpg"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/MoondreamInputParam"
        }
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum number of new tokens to generate",
        "required": false,
        "minimum": 32,
        "maximum": 1024,
        "default": 64
      },
      "temperature": {
        "type": "number",
        "description": "Temperature for sampling",
        "required": false,
        "maximum": 1,
        "default": 0.2
      },
      "top_p": {
        "type": "number",
        "description": "Top P for sampling",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      }
    },
    "outputParameters": {
      "filenames": {
        "type": "array",
        "description": "Filenames of the images processed",
        "items": {
          "type": "string"
        }
      },
      "outputs": {
        "type": "array",
        "description": "List of generated outputs",
        "items": {
          "type": "string"
        }
      },
      "partial": {
        "type": "boolean",
        "description": "Whether the output is partial"
      },
      "timings": {
        "type": "object",
        "description": "Timings for different parts of the process"
      }
    }
  },
  {
    "id": "fal-ai/fast-fooocus-sdxl/image-to-image",
    "title": "Fooocus",
    "category": "text-to-image",
    "description": "Fooocus extreme speed mode as a standalone app.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-fooocus-sdxl/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-fooocus-sdxl/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "enable_refiner": {
        "type": "boolean",
        "description": "If set to true, a smaller model will try to refine the output after it was processed.",
        "required": false,
        "default": true
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the prompt image.",
        "required": false,
        "examples": [
          null
        ]
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": true
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 24,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/face-to-sticker",
    "title": "Face to Sticker",
    "category": "image-to-image",
    "description": "Create stickers from faces.",
    "tags": [
      "sticker",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/face-to-sticker.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/face-to-sticker",
    "documentationUrl": "https://fal.ai/models/fal-ai/face-to-sticker/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a person"
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "ip_adapter_weight": {
        "type": "number",
        "description": "The weight of the IP adapter.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.2
      },
      "image_url": {
        "type": "string",
        "description": "URL of the video.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/face_to_sticker/elon.jpg"
        ]
      },
      "upscale_steps": {
        "type": "integer",
        "description": "The number of steps to use for upscaling. Only used if `upscale` is `true`.",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 10
      },
      "instant_id_strength": {
        "type": "number",
        "description": "The strength of the instant ID.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.7
      },
      "upscale": {
        "type": "boolean",
        "description": "Whether to upscale the image 2x.",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 4.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 10,
        "maximum": 40,
        "default": 20
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": ""
      },
      "ip_adapter_noise": {
        "type": "number",
        "description": "The amount of noise to add to the IP adapter.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated images.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "sticker_image": {
        "type": null,
        "description": "The generated face sticker image."
      },
      "sticker_image_background_removed": {
        "type": null,
        "description": "The generated face sticker image with the background removed."
      },
      "seed": {
        "type": "integer",
        "description": "Seed used during the inference."
      },
      "has_nsfw_concepts": {
        "type": "object",
        "description": "\n            Whether the generated images contain NSFW concepts.\n            The key is the image type and the value is a boolean.\n        "
      }
    }
  },
  {
    "id": "fal-ai/photomaker",
    "title": "PhotoMaker",
    "category": "image-to-image",
    "description": "Customizing Realistic Human Photos via Stacked ID Embedding",
    "tags": [
      "editing",
      "customization",
      "realism",
      "personalization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/photomaker.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/photomaker",
    "documentationUrl": "https://fal.ai/models/fal-ai/photomaker/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "instagram photo, portrait photo of a man img, colorful, perfect face, natural skin, hard shadows, film grain"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request. Note that the higher the batch size,\n            the longer it will take to generate the images.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "style_strength": {
        "type": "integer",
        "description": "",
        "required": false,
        "minimum": 15,
        "maximum": 50,
        "default": 20
      },
      "style": {
        "type": "string",
        "description": "",
        "required": false,
        "enum": [
          "(No style)",
          "Cinematic",
          "Disney Character",
          "Digital Art",
          "Photographic",
          "Fantasy art",
          "Neonpunk",
          "Enhance",
          "Comic book",
          "Lowpoly",
          "Line art"
        ],
        "default": "Photographic"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0.1,
        "maximum": 10,
        "default": 5
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          42
        ]
      },
      "image_archive_url": {
        "type": "string",
        "description": "The URL of the image archive containing the images you want to use.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/photomaker/elon.zip"
        ]
      },
      "initial_image_url": {
        "type": "string",
        "description": "Optional initial image for img2img",
        "required": false
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 20,
        "maximum": 100,
        "default": 50
      },
      "initial_image_strength": {
        "type": "number",
        "description": "How much noise to add to the latent image. O for no noise, 1 for maximum noise.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "base_pipeline": {
        "type": "string",
        "description": "The base pipeline to use for generating the image.",
        "required": false,
        "enum": [
          "photomaker",
          "photomaker-style"
        ],
        "default": "photomaker"
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"
        ]
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": ""
      }
    }
  },
  {
    "id": "fal-ai/t2v-turbo",
    "title": "T2V Turbo - Video Crafter",
    "category": "text-to-video",
    "description": "Generate short video clips from your prompts",
    "tags": [
      "turbo"
    ],
    "thumbnailUrl": "https://fal.media/files/monkey/yirvhUzF8h7DVpCoDGsdU.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/t2v-turbo",
    "documentationUrl": "https://fal.ai/models/fal-ai/t2v-turbo/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate images from",
        "required": true,
        "examples": [
          "a dog wearing vr goggles on a boat"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "The guidance scale",
        "required": false,
        "minimum": 0.1,
        "maximum": 30,
        "default": 7.5
      },
      "seed": {
        "type": null,
        "description": "The seed to use for the random number generator",
        "required": false
      },
      "export_fps": {
        "type": "integer",
        "description": "The FPS of the exported video",
        "required": false,
        "minimum": 1,
        "maximum": 24,
        "default": 8
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate",
        "required": false,
        "minimum": 16,
        "maximum": 32,
        "default": 16
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of steps to sample",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The URL to the generated video"
      }
    }
  },
  {
    "id": "fal-ai/fast-sdxl-controlnet-canny",
    "title": "ControlNet SDXL",
    "category": "text-to-image",
    "description": "Generate Images with ControlNet.",
    "tags": [
      "diffusion",
      "controlnet",
      "manipulation"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/ynzNm1f0ZoDCuOvAE9tKR.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-sdxl-controlnet-canny",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-sdxl-controlnet-canny/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "control_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": true,
        "examples": [
          "https://avatars.githubusercontent.com/u/74778219"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "enable_deep_cache": {
        "type": "boolean",
        "description": "\n            If set to true, DeepCache will be enabled. TBD\n        ",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/creative-upscaler",
    "title": "Creative Upscaler",
    "category": "image-to-image",
    "description": "Create creative upscaled images.",
    "tags": [
      "upscaling"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/creative-upscaler.webp?v=3",
    "playgroundUrl": "https://fal.ai/models/fal-ai/creative-upscaler",
    "documentationUrl": "https://fal.ai/models/fal-ai/creative-upscaler/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "shape_preservation": {
        "type": "number",
        "description": "How much to preserve the shape of the original image",
        "required": false,
        "minimum": 0,
        "maximum": 3,
        "default": 0.25
      },
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results. If no prompt is provide BLIP2 will be used to generate a prompt.",
        "required": false,
        "examples": []
      },
      "additional_embedding_url": {
        "type": "string",
        "description": "The URL to the additional embeddings to use for the upscaling. Default is None",
        "required": false
      },
      "enable_safety_checks": {
        "type": "boolean",
        "description": "\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ",
        "required": false,
        "default": true
      },
      "additional_lora_url": {
        "type": "string",
        "description": "The URL to the additional LORA model to use for the upscaling. Default is None",
        "required": false
      },
      "scale": {
        "type": "number",
        "description": "The scale of the output image. The higher the scale, the bigger the output image will be.",
        "required": false,
        "minimum": 1,
        "maximum": 5,
        "default": 2
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 16,
        "default": 7.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy",
        "examples": [
          "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy"
        ]
      },
      "skip_ccsr": {
        "type": "boolean",
        "description": "\n            If set to true, the image will not be processed by the CCSR model before\n            being processed by the creativity model.\n        ",
        "required": false,
        "default": false
      },
      "additional_lora_scale": {
        "type": "number",
        "description": "The scale of the additional LORA model to use for the upscaling. Default is 1.0",
        "required": false,
        "default": 1
      },
      "detail": {
        "type": "number",
        "description": "How much detail to add",
        "required": false,
        "minimum": 0,
        "maximum": 5,
        "default": 1
      },
      "base_model_url": {
        "type": "string",
        "description": "The URL to the base model to use for the upscaling",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The image to upscale.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/upscale/owl.png",
          "https://storage.googleapis.com/falserverless/gallery/blue-bird.jpeg"
        ]
      },
      "creativity": {
        "type": "number",
        "description": "How much the output can deviate from the original",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "override_size_limits": {
        "type": "boolean",
        "description": "\n            Allow for large uploads that could take a very long time.\n        ",
        "required": false,
        "default": false
      },
      "prompt_suffix": {
        "type": "string",
        "description": "The suffix to add to the prompt. This is useful to add a common ending to all prompts such as 'high quality' etc or embedding tokens.",
        "required": false,
        "default": " high quality, highly detailed, high resolution, sharp"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          42
        ]
      },
      "model_type": {
        "type": "string",
        "description": "The type of model to use for the upscaling. Default is SD_1_5",
        "required": false,
        "enum": [
          "SD_1_5",
          "SDXL"
        ],
        "default": "SD_1_5",
        "examples": [
          "SD_1_5",
          "SDXL"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 200,
        "default": 20
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/birefnet",
    "title": "Birefnet Background Removal",
    "category": "image-to-image",
    "description": "bilateral reference framework (BiRefNet) for high-resolution dichotomous image segmentation (DIS)",
    "tags": [
      "background removal",
      "segmentation",
      "high-res",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/birefnet.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/birefnet",
    "documentationUrl": "https://fal.ai/models/fal-ai/birefnet/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "operating_resolution": {
        "type": "string",
        "description": "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images.",
        "required": false,
        "enum": [
          "1024x1024",
          "2048x2048"
        ],
        "default": "1024x1024"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the output image",
        "required": false,
        "enum": [
          "webp",
          "png",
          "gif"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to remove background from",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/example_inputs/birefnet-input.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "model": {
        "type": "string",
        "description": "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet-DIS_ep580.pth\n            - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth\n            - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth\n        ",
        "required": false,
        "enum": [
          "General Use (Light)",
          "General Use (Heavy)",
          "Portrait"
        ],
        "default": "General Use (Light)"
      },
      "output_mask": {
        "type": "boolean",
        "description": "Whether to output the mask used to remove the background",
        "required": false,
        "default": false
      },
      "refine_foreground": {
        "type": "boolean",
        "description": "Whether to refine the foreground using the estimated mask",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Image with background removed"
      },
      "mask_image": {
        "type": null,
        "description": "Mask used to remove the background"
      }
    }
  },
  {
    "id": "fal-ai/fast-lightning-sdxl/image-to-image",
    "title": "Stable Diffusion XL Lightning",
    "category": "image-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "diffusion",
      "lightning",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/stable-diffusion-xl-lightning.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-lightning-sdxl/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-lightning-sdxl/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "preserve_aspect_ratio": {
        "type": "boolean",
        "description": "\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ",
        "required": false,
        "default": false
      },
      "crop_output": {
        "type": "boolean",
        "description": "\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ",
        "required": false,
        "default": false
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "string",
        "description": "The number of inference steps to perform.",
        "required": false,
        "enum": [
          "1",
          "2",
          "4",
          "8"
        ],
        "default": 4
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/playground-v25/inpainting",
    "title": "Playground v2.5",
    "category": "image-to-image",
    "description": "State-of-the-art open-source model in aesthetic quality",
    "tags": [
      "inpaint",
      "artistic",
      "style"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/monkey/8WXjrk5HEam79CPlQlo5T.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/playground-v25/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/playground-v25/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a tiger sitting on a park bench"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 65,
        "default": 25
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/playground-v25/image-to-image",
    "title": "Playground v2.5",
    "category": "image-to-image",
    "description": "State-of-the-art open-source model in aesthetic quality",
    "tags": [
      "artistic",
      "style"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/monkey/8WXjrk5HEam79CPlQlo5T.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/playground-v25/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/playground-v25/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 3
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 65,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-animatediff/text-to-video",
    "title": "AnimateDiff",
    "category": "text-to-video",
    "description": "Animate your ideas!",
    "tags": [
      "animation",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-animatediff-t2v.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-animatediff/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-animatediff/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the video. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "masterpiece, best quality, 1girl, solo, cherry blossoms, hanami, pink flower, white flower, spring season, wisteria, petals, flower, plum blossoms, outdoors, falling petals, white hair, black eyes",
          "panda playing a guitar, on a boat, in the ocean, high quality, high quality, ultra HD, realistic"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "fps": {
        "type": "integer",
        "description": "Number of frames per second to extract from the video.",
        "required": false,
        "minimum": 1,
        "maximum": 16,
        "default": 8
      },
      "video_size": {
        "type": null,
        "description": "The size of the video to generate.",
        "required": false,
        "default": "square"
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate for the video.",
        "required": false,
        "minimum": 1,
        "maximum": 32,
        "default": 16
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 25
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "(bad quality, worst quality:1.2), ugly faces, bad anime"
      },
      "motions": {
        "type": "array",
        "description": "The motions to apply to the video.",
        "required": false,
        "items": {
          "enum": [
            "zoom-out",
            "zoom-in",
            "pan-left",
            "pan-right",
            "tilt-up",
            "tilt-down"
          ],
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": "Generated video file."
      }
    }
  },
  {
    "id": "fal-ai/amt-interpolation",
    "title": "AMT Interpolation",
    "category": "video-to-video",
    "description": "Interpolate between video frames",
    "tags": [
      "interpolation",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/amt-interpolation.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/amt-interpolation",
    "documentationUrl": "https://fal.ai/models/fal-ai/amt-interpolation/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "video_url": {
        "type": "string",
        "description": "URL of the video to be processed",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-2.gif"
        ]
      },
      "recursive_interpolation_passes": {
        "type": "integer",
        "description": "Number of recursive interpolation passes",
        "required": false,
        "default": 2
      },
      "output_fps": {
        "type": "integer",
        "description": "Output frames per second",
        "required": false,
        "default": 24
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "Generated video"
      }
    }
  },
  {
    "id": "fal-ai/hyper-sdxl",
    "title": "Hyper SDXL",
    "category": "text-to-image",
    "description": "Hyper-charge SDXL's performance and creativity.",
    "tags": [
      "diffusion",
      "real-time"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/LM0fy_9qT_8FlKrWhR7Zt.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/hyper-sdxl",
    "documentationUrl": "https://fal.ai/models/fal-ai/hyper-sdxl/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "examples": [
          "An ethereal, awe-inspiring vista: a snowy landscape with a majestic ice sculpture illuminated by a celestial aurora."
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "num_inference_steps": {
        "type": "string",
        "description": "The number of inference steps to perform.",
        "required": false,
        "enum": [
          "1",
          "2",
          "4"
        ],
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-lightning-sdxl/inpainting",
    "title": "Stable Diffusion XL Lightning",
    "category": "image-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "diffusion",
      "lightning"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/stable-diffusion-xl-lightning.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-lightning-sdxl/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-lightning-sdxl/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a tiger sitting on a park bench"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "string",
        "description": "The number of inference steps to perform.",
        "required": false,
        "enum": [
          "1",
          "2",
          "4",
          "8"
        ],
        "default": 4
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/whisper",
    "title": "Whisper",
    "category": "speech-to-text",
    "description": "Whisper is a model for speech transcription and translation.",
    "tags": [
      "transcription",
      "translation",
      "speech"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/whisper.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/whisper",
    "documentationUrl": "https://fal.ai/models/fal-ai/whisper/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "version": {
        "type": "string",
        "description": "Version of the model to use. All of the models are the Whisper large variant.",
        "required": false,
        "enum": [
          "3"
        ],
        "default": "3"
      },
      "batch_size": {
        "type": "integer",
        "description": "",
        "required": false,
        "minimum": 1,
        "maximum": 64,
        "default": 64,
        "examples": [
          64
        ]
      },
      "language": {
        "type": "string",
        "description": "\n        Language of the audio file. If set to null, the language will be\n        automatically detected. Defaults to null.\n\n        If translate is selected as the task, the audio will be translated to\n        English, regardless of the language selected.\n        ",
        "required": false,
        "enum": [
          "af",
          "am",
          "ar",
          "as",
          "az",
          "ba",
          "be",
          "bg",
          "bn",
          "bo",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fo",
          "fr",
          "gl",
          "gu",
          "ha",
          "haw",
          "he",
          "hi",
          "hr",
          "ht",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jw",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "la",
          "lb",
          "ln",
          "lo",
          "lt",
          "lv",
          "mg",
          "mi",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "mt",
          "my",
          "ne",
          "nl",
          "nn",
          "no",
          "oc",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "sn",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "tg",
          "th",
          "tk",
          "tl",
          "tr",
          "tt",
          "uk",
          "ur",
          "uz",
          "vi",
          "yi",
          "yo",
          "zh"
        ]
      },
      "prompt": {
        "type": "string",
        "description": "Prompt to use for generation. Defaults to an empty string.",
        "required": false,
        "default": ""
      },
      "num_speakers": {
        "type": "integer",
        "description": "\n            Number of speakers in the audio file. Defaults to null.\n            If not provided, the number of speakers will be automatically\n            detected.\n        ",
        "required": false,
        "minimum": 1,
        "examples": [
          null
        ]
      },
      "task": {
        "type": "string",
        "description": "Task to perform on the audio file. Either transcribe or translate.",
        "required": false,
        "enum": [
          "transcribe",
          "translate"
        ],
        "default": "transcribe"
      },
      "chunk_level": {
        "type": "string",
        "description": "Level of the chunks to return. Either none, segment or word. `none` would imply that all of the audio will be transcribed without the timestamp tokens, we suggest to switch to `none` if you are not satisfied with the transcription quality, since it will usually improve the quality of the results. Switching to `none` will also provide minor speed ups in the transcription due to less amount of generated tokens. Notice that setting to none will produce **a single chunk with the whole transcription**.",
        "required": false,
        "enum": [
          "none",
          "segment",
          "word"
        ],
        "default": "segment"
      },
      "audio_url": {
        "type": "string",
        "description": "URL of the audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, wav or webm.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/whisper/dinner_conversation.mp3"
        ]
      },
      "diarize": {
        "type": "boolean",
        "description": "Whether to diarize the audio file. Defaults to false. Setting to true will add costs proportional to diarization inference time.",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "text": {
        "type": "string",
        "description": "Transcription of the audio file"
      },
      "inferred_languages": {
        "type": "array",
        "description": "List of languages that the audio file is inferred to be. Defaults to null.",
        "items": {
          "enum": [
            "af",
            "am",
            "ar",
            "as",
            "az",
            "ba",
            "be",
            "bg",
            "bn",
            "bo",
            "br",
            "bs",
            "ca",
            "cs",
            "cy",
            "da",
            "de",
            "el",
            "en",
            "es",
            "et",
            "eu",
            "fa",
            "fi",
            "fo",
            "fr",
            "gl",
            "gu",
            "ha",
            "haw",
            "he",
            "hi",
            "hr",
            "ht",
            "hu",
            "hy",
            "id",
            "is",
            "it",
            "ja",
            "jw",
            "ka",
            "kk",
            "km",
            "kn",
            "ko",
            "la",
            "lb",
            "ln",
            "lo",
            "lt",
            "lv",
            "mg",
            "mi",
            "mk",
            "ml",
            "mn",
            "mr",
            "ms",
            "mt",
            "my",
            "ne",
            "nl",
            "nn",
            "no",
            "oc",
            "pa",
            "pl",
            "ps",
            "pt",
            "ro",
            "ru",
            "sa",
            "sd",
            "si",
            "sk",
            "sl",
            "sn",
            "so",
            "sq",
            "sr",
            "su",
            "sv",
            "sw",
            "ta",
            "te",
            "tg",
            "th",
            "tk",
            "tl",
            "tr",
            "tt",
            "uk",
            "ur",
            "uz",
            "vi",
            "yi",
            "yo",
            "zh"
          ],
          "type": "string"
        }
      },
      "chunks": {
        "type": "array",
        "description": "Timestamp chunks of the audio file",
        "items": {
          "$ref": "#/components/schemas/WhisperChunk"
        }
      },
      "diarization_segments": {
        "type": "array",
        "description": "Speaker diarization segments of the audio file. Only present if diarization is enabled.",
        "items": {
          "$ref": "#/components/schemas/DiarizationSegment"
        }
      }
    }
  },
  {
    "id": "fal-ai/fast-lcm-diffusion/inpainting",
    "title": "Latent Consistency Models (v1.5/XL)",
    "category": "image-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "lcm",
      "diffusion",
      "turbo",
      "real-time",
      "editing"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/P322iQXlz2jOOuRFBWK-q.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-lcm-diffusion/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-lcm-diffusion/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a tiger sitting on a park bench"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1.5
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 32,
        "default": 6
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "model_name": {
        "type": "string",
        "description": "The name of the model to use.",
        "required": false,
        "enum": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5"
        ],
        "default": "stabilityai/stable-diffusion-xl-base-1.0",
        "examples": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5"
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-lcm-diffusion",
    "title": "Latent Consistency Models (v1.5/XL)",
    "category": "text-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "lcm",
      "diffusion",
      "turbo",
      "real-time"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/P322iQXlz2jOOuRFBWK-q.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-lcm-diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-lcm-diffusion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k."
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "model_name": {
        "type": "string",
        "description": "The name of the model to use.",
        "required": false,
        "enum": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5"
        ],
        "default": "stabilityai/stable-diffusion-xl-base-1.0",
        "examples": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 32,
        "default": 6
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-lcm-diffusion/image-to-image",
    "title": "Latent Consistency Models (v1.5/XL)",
    "category": "image-to-image",
    "description": "Run SDXL at the speed of light",
    "tags": [
      "lcm",
      "diffusion",
      "turbo",
      "real-time",
      "editing"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/P322iQXlz2jOOuRFBWK-q.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-lcm-diffusion/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-lcm-diffusion/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": true
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.05,
        "maximum": 1,
        "default": 0.95
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 32,
        "default": 6
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "model_name": {
        "type": "string",
        "description": "The name of the model to use.",
        "required": false,
        "enum": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5"
        ],
        "default": "stabilityai/stable-diffusion-xl-base-1.0",
        "examples": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5"
        ]
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-fooocus-sdxl",
    "title": "Fooocus",
    "category": "text-to-image",
    "description": "Fooocus extreme speed mode as a standalone app.",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-fooocus-sdxl",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-fooocus-sdxl/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k."
        ]
      },
      "enable_refiner": {
        "type": "boolean",
        "description": "If set to true, a smaller model will try to refine the output after it was processed.",
        "required": false,
        "default": true
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image.",
        "required": false,
        "default": "square_hd"
      },
      "embeddings": {
        "type": "array",
        "description": "The list of embeddings to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": true
      },
      "guidance_rescale": {
        "type": "number",
        "description": "The rescale factor for the CFG.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 2
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "jpeg"
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "safety_checker_version": {
        "type": "string",
        "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
        "required": false,
        "enum": [
          "v1",
          "v2"
        ],
        "default": "v1"
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 24,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt used for generating the image."
      },
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/any-llm",
    "title": "Any LLM",
    "category": "llm",
    "description": "Use any large language model from our selected catalogue (powered by OpenRouter)",
    "tags": [
      "chat",
      "claude",
      "gpt",
      "streaming"
    ],
    "thumbnailUrl": "https://fal.media/files/kangaroo/r7VxCWmYSAHuyZ8gow5-9_c1afdfb6e70d4ac8a4157d16369984b5.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/any-llm",
    "documentationUrl": "https://fal.ai/models/fal-ai/any-llm/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the chat completion",
        "required": true,
        "examples": [
          "What is the meaning of life?"
        ]
      },
      "system_prompt": {
        "type": "string",
        "description": "System prompt to provide context or instructions to the model",
        "required": false
      },
      "reasoning": {
        "type": "boolean",
        "description": "Should reasoning be the part of the final answer.",
        "required": false,
        "default": false
      },
      "model": {
        "type": "string",
        "description": "Name of the model to use. Premium models are charged at 10x the rate of standard models, they include: google/gemini-pro-1.5, meta-llama/llama-3.2-90b-vision-instruct, openai/gpt-4o, anthropic/claude-sonnet-4.5, google/gemini-2.5-pro, anthropic/claude-3.7-sonnet, anthropic/claude-3.5-sonnet, deepseek/deepseek-r1, anthropic/claude-3-5-haiku, openai/o3, openai/gpt-5-chat, openai/gpt-4.1.",
        "required": false,
        "enum": [
          "deepseek/deepseek-r1",
          "anthropic/claude-sonnet-4.5",
          "anthropic/claude-3.7-sonnet",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-3-5-haiku",
          "anthropic/claude-3-haiku",
          "google/gemini-pro-1.5",
          "google/gemini-flash-1.5",
          "google/gemini-flash-1.5-8b",
          "google/gemini-2.0-flash-001",
          "google/gemini-2.5-flash",
          "google/gemini-2.5-flash-lite",
          "google/gemini-2.5-pro",
          "meta-llama/llama-3.2-1b-instruct",
          "meta-llama/llama-3.2-3b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "openai/gpt-oss-120b",
          "openai/gpt-4o-mini",
          "openai/gpt-4o",
          "openai/gpt-4.1",
          "openai/o3",
          "openai/gpt-5-chat",
          "openai/gpt-5-mini",
          "openai/gpt-5-nano",
          "meta-llama/llama-4-maverick",
          "meta-llama/llama-4-scout"
        ],
        "default": "google/gemini-2.5-flash-lite",
        "examples": [
          "google/gemini-2.5-flash"
        ]
      },
      "max_tokens": {
        "type": "integer",
        "description": "This sets the upper limit for the number of tokens the model can generate in response. It won’t produce more than this limit. The maximum value is the context length minus the prompt length.",
        "required": false,
        "minimum": 1
      },
      "temperature": {
        "type": "number",
        "description": "This setting influences the variety in the model’s responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.",
        "required": false,
        "minimum": 0,
        "maximum": 2
      },
      "priority": {
        "type": "string",
        "description": "Throughput is the default and is recommended for most use cases. Latency is recommended for use cases where low latency is important.",
        "required": false,
        "enum": [
          "throughput",
          "latency"
        ],
        "default": "latency"
      }
    },
    "outputParameters": {
      "error": {
        "type": "string",
        "description": "Error message if an error occurred"
      },
      "partial": {
        "type": "boolean",
        "description": "Whether the output is partial"
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      },
      "reasoning": {
        "type": "string",
        "description": "Generated reasoning for the final answer"
      }
    }
  },
  {
    "id": "fal-ai/llava-next",
    "title": "LLaVA v1.6 34B",
    "category": "vision",
    "description": "Vision",
    "tags": [
      "multimodal",
      "vision"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/GkS_M-jVZnM3ioJCCkwhh.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/llava-next",
    "documentationUrl": "https://fal.ai/models/fal-ai/llava-next/api",
    "licenseType": "research",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to be used for the image",
        "required": true,
        "examples": [
          "Do you know who drew this painting?"
        ]
      },
      "top_p": {
        "type": "number",
        "description": "Top P for sampling",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum number of tokens to generate",
        "required": false,
        "default": 64
      },
      "temperature": {
        "type": "number",
        "description": "Temperature for sampling",
        "required": false,
        "maximum": 1,
        "default": 0.2
      },
      "image_url": {
        "type": "string",
        "description": "URL of the image to be processed",
        "required": true,
        "examples": [
          "https://llava-vl.github.io/static/images/monalisa.jpg"
        ]
      }
    },
    "outputParameters": {
      "partial": {
        "type": "boolean",
        "description": "Whether the output is partial"
      },
      "output": {
        "type": "string",
        "description": "Generated output"
      }
    }
  },
  {
    "id": "fal-ai/fast-svd-lcm",
    "title": "Stable Video Diffusion Turbo",
    "category": "image-to-video",
    "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed",
    "tags": [
      "turbo"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-svd-turbo.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-svd-lcm",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-svd-lcm/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "motion_bucket_id": {
        "type": "integer",
        "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 255,
        "default": 127
      },
      "fps": {
        "type": "integer",
        "description": "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 25,
        "default": 10
      },
      "steps": {
        "type": "integer",
        "description": "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 20,
        "default": 4
      },
      "cond_aug": {
        "type": "number",
        "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 10,
        "default": 0.02
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/svd/rocket.png",
          "https://storage.googleapis.com/falserverless/model_tests/svd/mustang.png",
          "https://storage.googleapis.com/falserverless/model_tests/svd/ship.png",
          "https://storage.googleapis.com/falserverless/model_tests/svd/rocket2.png"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        "
      },
      "video": {
        "type": null,
        "description": "The generated video file."
      }
    }
  },
  {
    "id": "fal-ai/fast-animatediff/turbo/text-to-video",
    "title": "AnimateDiff Turbo",
    "category": "text-to-video",
    "description": "Animate your ideas in lightning speed!",
    "tags": [
      "animation",
      "stylized",
      "turbo"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/fast-animatediff-t2v-turbo.webp",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-animatediff/turbo/text-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-animatediff/turbo/text-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the video. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "masterpiece, best quality, 1girl, solo, cherry blossoms, hanami, pink flower, white flower, spring season, wisteria, petals, flower, plum blossoms, outdoors, falling petals, white hair, black eyes",
          "panda playing a guitar, on a boat, in the ocean, high quality, high quality, ultra HD, realistic"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "fps": {
        "type": "integer",
        "description": "Number of frames per second to extract from the video.",
        "required": false,
        "minimum": 1,
        "maximum": 16,
        "default": 8
      },
      "video_size": {
        "type": null,
        "description": "The size of the video to generate.",
        "required": false,
        "default": "square"
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1
      },
      "num_frames": {
        "type": "integer",
        "description": "The number of frames to generate for the video.",
        "required": false,
        "minimum": 1,
        "maximum": 64,
        "default": 16
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform. 4-12 is recommended for turbo mode.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 4
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "(bad quality, worst quality:1.2), ugly faces, bad anime"
      },
      "motions": {
        "type": "array",
        "description": "The motions to apply to the video.",
        "required": false,
        "items": {
          "enum": [
            "zoom-out",
            "zoom-in",
            "pan-left",
            "pan-right",
            "tilt-up",
            "tilt-down"
          ],
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": "Generated video file."
      }
    }
  },
  {
    "id": "fal-ai/illusion-diffusion",
    "title": "Illusion Diffusion",
    "category": "text-to-image",
    "description": "Create illusions conditioned on image.",
    "tags": [
      "composition",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/illusion-diffusion.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/illusion-diffusion",
    "documentationUrl": "https://fal.ai/models/fal-ai/illusion-diffusion/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "(masterpiece:1.4), (best quality), (detailed), Medieval village scene with busy streets and castle in the distance"
        ]
      },
      "image_size": {
        "type": null,
        "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "square_hd"
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the ControlNet.",
        "required": false,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "Input image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/illusion-examples/pattern.png",
          "https://storage.googleapis.com/falserverless/illusion-examples/checkers.png",
          "https://storage.googleapis.com/falserverless/illusion-examples/checkers_mid.jpg",
          "https://storage.googleapis.com/falserverless/illusion-examples/ultra_checkers.png",
          "https://storage.googleapis.com/falserverless/illusion-examples/funky.jpeg",
          "https://storage.googleapis.com/falserverless/illusion-examples/cubes.jpeg",
          "https://storage.googleapis.com/falserverless/illusion-examples/turkey-flag.png",
          "https://storage.googleapis.com/falserverless/illusion-examples/india-flag.png",
          "https://storage.googleapis.com/falserverless/illusion-examples/usa-flag.png"
        ]
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler / sampler to use for the image denoising process.",
        "required": false,
        "enum": [
          "DPM++ Karras SDE",
          "Euler"
        ],
        "default": "Euler"
      },
      "control_guidance_start": {
        "type": "number",
        "description": "",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "maximum": 50,
        "default": 7.5
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ",
        "required": false
      },
      "control_guidance_end": {
        "type": "number",
        "description": "",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "(worst quality, poor details:1.4), lowres, (artist name, signature, watermark:1.4), bad-artist-anime, bad_prompt_version2, bad-hands-5, ng_deepnegative_v1_75t"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 80,
        "default": 40
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/imageutils/depth",
    "title": "Midas Depth Estimation",
    "category": "image-to-image",
    "description": "Create depth maps using Midas depth estimation.",
    "tags": [
      "depth",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/depth-estimation.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imageutils/depth",
    "documentationUrl": "https://fal.ai/models/fal-ai/imageutils/depth/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "bg_th": {
        "type": "number",
        "description": "bg_th",
        "required": false,
        "default": 0.1
      },
      "a": {
        "type": "number",
        "description": "a",
        "required": false,
        "default": 6.283185307179586
      },
      "depth_and_normal": {
        "type": "boolean",
        "description": "depth_and_normal",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "Input image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/remove_background/elephant.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The depth map."
      }
    }
  },
  {
    "id": "fal-ai/retoucher",
    "title": "Face Retoucher",
    "category": "image-to-image",
    "description": "Automatically retouches faces to smooth skin and remove blemishes.",
    "tags": [
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/model_tests/retoucher/Screenshot%20from%202024-02-13%2011-40-09.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/retoucher",
    "documentationUrl": "https://fal.ai/models/fal-ai/retoucher/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed for reproducibility. Different seeds will make slightly different results.",
        "required": false
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to be retouched.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/retoucher/Dalton-Meereskosmetik-Magazin-Pickelguide-Model_1.resized.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      },
      "seed": {
        "type": "integer",
        "description": "The seed used for the generation."
      }
    }
  },
  {
    "id": "fal-ai/fooocus/image-prompt",
    "title": "Fooocus Image Prompt",
    "category": "text-to-image",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fooocus/image-prompt",
    "documentationUrl": "https://fal.ai/models/fal-ai/fooocus/image-prompt/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "",
        "examples": [
          "pikachu"
        ]
      },
      "uov_image_url": {
        "type": "string",
        "description": "The image to upscale or vary.",
        "required": false
      },
      "performance": {
        "type": "string",
        "description": "\n            You can choose Speed or Quality\n        ",
        "required": false,
        "enum": [
          "Speed",
          "Quality",
          "Extreme Speed",
          "Lightning"
        ],
        "default": "Extreme Speed"
      },
      "image_prompt_3": {
        "type": null,
        "description": "",
        "required": false
      },
      "styles": {
        "type": "array",
        "description": "\n            The style to use.\n        ",
        "required": false,
        "default": [
          "Fooocus Enhance",
          "Fooocus V2",
          "Fooocus Sharp"
        ],
        "items": {
          "enum": [
            "Fooocus V2",
            "Fooocus Enhance",
            "Fooocus Sharp",
            "Fooocus Semi Realistic",
            "Fooocus Masterpiece",
            "Fooocus Photograph",
            "Fooocus Negative",
            "Fooocus Cinematic",
            "SAI 3D Model",
            "SAI Analog Film",
            "SAI Anime",
            "SAI Cinematic",
            "SAI Comic Book",
            "SAI Craft Clay",
            "SAI Digital Art",
            "SAI Enhance",
            "SAI Fantasy Art",
            "SAI Isometric",
            "SAI Line Art",
            "SAI Lowpoly",
            "SAI Neonpunk",
            "SAI Origami",
            "SAI Photographic",
            "SAI Pixel Art",
            "SAI Texture",
            "MRE Cinematic Dynamic",
            "MRE Spontaneous Picture",
            "MRE Artistic Vision",
            "MRE Dark Dream",
            "MRE Gloomy Art",
            "MRE Bad Dream",
            "MRE Underground",
            "MRE Surreal Painting",
            "MRE Dynamic Illustration",
            "MRE Undead Art",
            "MRE Elemental Art",
            "MRE Space Art",
            "MRE Ancient Illustration",
            "MRE Brave Art",
            "MRE Heroic Fantasy",
            "MRE Dark Cyberpunk",
            "MRE Lyrical Geometry",
            "MRE Sumi E Symbolic",
            "MRE Sumi E Detailed",
            "MRE Manga",
            "MRE Anime",
            "MRE Comic",
            "Ads Advertising",
            "Ads Automotive",
            "Ads Corporate",
            "Ads Fashion Editorial",
            "Ads Food Photography",
            "Ads Gourmet Food Photography",
            "Ads Luxury",
            "Ads Real Estate",
            "Ads Retail",
            "Artstyle Abstract",
            "Artstyle Abstract Expressionism",
            "Artstyle Art Deco",
            "Artstyle Art Nouveau",
            "Artstyle Constructivist",
            "Artstyle Cubist",
            "Artstyle Expressionist",
            "Artstyle Graffiti",
            "Artstyle Hyperrealism",
            "Artstyle Impressionist",
            "Artstyle Pointillism",
            "Artstyle Pop Art",
            "Artstyle Psychedelic",
            "Artstyle Renaissance",
            "Artstyle Steampunk",
            "Artstyle Surrealist",
            "Artstyle Typography",
            "Artstyle Watercolor",
            "Futuristic Biomechanical",
            "Futuristic Biomechanical Cyberpunk",
            "Futuristic Cybernetic",
            "Futuristic Cybernetic Robot",
            "Futuristic Cyberpunk Cityscape",
            "Futuristic Futuristic",
            "Futuristic Retro Cyberpunk",
            "Futuristic Retro Futurism",
            "Futuristic Sci Fi",
            "Futuristic Vaporwave",
            "Game Bubble Bobble",
            "Game Cyberpunk Game",
            "Game Fighting Game",
            "Game Gta",
            "Game Mario",
            "Game Minecraft",
            "Game Pokemon",
            "Game Retro Arcade",
            "Game Retro Game",
            "Game Rpg Fantasy Game",
            "Game Strategy Game",
            "Game Streetfighter",
            "Game Zelda",
            "Misc Architectural",
            "Misc Disco",
            "Misc Dreamscape",
            "Misc Dystopian",
            "Misc Fairy Tale",
            "Misc Gothic",
            "Misc Grunge",
            "Misc Horror",
            "Misc Kawaii",
            "Misc Lovecraftian",
            "Misc Macabre",
            "Misc Manga",
            "Misc Metropolis",
            "Misc Minimalist",
            "Misc Monochrome",
            "Misc Nautical",
            "Misc Space",
            "Misc Stained Glass",
            "Misc Techwear Fashion",
            "Misc Tribal",
            "Misc Zentangle",
            "Papercraft Collage",
            "Papercraft Flat Papercut",
            "Papercraft Kirigami",
            "Papercraft Paper Mache",
            "Papercraft Paper Quilling",
            "Papercraft Papercut Collage",
            "Papercraft Papercut Shadow Box",
            "Papercraft Stacked Papercut",
            "Papercraft Thick Layered Papercut",
            "Photo Alien",
            "Photo Film Noir",
            "Photo Glamour",
            "Photo Hdr",
            "Photo Iphone Photographic",
            "Photo Long Exposure",
            "Photo Neon Noir",
            "Photo Silhouette",
            "Photo Tilt Shift",
            "Cinematic Diva",
            "Abstract Expressionism",
            "Academia",
            "Action Figure",
            "Adorable 3D Character",
            "Adorable Kawaii",
            "Art Deco",
            "Art Nouveau",
            "Astral Aura",
            "Avant Garde",
            "Baroque",
            "Bauhaus Style Poster",
            "Blueprint Schematic Drawing",
            "Caricature",
            "Cel Shaded Art",
            "Character Design Sheet",
            "Classicism Art",
            "Color Field Painting",
            "Colored Pencil Art",
            "Conceptual Art",
            "Constructivism",
            "Cubism",
            "Dadaism",
            "Dark Fantasy",
            "Dark Moody Atmosphere",
            "Dmt Art Style",
            "Doodle Art",
            "Double Exposure",
            "Dripping Paint Splatter Art",
            "Expressionism",
            "Faded Polaroid Photo",
            "Fauvism",
            "Flat 2d Art",
            "Fortnite Art Style",
            "Futurism",
            "Glitchcore",
            "Glo Fi",
            "Googie Art Style",
            "Graffiti Art",
            "Harlem Renaissance Art",
            "High Fashion",
            "Idyllic",
            "Impressionism",
            "Infographic Drawing",
            "Ink Dripping Drawing",
            "Japanese Ink Drawing",
            "Knolling Photography",
            "Light Cheery Atmosphere",
            "Logo Design",
            "Luxurious Elegance",
            "Macro Photography",
            "Mandola Art",
            "Marker Drawing",
            "Medievalism",
            "Minimalism",
            "Neo Baroque",
            "Neo Byzantine",
            "Neo Futurism",
            "Neo Impressionism",
            "Neo Rococo",
            "Neoclassicism",
            "Op Art",
            "Ornate And Intricate",
            "Pencil Sketch Drawing",
            "Pop Art 2",
            "Rococo",
            "Silhouette Art",
            "Simple Vector Art",
            "Sketchup",
            "Steampunk 2",
            "Surrealism",
            "Suprematism",
            "Terragen",
            "Tranquil Relaxing Atmosphere",
            "Sticker Designs",
            "Vibrant Rim Light",
            "Volumetric Lighting",
            "Watercolor 2",
            "Whimsical And Playful",
            "Mk Chromolithography",
            "Mk Cross Processing Print",
            "Mk Dufaycolor Photograph",
            "Mk Herbarium",
            "Mk Punk Collage",
            "Mk Mosaic",
            "Mk Van Gogh",
            "Mk Coloring Book",
            "Mk Singer Sargent",
            "Mk Pollock",
            "Mk Basquiat",
            "Mk Andy Warhol",
            "Mk Halftone Print",
            "Mk Gond Painting",
            "Mk Albumen Print",
            "Mk Aquatint Print",
            "Mk Anthotype Print",
            "Mk Inuit Carving",
            "Mk Bromoil Print",
            "Mk Calotype Print",
            "Mk Color Sketchnote",
            "Mk Cibulak Porcelain",
            "Mk Alcohol Ink Art",
            "Mk One Line Art",
            "Mk Blacklight Paint",
            "Mk Carnival Glass",
            "Mk Cyanotype Print",
            "Mk Cross Stitching",
            "Mk Encaustic Paint",
            "Mk Embroidery",
            "Mk Gyotaku",
            "Mk Luminogram",
            "Mk Lite Brite Art",
            "Mk Mokume Gane",
            "Pebble Art",
            "Mk Palekh",
            "Mk Suminagashi",
            "Mk Scrimshaw",
            "Mk Shibori",
            "Mk Vitreous Enamel",
            "Mk Ukiyo E",
            "Mk Vintage Airline Poster",
            "Mk Vintage Travel Poster",
            "Mk Bauhaus Style",
            "Mk Afrofuturism",
            "Mk Atompunk",
            "Mk Constructivism",
            "Mk Chicano Art",
            "Mk De Stijl",
            "Mk Dayak Art",
            "Mk Fayum Portrait",
            "Mk Illuminated Manuscript",
            "Mk Kalighat Painting",
            "Mk Madhubani Painting",
            "Mk Pictorialism",
            "Mk Pichwai Painting",
            "Mk Patachitra Painting",
            "Mk Samoan Art Inspired",
            "Mk Tlingit Art",
            "Mk Adnate Style",
            "Mk Ron English Style",
            "Mk Shepard Fairey Style"
          ],
          "type": "string"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [
          {
            "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
            "scale": 0.1
          }
        ],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "image_prompt_4": {
        "type": null,
        "description": "",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 4
      },
      "sharpness": {
        "type": "number",
        "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 30,
        "default": 2
      },
      "mixing_image_prompt_and_inpaint": {
        "type": "boolean",
        "description": "Mixing Image Prompt and Inpaint",
        "required": false,
        "default": false
      },
      "outpaint_selections": {
        "type": "array",
        "description": "The directions to outpaint.",
        "required": false,
        "default": [],
        "items": {
          "enum": [
            "Left",
            "Right",
            "Top",
            "Bottom"
          ],
          "type": "string"
        }
      },
      "inpaint_image_url": {
        "type": "string",
        "description": "The image to use as a reference for inpainting.",
        "required": false
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "jpeg"
      },
      "refiner_model": {
        "type": "string",
        "description": "Refiner (SDXL or SD 1.5)",
        "required": false,
        "enum": [
          "None",
          "realisticVisionV60B1_v51VAE.safetensors"
        ],
        "default": "None"
      },
      "image_prompt_2": {
        "type": null,
        "description": "",
        "required": false
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "inpaint_mode": {
        "type": "string",
        "description": "The mode to use for inpainting.",
        "required": false,
        "enum": [
          "Inpaint or Outpaint (default)",
          "Improve Detail (face, hand, eyes, etc.)",
          "Modify Content (add objects, change background, etc.)"
        ],
        "default": "Inpaint or Outpaint (default)"
      },
      "uov_method": {
        "type": "string",
        "description": "The method to use for upscaling or varying.",
        "required": false,
        "enum": [
          "Disabled",
          "Vary (Subtle)",
          "Vary (Strong)",
          "Upscale (1.5x)",
          "Upscale (2x)",
          "Upscale (Fast 2x)"
        ],
        "default": "Disabled"
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          176400
        ]
      },
      "refiner_switch": {
        "type": "number",
        "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "mixing_image_prompt_and_vary_upscale": {
        "type": "boolean",
        "description": "Mixing Image Prompt and Vary/Upscale",
        "required": false,
        "default": false
      },
      "mask_image_url": {
        "type": "string",
        "description": "The image to use as a mask for the generated image.",
        "required": false
      },
      "image_prompt_1": {
        "type": null,
        "description": "",
        "required": true,
        "examples": [
          {
            "weight": 1,
            "stop_at": 1,
            "type": "PyraCanny",
            "image_url": "https://storage.googleapis.com/falserverless/model_tests/fooocus/Pikachu.webp"
          }
        ]
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "1024x1024"
      },
      "inpaint_additional_prompt": {
        "type": "string",
        "description": "Describe what you want to inpaint.",
        "required": false,
        "default": ""
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image file info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "The time taken for the generation process."
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/fast-animatediff/turbo/video-to-video",
    "title": "AnimateDiff Turbo",
    "category": "video-to-video",
    "description": "Re-animate your videos in lightning speed!",
    "tags": [
      "animation",
      "stylized",
      "turbo"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/animatediff-v2v.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-animatediff/turbo/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-animatediff/turbo/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "closeup of tony stark, robert downey jr, fireworks, high quality, ultra HD",
          "panda playing a guitar, on a boat, in the ocean, high quality, high quality, ultra HD, realistic"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-2.gif",
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-1.gif"
        ]
      },
      "first_n_seconds": {
        "type": "integer",
        "description": "The first N number of seconds of video to animate.",
        "required": false,
        "minimum": 2,
        "maximum": 12,
        "default": 3
      },
      "fps": {
        "type": "integer",
        "description": "Number of frames per second to extract from the video.",
        "required": false,
        "minimum": 1,
        "maximum": 16,
        "default": 8
      },
      "strength": {
        "type": "number",
        "description": "The strength of the input video in the final output.",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 0.7
      },
      "guidance_scale": {
        "type": "number",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 1
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform. 4-12 is recommended for turbo mode.",
        "required": false,
        "minimum": 1,
        "maximum": 32,
        "default": 8
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "(bad quality, worst quality:1.2), ugly faces, bad anime"
      },
      "motions": {
        "type": "array",
        "description": "The motions to apply to the video.",
        "required": false,
        "items": {
          "enum": [
            "zoom-out",
            "zoom-in",
            "pan-left",
            "pan-right",
            "tilt-up",
            "tilt-down"
          ],
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": "Generated video file."
      }
    }
  },
  {
    "id": "fal-ai/minimax/video-01",
    "title": "MiniMax (Hailuo AI) Video 01",
    "category": "text-to-video",
    "description": "Generate video clips from your prompts using MiniMax model",
    "tags": [
      "motion",
      "transformation"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/red_clouds.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/minimax/video-01",
    "documentationUrl": "https://fal.ai/models/fal-ai/minimax/video-01/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "",
        "required": true,
        "maxLength": 2000,
        "examples": [
          "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
        ]
      },
      "prompt_optimizer": {
        "type": "boolean",
        "description": "Whether to use the model's prompt optimizer",
        "required": false,
        "default": true
      }
    },
    "outputParameters": {
      "video": {
        "type": null,
        "description": "The generated video"
      }
    }
  },
  {
    "id": "fal-ai/fooocus/inpaint",
    "title": "Fooocus Inpainting",
    "category": "text-to-image",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "tags": [
      "stylized",
      "editing"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fooocus/inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/fooocus/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "",
        "examples": [
          "a cat on a bench, realistic, highly detailed, 8k"
        ]
      },
      "performance": {
        "type": "string",
        "description": "\n            You can choose Speed or Quality\n        ",
        "required": false,
        "enum": [
          "Speed",
          "Quality",
          "Extreme Speed",
          "Lightning"
        ],
        "default": "Extreme Speed"
      },
      "styles": {
        "type": "array",
        "description": "\n            The style to use.\n        ",
        "required": false,
        "default": [
          "Fooocus Enhance",
          "Fooocus V2",
          "Fooocus Sharp"
        ],
        "items": {
          "enum": [
            "Fooocus V2",
            "Fooocus Enhance",
            "Fooocus Sharp",
            "Fooocus Semi Realistic",
            "Fooocus Masterpiece",
            "Fooocus Photograph",
            "Fooocus Negative",
            "Fooocus Cinematic",
            "SAI 3D Model",
            "SAI Analog Film",
            "SAI Anime",
            "SAI Cinematic",
            "SAI Comic Book",
            "SAI Craft Clay",
            "SAI Digital Art",
            "SAI Enhance",
            "SAI Fantasy Art",
            "SAI Isometric",
            "SAI Line Art",
            "SAI Lowpoly",
            "SAI Neonpunk",
            "SAI Origami",
            "SAI Photographic",
            "SAI Pixel Art",
            "SAI Texture",
            "MRE Cinematic Dynamic",
            "MRE Spontaneous Picture",
            "MRE Artistic Vision",
            "MRE Dark Dream",
            "MRE Gloomy Art",
            "MRE Bad Dream",
            "MRE Underground",
            "MRE Surreal Painting",
            "MRE Dynamic Illustration",
            "MRE Undead Art",
            "MRE Elemental Art",
            "MRE Space Art",
            "MRE Ancient Illustration",
            "MRE Brave Art",
            "MRE Heroic Fantasy",
            "MRE Dark Cyberpunk",
            "MRE Lyrical Geometry",
            "MRE Sumi E Symbolic",
            "MRE Sumi E Detailed",
            "MRE Manga",
            "MRE Anime",
            "MRE Comic",
            "Ads Advertising",
            "Ads Automotive",
            "Ads Corporate",
            "Ads Fashion Editorial",
            "Ads Food Photography",
            "Ads Gourmet Food Photography",
            "Ads Luxury",
            "Ads Real Estate",
            "Ads Retail",
            "Artstyle Abstract",
            "Artstyle Abstract Expressionism",
            "Artstyle Art Deco",
            "Artstyle Art Nouveau",
            "Artstyle Constructivist",
            "Artstyle Cubist",
            "Artstyle Expressionist",
            "Artstyle Graffiti",
            "Artstyle Hyperrealism",
            "Artstyle Impressionist",
            "Artstyle Pointillism",
            "Artstyle Pop Art",
            "Artstyle Psychedelic",
            "Artstyle Renaissance",
            "Artstyle Steampunk",
            "Artstyle Surrealist",
            "Artstyle Typography",
            "Artstyle Watercolor",
            "Futuristic Biomechanical",
            "Futuristic Biomechanical Cyberpunk",
            "Futuristic Cybernetic",
            "Futuristic Cybernetic Robot",
            "Futuristic Cyberpunk Cityscape",
            "Futuristic Futuristic",
            "Futuristic Retro Cyberpunk",
            "Futuristic Retro Futurism",
            "Futuristic Sci Fi",
            "Futuristic Vaporwave",
            "Game Bubble Bobble",
            "Game Cyberpunk Game",
            "Game Fighting Game",
            "Game Gta",
            "Game Mario",
            "Game Minecraft",
            "Game Pokemon",
            "Game Retro Arcade",
            "Game Retro Game",
            "Game Rpg Fantasy Game",
            "Game Strategy Game",
            "Game Streetfighter",
            "Game Zelda",
            "Misc Architectural",
            "Misc Disco",
            "Misc Dreamscape",
            "Misc Dystopian",
            "Misc Fairy Tale",
            "Misc Gothic",
            "Misc Grunge",
            "Misc Horror",
            "Misc Kawaii",
            "Misc Lovecraftian",
            "Misc Macabre",
            "Misc Manga",
            "Misc Metropolis",
            "Misc Minimalist",
            "Misc Monochrome",
            "Misc Nautical",
            "Misc Space",
            "Misc Stained Glass",
            "Misc Techwear Fashion",
            "Misc Tribal",
            "Misc Zentangle",
            "Papercraft Collage",
            "Papercraft Flat Papercut",
            "Papercraft Kirigami",
            "Papercraft Paper Mache",
            "Papercraft Paper Quilling",
            "Papercraft Papercut Collage",
            "Papercraft Papercut Shadow Box",
            "Papercraft Stacked Papercut",
            "Papercraft Thick Layered Papercut",
            "Photo Alien",
            "Photo Film Noir",
            "Photo Glamour",
            "Photo Hdr",
            "Photo Iphone Photographic",
            "Photo Long Exposure",
            "Photo Neon Noir",
            "Photo Silhouette",
            "Photo Tilt Shift",
            "Cinematic Diva",
            "Abstract Expressionism",
            "Academia",
            "Action Figure",
            "Adorable 3D Character",
            "Adorable Kawaii",
            "Art Deco",
            "Art Nouveau",
            "Astral Aura",
            "Avant Garde",
            "Baroque",
            "Bauhaus Style Poster",
            "Blueprint Schematic Drawing",
            "Caricature",
            "Cel Shaded Art",
            "Character Design Sheet",
            "Classicism Art",
            "Color Field Painting",
            "Colored Pencil Art",
            "Conceptual Art",
            "Constructivism",
            "Cubism",
            "Dadaism",
            "Dark Fantasy",
            "Dark Moody Atmosphere",
            "Dmt Art Style",
            "Doodle Art",
            "Double Exposure",
            "Dripping Paint Splatter Art",
            "Expressionism",
            "Faded Polaroid Photo",
            "Fauvism",
            "Flat 2d Art",
            "Fortnite Art Style",
            "Futurism",
            "Glitchcore",
            "Glo Fi",
            "Googie Art Style",
            "Graffiti Art",
            "Harlem Renaissance Art",
            "High Fashion",
            "Idyllic",
            "Impressionism",
            "Infographic Drawing",
            "Ink Dripping Drawing",
            "Japanese Ink Drawing",
            "Knolling Photography",
            "Light Cheery Atmosphere",
            "Logo Design",
            "Luxurious Elegance",
            "Macro Photography",
            "Mandola Art",
            "Marker Drawing",
            "Medievalism",
            "Minimalism",
            "Neo Baroque",
            "Neo Byzantine",
            "Neo Futurism",
            "Neo Impressionism",
            "Neo Rococo",
            "Neoclassicism",
            "Op Art",
            "Ornate And Intricate",
            "Pencil Sketch Drawing",
            "Pop Art 2",
            "Rococo",
            "Silhouette Art",
            "Simple Vector Art",
            "Sketchup",
            "Steampunk 2",
            "Surrealism",
            "Suprematism",
            "Terragen",
            "Tranquil Relaxing Atmosphere",
            "Sticker Designs",
            "Vibrant Rim Light",
            "Volumetric Lighting",
            "Watercolor 2",
            "Whimsical And Playful",
            "Mk Chromolithography",
            "Mk Cross Processing Print",
            "Mk Dufaycolor Photograph",
            "Mk Herbarium",
            "Mk Punk Collage",
            "Mk Mosaic",
            "Mk Van Gogh",
            "Mk Coloring Book",
            "Mk Singer Sargent",
            "Mk Pollock",
            "Mk Basquiat",
            "Mk Andy Warhol",
            "Mk Halftone Print",
            "Mk Gond Painting",
            "Mk Albumen Print",
            "Mk Aquatint Print",
            "Mk Anthotype Print",
            "Mk Inuit Carving",
            "Mk Bromoil Print",
            "Mk Calotype Print",
            "Mk Color Sketchnote",
            "Mk Cibulak Porcelain",
            "Mk Alcohol Ink Art",
            "Mk One Line Art",
            "Mk Blacklight Paint",
            "Mk Carnival Glass",
            "Mk Cyanotype Print",
            "Mk Cross Stitching",
            "Mk Encaustic Paint",
            "Mk Embroidery",
            "Mk Gyotaku",
            "Mk Luminogram",
            "Mk Lite Brite Art",
            "Mk Mokume Gane",
            "Pebble Art",
            "Mk Palekh",
            "Mk Suminagashi",
            "Mk Scrimshaw",
            "Mk Shibori",
            "Mk Vitreous Enamel",
            "Mk Ukiyo E",
            "Mk Vintage Airline Poster",
            "Mk Vintage Travel Poster",
            "Mk Bauhaus Style",
            "Mk Afrofuturism",
            "Mk Atompunk",
            "Mk Constructivism",
            "Mk Chicano Art",
            "Mk De Stijl",
            "Mk Dayak Art",
            "Mk Fayum Portrait",
            "Mk Illuminated Manuscript",
            "Mk Kalighat Painting",
            "Mk Madhubani Painting",
            "Mk Pictorialism",
            "Mk Pichwai Painting",
            "Mk Patachitra Painting",
            "Mk Samoan Art Inspired",
            "Mk Tlingit Art",
            "Mk Adnate Style",
            "Mk Ron English Style",
            "Mk Shepard Fairey Style"
          ],
          "type": "string"
        }
      },
      "image_prompt_3": {
        "type": null,
        "description": "",
        "required": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [
          {
            "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
            "scale": 0.1
          }
        ],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "image_prompt_4": {
        "type": null,
        "description": "",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 4
      },
      "sharpness": {
        "type": "number",
        "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 30,
        "default": 2
      },
      "mixing_image_prompt_and_inpaint": {
        "type": "boolean",
        "description": "Mixing Image Prompt and Inpaint",
        "required": false,
        "default": false
      },
      "outpaint_selections": {
        "type": "array",
        "description": "The directions to outpaint.",
        "required": false,
        "default": [],
        "items": {
          "enum": [
            "Left",
            "Right",
            "Top",
            "Bottom"
          ],
          "type": "string"
        }
      },
      "inpaint_image_url": {
        "type": "string",
        "description": "The image to use as a reference for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "refiner_model": {
        "type": "string",
        "description": "Refiner (SDXL or SD 1.5)",
        "required": false,
        "enum": [
          "None",
          "realisticVisionV60B1_v51VAE.safetensors"
        ],
        "default": "None"
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "jpeg"
      },
      "image_prompt_2": {
        "type": null,
        "description": "",
        "required": false
      },
      "inpaint_respective_field": {
        "type": "number",
        "description": "\n            The area to inpaint. Value 0 is same as \"Only Masked\" in A1111. Value 1 is\n            same as \"Whole Image\" in A1111. Only used in inpaint, not used in outpaint.\n            (Outpaint always use 1.0)\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.618
      },
      "inpaint_mode": {
        "type": "string",
        "description": "The mode to use for inpainting.",
        "required": false,
        "enum": [
          "Inpaint or Outpaint (default)",
          "Improve Detail (face, hand, eyes, etc.)",
          "Modify Content (add objects, change background, etc.)"
        ],
        "default": "Inpaint or Outpaint (default)"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          176400
        ]
      },
      "refiner_switch": {
        "type": "number",
        "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "inpaint_disable_initial_latent": {
        "type": "boolean",
        "description": "If set to true, the initial preprocessing will be disabled.",
        "required": false,
        "default": false
      },
      "mask_image_url": {
        "type": "string",
        "description": "The image to use as a mask for the generated image.",
        "required": false,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "invert_mask": {
        "type": "boolean",
        "description": "If set to true, the mask will be inverted.",
        "required": false,
        "default": false
      },
      "image_prompt_1": {
        "type": null,
        "description": "",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "aspect_ratio": {
        "type": "string",
        "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "1024x1024"
      },
      "inpaint_additional_prompt": {
        "type": "string",
        "description": "Describe what you want to inpaint.",
        "required": false,
        "default": ""
      },
      "inpaint_strength": {
        "type": "number",
        "description": "\n            Same as the denoising strength in A1111 inpaint. Only used in inpaint, not\n            used in outpaint. (Outpaint always use 1.0)\n        ",
        "required": false,
        "maximum": 1,
        "default": 1
      },
      "override_inpaint_options": {
        "type": "boolean",
        "description": "\n            If set to true, the advanced inpaint options ('inpaint_disable_initial_latent',\n            'inpaint_engine', 'inpaint_strength', 'inpaint_respective_field',\n            'inpaint_erode_or_dilate') will be overridden.\n            Otherwise, the default values will be used.\n        ",
        "required": false,
        "default": false
      },
      "inpaint_engine": {
        "type": "string",
        "description": "Version of Fooocus inpaint model",
        "required": false,
        "enum": [
          "None",
          "v1",
          "v2.5",
          "v2.6"
        ],
        "default": "v2.6"
      },
      "inpaint_erode_or_dilate": {
        "type": "number",
        "description": "\n            Positive value will make white area in the mask larger, negative value will\n            make white area smaller. (default is 0, always process before any mask\n            invert)\n        ",
        "required": false,
        "minimum": -64,
        "maximum": 64,
        "default": 0
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image file info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "The time taken for the generation process."
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/fast-animatediff/video-to-video",
    "title": "AnimateDiff",
    "category": "video-to-video",
    "description": "Re-animate your videos!",
    "tags": [
      "animation",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/animatediff-v2v.gif",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-animatediff/video-to-video",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-animatediff/video-to-video/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "closeup of tony stark, robert downey jr, fireworks, high quality, ultra HD",
          "panda playing a guitar, on a boat, in the ocean, high quality, high quality, ultra HD, realistic"
        ]
      },
      "video_url": {
        "type": "string",
        "description": "URL of the video.",
        "required": true,
        "examples": [
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-2.gif",
          "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-1.gif"
        ]
      },
      "first_n_seconds": {
        "type": "integer",
        "description": "The first N number of seconds of video to animate.",
        "required": false,
        "minimum": 2,
        "maximum": 4,
        "default": 3
      },
      "fps": {
        "type": "integer",
        "description": "Number of frames per second to extract from the video.",
        "required": false,
        "minimum": 1,
        "maximum": 16,
        "default": 8
      },
      "strength": {
        "type": "number",
        "description": "The strength of the input video in the final output.",
        "required": false,
        "minimum": 0.1,
        "maximum": 1,
        "default": 0.7
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 50,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "(bad quality, worst quality:1.2), ugly faces, bad anime"
      },
      "motions": {
        "type": "array",
        "description": "The motions to apply to the video.",
        "required": false,
        "items": {
          "enum": [
            "zoom-out",
            "zoom-in",
            "pan-left",
            "pan-right",
            "tilt-up",
            "tilt-down"
          ],
          "type": "string"
        }
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "Seed used for generating the video."
      },
      "video": {
        "type": null,
        "description": "Generated video file."
      }
    }
  },
  {
    "id": "fal-ai/lcm",
    "title": "Latent Consistency (SDXL & SDv1.5)",
    "category": "text-to-image",
    "description": "Produce high-quality images with minimal inference steps.",
    "tags": [
      "diffusion",
      "lcm",
      "real-time"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/penguin/FS1_8TqEc1VEk8fFSes1C.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lcm",
    "documentationUrl": "https://fal.ai/models/fal-ai/lcm/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k",
          "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
        ]
      },
      "controlnet_inpaint": {
        "type": "boolean",
        "description": "\n            If set to true, the inpainting pipeline will use controlnet inpainting.\n            Only effective for inpainting pipelines.\n        ",
        "required": false,
        "default": false
      },
      "image_size": {
        "type": null,
        "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n\n            If not provided:\n            - For text-to-image generations, the default size is 512x512.\n            - For image-to-image generations, the default size is the same as the input image.\n            - For inpainting generations, the default size is the same as the input image.\n        ",
        "required": false
      },
      "enable_safety_checks": {
        "type": "boolean",
        "description": "\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ",
        "required": false,
        "default": true
      },
      "model": {
        "type": "string",
        "description": "The model to use for generating the image.",
        "required": false,
        "enum": [
          "sdxl",
          "sdv1-5"
        ],
        "default": "sdv1-5"
      },
      "lora_url": {
        "type": "string",
        "description": "\n            The url of the lora server to use for image generation.\n        ",
        "required": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 8,
        "default": 1
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "inpaint_mask_only": {
        "type": "boolean",
        "description": "\n            If set to true, the inpainting pipeline will only inpaint the provided mask\n            area. Only effective for inpainting pipelines.\n        ",
        "required": false,
        "default": false
      },
      "num_images": {
        "type": "integer",
        "description": "\n            The number of images to generate. The function will return a list of images\n            with the same prompt and negative prompt but different seeds.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "lora_scale": {
        "type": "number",
        "description": "\n            The scale of the lora server to use for image generation.\n        ",
        "required": false,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "\n        The base image to use for guiding the image generation on image-to-image\n        generations. If the either width or height of the image is larger than 1024\n        pixels, the image will be resized to 1024 pixels while keeping the aspect ratio.\n        ",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/lcm/inpaint_image.png",
          "https://storage.googleapis.com/falserverless/model_tests/lcm/beach.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "\n        The strength of the image that is passed as `image_url`. The strength\n        determines how much the generated image will be similar to the image passed as\n        `image_url`. The higher the strength the more model gets \"creative\" and\n        generates an image that's different from the initial image. A strength of 1.0\n        means that the initial image is more or less ignored and the model will try to\n        generate an image that's as close as possible to the prompt.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          42
        ]
      },
      "mask_url": {
        "type": "string",
        "description": "\n        The mask to use for guiding the image generation on image\n        inpainting. The model will focus on the mask area and try to fill it with\n        the most relevant content.\n\n        The mask must be a black and white image where the white area is the area\n        that needs to be filled and the black area is the area that should be\n        ignored.\n\n        The mask must have the same dimensions as the image passed as `image_url`.\n        ",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/lcm/inpaint_mask.png"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        "
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Number of inference steps used to generate the image. It will be the same value of the one passed in the\n            input or the default one in case none was passed.\n        "
      },
      "nsfw_content_detected": {
        "type": "array",
        "description": "\n            A list of booleans indicating whether the generated image contains any\n            potentially unsafe content. If the safety check is disabled, this field\n            will all will be false.\n        ",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/triposr",
    "title": "TripoSR",
    "category": "image-to-3d",
    "description": "State of the art Image to 3D Object generation",
    "tags": [],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/triposr.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/triposr",
    "documentationUrl": "https://fal.ai/models/fal-ai/triposr/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "mc_resolution": {
        "type": "integer",
        "description": "Resolution of the marching cubes. Above 512 is not recommended.",
        "required": false,
        "minimum": 32,
        "maximum": 1024,
        "default": 256
      },
      "do_remove_background": {
        "type": "boolean",
        "description": "Whether to remove the background from the input image.",
        "required": false,
        "default": true
      },
      "foreground_ratio": {
        "type": "number",
        "description": "Ratio of the foreground image to the original image.",
        "required": false,
        "minimum": 0.5,
        "maximum": 1,
        "default": 0.9
      },
      "output_format": {
        "type": "string",
        "description": "Output format for the 3D model.",
        "required": false,
        "enum": [
          "glb",
          "obj"
        ],
        "default": "glb"
      },
      "image_url": {
        "type": "string",
        "description": "Path for the image file to be processed.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/hamburger.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/poly_fox.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/robot.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/teapot.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/tiger_girl.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/horse.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/flamingo.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/unicorn.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/chair.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/iso_house.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/marble.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/police_woman.png",
          "https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/ea034e12a428fa848684a3f9f267b2042d298ca6/examples/captured_p.png"
        ]
      }
    },
    "outputParameters": {
      "remeshing_dir": {
        "type": null,
        "description": "Directory containing textures for the remeshed model."
      },
      "model_mesh": {
        "type": null,
        "description": "Generated 3D object file."
      },
      "timings": {
        "type": "object",
        "description": "Inference timings."
      }
    }
  },
  {
    "id": "fal-ai/diffusion-edge",
    "title": "DiffusionEdge",
    "category": "text-to-image",
    "description": "Diffusion based high quality edge detection",
    "tags": [
      "detection"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/diffusion_edge_1.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/diffusion-edge",
    "documentationUrl": "https://fal.ai/models/fal-ai/diffusion-edge/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "image_url": {
        "type": "string",
        "description": "The text prompt you would like to convert to speech.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/upscale/hamburger.png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image file info."
      }
    }
  },
  {
    "id": "fal-ai/stable-audio",
    "title": "Stable Audio Open",
    "category": "text-to-audio",
    "description": "Open source text-to-audio model.",
    "tags": [
      "music"
    ],
    "thumbnailUrl": "https://fal.media/files/rabbit/vO63ofRg1Fz5L2ByZ5wt5_d48da0f7ccfd42ac9b39ce86b3f1cbd9.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/stable-audio",
    "documentationUrl": "https://fal.ai/models/fal-ai/stable-audio/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to generate audio from",
        "required": true,
        "examples": [
          "128 BPM tech house drum loop"
        ]
      },
      "steps": {
        "type": "integer",
        "description": "The number of steps to denoise the audio for",
        "required": false,
        "minimum": 1,
        "maximum": 1000,
        "default": 100
      },
      "seconds_total": {
        "type": "integer",
        "description": "The duration of the audio clip to generate",
        "required": false,
        "minimum": 0,
        "maximum": 47,
        "default": 30
      },
      "seconds_start": {
        "type": "integer",
        "description": "The start point of the audio clip to generate",
        "required": false,
        "minimum": 0,
        "maximum": 47,
        "default": 0
      }
    },
    "outputParameters": {
      "audio_file": {
        "type": null,
        "description": "The generated audio clip"
      }
    }
  },
  {
    "id": "fal-ai/imageutils/marigold-depth",
    "title": "Marigold Depth Estimation",
    "category": "image-to-image",
    "description": "Create depth maps using Marigold depth estimation.",
    "tags": [
      "depth",
      "utility"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/marigold.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imageutils/marigold-depth",
    "documentationUrl": "https://fal.ai/models/fal-ai/imageutils/marigold-depth/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "ensemble_size": {
        "type": "integer",
        "description": "Number of predictions to average over. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 10
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of denoising steps. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.",
        "required": false,
        "minimum": 2,
        "maximum": 50,
        "default": 10
      },
      "processing_res": {
        "type": "integer",
        "description": "Maximum processing resolution. Defaults `0` which means it uses the size of the input image.",
        "required": false,
        "minimum": 0,
        "maximum": 2048,
        "default": 0
      },
      "image_url": {
        "type": "string",
        "description": "Input image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/remove_background/elephant.jpg"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The depth map."
      }
    }
  },
  {
    "id": "fal-ai/pulid",
    "title": "PuLID",
    "category": "image-to-image",
    "description": "Tuning-free ID customization.",
    "tags": [
      "editing",
      "customization",
      "personalization"
    ],
    "thumbnailUrl": "https://fal.media/files/tiger/fM1msKxGhFY7BO3J_vNiE.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/pulid",
    "documentationUrl": "https://fal.ai/models/fal-ai/pulid/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "Prompt to generate the face from",
        "required": true,
        "examples": [
          "portrait, impressionist painting, loose brushwork, vibrant color, light and shadow play"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "Number of images to generate",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_size": {
        "type": null,
        "description": "Size of the generated image",
        "required": false,
        "default": {
          "height": 1024,
          "width": 768
        }
      },
      "id_scale": {
        "type": "number",
        "description": "ID scale",
        "required": false,
        "maximum": 5,
        "default": 0.8
      },
      "mode": {
        "type": "string",
        "description": "Mode of generation",
        "required": false,
        "enum": [
          "fidelity",
          "extreme style"
        ],
        "default": "fidelity"
      },
      "id_mix": {
        "type": "boolean",
        "description": "if you want to mix two ID image, please turn this on, otherwise, turn this off",
        "required": false,
        "default": false
      },
      "guidance_scale": {
        "type": "number",
        "description": "Guidance scale",
        "required": false,
        "minimum": 1,
        "maximum": 1.5,
        "default": 1.2
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Number of steps to take",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      },
      "reference_images": {
        "type": "array",
        "description": "List of reference faces, ideally 4 images.",
        "required": true,
        "examples": [
          [
            {
              "image_url": "https://storage.googleapis.com/falserverless/pulid/img2.png"
            },
            {
              "image_url": "https://storage.googleapis.com/falserverless/pulid/img1.png"
            }
          ]
        ],
        "items": {
          "$ref": "#/components/schemas/ReferenceFace"
        }
      },
      "negative_prompt": {
        "type": "string",
        "description": "Negative prompt to generate the face from",
        "required": false,
        "default": "flaws in the eyes, flaws in the face, flaws, lowres, non-HDRi, low quality, worst quality,artifacts noise, text, watermark, glitch, deformed, mutated, ugly, disfigured, hands, low resolution, partially rendered objects,  deformed or partially rendered eyes, deformed, deformed eyeballs, cross-eyed,blurry"
      },
      "seed": {
        "type": "integer",
        "description": "Random seed for reproducibility",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "List of generated images",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "seed": {
        "type": "integer",
        "description": "Random seed used for reproducibility"
      }
    }
  },
  {
    "id": "fal-ai/fast-sdxl-controlnet-canny/inpainting",
    "title": "ControlNet SDXL",
    "category": "image-to-image",
    "description": "Generate Images with ControlNet.",
    "tags": [
      "diffusion",
      "controlnet",
      "editing",
      "manipulation"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/ynzNm1f0ZoDCuOvAE9tKR.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-sdxl-controlnet-canny/inpainting",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-sdxl-controlnet-canny/inpainting/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "control_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": true,
        "examples": [
          "https://avatars.githubusercontent.com/u/74778219"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "mask_url": {
        "type": "string",
        "description": "The URL of the mask to use for inpainting.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 65,
        "default": 25
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fast-sdxl-controlnet-canny/image-to-image",
    "title": "ControlNet SDXL",
    "category": "image-to-image",
    "description": "Generate Images with ControlNet.",
    "tags": [
      "diffusion",
      "controlnet",
      "editing",
      "manipulation"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/ynzNm1f0ZoDCuOvAE9tKR.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fast-sdxl-controlnet-canny/image-to-image",
    "documentationUrl": "https://fal.ai/models/fal-ai/fast-sdxl-controlnet-canny/image-to-image/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Ice fortress, aurora skies, polar wildlife, twilight"
        ]
      },
      "image_size": {
        "type": null,
        "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
        "required": false
      },
      "expand_prompt": {
        "type": "boolean",
        "description": "If set to true, the prompt will be expanded with additional prompts.",
        "required": false,
        "default": false
      },
      "loras": {
        "type": "array",
        "description": "The list of LoRA weights to use.",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "The number of images to generate.",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "controlnet_conditioning_scale": {
        "type": "number",
        "description": "The scale of the controlnet conditioning.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.5
      },
      "image_url": {
        "type": "string",
        "description": "The URL of the image to use as a starting point for the generation.",
        "required": true,
        "examples": [
          "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
        ]
      },
      "strength": {
        "type": "number",
        "description": "determines how much the generated image resembles the initial image",
        "required": false,
        "minimum": 0.01,
        "maximum": 1,
        "default": 0.95
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "control_image_url": {
        "type": "string",
        "description": "The URL of the control image.",
        "required": true,
        "examples": [
          "https://avatars.githubusercontent.com/u/74778219"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "The number of inference steps to perform.",
        "required": false,
        "minimum": 1,
        "maximum": 65,
        "default": 25
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/fooocus",
    "title": "Fooocus",
    "category": "text-to-image",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "tags": [
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/fooocus",
    "documentationUrl": "https://fal.ai/models/fal-ai/fooocus/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": false,
        "default": "",
        "examples": [
          "an astronaut in the jungle, cold color palette with butterflies in the background, highly detailed, 8k"
        ]
      },
      "performance": {
        "type": "string",
        "description": "\n            You can choose Speed or Quality\n        ",
        "required": false,
        "enum": [
          "Speed",
          "Quality",
          "Extreme Speed",
          "Lightning"
        ],
        "default": "Extreme Speed"
      },
      "styles": {
        "type": "array",
        "description": "\n            The style to use.\n        ",
        "required": false,
        "default": [
          "Fooocus Enhance",
          "Fooocus V2",
          "Fooocus Sharp"
        ],
        "items": {
          "enum": [
            "Fooocus V2",
            "Fooocus Enhance",
            "Fooocus Sharp",
            "Fooocus Semi Realistic",
            "Fooocus Masterpiece",
            "Fooocus Photograph",
            "Fooocus Negative",
            "Fooocus Cinematic",
            "SAI 3D Model",
            "SAI Analog Film",
            "SAI Anime",
            "SAI Cinematic",
            "SAI Comic Book",
            "SAI Craft Clay",
            "SAI Digital Art",
            "SAI Enhance",
            "SAI Fantasy Art",
            "SAI Isometric",
            "SAI Line Art",
            "SAI Lowpoly",
            "SAI Neonpunk",
            "SAI Origami",
            "SAI Photographic",
            "SAI Pixel Art",
            "SAI Texture",
            "MRE Cinematic Dynamic",
            "MRE Spontaneous Picture",
            "MRE Artistic Vision",
            "MRE Dark Dream",
            "MRE Gloomy Art",
            "MRE Bad Dream",
            "MRE Underground",
            "MRE Surreal Painting",
            "MRE Dynamic Illustration",
            "MRE Undead Art",
            "MRE Elemental Art",
            "MRE Space Art",
            "MRE Ancient Illustration",
            "MRE Brave Art",
            "MRE Heroic Fantasy",
            "MRE Dark Cyberpunk",
            "MRE Lyrical Geometry",
            "MRE Sumi E Symbolic",
            "MRE Sumi E Detailed",
            "MRE Manga",
            "MRE Anime",
            "MRE Comic",
            "Ads Advertising",
            "Ads Automotive",
            "Ads Corporate",
            "Ads Fashion Editorial",
            "Ads Food Photography",
            "Ads Gourmet Food Photography",
            "Ads Luxury",
            "Ads Real Estate",
            "Ads Retail",
            "Artstyle Abstract",
            "Artstyle Abstract Expressionism",
            "Artstyle Art Deco",
            "Artstyle Art Nouveau",
            "Artstyle Constructivist",
            "Artstyle Cubist",
            "Artstyle Expressionist",
            "Artstyle Graffiti",
            "Artstyle Hyperrealism",
            "Artstyle Impressionist",
            "Artstyle Pointillism",
            "Artstyle Pop Art",
            "Artstyle Psychedelic",
            "Artstyle Renaissance",
            "Artstyle Steampunk",
            "Artstyle Surrealist",
            "Artstyle Typography",
            "Artstyle Watercolor",
            "Futuristic Biomechanical",
            "Futuristic Biomechanical Cyberpunk",
            "Futuristic Cybernetic",
            "Futuristic Cybernetic Robot",
            "Futuristic Cyberpunk Cityscape",
            "Futuristic Futuristic",
            "Futuristic Retro Cyberpunk",
            "Futuristic Retro Futurism",
            "Futuristic Sci Fi",
            "Futuristic Vaporwave",
            "Game Bubble Bobble",
            "Game Cyberpunk Game",
            "Game Fighting Game",
            "Game Gta",
            "Game Mario",
            "Game Minecraft",
            "Game Pokemon",
            "Game Retro Arcade",
            "Game Retro Game",
            "Game Rpg Fantasy Game",
            "Game Strategy Game",
            "Game Streetfighter",
            "Game Zelda",
            "Misc Architectural",
            "Misc Disco",
            "Misc Dreamscape",
            "Misc Dystopian",
            "Misc Fairy Tale",
            "Misc Gothic",
            "Misc Grunge",
            "Misc Horror",
            "Misc Kawaii",
            "Misc Lovecraftian",
            "Misc Macabre",
            "Misc Manga",
            "Misc Metropolis",
            "Misc Minimalist",
            "Misc Monochrome",
            "Misc Nautical",
            "Misc Space",
            "Misc Stained Glass",
            "Misc Techwear Fashion",
            "Misc Tribal",
            "Misc Zentangle",
            "Papercraft Collage",
            "Papercraft Flat Papercut",
            "Papercraft Kirigami",
            "Papercraft Paper Mache",
            "Papercraft Paper Quilling",
            "Papercraft Papercut Collage",
            "Papercraft Papercut Shadow Box",
            "Papercraft Stacked Papercut",
            "Papercraft Thick Layered Papercut",
            "Photo Alien",
            "Photo Film Noir",
            "Photo Glamour",
            "Photo Hdr",
            "Photo Iphone Photographic",
            "Photo Long Exposure",
            "Photo Neon Noir",
            "Photo Silhouette",
            "Photo Tilt Shift",
            "Cinematic Diva",
            "Abstract Expressionism",
            "Academia",
            "Action Figure",
            "Adorable 3D Character",
            "Adorable Kawaii",
            "Art Deco",
            "Art Nouveau",
            "Astral Aura",
            "Avant Garde",
            "Baroque",
            "Bauhaus Style Poster",
            "Blueprint Schematic Drawing",
            "Caricature",
            "Cel Shaded Art",
            "Character Design Sheet",
            "Classicism Art",
            "Color Field Painting",
            "Colored Pencil Art",
            "Conceptual Art",
            "Constructivism",
            "Cubism",
            "Dadaism",
            "Dark Fantasy",
            "Dark Moody Atmosphere",
            "Dmt Art Style",
            "Doodle Art",
            "Double Exposure",
            "Dripping Paint Splatter Art",
            "Expressionism",
            "Faded Polaroid Photo",
            "Fauvism",
            "Flat 2d Art",
            "Fortnite Art Style",
            "Futurism",
            "Glitchcore",
            "Glo Fi",
            "Googie Art Style",
            "Graffiti Art",
            "Harlem Renaissance Art",
            "High Fashion",
            "Idyllic",
            "Impressionism",
            "Infographic Drawing",
            "Ink Dripping Drawing",
            "Japanese Ink Drawing",
            "Knolling Photography",
            "Light Cheery Atmosphere",
            "Logo Design",
            "Luxurious Elegance",
            "Macro Photography",
            "Mandola Art",
            "Marker Drawing",
            "Medievalism",
            "Minimalism",
            "Neo Baroque",
            "Neo Byzantine",
            "Neo Futurism",
            "Neo Impressionism",
            "Neo Rococo",
            "Neoclassicism",
            "Op Art",
            "Ornate And Intricate",
            "Pencil Sketch Drawing",
            "Pop Art 2",
            "Rococo",
            "Silhouette Art",
            "Simple Vector Art",
            "Sketchup",
            "Steampunk 2",
            "Surrealism",
            "Suprematism",
            "Terragen",
            "Tranquil Relaxing Atmosphere",
            "Sticker Designs",
            "Vibrant Rim Light",
            "Volumetric Lighting",
            "Watercolor 2",
            "Whimsical And Playful",
            "Mk Chromolithography",
            "Mk Cross Processing Print",
            "Mk Dufaycolor Photograph",
            "Mk Herbarium",
            "Mk Punk Collage",
            "Mk Mosaic",
            "Mk Van Gogh",
            "Mk Coloring Book",
            "Mk Singer Sargent",
            "Mk Pollock",
            "Mk Basquiat",
            "Mk Andy Warhol",
            "Mk Halftone Print",
            "Mk Gond Painting",
            "Mk Albumen Print",
            "Mk Aquatint Print",
            "Mk Anthotype Print",
            "Mk Inuit Carving",
            "Mk Bromoil Print",
            "Mk Calotype Print",
            "Mk Color Sketchnote",
            "Mk Cibulak Porcelain",
            "Mk Alcohol Ink Art",
            "Mk One Line Art",
            "Mk Blacklight Paint",
            "Mk Carnival Glass",
            "Mk Cyanotype Print",
            "Mk Cross Stitching",
            "Mk Encaustic Paint",
            "Mk Embroidery",
            "Mk Gyotaku",
            "Mk Luminogram",
            "Mk Lite Brite Art",
            "Mk Mokume Gane",
            "Pebble Art",
            "Mk Palekh",
            "Mk Suminagashi",
            "Mk Scrimshaw",
            "Mk Shibori",
            "Mk Vitreous Enamel",
            "Mk Ukiyo E",
            "Mk Vintage Airline Poster",
            "Mk Vintage Travel Poster",
            "Mk Bauhaus Style",
            "Mk Afrofuturism",
            "Mk Atompunk",
            "Mk Constructivism",
            "Mk Chicano Art",
            "Mk De Stijl",
            "Mk Dayak Art",
            "Mk Fayum Portrait",
            "Mk Illuminated Manuscript",
            "Mk Kalighat Painting",
            "Mk Madhubani Painting",
            "Mk Pictorialism",
            "Mk Pichwai Painting",
            "Mk Patachitra Painting",
            "Mk Samoan Art Inspired",
            "Mk Tlingit Art",
            "Mk Adnate Style",
            "Mk Ron English Style",
            "Mk Shepard Fairey Style"
          ],
          "type": "string"
        }
      },
      "control_type": {
        "type": "string",
        "description": "The type of image control",
        "required": false,
        "enum": [
          "ImagePrompt",
          "PyraCanny",
          "CPDS",
          "FaceSwap"
        ],
        "default": "PyraCanny",
        "examples": [
          "ImagePrompt",
          "PyraCanny",
          "CPDS",
          "FaceSwap"
        ]
      },
      "mask_image_url": {
        "type": "string",
        "description": "The image to use as a mask for the generated image.",
        "required": false
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [
          {
            "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
            "scale": 0.1
          }
        ],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to false, the safety checker will be disabled.",
        "required": false,
        "default": true
      },
      "sharpness": {
        "type": "number",
        "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 30,
        "default": 2
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 30,
        "default": 4
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        ]
      },
      "inpaint_image_url": {
        "type": "string",
        "description": "The image to use as a reference for inpainting.",
        "required": false
      },
      "mixing_image_prompt_and_inpaint": {
        "type": "boolean",
        "description": "",
        "required": false,
        "default": false
      },
      "aspect_ratio": {
        "type": "string",
        "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "1024x1024"
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 4,
        "default": 1
      },
      "output_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "png",
          "jpeg",
          "webp"
        ],
        "default": "jpeg"
      },
      "refiner_model": {
        "type": "string",
        "description": "Refiner (SDXL or SD 1.5)",
        "required": false,
        "enum": [
          "None",
          "realisticVisionV60B1_v51VAE.safetensors"
        ],
        "default": "None"
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "control_image_url": {
        "type": "string",
        "description": "The image to use as a reference for the generated image.",
        "required": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          176400
        ]
      },
      "refiner_switch": {
        "type": "number",
        "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "control_image_weight": {
        "type": "number",
        "description": "\n            The strength of the control image. Use it to control how much the generated image\n            should look like the control image.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "control_image_stop_at": {
        "type": "number",
        "description": "\n            The stop at value of the control image. Use it to control how much the generated image\n            should look like the control image.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 1
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image file info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "timings": {
        "type": "object",
        "description": "The time taken for the generation process."
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/lcm-sd15-i2i",
    "title": "Optimized Latent Consistency (SDv1.5)",
    "category": "image-to-image",
    "description": "Produce high-quality images with minimal inference steps. Optimized for 512x512 input image size.",
    "tags": [
      "diffusion",
      "lcm",
      "real-time"
    ],
    "thumbnailUrl": "https://fal-cdn.batuhan-941.workers.dev/files/kangaroo/4HI4amBAnKjvUi0SYLVwb.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lcm-sd15-i2i",
    "documentationUrl": "https://fal.ai/models/fal-ai/lcm-sd15-i2i/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "masterpiece, colorful, photo of a beach in hawaii, sun"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            The number of images to generate. The function will return a list of images\n            with the same prompt and negative prompt but different seeds.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "image_url": {
        "type": "string",
        "description": "The image to use as a base.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/lcm/beach.png"
        ]
      },
      "strength": {
        "type": "number",
        "description": "The strength of the image.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0.8
      },
      "sync_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
        "required": false,
        "default": false
      },
      "enable_safety_checks": {
        "type": "boolean",
        "description": "\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ",
        "required": false,
        "default": true
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 16,
        "default": 1
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          42
        ]
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
        "required": false,
        "default": ""
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, illustration, animation. face. male, female",
          "ugly, deformed"
        ]
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "request_id": {
        "type": "string",
        "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        "
      },
      "timings": {
        "type": "object",
        "description": ""
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Number of inference steps used to generate the image. It will be the same value of the one passed in the\n            input or the default one in case none was passed.\n        "
      },
      "nsfw_content_detected": {
        "type": "array",
        "description": "\n            A list of booleans indicating whether the generated image contains any\n            potentially unsafe content. If the safety check is disabled, this field\n            will have a false for each generated image.\n        ",
        "items": {
          "type": "boolean"
        }
      }
    }
  },
  {
    "id": "fal-ai/animatediff-sparsectrl-lcm",
    "title": "Animatediff SparseCtrl LCM",
    "category": "text-to-video",
    "description": "Animate Your Drawings with Latent Consistency Models!",
    "tags": [
      "lcm",
      "animation",
      "stylized"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/ad-sparsectrl-lcm.png",
    "playgroundUrl": "https://fal.ai/models/fal-ai/animatediff-sparsectrl-lcm",
    "documentationUrl": "https://fal.ai/models/fal-ai/animatediff-sparsectrl-lcm/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Drone footage, futuristic city at night, synthwave, vaporware, neon lights, highly detailed, masterpeice, high quality"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n        The same seed and the same prompt given to the same version of Stable\n        Diffusion will output the same image every time.\n        ",
        "required": false,
        "examples": [
          42
        ]
      },
      "controlnet_type": {
        "type": "string",
        "description": "The type of controlnet to use for generating the video. The controlnet determines how the video will be animated.",
        "required": false,
        "enum": [
          "scribble",
          "rgb"
        ],
        "default": "scribble"
      },
      "keyframe_2_index": {
        "type": "integer",
        "description": "The frame index of the third keyframe to use for the generation.",
        "required": false,
        "default": 0,
        "examples": [
          15
        ]
      },
      "keyframe_0_index": {
        "type": "integer",
        "description": "The frame index of the first keyframe to use for the generation.",
        "required": false,
        "default": 0,
        "examples": [
          0
        ]
      },
      "keyframe_1_image_url": {
        "type": "string",
        "description": "The URL of the second keyframe to use for the generation.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/scribble2/scribble_2_2.png"
        ]
      },
      "keyframe_1_index": {
        "type": "integer",
        "description": "The frame index of the second keyframe to use for the generation.",
        "required": false,
        "default": 0,
        "examples": [
          8
        ]
      },
      "guidance_scale": {
        "type": "integer",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 1
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "Increasing the amount of steps tells Stable Diffusion that it should take more steps to generate your final result which can increase the amount of detail in your image.",
        "required": false,
        "minimum": 1,
        "maximum": 12,
        "default": 4
      },
      "keyframe_2_image_url": {
        "type": "string",
        "description": "The URL of the third keyframe to use for the generation.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/scribble2/scribble_2_3.png"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to specify what you don't want.\n        ",
        "required": false,
        "default": "",
        "examples": [
          "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy"
        ]
      },
      "keyframe_0_image_url": {
        "type": "string",
        "description": "The URL of the first keyframe to use for the generation.",
        "required": false,
        "examples": [
          "https://storage.googleapis.com/falserverless/scribble2/scribble_2_1.png"
        ]
      }
    },
    "outputParameters": {
      "seed": {
        "type": "integer",
        "description": "The seed used to generate the video."
      },
      "video": {
        "type": null,
        "description": "Generated video file."
      }
    }
  },
  {
    "id": "fal-ai/inpaint",
    "title": "Inpainting sdxl and sd",
    "category": "image-to-image",
    "description": "Inpaint images with SD and SDXL",
    "tags": [
      "editing",
      "diffusion"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/inpaint.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/inpaint",
    "documentationUrl": "https://fal.ai/models/fal-ai/inpaint/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "a photo of a cat"
        ]
      },
      "image_url": {
        "type": "string",
        "description": "Input image for img2img or inpaint mode",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
        ]
      },
      "model_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the base model to generate the image.",
        "required": true,
        "examples": [
          "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5",
          "SG161222/Realistic_Vision_V2.0"
        ]
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 150,
        "default": 30
      },
      "mask_url": {
        "type": "string",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "required": true,
        "examples": [
          "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
        ]
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, painting, illustration, (worst quality, low quality, normal quality:2)",
          "nsfw, cartoon, (epicnegative:0.9)"
        ]
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false,
        "examples": [
          1234
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "The generated image files info."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      }
    }
  },
  {
    "id": "fal-ai/esrgan",
    "title": "Upscale Images",
    "category": "image-to-image",
    "description": "Upscale images by a given factor.",
    "tags": [
      "upscaling",
      "high-res"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/esrgan.webp?v=2",
    "playgroundUrl": "https://fal.ai/models/fal-ai/esrgan",
    "documentationUrl": "https://fal.ai/models/fal-ai/esrgan/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "model": {
        "type": "string",
        "description": "Model to use for upscaling",
        "required": false,
        "enum": [
          "RealESRGAN_x4plus",
          "RealESRGAN_x2plus",
          "RealESRGAN_x4plus_anime_6B",
          "RealESRGAN_x4_v3",
          "RealESRGAN_x4_wdn_v3",
          "RealESRGAN_x4_anime_v3"
        ],
        "default": "RealESRGAN_x4plus"
      },
      "face": {
        "type": "boolean",
        "description": "Upscaling a face",
        "required": false,
        "default": false
      },
      "scale": {
        "type": "number",
        "description": "Rescaling factor",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 2
      },
      "tile": {
        "type": "integer",
        "description": "Tile size. Default is 0, that is no tile. When encountering the out-of-GPU-memory issue, please specify it, e.g., 400 or 200",
        "required": false,
        "default": 0
      },
      "output_format": {
        "type": "string",
        "description": "Output image format (png or jpeg)",
        "required": false,
        "enum": [
          "png",
          "jpeg"
        ],
        "default": "png"
      },
      "image_url": {
        "type": "string",
        "description": "Url to input image",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/remove_background/elephant.jpg",
          "https://storage.googleapis.com/falserverless/gallery/blue-bird.jpeg",
          "https://storage.googleapis.com/falserverless/model_tests/upscale/image%20(8).png"
        ]
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Upscaled image"
      }
    }
  },
  {
    "id": "fal-ai/imageutils/rembg",
    "title": "Remove Background",
    "category": "image-to-image",
    "description": "Remove the background from an image.",
    "tags": [
      "background removal",
      "utility",
      "editing"
    ],
    "thumbnailUrl": "https://fal.media/files/panda/m5RPLAJZ_HnPQVRqCtiTi_cbfbb775bff3463bba8116be399e120d.jpg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/imageutils/rembg",
    "documentationUrl": "https://fal.ai/models/fal-ai/imageutils/rembg/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "sync_mode": {
        "type": "boolean",
        "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        "required": false,
        "default": false
      },
      "image_url": {
        "type": "string",
        "description": "Input image url.",
        "required": true,
        "examples": [
          "https://storage.googleapis.com/falserverless/model_tests/remove_background/elephant.jpg"
        ]
      },
      "crop_to_bbox": {
        "type": "boolean",
        "description": "\n            If set to true, the resulting image be cropped to a bounding box around the subject\n        ",
        "required": false,
        "default": false
      }
    },
    "outputParameters": {
      "image": {
        "type": null,
        "description": "Background removed image."
      }
    }
  },
  {
    "id": "fal-ai/lora",
    "title": "Stable Diffusion with LoRAs",
    "category": "text-to-image",
    "description": "Run Any Stable Diffusion model with customizable LoRA weights.",
    "tags": [
      "diffusion",
      "lora",
      "customization"
    ],
    "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/sd-loras.jpeg",
    "playgroundUrl": "https://fal.ai/models/fal-ai/lora",
    "documentationUrl": "https://fal.ai/models/fal-ai/lora/api",
    "licenseType": "commercial",
    "deprecated": false,
    "unlisted": false,
    "inputParameters": {
      "prompt": {
        "type": "string",
        "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
        "required": true,
        "examples": [
          "Photo of a european medieval 40 year old queen, silver hair, highly detailed face, detailed eyes, head shot, intricate crown, age spots, wrinkles",
          "Photo of a classic red mustang car parked in las vegas strip at night"
        ]
      },
      "image_size": {
        "type": null,
        "description": "\n            The size of the generated image. You can choose between some presets or custom height and width\n            that **must be multiples of 8**.\n        ",
        "required": false,
        "default": "square_hd"
      },
      "tile_height": {
        "type": "integer",
        "description": "The size of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 128,
        "maximum": 4096,
        "default": 4096
      },
      "embeddings": {
        "type": "array",
        "description": "\n            The embeddings to use for the image generation. Only a single embedding is supported at the moment.\n            The embeddings will be used to map the tokens in the prompt to the embedding weights.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/Embedding"
        }
      },
      "ic_light_model_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model to use for the image generation.\n        ",
        "required": false
      },
      "image_encoder_weight_name": {
        "type": "string",
        "description": "\n            The weight name of the image encoder model to use for the image generation.\n        ",
        "required": false,
        "default": "pytorch_model.bin",
        "examples": [
          "pytorch_model.bin"
        ]
      },
      "ip_adapter": {
        "type": "array",
        "description": "\n            The IP adapter to use for the image generation.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/IPAdapter"
        }
      },
      "loras": {
        "type": "array",
        "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/LoraWeight"
        }
      },
      "scheduler": {
        "type": "string",
        "description": "Scheduler / sampler to use for the image denoising process.",
        "required": false,
        "enum": [
          "DPM++ 2M",
          "DPM++ 2M Karras",
          "DPM++ 2M SDE",
          "DPM++ 2M SDE Karras",
          "Euler",
          "Euler A",
          "Euler (trailing timesteps)",
          "LCM",
          "LCM (trailing timesteps)",
          "DDIM",
          "TCD"
        ]
      },
      "sigmas": {
        "type": null,
        "description": "\n            Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.\n            If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.\n        ",
        "required": false,
        "default": {
          "method": "default",
          "array": []
        }
      },
      "guidance_scale": {
        "type": "number",
        "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 20,
        "default": 7.5
      },
      "tile_stride_width": {
        "type": "integer",
        "description": "The stride of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 2048
      },
      "debug_per_pass_latents": {
        "type": "boolean",
        "description": "If set to true, the latents will be saved for debugging per pass.",
        "required": false,
        "default": false
      },
      "timesteps": {
        "type": null,
        "description": "\n            Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.\n            If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.\n        ",
        "required": false,
        "default": {
          "method": "default",
          "array": []
        }
      },
      "image_encoder_subfolder": {
        "type": "string",
        "description": "\n            The subfolder of the image encoder model to use for the image generation.\n        ",
        "required": false,
        "examples": []
      },
      "prompt_weighting": {
        "type": "boolean",
        "description": "\n            If set to true, the prompt weighting syntax will be used.\n            Additionally, this will lift the 77 token limit by averaging embeddings.\n        ",
        "required": false,
        "default": false,
        "examples": [
          true
        ]
      },
      "variant": {
        "type": "string",
        "description": "The variant of the model to use for huggingface models, e.g. 'fp16'.",
        "required": false
      },
      "model_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the base model to generate the image.",
        "required": true,
        "examples": [
          "stabilityai/stable-diffusion-xl-base-1.0",
          "runwayml/stable-diffusion-v1-5",
          "SG161222/Realistic_Vision_V2.0"
        ]
      },
      "controlnet_guess_mode": {
        "type": "boolean",
        "description": "\n            If set to true, the controlnet will be applied to only the conditional predictions.\n        ",
        "required": false,
        "default": false
      },
      "seed": {
        "type": "integer",
        "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
        "required": false
      },
      "ic_light_model_background_image_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model background image to use for the image generation.\n            Make sure to use a background compatible with the model.\n        ",
        "required": false
      },
      "rescale_betas_snr_zero": {
        "type": "boolean",
        "description": "\n            Whether to set the rescale_betas_snr_zero option or not for the sampler\n        ",
        "required": false,
        "default": false
      },
      "tile_width": {
        "type": "integer",
        "description": "The size of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 128,
        "maximum": 4096,
        "default": 4096
      },
      "prediction_type": {
        "type": "string",
        "description": "\n            The type of prediction to use for the image generation.\n            The `epsilon` is the default.\n        ",
        "required": false,
        "enum": [
          "v_prediction",
          "epsilon"
        ],
        "default": "epsilon"
      },
      "eta": {
        "type": "number",
        "description": "The eta value to be used for the image generation.",
        "required": false,
        "minimum": 0,
        "maximum": 1,
        "default": 0
      },
      "image_encoder_path": {
        "type": "string",
        "description": "\n            The path to the image encoder model to use for the image generation.\n        ",
        "required": false
      },
      "enable_safety_checker": {
        "type": "boolean",
        "description": "If set to true, the safety checker will be enabled.",
        "required": false,
        "default": false
      },
      "negative_prompt": {
        "type": "string",
        "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
        "required": false,
        "default": "",
        "examples": [
          "cartoon, painting, illustration, worst quality, low quality, normal quality"
        ]
      },
      "image_format": {
        "type": "string",
        "description": "The format of the generated image.",
        "required": false,
        "enum": [
          "jpeg",
          "png"
        ],
        "default": "png",
        "examples": [
          "jpeg"
        ]
      },
      "num_images": {
        "type": "integer",
        "description": "\n            Number of images to generate in one request. Note that the higher the batch size,\n            the longer it will take to generate the images.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 8,
        "default": 1
      },
      "debug_latents": {
        "type": "boolean",
        "description": "If set to true, the latents will be saved for debugging.",
        "required": false,
        "default": false
      },
      "ic_light_image_url": {
        "type": "string",
        "description": "\n            The URL of the IC Light model image to use for the image generation.\n        ",
        "required": false
      },
      "unet_name": {
        "type": "string",
        "description": "URL or HuggingFace ID of the custom U-Net model to use for the image generation.",
        "required": false
      },
      "clip_skip": {
        "type": "integer",
        "description": "\n            Skips part of the image generation process, leading to slightly different results.\n            This means the image renders faster, too.\n        ",
        "required": false,
        "minimum": 0,
        "maximum": 2,
        "default": 0
      },
      "tile_stride_height": {
        "type": "integer",
        "description": "The stride of the tiles to be used for the image generation.",
        "required": false,
        "minimum": 64,
        "maximum": 2048,
        "default": 2048
      },
      "controlnets": {
        "type": "array",
        "description": "\n            The control nets to use for the image generation. You can use any number of control nets\n            and they will be applied to the image at the specified timesteps.\n        ",
        "required": false,
        "default": [],
        "items": {
          "$ref": "#/components/schemas/ControlNet"
        }
      },
      "num_inference_steps": {
        "type": "integer",
        "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
        "required": false,
        "minimum": 1,
        "maximum": 150,
        "default": 30
      }
    },
    "outputParameters": {
      "images": {
        "type": "array",
        "description": "The generated image files info.",
        "items": {
          "$ref": "#/components/schemas/Image"
        }
      },
      "debug_latents": {
        "type": null,
        "description": "The latents saved for debugging."
      },
      "seed": {
        "type": "integer",
        "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
      },
      "has_nsfw_concepts": {
        "type": "array",
        "description": "Whether the generated images contain NSFW concepts.",
        "items": {
          "type": "boolean"
        }
      },
      "debug_per_pass_latents": {
        "type": null,
        "description": "The latents saved for debugging per pass."
      }
    }
  }
]